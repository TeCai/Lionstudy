{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, BertForSequenceClassification, get_linear_schedule_with_warmup,get_polynomial_decay_schedule_with_warmup, Adafactor\n",
    "import torch.nn as nn\n",
    "import logging\n",
    "from lion_pytorch import Lion\n",
    "from torch.utils.data import DataLoader\n",
    "import GLUEforQQP\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "dataset_name = 'qqp'\n",
    "current_path = Path.cwd().parents[0]/dataset_name\n",
    "current_path.mkdir(exist_ok=True)\n",
    "# lr_list = [3e-5,3e-4,3e-3]\n",
    "# scheduler_list = ['no', 'linear']\n",
    "# optimizer_list = ['Lion', 'AdamW','AdaFactor']\n",
    "# batch_size_list = [32,64,128]\n",
    "# steps = 50*1000\n",
    "lr_list = [3e-5,3e-6,3e-7]\n",
    "scheduler_list = ['no','linear']\n",
    "optimizer_list = ['Lion']\n",
    "batch_size_list = [16,32,64]\n",
    "steps = 20*1000\n",
    "report_step = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (C:/Users/Xiang/.cache/huggingface/datasets/mariosasko___glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "095f62ad24394b478b9563ac90ecded5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Xiang\\.cache\\huggingface\\datasets\\mariosasko___glue\\cola\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-2bc0360bf4726f4f.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Xiang\\.cache\\huggingface\\datasets\\mariosasko___glue\\cola\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-77227c16e4defc4f.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Xiang\\.cache\\huggingface\\datasets\\mariosasko___glue\\cola\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-c61c89821cd722e6.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "train_dataset,_,test_dataset = GLUEforQQP.get_torch_dataset(tokenizer, \"qqp\", padding=\"max_length\", truncation=True, max_length = 128)\n",
    "\n",
    "def constant_scheduler(\n",
    "    optimizer, num_warmup_steps, num_training_steps, lr_end=1e-7, power=1.0, last_epoch=-1\n",
    "):\n",
    "    def lambda_func(step:int):\n",
    "        return 1.\n",
    "\n",
    "    return LambdaLR(optimizer, lambda_func, last_epoch)\n",
    "\n",
    "def prepare(sche, opt):\n",
    "    if sche == 'no':\n",
    "        sches = partial(constant_scheduler)\n",
    "    if sche == 'linear':\n",
    "        sches = partial(get_linear_schedule_with_warmup)\n",
    "\n",
    "    if opt == 'Lion':\n",
    "        opts = partial(Lion, betas = (0.95,0.98), weight_decay = 0.01)\n",
    "    if opt == 'AdaFactor':\n",
    "        opts = partial(Adafactor, weight_decay = 0.001, relative_step = False, scale_parameter=False)\n",
    "    if opt == 'AdamW':\n",
    "        opts = partial(torch.optim.AdamW, betas = (0.9,0.99), weight_decay = 0.001)\n",
    "\n",
    "\n",
    "    return sches, opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_log(file_name):\n",
    "    logger = logging.getLogger('train')  # 设定logger的名字\n",
    "    logger.setLevel(logging.INFO)  # 设定logger得等级\n",
    "\n",
    "    ch = logging.StreamHandler()  # 输出流的hander，用与设定logger的各种信息\n",
    "    ch.setLevel(logging.INFO)  # 设定输出hander的level\n",
    "\n",
    "    fh = logging.FileHandler(file_name, mode='a')  # 文件流的hander，输出得文件名称，以及mode设置为覆盖模式\n",
    "    fh.setLevel(logging.INFO)  # 设定文件hander得lever\n",
    "\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    ch.setFormatter(formatter)  # 两个hander设置个是，输出得信息包括，时间，信息得等级，以及message\n",
    "    fh.setFormatter(formatter)\n",
    "    logger.addHandler(fh)  # 将两个hander添加到我们声明的logger中去\n",
    "    logger.addHandler(ch)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logger = get_log('logQQP.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test_loader = DataLoader(test_dataset, shuffle = False, batch_size = 32)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dataset):\n",
    "    model.eval()\n",
    "    eval_loader = DataLoader(dataset, shuffle = False, batch_size = 32)\n",
    "    logits = []\n",
    "    labelss = []\n",
    "    with torch.no_grad():\n",
    "        for X in eval_loader:\n",
    "            batch = {k: v.to(device) for k, v in X.items()}\n",
    "            logits.append(model(**batch).logits)\n",
    "            labelss.append(batch['labels'])\n",
    "        total_test = torch.concat(logits, dim = 0)\n",
    "        _,predicted = torch.max(total_test,dim = 1)\n",
    "        real_label =torch.concat(labelss,dim=0).cpu().numpy()\n",
    "        predicted = predicted.cpu().numpy()\n",
    "        metric = matthews_corrcoef(real_label, predicted)\n",
    "        acc = np.mean(predicted==real_label)\n",
    "\n",
    "    return metric, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "2023-03-14 22:00:40,098 - INFO - Start training for: sche:linear,opt:AdamW,batchsize:32, lr:0.0003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:0, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n",
      "step: 1, loss:0.61034375\n",
      "step: 2, loss:0.66064429\n",
      "step: 3, loss:0.59298635\n",
      "step: 4, loss:0.64480376\n",
      "step: 5, loss:0.73384029\n",
      "step: 6, loss:0.67509502\n",
      "step: 7, loss:0.69257718\n",
      "step: 8, loss:0.61417204\n",
      "step: 9, loss:0.66316622\n",
      "step: 10, loss:0.68851578\n",
      "step: 11, loss:0.60336715\n",
      "step: 12, loss:0.59988374\n",
      "step: 13, loss:0.67533374\n",
      "step: 14, loss:0.66408962\n",
      "step: 15, loss:0.62408823\n",
      "step: 16, loss:0.59205210\n",
      "step: 17, loss:0.63761103\n",
      "step: 18, loss:0.41686618\n",
      "step: 19, loss:0.71400911\n",
      "step: 20, loss:0.53120041\n",
      "step: 21, loss:0.52699929\n",
      "step: 22, loss:0.60595208\n",
      "step: 23, loss:0.83450842\n",
      "step: 24, loss:0.80086613\n",
      "step: 25, loss:0.67975205\n",
      "step: 26, loss:0.72908628\n",
      "step: 27, loss:0.74066955\n",
      "step: 28, loss:0.76617563\n",
      "step: 29, loss:0.73170388\n",
      "step: 30, loss:0.67078042\n",
      "step: 31, loss:0.70432043\n",
      "step: 32, loss:0.64583963\n",
      "step: 33, loss:0.61035454\n",
      "step: 34, loss:0.64525199\n",
      "step: 35, loss:0.63614368\n",
      "step: 36, loss:0.70414037\n",
      "step: 37, loss:0.66570586\n",
      "step: 38, loss:0.65289629\n",
      "step: 39, loss:0.57237017\n",
      "step: 40, loss:0.71744508\n",
      "step: 41, loss:0.71859282\n",
      "step: 42, loss:0.63372624\n",
      "step: 43, loss:0.73863626\n",
      "step: 44, loss:0.67242581\n",
      "step: 45, loss:0.61565697\n",
      "step: 46, loss:0.72005731\n",
      "step: 47, loss:0.52344722\n",
      "step: 48, loss:0.63390750\n",
      "step: 49, loss:0.58834314\n",
      "step: 50, loss:0.56329209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:01:06,321 - INFO - step:50, matthews_corr:0.101579, Acc:69.606903%, Train: matthews_corr:0.110180, Acc:70.974155%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 51, loss:0.57804012\n",
      "step: 52, loss:0.85394692\n",
      "step: 53, loss:0.72642255\n",
      "step: 54, loss:0.68567646\n",
      "step: 55, loss:0.62700123\n",
      "step: 56, loss:0.68476170\n",
      "step: 57, loss:0.65552586\n",
      "step: 58, loss:0.66478032\n",
      "step: 59, loss:0.71052688\n",
      "step: 60, loss:0.67145962\n",
      "step: 61, loss:0.67112565\n",
      "step: 62, loss:0.66009057\n",
      "step: 63, loss:0.50286579\n",
      "step: 64, loss:0.73750454\n",
      "step: 65, loss:0.59366965\n",
      "step: 66, loss:0.60164285\n",
      "step: 67, loss:0.51865393\n",
      "step: 68, loss:0.58071423\n",
      "step: 69, loss:0.56763107\n",
      "step: 70, loss:0.40209579\n",
      "step: 71, loss:0.39870575\n",
      "step: 72, loss:0.93943655\n",
      "step: 73, loss:0.70608222\n",
      "step: 74, loss:0.61325645\n",
      "step: 75, loss:0.45463094\n",
      "step: 76, loss:0.56605810\n",
      "step: 77, loss:0.49052414\n",
      "step: 78, loss:0.52445620\n",
      "step: 79, loss:0.67862177\n",
      "step: 80, loss:0.90745294\n",
      "step: 81, loss:0.73731112\n",
      "step: 82, loss:0.73163581\n",
      "step: 83, loss:0.56999749\n",
      "step: 84, loss:0.68587291\n",
      "step: 85, loss:0.59865040\n",
      "step: 86, loss:0.75478929\n",
      "step: 87, loss:0.64339650\n",
      "step: 88, loss:0.67281717\n",
      "step: 89, loss:0.66544574\n",
      "step: 90, loss:0.64729542\n",
      "step: 91, loss:0.65951931\n",
      "step: 92, loss:0.60960579\n",
      "step: 93, loss:0.65012622\n",
      "step: 94, loss:0.54778928\n",
      "step: 95, loss:0.58451420\n",
      "step: 96, loss:0.40370843\n",
      "step: 97, loss:0.51357448\n",
      "step: 98, loss:0.78946048\n",
      "step: 99, loss:0.69343966\n",
      "step: 100, loss:0.71691674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:01:32,682 - INFO - step:100, matthews_corr:0.077385, Acc:69.319271%, Train: matthews_corr:0.161616, Acc:71.722606%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 101, loss:0.57246965\n",
      "step: 102, loss:0.48880187\n",
      "step: 103, loss:0.73199117\n",
      "step: 104, loss:0.55041295\n",
      "step: 105, loss:0.40775061\n",
      "step: 106, loss:0.45957574\n",
      "step: 107, loss:0.60251898\n",
      "step: 108, loss:0.54524636\n",
      "step: 109, loss:0.88527966\n",
      "step: 110, loss:0.53147870\n",
      "step: 111, loss:0.58402038\n",
      "step: 112, loss:0.57698965\n",
      "step: 113, loss:0.50917321\n",
      "step: 114, loss:0.55512846\n",
      "step: 115, loss:0.61449492\n",
      "step: 116, loss:0.54871160\n",
      "step: 117, loss:0.54126656\n",
      "step: 118, loss:0.45962453\n",
      "step: 119, loss:0.31199533\n",
      "step: 120, loss:0.38569903\n",
      "step: 121, loss:0.41258991\n",
      "step: 122, loss:0.87177026\n",
      "step: 123, loss:0.87777990\n",
      "step: 124, loss:0.25606275\n",
      "step: 125, loss:0.76054376\n",
      "step: 126, loss:0.86368382\n",
      "step: 127, loss:0.49826545\n",
      "step: 128, loss:0.48950353\n",
      "step: 129, loss:0.77017534\n",
      "step: 130, loss:0.61842602\n",
      "step: 131, loss:0.56866133\n",
      "step: 132, loss:0.62570763\n",
      "step: 133, loss:0.62053514\n",
      "step: 134, loss:0.67223573\n",
      "step: 135, loss:0.62410074\n",
      "step: 136, loss:0.76227146\n",
      "step: 137, loss:0.66226727\n",
      "step: 138, loss:0.69043678\n",
      "step: 139, loss:0.62433159\n",
      "step: 140, loss:0.68979603\n",
      "step: 141, loss:0.64821529\n",
      "step: 142, loss:0.60717803\n",
      "step: 143, loss:0.67317253\n",
      "step: 144, loss:0.56741500\n",
      "step: 145, loss:0.58212173\n",
      "step: 146, loss:0.51403522\n",
      "step: 147, loss:0.49215478\n",
      "step: 148, loss:0.53936762\n",
      "step: 149, loss:0.59935558\n",
      "step: 150, loss:0.49160570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:02:01,279 - INFO - step:150, matthews_corr:0.231225, Acc:71.907958%, Train: matthews_corr:0.337180, Acc:75.511636%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 151, loss:0.75990236\n",
      "step: 152, loss:0.69919151\n",
      "step: 153, loss:0.72229910\n",
      "step: 154, loss:0.50424647\n",
      "step: 155, loss:0.59423733\n",
      "step: 156, loss:0.74523729\n",
      "step: 157, loss:0.56370938\n",
      "step: 158, loss:0.42007345\n",
      "step: 159, loss:0.47169963\n",
      "step: 160, loss:0.65528888\n",
      "step: 161, loss:0.64062649\n",
      "step: 162, loss:0.43507239\n",
      "step: 163, loss:0.36616999\n",
      "step: 164, loss:0.57912058\n",
      "step: 165, loss:0.58191150\n",
      "step: 166, loss:0.81002736\n",
      "step: 167, loss:0.58974147\n",
      "step: 168, loss:0.56813550\n",
      "step: 169, loss:0.69966865\n",
      "step: 170, loss:0.75822532\n",
      "step: 171, loss:0.71127021\n",
      "step: 172, loss:0.50489545\n",
      "step: 173, loss:0.65522909\n",
      "step: 174, loss:0.65929401\n",
      "step: 175, loss:0.61203676\n",
      "step: 176, loss:0.62461454\n",
      "step: 177, loss:0.60005671\n",
      "step: 178, loss:0.47308415\n",
      "step: 179, loss:0.45762435\n",
      "step: 180, loss:0.34988260\n",
      "step: 181, loss:0.40806955\n",
      "step: 182, loss:0.42841110\n",
      "step: 183, loss:0.48613113\n",
      "step: 184, loss:0.49525598\n",
      "step: 185, loss:0.30580300\n",
      "step: 186, loss:0.65948808\n",
      "step: 187, loss:0.66414154\n",
      "step: 188, loss:1.05896103\n",
      "step: 189, loss:0.95783997\n",
      "step: 190, loss:0.54570597\n",
      "step: 191, loss:0.40411830\n",
      "step: 192, loss:0.74924976\n",
      "step: 193, loss:0.48634964\n",
      "step: 194, loss:0.56231642\n",
      "step: 195, loss:0.45073155\n",
      "step: 196, loss:0.48491859\n",
      "step: 197, loss:0.18572484\n",
      "step: 198, loss:0.63466996\n",
      "step: 199, loss:0.61985087\n",
      "step: 200, loss:0.38478872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:02:29,266 - INFO - step:200, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 201, loss:0.64220345\n",
      "step: 202, loss:0.80437589\n",
      "step: 203, loss:0.50146079\n",
      "step: 204, loss:0.64006650\n",
      "step: 205, loss:0.86980820\n",
      "step: 206, loss:0.65214813\n",
      "step: 207, loss:0.64720672\n",
      "step: 208, loss:0.53161830\n",
      "step: 209, loss:0.33679169\n",
      "step: 210, loss:0.36575001\n",
      "step: 211, loss:0.23139460\n",
      "step: 212, loss:1.53490782\n",
      "step: 213, loss:0.54873782\n",
      "step: 214, loss:0.58146715\n",
      "step: 215, loss:0.57343304\n",
      "step: 216, loss:0.23842397\n",
      "step: 217, loss:0.45657966\n",
      "step: 218, loss:0.19222789\n",
      "step: 219, loss:0.43996629\n",
      "step: 220, loss:0.87156487\n",
      "step: 221, loss:0.67198414\n",
      "step: 222, loss:0.54846799\n",
      "step: 223, loss:0.97691041\n",
      "step: 224, loss:0.41205850\n",
      "step: 225, loss:0.75064141\n",
      "step: 226, loss:0.69003451\n",
      "step: 227, loss:0.45859185\n",
      "step: 228, loss:0.56768602\n",
      "step: 229, loss:0.50884211\n",
      "step: 230, loss:0.62060481\n",
      "step: 231, loss:0.52034640\n",
      "step: 232, loss:0.54467469\n",
      "step: 233, loss:0.71472752\n",
      "step: 234, loss:0.71367753\n",
      "step: 235, loss:0.65599221\n",
      "step: 236, loss:0.71214318\n",
      "step: 237, loss:0.62416470\n",
      "step: 238, loss:0.65013349\n",
      "step: 239, loss:0.60188341\n",
      "step: 240, loss:0.67833465\n",
      "step: 241, loss:0.53697842\n",
      "step: 242, loss:0.55301630\n",
      "step: 243, loss:0.55233449\n",
      "step: 244, loss:0.55933720\n",
      "step: 245, loss:0.44559640\n",
      "step: 246, loss:0.45937455\n",
      "step: 247, loss:0.55986279\n",
      "step: 248, loss:0.61055213\n",
      "step: 249, loss:0.56622332\n",
      "step: 250, loss:0.56942219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:02:57,152 - INFO - step:250, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 251, loss:0.49382302\n",
      "step: 252, loss:0.87727284\n",
      "step: 253, loss:0.65029728\n",
      "step: 254, loss:0.71687669\n",
      "step: 255, loss:0.62954938\n",
      "step: 256, loss:0.62797397\n",
      "step: 257, loss:0.61335701\n",
      "step: 258, loss:0.59787059\n",
      "step: 259, loss:0.68069100\n",
      "step: 260, loss:0.63838923\n",
      "step: 261, loss:0.61178100\n",
      "step: 262, loss:0.59251577\n",
      "step: 263, loss:0.67114377\n",
      "step: 264, loss:0.67660129\n",
      "step: 265, loss:0.61691183\n",
      "step: 266, loss:0.57432902\n",
      "step: 267, loss:0.58626252\n",
      "step: 268, loss:0.70209682\n",
      "step: 269, loss:0.51575696\n",
      "step: 270, loss:0.60633373\n",
      "step: 271, loss:0.55404687\n",
      "step: 272, loss:0.60441107\n",
      "step: 273, loss:0.92387831\n",
      "step: 274, loss:0.72502369\n",
      "step: 275, loss:0.74544209\n",
      "step: 276, loss:0.57115984\n",
      "step: 277, loss:0.71627229\n",
      "step: 278, loss:0.71422499\n",
      "step: 279, loss:0.62724131\n",
      "step: 280, loss:0.65611893\n",
      "step: 281, loss:0.68289649\n",
      "step: 282, loss:0.67915195\n",
      "step: 283, loss:0.65214920\n",
      "step: 284, loss:0.64489114\n",
      "step: 285, loss:0.64065194\n",
      "step: 286, loss:0.47965428\n",
      "step: 287, loss:0.73749191\n",
      "step: 288, loss:0.51265222\n",
      "step: 289, loss:0.50796890\n",
      "step: 290, loss:0.63755500\n",
      "step: 291, loss:1.00140798\n",
      "step: 292, loss:0.95436889\n",
      "step: 293, loss:0.71393633\n",
      "step: 294, loss:0.77449620\n",
      "step: 295, loss:0.76714647\n",
      "step: 296, loss:0.79144001\n",
      "step: 297, loss:0.70753598\n",
      "step: 298, loss:0.63477683\n",
      "step: 299, loss:0.68718219\n",
      "step: 300, loss:0.68438739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:03:24,938 - INFO - step:300, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 301, loss:0.68008035\n",
      "step: 302, loss:0.67386025\n",
      "step: 303, loss:0.66046470\n",
      "step: 304, loss:0.69854915\n",
      "step: 305, loss:0.67187649\n",
      "step: 306, loss:0.62130535\n",
      "step: 307, loss:0.56796730\n",
      "step: 308, loss:0.73128712\n",
      "step: 309, loss:0.71820641\n",
      "step: 310, loss:0.65355206\n",
      "step: 311, loss:0.73779583\n",
      "step: 312, loss:0.69126081\n",
      "step: 313, loss:0.66892588\n",
      "step: 314, loss:0.71674371\n",
      "step: 315, loss:0.63983464\n",
      "step: 316, loss:0.64493573\n",
      "step: 317, loss:0.64159459\n",
      "step: 318, loss:0.60057968\n",
      "step: 319, loss:0.55555660\n",
      "step: 320, loss:0.87784648\n",
      "step: 321, loss:0.77597964\n",
      "step: 322, loss:0.86086172\n",
      "step: 323, loss:0.68649387\n",
      "step: 324, loss:0.67296749\n",
      "step: 325, loss:0.70326698\n",
      "step: 326, loss:0.70989645\n",
      "step: 327, loss:0.68131655\n",
      "step: 328, loss:0.68623781\n",
      "step: 329, loss:0.69974416\n",
      "step: 330, loss:0.68473589\n",
      "step: 331, loss:0.71122599\n",
      "step: 332, loss:0.68082422\n",
      "step: 333, loss:0.63971025\n",
      "step: 334, loss:0.65366024\n",
      "step: 335, loss:0.56366813\n",
      "step: 336, loss:0.61882186\n",
      "step: 337, loss:0.62384987\n",
      "step: 338, loss:0.49030638\n",
      "step: 339, loss:0.49356174\n",
      "step: 340, loss:0.67171353\n",
      "step: 341, loss:0.66190648\n",
      "step: 342, loss:0.67774510\n",
      "step: 343, loss:0.49228233\n",
      "step: 344, loss:0.41617608\n",
      "step: 345, loss:0.45491618\n",
      "step: 346, loss:0.52695715\n",
      "step: 347, loss:0.69673508\n",
      "step: 348, loss:1.08470583\n",
      "step: 349, loss:0.79821348\n",
      "step: 350, loss:0.77613974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:03:52,201 - INFO - step:350, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 351, loss:0.60373533\n",
      "step: 352, loss:0.66697794\n",
      "step: 353, loss:0.67420536\n",
      "step: 354, loss:0.69457096\n",
      "step: 355, loss:0.74964345\n",
      "step: 356, loss:0.68006003\n",
      "step: 357, loss:0.68859452\n",
      "step: 358, loss:0.68693751\n",
      "step: 359, loss:0.64894825\n",
      "step: 360, loss:0.50742054\n",
      "step: 361, loss:0.79359519\n",
      "step: 362, loss:0.55854338\n",
      "step: 363, loss:0.68019944\n",
      "step: 364, loss:0.45487618\n",
      "step: 365, loss:0.61521453\n",
      "step: 366, loss:0.96602881\n",
      "step: 367, loss:0.60163254\n",
      "step: 368, loss:0.75572485\n",
      "step: 369, loss:0.59779984\n",
      "step: 370, loss:0.57343823\n",
      "step: 371, loss:0.73002005\n",
      "step: 372, loss:0.51243776\n",
      "step: 373, loss:0.52516639\n",
      "step: 374, loss:0.50604445\n",
      "step: 375, loss:0.65019339\n",
      "step: 376, loss:0.59723973\n",
      "step: 377, loss:0.77734345\n",
      "step: 378, loss:0.54324180\n",
      "step: 379, loss:0.65900308\n",
      "step: 380, loss:0.60554445\n",
      "step: 381, loss:0.52400404\n",
      "step: 382, loss:0.56882524\n",
      "step: 383, loss:0.63634330\n",
      "step: 384, loss:0.44748661\n",
      "step: 385, loss:0.49740574\n",
      "step: 386, loss:0.45221224\n",
      "step: 387, loss:0.34728318\n",
      "step: 388, loss:0.39675099\n",
      "step: 389, loss:0.43359244\n",
      "step: 390, loss:0.85584033\n",
      "step: 391, loss:0.85475439\n",
      "step: 392, loss:0.26961866\n",
      "step: 393, loss:0.79555231\n",
      "step: 394, loss:0.88335019\n",
      "step: 395, loss:0.51839662\n",
      "step: 396, loss:0.48656636\n",
      "step: 397, loss:0.86557150\n",
      "step: 398, loss:0.62825334\n",
      "step: 399, loss:0.54678649\n",
      "step: 400, loss:0.62051111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:04:19,418 - INFO - step:400, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 401, loss:0.59086835\n",
      "step: 402, loss:0.68317789\n",
      "step: 403, loss:0.62779492\n",
      "step: 404, loss:0.73971277\n",
      "step: 405, loss:0.66084605\n",
      "step: 406, loss:0.69880176\n",
      "step: 407, loss:0.64885324\n",
      "step: 408, loss:0.71228379\n",
      "step: 409, loss:0.67436409\n",
      "step: 410, loss:0.64673990\n",
      "step: 411, loss:0.71448290\n",
      "step: 412, loss:0.61373734\n",
      "step: 413, loss:0.63509279\n",
      "step: 414, loss:0.56187326\n",
      "step: 415, loss:0.56972480\n",
      "step: 416, loss:0.56907117\n",
      "step: 417, loss:0.59896314\n",
      "step: 418, loss:0.49279600\n",
      "step: 419, loss:0.66253608\n",
      "step: 420, loss:0.64344716\n",
      "step: 421, loss:0.65479565\n",
      "step: 422, loss:0.60217327\n",
      "step: 423, loss:0.59880185\n",
      "step: 424, loss:0.67739946\n",
      "step: 425, loss:0.56477094\n",
      "step: 426, loss:0.44985306\n",
      "step: 427, loss:0.48055303\n",
      "step: 428, loss:0.66296303\n",
      "step: 429, loss:0.63679618\n",
      "step: 430, loss:0.47614726\n",
      "step: 431, loss:0.40889499\n",
      "step: 432, loss:0.55763561\n",
      "step: 433, loss:0.56663829\n",
      "step: 434, loss:0.77419233\n",
      "step: 435, loss:0.57064611\n",
      "step: 436, loss:0.56377757\n",
      "step: 437, loss:0.72187495\n",
      "step: 438, loss:0.77020842\n",
      "step: 439, loss:0.73694378\n",
      "step: 440, loss:0.49610251\n",
      "step: 441, loss:0.67616081\n",
      "step: 442, loss:0.65863776\n",
      "step: 443, loss:0.60242671\n",
      "step: 444, loss:0.61971968\n",
      "step: 445, loss:0.59884906\n",
      "step: 446, loss:0.50066900\n",
      "step: 447, loss:0.44848654\n",
      "step: 448, loss:0.35256761\n",
      "step: 449, loss:0.39447567\n",
      "step: 450, loss:0.44220304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:04:45,544 - INFO - step:450, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 451, loss:0.49516231\n",
      "step: 452, loss:0.49067742\n",
      "step: 453, loss:0.31761587\n",
      "step: 454, loss:0.64837277\n",
      "step: 455, loss:0.64970183\n",
      "step: 456, loss:1.01780772\n",
      "step: 457, loss:0.85953003\n",
      "step: 458, loss:0.49009198\n",
      "step: 459, loss:0.49417806\n",
      "step: 460, loss:0.69929445\n",
      "step: 461, loss:0.54607379\n",
      "step: 462, loss:0.57837296\n",
      "step: 463, loss:0.50390869\n",
      "step: 464, loss:0.50100315\n",
      "step: 465, loss:0.22157955\n",
      "step: 466, loss:0.61158502\n",
      "step: 467, loss:0.60681576\n",
      "step: 468, loss:0.37685001\n",
      "step: 469, loss:0.67286098\n",
      "step: 470, loss:0.96527678\n",
      "step: 471, loss:0.44769117\n",
      "step: 472, loss:0.65633285\n",
      "step: 473, loss:1.21291339\n",
      "step: 474, loss:0.56946886\n",
      "step: 475, loss:0.52603650\n",
      "step: 476, loss:0.36939228\n",
      "step: 477, loss:0.31091487\n",
      "step: 478, loss:0.40590668\n",
      "step: 479, loss:0.33943534\n",
      "step: 480, loss:1.00988090\n",
      "step: 481, loss:0.53039861\n",
      "step: 482, loss:0.55666184\n",
      "step: 483, loss:0.53804892\n",
      "step: 484, loss:0.31728274\n",
      "step: 485, loss:0.46733668\n",
      "step: 486, loss:0.31297848\n",
      "step: 487, loss:0.45750779\n",
      "step: 488, loss:0.72403383\n",
      "step: 489, loss:0.61037803\n",
      "step: 490, loss:0.53109497\n",
      "step: 491, loss:0.96331513\n",
      "step: 492, loss:0.38207287\n",
      "step: 493, loss:0.79022354\n",
      "step: 494, loss:0.73554188\n",
      "step: 495, loss:0.36963299\n",
      "step: 496, loss:0.55341202\n",
      "step: 497, loss:0.46530217\n",
      "step: 498, loss:0.63427544\n",
      "step: 499, loss:0.49984431\n",
      "step: 500, loss:0.52028233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:05:12,330 - INFO - step:500, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 501, loss:0.71652222\n",
      "step: 502, loss:0.71706909\n",
      "step: 503, loss:0.65173030\n",
      "step: 504, loss:0.71709985\n",
      "step: 505, loss:0.60029066\n",
      "step: 506, loss:0.65019798\n",
      "step: 507, loss:0.58201897\n",
      "step: 508, loss:0.67185706\n",
      "step: 509, loss:0.53004181\n",
      "step: 510, loss:0.55929488\n",
      "step: 511, loss:0.58618355\n",
      "step: 512, loss:0.55199683\n",
      "step: 513, loss:0.48453602\n",
      "step: 514, loss:0.48704669\n",
      "step: 515, loss:0.57354742\n",
      "step: 516, loss:0.60604030\n",
      "step: 517, loss:0.56138200\n",
      "step: 518, loss:0.56331950\n",
      "step: 519, loss:0.49168885\n",
      "step: 520, loss:0.84530711\n",
      "step: 521, loss:0.64512688\n",
      "step: 522, loss:0.72688627\n",
      "step: 523, loss:0.64224434\n",
      "step: 524, loss:0.65004575\n",
      "step: 525, loss:0.59530908\n",
      "step: 526, loss:0.58431464\n",
      "step: 527, loss:0.73240769\n",
      "step: 528, loss:0.66457123\n",
      "step: 529, loss:0.62569886\n",
      "step: 530, loss:0.52293479\n",
      "step: 531, loss:0.64806575\n",
      "step: 532, loss:0.69900966\n",
      "step: 533, loss:0.61816430\n",
      "step: 534, loss:0.57514352\n",
      "step: 535, loss:0.58539420\n",
      "step: 536, loss:0.71681726\n",
      "step: 537, loss:0.54633045\n",
      "step: 538, loss:0.62751210\n",
      "step: 539, loss:0.56756914\n",
      "step: 540, loss:0.59253204\n",
      "step: 541, loss:0.79164946\n",
      "step: 542, loss:0.67646980\n",
      "step: 543, loss:0.70272034\n",
      "step: 544, loss:0.58153009\n",
      "step: 545, loss:0.70053250\n",
      "step: 546, loss:0.72669536\n",
      "step: 547, loss:0.59582257\n",
      "step: 548, loss:0.63506693\n",
      "step: 549, loss:0.66210741\n",
      "step: 550, loss:0.68287444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:05:39,260 - INFO - step:550, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 551, loss:0.62571734\n",
      "step: 552, loss:0.61567515\n",
      "step: 553, loss:0.65077454\n",
      "step: 554, loss:0.44773430\n",
      "step: 555, loss:0.73373663\n",
      "step: 556, loss:0.53014708\n",
      "step: 557, loss:0.52275968\n",
      "step: 558, loss:0.62491471\n",
      "step: 559, loss:0.86011821\n",
      "step: 560, loss:0.83023363\n",
      "step: 561, loss:0.68078208\n",
      "step: 562, loss:0.72322953\n",
      "step: 563, loss:0.75172216\n",
      "step: 564, loss:0.81084347\n",
      "step: 565, loss:0.71103507\n",
      "step: 566, loss:0.59281862\n",
      "step: 567, loss:0.67612094\n",
      "step: 568, loss:0.57789463\n",
      "step: 569, loss:0.56815094\n",
      "step: 570, loss:0.61337501\n",
      "step: 571, loss:0.64803475\n",
      "step: 572, loss:0.67069125\n",
      "step: 573, loss:0.66277206\n",
      "step: 574, loss:0.63552380\n",
      "step: 575, loss:0.58605701\n",
      "step: 576, loss:0.71241689\n",
      "step: 577, loss:0.68350118\n",
      "step: 578, loss:0.64272118\n",
      "step: 579, loss:0.72398072\n",
      "step: 580, loss:0.68890458\n",
      "step: 581, loss:0.65936065\n",
      "step: 582, loss:0.76242119\n",
      "step: 583, loss:0.54214269\n",
      "step: 584, loss:0.61909920\n",
      "step: 585, loss:0.59377223\n",
      "step: 586, loss:0.57615805\n",
      "step: 587, loss:0.56755239\n",
      "step: 588, loss:0.81062347\n",
      "step: 589, loss:0.75197220\n",
      "step: 590, loss:0.79521251\n",
      "step: 591, loss:0.67669296\n",
      "step: 592, loss:0.65764320\n",
      "step: 593, loss:0.69800675\n",
      "step: 594, loss:0.73318595\n",
      "step: 595, loss:0.68111098\n",
      "step: 596, loss:0.68451500\n",
      "step: 597, loss:0.67532754\n",
      "step: 598, loss:0.68895429\n",
      "step: 599, loss:0.60390651\n",
      "step: 600, loss:0.71102393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:06:11,572 - INFO - step:600, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 601, loss:0.63378602\n",
      "step: 602, loss:0.65017080\n",
      "step: 603, loss:0.60068268\n",
      "step: 604, loss:0.63712150\n",
      "step: 605, loss:0.62660122\n",
      "step: 606, loss:0.54892433\n",
      "step: 607, loss:0.53961122\n",
      "step: 608, loss:0.64752954\n",
      "step: 609, loss:0.65229654\n",
      "step: 610, loss:0.66614562\n",
      "step: 611, loss:0.49451500\n",
      "step: 612, loss:0.42743337\n",
      "step: 613, loss:0.46058592\n",
      "step: 614, loss:0.51789302\n",
      "step: 615, loss:0.70189148\n",
      "step: 616, loss:1.05037713\n",
      "step: 617, loss:0.82514417\n",
      "step: 618, loss:0.87712455\n",
      "step: 619, loss:0.56798714\n",
      "step: 620, loss:0.75809634\n",
      "step: 621, loss:0.63621747\n",
      "step: 622, loss:0.82564342\n",
      "step: 623, loss:0.63545740\n",
      "step: 624, loss:0.72791415\n",
      "step: 625, loss:0.69422311\n",
      "step: 626, loss:0.66833699\n",
      "step: 627, loss:0.67360765\n",
      "step: 628, loss:0.64234096\n",
      "step: 629, loss:0.70510632\n",
      "step: 630, loss:0.60926777\n",
      "step: 631, loss:0.65297574\n",
      "step: 632, loss:0.52630818\n",
      "step: 633, loss:0.60687232\n",
      "step: 634, loss:0.81679523\n",
      "step: 635, loss:0.59266877\n",
      "step: 636, loss:0.71747661\n",
      "step: 637, loss:0.58114392\n",
      "step: 638, loss:0.56571364\n",
      "step: 639, loss:0.73532736\n",
      "step: 640, loss:0.48194689\n",
      "step: 641, loss:0.49546912\n",
      "step: 642, loss:0.50114447\n",
      "step: 643, loss:0.66198164\n",
      "step: 644, loss:0.60487306\n",
      "step: 645, loss:0.82983714\n",
      "step: 646, loss:0.51789486\n",
      "step: 647, loss:0.66004211\n",
      "step: 648, loss:0.63762951\n",
      "step: 649, loss:0.52400148\n",
      "step: 650, loss:0.56277263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:06:44,431 - INFO - step:650, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 651, loss:0.63979280\n",
      "step: 652, loss:0.45864102\n",
      "step: 653, loss:0.51519656\n",
      "step: 654, loss:0.46779209\n",
      "step: 655, loss:0.35657182\n",
      "step: 656, loss:0.42116904\n",
      "step: 657, loss:0.44589567\n",
      "step: 658, loss:0.80935580\n",
      "step: 659, loss:0.81718969\n",
      "step: 660, loss:0.28955925\n",
      "step: 661, loss:0.79447091\n",
      "step: 662, loss:0.84725124\n",
      "step: 663, loss:0.52413845\n",
      "step: 664, loss:0.48923969\n",
      "step: 665, loss:0.84981507\n",
      "step: 666, loss:0.63896608\n",
      "step: 667, loss:0.52543199\n",
      "step: 668, loss:0.62093890\n",
      "step: 669, loss:0.61163574\n",
      "step: 670, loss:0.69025177\n",
      "step: 671, loss:0.62804091\n",
      "step: 672, loss:0.77685803\n",
      "step: 673, loss:0.66436243\n",
      "step: 674, loss:0.72408342\n",
      "step: 675, loss:0.60608393\n",
      "step: 676, loss:0.72360849\n",
      "step: 677, loss:0.65153438\n",
      "step: 678, loss:0.59988356\n",
      "step: 679, loss:0.72031307\n",
      "step: 680, loss:0.61325723\n",
      "step: 681, loss:0.64184099\n",
      "step: 682, loss:0.60219055\n",
      "step: 683, loss:0.59821838\n",
      "step: 684, loss:0.59797847\n",
      "step: 685, loss:0.61170435\n",
      "step: 686, loss:0.53952420\n",
      "step: 687, loss:0.63832194\n",
      "step: 688, loss:0.62099528\n",
      "step: 689, loss:0.62421590\n",
      "step: 690, loss:0.59375733\n",
      "step: 691, loss:0.59125859\n",
      "step: 692, loss:0.66288370\n",
      "step: 693, loss:0.56482100\n",
      "step: 694, loss:0.42732647\n",
      "step: 695, loss:0.47511140\n",
      "step: 696, loss:0.67198324\n",
      "step: 697, loss:0.63824326\n",
      "step: 698, loss:0.45122790\n",
      "step: 699, loss:0.37189606\n",
      "step: 700, loss:0.57741708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:07:15,021 - INFO - step:700, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 701, loss:0.55644161\n",
      "step: 702, loss:0.77612287\n",
      "step: 703, loss:0.57023090\n",
      "step: 704, loss:0.56419879\n",
      "step: 705, loss:0.71223366\n",
      "step: 706, loss:0.77025962\n",
      "step: 707, loss:0.70904189\n",
      "step: 708, loss:0.49918962\n",
      "step: 709, loss:0.66930866\n",
      "step: 710, loss:0.67713803\n",
      "step: 711, loss:0.58388704\n",
      "step: 712, loss:0.59628808\n",
      "step: 713, loss:0.58816081\n",
      "step: 714, loss:0.48306254\n",
      "step: 715, loss:0.47507915\n",
      "step: 716, loss:0.40197608\n",
      "step: 717, loss:0.44840807\n",
      "step: 718, loss:0.45815319\n",
      "step: 719, loss:0.48411545\n",
      "step: 720, loss:0.48645464\n",
      "step: 721, loss:0.35512948\n",
      "step: 722, loss:0.57910240\n",
      "step: 723, loss:0.57439572\n",
      "step: 724, loss:0.86549127\n",
      "step: 725, loss:0.78318125\n",
      "step: 726, loss:0.53138816\n",
      "step: 727, loss:0.45661706\n",
      "step: 728, loss:0.69913214\n",
      "step: 729, loss:0.50571394\n",
      "step: 730, loss:0.56285167\n",
      "step: 731, loss:0.50425678\n",
      "step: 732, loss:0.50842428\n",
      "step: 733, loss:0.29288030\n",
      "step: 734, loss:0.55312800\n",
      "step: 735, loss:0.57083768\n",
      "step: 736, loss:0.38044706\n",
      "step: 737, loss:0.67216647\n",
      "step: 738, loss:0.95315868\n",
      "step: 739, loss:0.42497209\n",
      "step: 740, loss:0.66138250\n",
      "step: 741, loss:1.19844806\n",
      "step: 742, loss:0.55827016\n",
      "step: 743, loss:0.53293449\n",
      "step: 744, loss:0.38619876\n",
      "step: 745, loss:0.31420147\n",
      "step: 746, loss:0.40945923\n",
      "step: 747, loss:0.34548602\n",
      "step: 748, loss:1.04583180\n",
      "step: 749, loss:0.55246943\n",
      "step: 750, loss:0.56760716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:07:46,321 - INFO - step:750, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 751, loss:0.52203178\n",
      "step: 752, loss:0.30742243\n",
      "step: 753, loss:0.47684488\n",
      "step: 754, loss:0.31793264\n",
      "step: 755, loss:0.45090014\n",
      "step: 756, loss:0.72780758\n",
      "step: 757, loss:0.61605793\n",
      "step: 758, loss:0.51992631\n",
      "step: 759, loss:0.97908175\n",
      "step: 760, loss:0.39441368\n",
      "step: 761, loss:0.79146647\n",
      "step: 762, loss:0.73460716\n",
      "step: 763, loss:0.36748937\n",
      "step: 764, loss:0.56389159\n",
      "step: 765, loss:0.45910349\n",
      "step: 766, loss:0.64908159\n",
      "step: 767, loss:0.48410302\n",
      "step: 768, loss:0.51892030\n",
      "step: 769, loss:0.72711879\n",
      "step: 770, loss:0.73380643\n",
      "step: 771, loss:0.65896970\n",
      "step: 772, loss:0.73095179\n",
      "step: 773, loss:0.60013217\n",
      "step: 774, loss:0.64799690\n",
      "step: 775, loss:0.57541466\n",
      "step: 776, loss:0.68714422\n",
      "step: 777, loss:0.53616804\n",
      "step: 778, loss:0.57500041\n",
      "step: 779, loss:0.59869874\n",
      "step: 780, loss:0.56782705\n",
      "step: 781, loss:0.48418194\n",
      "step: 782, loss:0.50632918\n",
      "step: 783, loss:0.57061988\n",
      "step: 784, loss:0.59162974\n",
      "step: 785, loss:0.56756645\n",
      "step: 786, loss:0.57209504\n",
      "step: 787, loss:0.48370194\n",
      "step: 788, loss:0.82990605\n",
      "step: 789, loss:0.63830382\n",
      "step: 790, loss:0.71156812\n",
      "step: 791, loss:0.65432745\n",
      "step: 792, loss:0.62646675\n",
      "step: 793, loss:0.60067719\n",
      "step: 794, loss:0.60499644\n",
      "step: 795, loss:0.71333307\n",
      "step: 796, loss:0.63942611\n",
      "step: 797, loss:0.62048334\n",
      "step: 798, loss:0.53250152\n",
      "step: 799, loss:0.67433339\n",
      "step: 800, loss:0.70927465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:08:17,563 - INFO - step:800, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 801, loss:0.62695348\n",
      "step: 802, loss:0.59839505\n",
      "step: 803, loss:0.59710264\n",
      "step: 804, loss:0.68055600\n",
      "step: 805, loss:0.54276079\n",
      "step: 806, loss:0.63226610\n",
      "step: 807, loss:0.53548574\n",
      "step: 808, loss:0.59296763\n",
      "step: 809, loss:0.86522526\n",
      "step: 810, loss:0.71249896\n",
      "step: 811, loss:0.73249620\n",
      "step: 812, loss:0.57825100\n",
      "step: 813, loss:0.72268146\n",
      "step: 814, loss:0.75752020\n",
      "step: 815, loss:0.58717263\n",
      "step: 816, loss:0.61213100\n",
      "step: 817, loss:0.66286331\n",
      "step: 818, loss:0.68403441\n",
      "step: 819, loss:0.59823376\n",
      "step: 820, loss:0.62630570\n",
      "step: 821, loss:0.64558113\n",
      "step: 822, loss:0.46532986\n",
      "step: 823, loss:0.71644467\n",
      "step: 824, loss:0.54412657\n",
      "step: 825, loss:0.53163010\n",
      "step: 826, loss:0.61733758\n",
      "step: 827, loss:0.82993180\n",
      "step: 828, loss:0.80192703\n",
      "step: 829, loss:0.67459315\n",
      "step: 830, loss:0.71908683\n",
      "step: 831, loss:0.74878258\n",
      "step: 832, loss:0.79868591\n",
      "step: 833, loss:0.69715494\n",
      "step: 834, loss:0.59206045\n",
      "step: 835, loss:0.69696468\n",
      "step: 836, loss:0.56742269\n",
      "step: 837, loss:0.53495413\n",
      "step: 838, loss:0.60224247\n",
      "step: 839, loss:0.64500606\n",
      "step: 840, loss:0.69638377\n",
      "step: 841, loss:0.67389351\n",
      "step: 842, loss:0.62609327\n",
      "step: 843, loss:0.59219593\n",
      "step: 844, loss:0.70342910\n",
      "step: 845, loss:0.67614776\n",
      "step: 846, loss:0.64177102\n",
      "step: 847, loss:0.72850800\n",
      "step: 848, loss:0.67440414\n",
      "step: 849, loss:0.65882748\n",
      "step: 850, loss:0.73442650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:08:46,940 - INFO - step:850, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 851, loss:0.56127620\n",
      "step: 852, loss:0.61382246\n",
      "step: 853, loss:0.60998136\n",
      "step: 854, loss:0.58763301\n",
      "step: 855, loss:0.56680799\n",
      "step: 856, loss:0.80015367\n",
      "step: 857, loss:0.71895152\n",
      "step: 858, loss:0.77643138\n",
      "step: 859, loss:0.66047680\n",
      "step: 860, loss:0.66990387\n",
      "step: 861, loss:0.70097268\n",
      "step: 862, loss:0.72242022\n",
      "step: 863, loss:0.68162280\n",
      "step: 864, loss:0.68754482\n",
      "step: 865, loss:0.67072606\n",
      "step: 866, loss:0.67864776\n",
      "step: 867, loss:0.57062614\n",
      "step: 868, loss:0.70897567\n",
      "step: 869, loss:0.62368286\n",
      "step: 870, loss:0.65429467\n",
      "step: 871, loss:0.59115905\n",
      "step: 872, loss:0.63669091\n",
      "step: 873, loss:0.62677014\n",
      "step: 874, loss:0.54671109\n",
      "step: 875, loss:0.55188340\n",
      "step: 876, loss:0.64735073\n",
      "step: 877, loss:0.64651591\n",
      "step: 878, loss:0.64268762\n",
      "step: 879, loss:0.51457167\n",
      "step: 880, loss:0.45382467\n",
      "step: 881, loss:0.48266545\n",
      "step: 882, loss:0.53746265\n",
      "step: 883, loss:0.67931390\n",
      "step: 884, loss:0.95545995\n",
      "step: 885, loss:0.79267758\n",
      "step: 886, loss:0.83977413\n",
      "step: 887, loss:0.56621718\n",
      "step: 888, loss:0.74892497\n",
      "step: 889, loss:0.63453120\n",
      "step: 890, loss:0.84061480\n",
      "step: 891, loss:0.66741014\n",
      "step: 892, loss:0.73191184\n",
      "step: 893, loss:0.71113414\n",
      "step: 894, loss:0.61127406\n",
      "step: 895, loss:0.63799423\n",
      "step: 896, loss:0.59086221\n",
      "step: 897, loss:0.70949298\n",
      "step: 898, loss:0.59927189\n",
      "step: 899, loss:0.64144415\n",
      "step: 900, loss:0.52604997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:09:16,705 - INFO - step:900, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 901, loss:0.60294569\n",
      "step: 902, loss:0.81081140\n",
      "step: 903, loss:0.59185696\n",
      "step: 904, loss:0.70508409\n",
      "step: 905, loss:0.59013563\n",
      "step: 906, loss:0.56481880\n",
      "step: 907, loss:0.73120427\n",
      "step: 908, loss:0.48660162\n",
      "step: 909, loss:0.48367944\n",
      "step: 910, loss:0.48693419\n",
      "step: 911, loss:0.64667654\n",
      "step: 912, loss:0.59021837\n",
      "step: 913, loss:0.81855601\n",
      "step: 914, loss:0.54484087\n",
      "step: 915, loss:0.65392065\n",
      "step: 916, loss:0.62506384\n",
      "step: 917, loss:0.51312524\n",
      "step: 918, loss:0.58031619\n",
      "step: 919, loss:0.66511679\n",
      "step: 920, loss:0.45399675\n",
      "step: 921, loss:0.50683784\n",
      "step: 922, loss:0.47513428\n",
      "step: 923, loss:0.36858398\n",
      "step: 924, loss:0.42290384\n",
      "step: 925, loss:0.43611342\n",
      "step: 926, loss:0.77976227\n",
      "step: 927, loss:0.80515999\n",
      "step: 928, loss:0.30335042\n",
      "step: 929, loss:0.75153685\n",
      "step: 930, loss:0.84058505\n",
      "step: 931, loss:0.52486342\n",
      "step: 932, loss:0.48689672\n",
      "step: 933, loss:0.88533026\n",
      "step: 934, loss:0.63665485\n",
      "step: 935, loss:0.52518749\n",
      "step: 936, loss:0.63082486\n",
      "step: 937, loss:0.59628808\n",
      "step: 938, loss:0.70888287\n",
      "step: 939, loss:0.61554098\n",
      "step: 940, loss:0.80832845\n",
      "step: 941, loss:0.66318160\n",
      "step: 942, loss:0.74016738\n",
      "step: 943, loss:0.58742708\n",
      "step: 944, loss:0.74159932\n",
      "step: 945, loss:0.65144020\n",
      "step: 946, loss:0.58780664\n",
      "step: 947, loss:0.73542821\n",
      "step: 948, loss:0.59813124\n",
      "step: 949, loss:0.64042473\n",
      "step: 950, loss:0.59177661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:09:42,309 - INFO - step:950, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 951, loss:0.60186577\n",
      "step: 952, loss:0.60398847\n",
      "step: 953, loss:0.61289287\n",
      "step: 954, loss:0.55197400\n",
      "step: 955, loss:0.64404184\n",
      "step: 956, loss:0.62124997\n",
      "step: 957, loss:0.62048250\n",
      "step: 958, loss:0.59243131\n",
      "step: 959, loss:0.59102505\n",
      "step: 960, loss:0.62241894\n",
      "step: 961, loss:0.55465776\n",
      "step: 962, loss:0.45701888\n",
      "step: 963, loss:0.44275904\n",
      "step: 964, loss:0.66615611\n",
      "step: 965, loss:0.61651486\n",
      "step: 966, loss:0.46604964\n",
      "step: 967, loss:0.38953102\n",
      "step: 968, loss:0.56629133\n",
      "step: 969, loss:0.56672126\n",
      "step: 970, loss:0.77839160\n",
      "step: 971, loss:0.56153107\n",
      "step: 972, loss:0.58392143\n",
      "step: 973, loss:0.69689626\n",
      "step: 974, loss:0.77917057\n",
      "step: 975, loss:0.73369396\n",
      "step: 976, loss:0.48194277\n",
      "step: 977, loss:0.68648434\n",
      "step: 978, loss:0.66021127\n",
      "step: 979, loss:0.60349083\n",
      "step: 980, loss:0.58677799\n",
      "step: 981, loss:0.58946276\n",
      "step: 982, loss:0.54501659\n",
      "step: 983, loss:0.50302100\n",
      "step: 984, loss:0.41752273\n",
      "step: 985, loss:0.46675962\n",
      "step: 986, loss:0.47111836\n",
      "step: 987, loss:0.50133991\n",
      "step: 988, loss:0.48950291\n",
      "step: 989, loss:0.37588415\n",
      "step: 990, loss:0.57162338\n",
      "step: 991, loss:0.56303531\n",
      "step: 992, loss:0.82401687\n",
      "step: 993, loss:0.76814556\n",
      "step: 994, loss:0.53036582\n",
      "step: 995, loss:0.42734981\n",
      "step: 996, loss:0.72707045\n",
      "step: 997, loss:0.44266179\n",
      "step: 998, loss:0.54142463\n",
      "step: 999, loss:0.47613725\n",
      "step: 1000, loss:0.50679076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:10:07,831 - INFO - step:1000, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1001, loss:0.30842206\n",
      "step: 1002, loss:0.55713898\n",
      "step: 1003, loss:0.56658351\n",
      "step: 1004, loss:0.38770857\n",
      "step: 1005, loss:0.61980891\n",
      "step: 1006, loss:0.89622313\n",
      "step: 1007, loss:0.43350729\n",
      "step: 1008, loss:0.63346344\n",
      "step: 1009, loss:1.16390407\n",
      "step: 1010, loss:0.57478374\n",
      "step: 1011, loss:0.52584559\n",
      "step: 1012, loss:0.39673531\n",
      "step: 1013, loss:0.31868285\n",
      "step: 1014, loss:0.40613925\n",
      "step: 1015, loss:0.32521766\n",
      "step: 1016, loss:1.07460999\n",
      "step: 1017, loss:0.52344942\n",
      "step: 1018, loss:0.55998111\n",
      "step: 1019, loss:0.51417243\n",
      "step: 1020, loss:0.27744588\n",
      "step: 1021, loss:0.45368737\n",
      "step: 1022, loss:0.29027632\n",
      "step: 1023, loss:0.45613214\n",
      "step: 1024, loss:0.74122077\n",
      "step: 1025, loss:0.61081332\n",
      "step: 1026, loss:0.53590220\n",
      "step: 1027, loss:0.99444169\n",
      "step: 1028, loss:0.40322775\n",
      "step: 1029, loss:0.78833663\n",
      "step: 1030, loss:0.73577231\n",
      "step: 1031, loss:0.36417782\n",
      "step: 1032, loss:0.56853718\n",
      "step: 1033, loss:0.44772324\n",
      "step: 1034, loss:0.64453286\n",
      "step: 1035, loss:0.49184936\n",
      "step: 1036, loss:0.52840149\n",
      "step: 1037, loss:0.73689258\n",
      "step: 1038, loss:0.72881061\n",
      "step: 1039, loss:0.65456408\n",
      "step: 1040, loss:0.74180162\n",
      "step: 1041, loss:0.59784192\n",
      "step: 1042, loss:0.65170938\n",
      "step: 1043, loss:0.57321507\n",
      "step: 1044, loss:0.68172789\n",
      "step: 1045, loss:0.52270335\n",
      "step: 1046, loss:0.58366621\n",
      "step: 1047, loss:0.57875907\n",
      "step: 1048, loss:0.56093395\n",
      "step: 1049, loss:0.49013779\n",
      "step: 1050, loss:0.50003332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:10:33,351 - INFO - step:1050, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1051, loss:0.56371665\n",
      "step: 1052, loss:0.59621620\n",
      "step: 1053, loss:0.56923407\n",
      "step: 1054, loss:0.55797142\n",
      "step: 1055, loss:0.49154601\n",
      "step: 1056, loss:0.81633717\n",
      "step: 1057, loss:0.62843841\n",
      "step: 1058, loss:0.70740056\n",
      "step: 1059, loss:0.63012952\n",
      "step: 1060, loss:0.63536531\n",
      "step: 1061, loss:0.59275818\n",
      "step: 1062, loss:0.60199934\n",
      "step: 1063, loss:0.74319404\n",
      "step: 1064, loss:0.65499264\n",
      "step: 1065, loss:0.63755429\n",
      "step: 1066, loss:0.50209600\n",
      "step: 1067, loss:0.65610713\n",
      "step: 1068, loss:0.71210468\n",
      "step: 1069, loss:0.61714613\n",
      "step: 1070, loss:0.57453781\n",
      "step: 1071, loss:0.56873184\n",
      "step: 1072, loss:0.74165088\n",
      "step: 1073, loss:0.52184868\n",
      "step: 1074, loss:0.61664295\n",
      "step: 1075, loss:0.55263150\n",
      "step: 1076, loss:0.59742260\n",
      "step: 1077, loss:0.80226308\n",
      "step: 1078, loss:0.68114865\n",
      "step: 1079, loss:0.71583182\n",
      "step: 1080, loss:0.58184618\n",
      "step: 1081, loss:0.69730443\n",
      "step: 1082, loss:0.71670526\n",
      "step: 1083, loss:0.59301710\n",
      "step: 1084, loss:0.63041329\n",
      "step: 1085, loss:0.66260737\n",
      "step: 1086, loss:0.66624868\n",
      "step: 1087, loss:0.62035286\n",
      "step: 1088, loss:0.61269343\n",
      "step: 1089, loss:0.64555472\n",
      "step: 1090, loss:0.47205076\n",
      "step: 1091, loss:0.71238840\n",
      "step: 1092, loss:0.55230826\n",
      "step: 1093, loss:0.55132067\n",
      "step: 1094, loss:0.61682332\n",
      "step: 1095, loss:0.80626959\n",
      "step: 1096, loss:0.79107434\n",
      "step: 1097, loss:0.66860962\n",
      "step: 1098, loss:0.71637613\n",
      "step: 1099, loss:0.73717934\n",
      "step: 1100, loss:0.80710983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:10:58,772 - INFO - step:1100, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1101, loss:0.69927979\n",
      "step: 1102, loss:0.58004832\n",
      "step: 1103, loss:0.69760597\n",
      "step: 1104, loss:0.55412489\n",
      "step: 1105, loss:0.50264692\n",
      "step: 1106, loss:0.58539975\n",
      "step: 1107, loss:0.63992751\n",
      "step: 1108, loss:0.70333773\n",
      "step: 1109, loss:0.67824036\n",
      "step: 1110, loss:0.62633198\n",
      "step: 1111, loss:0.57773387\n",
      "step: 1112, loss:0.69865882\n",
      "step: 1113, loss:0.68117672\n",
      "step: 1114, loss:0.64866459\n",
      "step: 1115, loss:0.72840708\n",
      "step: 1116, loss:0.67956048\n",
      "step: 1117, loss:0.64342701\n",
      "step: 1118, loss:0.74147421\n",
      "step: 1119, loss:0.55675387\n",
      "step: 1120, loss:0.61153013\n",
      "step: 1121, loss:0.60553312\n",
      "step: 1122, loss:0.59088880\n",
      "step: 1123, loss:0.57154554\n",
      "step: 1124, loss:0.80515856\n",
      "step: 1125, loss:0.72399586\n",
      "step: 1126, loss:0.78207296\n",
      "step: 1127, loss:0.65535241\n",
      "step: 1128, loss:0.66428900\n",
      "step: 1129, loss:0.70018262\n",
      "step: 1130, loss:0.72473222\n",
      "step: 1131, loss:0.67980504\n",
      "step: 1132, loss:0.69424123\n",
      "step: 1133, loss:0.66199940\n",
      "step: 1134, loss:0.69181043\n",
      "step: 1135, loss:0.54666972\n",
      "step: 1136, loss:0.71084869\n",
      "step: 1137, loss:0.61160678\n",
      "step: 1138, loss:0.64471138\n",
      "step: 1139, loss:0.58020014\n",
      "step: 1140, loss:0.63848037\n",
      "step: 1141, loss:0.63551402\n",
      "step: 1142, loss:0.54304194\n",
      "step: 1143, loss:0.55545926\n",
      "step: 1144, loss:0.64377862\n",
      "step: 1145, loss:0.64854360\n",
      "step: 1146, loss:0.63803411\n",
      "step: 1147, loss:0.51174146\n",
      "step: 1148, loss:0.46546441\n",
      "step: 1149, loss:0.48625511\n",
      "step: 1150, loss:0.53197104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:11:24,293 - INFO - step:1150, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1151, loss:0.67415047\n",
      "step: 1152, loss:0.94477713\n",
      "step: 1153, loss:0.74113917\n",
      "step: 1154, loss:0.81705797\n",
      "step: 1155, loss:0.56918955\n",
      "step: 1156, loss:0.76832527\n",
      "step: 1157, loss:0.61249423\n",
      "step: 1158, loss:0.88022935\n",
      "step: 1159, loss:0.64007002\n",
      "step: 1160, loss:0.77358079\n",
      "step: 1161, loss:0.74062526\n",
      "step: 1162, loss:0.53902191\n",
      "step: 1163, loss:0.61498010\n",
      "step: 1164, loss:0.54602867\n",
      "step: 1165, loss:0.71115232\n",
      "step: 1166, loss:0.59816658\n",
      "step: 1167, loss:0.65561569\n",
      "step: 1168, loss:0.53872299\n",
      "step: 1169, loss:0.59888715\n",
      "step: 1170, loss:0.76646262\n",
      "step: 1171, loss:0.59480751\n",
      "step: 1172, loss:0.67799354\n",
      "step: 1173, loss:0.60355651\n",
      "step: 1174, loss:0.57651401\n",
      "step: 1175, loss:0.72182071\n",
      "step: 1176, loss:0.50069320\n",
      "step: 1177, loss:0.49389341\n",
      "step: 1178, loss:0.48793226\n",
      "step: 1179, loss:0.65379375\n",
      "step: 1180, loss:0.59275019\n",
      "step: 1181, loss:0.79490036\n",
      "step: 1182, loss:0.53429514\n",
      "step: 1183, loss:0.64588094\n",
      "step: 1184, loss:0.62628388\n",
      "step: 1185, loss:0.51021612\n",
      "step: 1186, loss:0.56867218\n",
      "step: 1187, loss:0.65987146\n",
      "step: 1188, loss:0.43417937\n",
      "step: 1189, loss:0.50110215\n",
      "step: 1190, loss:0.46744397\n",
      "step: 1191, loss:0.35742658\n",
      "step: 1192, loss:0.41878355\n",
      "step: 1193, loss:0.44276479\n",
      "step: 1194, loss:0.79777688\n",
      "step: 1195, loss:0.81220317\n",
      "step: 1196, loss:0.30213821\n",
      "step: 1197, loss:0.75270236\n",
      "step: 1198, loss:0.84753406\n",
      "step: 1199, loss:0.51787430\n",
      "step: 1200, loss:0.48704463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:11:49,892 - INFO - step:1200, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1201, loss:0.85573453\n",
      "step: 1202, loss:0.64058399\n",
      "step: 1203, loss:0.52981180\n",
      "step: 1204, loss:0.62193251\n",
      "step: 1205, loss:0.59196979\n",
      "step: 1206, loss:0.69775575\n",
      "step: 1207, loss:0.61887956\n",
      "step: 1208, loss:0.81395185\n",
      "step: 1209, loss:0.67446983\n",
      "step: 1210, loss:0.75784445\n",
      "step: 1211, loss:0.58445346\n",
      "step: 1212, loss:0.76281428\n",
      "step: 1213, loss:0.64189357\n",
      "step: 1214, loss:0.55648202\n",
      "step: 1215, loss:0.76831585\n",
      "step: 1216, loss:0.56602079\n",
      "step: 1217, loss:0.62746674\n",
      "step: 1218, loss:0.56410414\n",
      "step: 1219, loss:0.57743776\n",
      "step: 1220, loss:0.59653181\n",
      "step: 1221, loss:0.61151212\n",
      "step: 1222, loss:0.55241865\n",
      "step: 1223, loss:0.64117616\n",
      "step: 1224, loss:0.61291337\n",
      "step: 1225, loss:0.62637448\n",
      "step: 1226, loss:0.59371442\n",
      "step: 1227, loss:0.59726644\n",
      "step: 1228, loss:0.66820019\n",
      "step: 1229, loss:0.56226200\n",
      "step: 1230, loss:0.43370935\n",
      "step: 1231, loss:0.46669784\n",
      "step: 1232, loss:0.66125578\n",
      "step: 1233, loss:0.64111835\n",
      "step: 1234, loss:0.45982087\n",
      "step: 1235, loss:0.38727796\n",
      "step: 1236, loss:0.56670690\n",
      "step: 1237, loss:0.57794648\n",
      "step: 1238, loss:0.77251667\n",
      "step: 1239, loss:0.57167959\n",
      "step: 1240, loss:0.57126194\n",
      "step: 1241, loss:0.71475226\n",
      "step: 1242, loss:0.80314761\n",
      "step: 1243, loss:0.74022269\n",
      "step: 1244, loss:0.46771652\n",
      "step: 1245, loss:0.67621672\n",
      "step: 1246, loss:0.67128336\n",
      "step: 1247, loss:0.57110399\n",
      "step: 1248, loss:0.56981409\n",
      "step: 1249, loss:0.56241810\n",
      "step: 1250, loss:0.45639843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:12:15,410 - INFO - step:1250, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1251, loss:0.47136521\n",
      "step: 1252, loss:0.42020804\n",
      "step: 1253, loss:0.48118958\n",
      "step: 1254, loss:0.49482557\n",
      "step: 1255, loss:0.51102376\n",
      "step: 1256, loss:0.50385410\n",
      "step: 1257, loss:0.41797128\n",
      "step: 1258, loss:0.57571995\n",
      "step: 1259, loss:0.55212277\n",
      "step: 1260, loss:0.77828425\n",
      "step: 1261, loss:0.75492877\n",
      "step: 1262, loss:0.51771486\n",
      "step: 1263, loss:0.40828988\n",
      "step: 1264, loss:0.77772474\n",
      "step: 1265, loss:0.42407119\n",
      "step: 1266, loss:0.52983981\n",
      "step: 1267, loss:0.46132702\n",
      "step: 1268, loss:0.49060550\n",
      "step: 1269, loss:0.25844887\n",
      "step: 1270, loss:0.57577187\n",
      "step: 1271, loss:0.57571793\n",
      "step: 1272, loss:0.40743485\n",
      "step: 1273, loss:0.60867226\n",
      "step: 1274, loss:0.84740847\n",
      "step: 1275, loss:0.42430103\n",
      "step: 1276, loss:0.60445470\n",
      "step: 1277, loss:1.06466126\n",
      "step: 1278, loss:0.54507846\n",
      "step: 1279, loss:0.51872391\n",
      "step: 1280, loss:0.38931572\n",
      "step: 1281, loss:0.29846537\n",
      "step: 1282, loss:0.40903705\n",
      "step: 1283, loss:0.33288223\n",
      "step: 1284, loss:1.05174017\n",
      "step: 1285, loss:0.53811431\n",
      "step: 1286, loss:0.56977999\n",
      "step: 1287, loss:0.51587582\n",
      "step: 1288, loss:0.29229680\n",
      "step: 1289, loss:0.45811942\n",
      "step: 1290, loss:0.32050982\n",
      "step: 1291, loss:0.44917127\n",
      "step: 1292, loss:0.72705847\n",
      "step: 1293, loss:0.60641181\n",
      "step: 1294, loss:0.51946121\n",
      "step: 1295, loss:0.92398155\n",
      "step: 1296, loss:0.40840462\n",
      "step: 1297, loss:0.74749559\n",
      "step: 1298, loss:0.72060096\n",
      "step: 1299, loss:0.37353456\n",
      "step: 1300, loss:0.56094968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:12:40,926 - INFO - step:1300, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1301, loss:0.44745204\n",
      "step: 1302, loss:0.61977488\n",
      "step: 1303, loss:0.48214000\n",
      "step: 1304, loss:0.53027350\n",
      "step: 1305, loss:0.74173754\n",
      "step: 1306, loss:0.72449768\n",
      "step: 1307, loss:0.67605209\n",
      "step: 1308, loss:0.77800769\n",
      "step: 1309, loss:0.60300797\n",
      "step: 1310, loss:0.65455389\n",
      "step: 1311, loss:0.57624751\n",
      "step: 1312, loss:0.69722873\n",
      "step: 1313, loss:0.47516698\n",
      "step: 1314, loss:0.54126894\n",
      "step: 1315, loss:0.57110280\n",
      "step: 1316, loss:0.54484963\n",
      "step: 1317, loss:0.46642423\n",
      "step: 1318, loss:0.49257538\n",
      "step: 1319, loss:0.56941241\n",
      "step: 1320, loss:0.58641219\n",
      "step: 1321, loss:0.57281381\n",
      "step: 1322, loss:0.57244271\n",
      "step: 1323, loss:0.51536608\n",
      "step: 1324, loss:0.78629285\n",
      "step: 1325, loss:0.62467653\n",
      "step: 1326, loss:0.67930436\n",
      "step: 1327, loss:0.63705075\n",
      "step: 1328, loss:0.62591994\n",
      "step: 1329, loss:0.58750081\n",
      "step: 1330, loss:0.60382020\n",
      "step: 1331, loss:0.71517050\n",
      "step: 1332, loss:0.63806516\n",
      "step: 1333, loss:0.62153220\n",
      "step: 1334, loss:0.51249105\n",
      "step: 1335, loss:0.64808261\n",
      "step: 1336, loss:0.70318931\n",
      "step: 1337, loss:0.62232977\n",
      "step: 1338, loss:0.57160407\n",
      "step: 1339, loss:0.56500554\n",
      "step: 1340, loss:0.72300816\n",
      "step: 1341, loss:0.52342165\n",
      "step: 1342, loss:0.62029099\n",
      "step: 1343, loss:0.54715365\n",
      "step: 1344, loss:0.60343033\n",
      "step: 1345, loss:0.82992595\n",
      "step: 1346, loss:0.70051104\n",
      "step: 1347, loss:0.70901912\n",
      "step: 1348, loss:0.58177906\n",
      "step: 1349, loss:0.71860301\n",
      "step: 1350, loss:0.74205655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:13:06,341 - INFO - step:1350, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1351, loss:0.57677197\n",
      "step: 1352, loss:0.62822455\n",
      "step: 1353, loss:0.65573609\n",
      "step: 1354, loss:0.68771625\n",
      "step: 1355, loss:0.60046262\n",
      "step: 1356, loss:0.59647131\n",
      "step: 1357, loss:0.63858372\n",
      "step: 1358, loss:0.43551758\n",
      "step: 1359, loss:0.71874446\n",
      "step: 1360, loss:0.54626566\n",
      "step: 1361, loss:0.53978771\n",
      "step: 1362, loss:0.62208557\n",
      "step: 1363, loss:0.80642062\n",
      "step: 1364, loss:0.78785551\n",
      "step: 1365, loss:0.66853285\n",
      "step: 1366, loss:0.71057886\n",
      "step: 1367, loss:0.73287433\n",
      "step: 1368, loss:0.79423952\n",
      "step: 1369, loss:0.70597327\n",
      "step: 1370, loss:0.59250575\n",
      "step: 1371, loss:0.69565016\n",
      "step: 1372, loss:0.55540681\n",
      "step: 1373, loss:0.51072311\n",
      "step: 1374, loss:0.59458148\n",
      "step: 1375, loss:0.64341849\n",
      "step: 1376, loss:0.70260656\n",
      "step: 1377, loss:0.68215281\n",
      "step: 1378, loss:0.63105470\n",
      "step: 1379, loss:0.58437222\n",
      "step: 1380, loss:0.69710171\n",
      "step: 1381, loss:0.68460214\n",
      "step: 1382, loss:0.64622402\n",
      "step: 1383, loss:0.71434921\n",
      "step: 1384, loss:0.67774498\n",
      "step: 1385, loss:0.63907832\n",
      "step: 1386, loss:0.74425679\n",
      "step: 1387, loss:0.55259132\n",
      "step: 1388, loss:0.61301559\n",
      "step: 1389, loss:0.61175984\n",
      "step: 1390, loss:0.58716154\n",
      "step: 1391, loss:0.57298774\n",
      "step: 1392, loss:0.79047555\n",
      "step: 1393, loss:0.71897662\n",
      "step: 1394, loss:0.77157903\n",
      "step: 1395, loss:0.65695083\n",
      "step: 1396, loss:0.66911149\n",
      "step: 1397, loss:0.69918239\n",
      "step: 1398, loss:0.73517752\n",
      "step: 1399, loss:0.67218220\n",
      "step: 1400, loss:0.68830180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:13:31,829 - INFO - step:1400, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1401, loss:0.66464716\n",
      "step: 1402, loss:0.68733060\n",
      "step: 1403, loss:0.54633254\n",
      "step: 1404, loss:0.70545667\n",
      "step: 1405, loss:0.61387879\n",
      "step: 1406, loss:0.65016377\n",
      "step: 1407, loss:0.57907927\n",
      "step: 1408, loss:0.63363701\n",
      "step: 1409, loss:0.63764071\n",
      "step: 1410, loss:0.54842818\n",
      "step: 1411, loss:0.55584151\n",
      "step: 1412, loss:0.64880633\n",
      "step: 1413, loss:0.64858180\n",
      "step: 1414, loss:0.64342928\n",
      "step: 1415, loss:0.53554434\n",
      "step: 1416, loss:0.49525824\n",
      "step: 1417, loss:0.51607549\n",
      "step: 1418, loss:0.54990196\n",
      "step: 1419, loss:0.65427262\n",
      "step: 1420, loss:0.85352999\n",
      "step: 1421, loss:0.72699195\n",
      "step: 1422, loss:0.77709103\n",
      "step: 1423, loss:0.56932837\n",
      "step: 1424, loss:0.73773164\n",
      "step: 1425, loss:0.62861240\n",
      "step: 1426, loss:0.84622806\n",
      "step: 1427, loss:0.64800996\n",
      "step: 1428, loss:0.78008139\n",
      "step: 1429, loss:0.73629433\n",
      "step: 1430, loss:0.49703315\n",
      "step: 1431, loss:0.58725339\n",
      "step: 1432, loss:0.48750606\n",
      "step: 1433, loss:0.74254084\n",
      "step: 1434, loss:0.58512539\n",
      "step: 1435, loss:0.63726914\n",
      "step: 1436, loss:0.52591664\n",
      "step: 1437, loss:0.59991699\n",
      "step: 1438, loss:0.76627380\n",
      "step: 1439, loss:0.60212225\n",
      "step: 1440, loss:0.69007659\n",
      "step: 1441, loss:0.59656334\n",
      "step: 1442, loss:0.57054317\n",
      "step: 1443, loss:0.69907898\n",
      "step: 1444, loss:0.51790744\n",
      "step: 1445, loss:0.50079608\n",
      "step: 1446, loss:0.50709122\n",
      "step: 1447, loss:0.64454746\n",
      "step: 1448, loss:0.58498245\n",
      "step: 1449, loss:0.77937472\n",
      "step: 1450, loss:0.54542917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:13:57,357 - INFO - step:1450, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1451, loss:0.64128137\n",
      "step: 1452, loss:0.60334933\n",
      "step: 1453, loss:0.50871122\n",
      "step: 1454, loss:0.54848897\n",
      "step: 1455, loss:0.64950061\n",
      "step: 1456, loss:0.46023589\n",
      "step: 1457, loss:0.51782578\n",
      "step: 1458, loss:0.45897305\n",
      "step: 1459, loss:0.38607061\n",
      "step: 1460, loss:0.43489876\n",
      "step: 1461, loss:0.45559016\n",
      "step: 1462, loss:0.75766611\n",
      "step: 1463, loss:0.77269489\n",
      "step: 1464, loss:0.31801972\n",
      "step: 1465, loss:0.74988425\n",
      "step: 1466, loss:0.83139479\n",
      "step: 1467, loss:0.51810735\n",
      "step: 1468, loss:0.50121325\n",
      "step: 1469, loss:0.86829144\n",
      "step: 1470, loss:0.62653697\n",
      "step: 1471, loss:0.52410960\n",
      "step: 1472, loss:0.63072413\n",
      "step: 1473, loss:0.59446418\n",
      "step: 1474, loss:0.71104270\n",
      "step: 1475, loss:0.61172819\n",
      "step: 1476, loss:0.85623133\n",
      "step: 1477, loss:0.66780877\n",
      "step: 1478, loss:0.79052967\n",
      "step: 1479, loss:0.56954074\n",
      "step: 1480, loss:0.76759404\n",
      "step: 1481, loss:0.63985384\n",
      "step: 1482, loss:0.56758761\n",
      "step: 1483, loss:0.75120693\n",
      "step: 1484, loss:0.58086061\n",
      "step: 1485, loss:0.63471007\n",
      "step: 1486, loss:0.58266896\n",
      "step: 1487, loss:0.58181232\n",
      "step: 1488, loss:0.59412360\n",
      "step: 1489, loss:0.59930265\n",
      "step: 1490, loss:0.54186547\n",
      "step: 1491, loss:0.63769042\n",
      "step: 1492, loss:0.61255586\n",
      "step: 1493, loss:0.61192209\n",
      "step: 1494, loss:0.58793426\n",
      "step: 1495, loss:0.59016556\n",
      "step: 1496, loss:0.64568400\n",
      "step: 1497, loss:0.57536477\n",
      "step: 1498, loss:0.43947348\n",
      "step: 1499, loss:0.47236347\n",
      "step: 1500, loss:0.65613198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:14:22,889 - INFO - step:1500, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1501, loss:0.62945253\n",
      "step: 1502, loss:0.46135208\n",
      "step: 1503, loss:0.38669774\n",
      "step: 1504, loss:0.55538207\n",
      "step: 1505, loss:0.57326013\n",
      "step: 1506, loss:0.75455129\n",
      "step: 1507, loss:0.55633765\n",
      "step: 1508, loss:0.57251787\n",
      "step: 1509, loss:0.71859574\n",
      "step: 1510, loss:0.79041141\n",
      "step: 1511, loss:0.73648292\n",
      "step: 1512, loss:0.48098621\n",
      "step: 1513, loss:0.67711979\n",
      "step: 1514, loss:0.68140304\n",
      "step: 1515, loss:0.57837528\n",
      "step: 1516, loss:0.58469719\n",
      "step: 1517, loss:0.56049299\n",
      "step: 1518, loss:0.44678462\n",
      "step: 1519, loss:0.45640004\n",
      "step: 1520, loss:0.40633088\n",
      "step: 1521, loss:0.46692646\n",
      "step: 1522, loss:0.47781193\n",
      "step: 1523, loss:0.50479001\n",
      "step: 1524, loss:0.49933559\n",
      "step: 1525, loss:0.39498654\n",
      "step: 1526, loss:0.57711756\n",
      "step: 1527, loss:0.57078981\n",
      "step: 1528, loss:0.80176449\n",
      "step: 1529, loss:0.75086188\n",
      "step: 1530, loss:0.52995783\n",
      "step: 1531, loss:0.43319365\n",
      "step: 1532, loss:0.71826977\n",
      "step: 1533, loss:0.45029676\n",
      "step: 1534, loss:0.53087437\n",
      "step: 1535, loss:0.47978294\n",
      "step: 1536, loss:0.50273651\n",
      "step: 1537, loss:0.28617105\n",
      "step: 1538, loss:0.55344492\n",
      "step: 1539, loss:0.56926036\n",
      "step: 1540, loss:0.39477473\n",
      "step: 1541, loss:0.62330127\n",
      "step: 1542, loss:0.86787540\n",
      "step: 1543, loss:0.43598595\n",
      "step: 1544, loss:0.62621474\n",
      "step: 1545, loss:1.12534690\n",
      "step: 1546, loss:0.57860816\n",
      "step: 1547, loss:0.53554964\n",
      "step: 1548, loss:0.37752956\n",
      "step: 1549, loss:0.26374295\n",
      "step: 1550, loss:0.38465384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:14:48,412 - INFO - step:1550, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1551, loss:0.30484602\n",
      "step: 1552, loss:1.09908402\n",
      "step: 1553, loss:0.52051497\n",
      "step: 1554, loss:0.56584013\n",
      "step: 1555, loss:0.52632499\n",
      "step: 1556, loss:0.28372768\n",
      "step: 1557, loss:0.46363184\n",
      "step: 1558, loss:0.31951049\n",
      "step: 1559, loss:0.45141274\n",
      "step: 1560, loss:0.72761834\n",
      "step: 1561, loss:0.59953529\n",
      "step: 1562, loss:0.52295005\n",
      "step: 1563, loss:0.91974366\n",
      "step: 1564, loss:0.41673771\n",
      "step: 1565, loss:0.75154728\n",
      "step: 1566, loss:0.70901483\n",
      "step: 1567, loss:0.38536051\n",
      "step: 1568, loss:0.57281011\n",
      "step: 1569, loss:0.45908448\n",
      "step: 1570, loss:0.64281559\n",
      "step: 1571, loss:0.49570513\n",
      "step: 1572, loss:0.52836084\n",
      "step: 1573, loss:0.73567098\n",
      "step: 1574, loss:0.74146712\n",
      "step: 1575, loss:0.66087878\n",
      "step: 1576, loss:0.75348532\n",
      "step: 1577, loss:0.59760576\n",
      "step: 1578, loss:0.66554552\n",
      "step: 1579, loss:0.55395365\n",
      "step: 1580, loss:0.71974945\n",
      "step: 1581, loss:0.47632235\n",
      "step: 1582, loss:0.53806019\n",
      "step: 1583, loss:0.56253791\n",
      "step: 1584, loss:0.54479557\n",
      "step: 1585, loss:0.46113679\n",
      "step: 1586, loss:0.49100348\n",
      "step: 1587, loss:0.56107688\n",
      "step: 1588, loss:0.60541844\n",
      "step: 1589, loss:0.58376133\n",
      "step: 1590, loss:0.56133980\n",
      "step: 1591, loss:0.51295078\n",
      "step: 1592, loss:0.78844303\n",
      "step: 1593, loss:0.63014400\n",
      "step: 1594, loss:0.69529653\n",
      "step: 1595, loss:0.62752980\n",
      "step: 1596, loss:0.63148862\n",
      "step: 1597, loss:0.60209048\n",
      "step: 1598, loss:0.59267336\n",
      "step: 1599, loss:0.70841557\n",
      "step: 1600, loss:0.63945389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:15:13,929 - INFO - step:1600, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1601, loss:0.63027817\n",
      "step: 1602, loss:0.50330335\n",
      "step: 1603, loss:0.64597809\n",
      "step: 1604, loss:0.71475166\n",
      "step: 1605, loss:0.62192649\n",
      "step: 1606, loss:0.56433809\n",
      "step: 1607, loss:0.57361019\n",
      "step: 1608, loss:0.74228036\n",
      "step: 1609, loss:0.52224815\n",
      "step: 1610, loss:0.62198687\n",
      "step: 1611, loss:0.55080754\n",
      "step: 1612, loss:0.59336400\n",
      "step: 1613, loss:0.81859195\n",
      "step: 1614, loss:0.69454479\n",
      "step: 1615, loss:0.72002351\n",
      "step: 1616, loss:0.57161754\n",
      "step: 1617, loss:0.70722872\n",
      "step: 1618, loss:0.72849679\n",
      "step: 1619, loss:0.57667035\n",
      "step: 1620, loss:0.62294292\n",
      "step: 1621, loss:0.65754765\n",
      "step: 1622, loss:0.68372071\n",
      "step: 1623, loss:0.61179662\n",
      "step: 1624, loss:0.60989338\n",
      "step: 1625, loss:0.64303815\n",
      "step: 1626, loss:0.45897675\n",
      "step: 1627, loss:0.71356320\n",
      "step: 1628, loss:0.54919368\n",
      "step: 1629, loss:0.54585606\n",
      "step: 1630, loss:0.61484212\n",
      "step: 1631, loss:0.79969066\n",
      "step: 1632, loss:0.78873575\n",
      "step: 1633, loss:0.66591370\n",
      "step: 1634, loss:0.71158522\n",
      "step: 1635, loss:0.74010342\n",
      "step: 1636, loss:0.80763590\n",
      "step: 1637, loss:0.70723015\n",
      "step: 1638, loss:0.58361179\n",
      "step: 1639, loss:0.70094991\n",
      "step: 1640, loss:0.53995615\n",
      "step: 1641, loss:0.48941788\n",
      "step: 1642, loss:0.58408511\n",
      "step: 1643, loss:0.64577150\n",
      "step: 1644, loss:0.70321435\n",
      "step: 1645, loss:0.67684430\n",
      "step: 1646, loss:0.62084502\n",
      "step: 1647, loss:0.59191489\n",
      "step: 1648, loss:0.70370370\n",
      "step: 1649, loss:0.68072349\n",
      "step: 1650, loss:0.63562644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:15:39,338 - INFO - step:1650, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1651, loss:0.70881730\n",
      "step: 1652, loss:0.68395013\n",
      "step: 1653, loss:0.64658904\n",
      "step: 1654, loss:0.73808706\n",
      "step: 1655, loss:0.56015444\n",
      "step: 1656, loss:0.61448044\n",
      "step: 1657, loss:0.61023438\n",
      "step: 1658, loss:0.58557183\n",
      "step: 1659, loss:0.56994414\n",
      "step: 1660, loss:0.80080169\n",
      "step: 1661, loss:0.71759117\n",
      "step: 1662, loss:0.79030389\n",
      "step: 1663, loss:0.66255969\n",
      "step: 1664, loss:0.66010302\n",
      "step: 1665, loss:0.70585233\n",
      "step: 1666, loss:0.72901917\n",
      "step: 1667, loss:0.68774635\n",
      "step: 1668, loss:0.69330454\n",
      "step: 1669, loss:0.66428304\n",
      "step: 1670, loss:0.69220972\n",
      "step: 1671, loss:0.54601574\n",
      "step: 1672, loss:0.71602243\n",
      "step: 1673, loss:0.60353053\n",
      "step: 1674, loss:0.65376264\n",
      "step: 1675, loss:0.58629072\n",
      "step: 1676, loss:0.63056952\n",
      "step: 1677, loss:0.62966478\n",
      "step: 1678, loss:0.55020690\n",
      "step: 1679, loss:0.55670953\n",
      "step: 1680, loss:0.64262879\n",
      "step: 1681, loss:0.64487600\n",
      "step: 1682, loss:0.64066356\n",
      "step: 1683, loss:0.53780502\n",
      "step: 1684, loss:0.48442474\n",
      "step: 1685, loss:0.50273120\n",
      "step: 1686, loss:0.53906453\n",
      "step: 1687, loss:0.65093416\n",
      "step: 1688, loss:0.86687011\n",
      "step: 1689, loss:0.73251969\n",
      "step: 1690, loss:0.79583371\n",
      "step: 1691, loss:0.56378692\n",
      "step: 1692, loss:0.73637426\n",
      "step: 1693, loss:0.62037712\n",
      "step: 1694, loss:0.85687876\n",
      "step: 1695, loss:0.64391387\n",
      "step: 1696, loss:0.80083394\n",
      "step: 1697, loss:0.72995055\n",
      "step: 1698, loss:0.49040478\n",
      "step: 1699, loss:0.58967090\n",
      "step: 1700, loss:0.50104630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:16:04,856 - INFO - step:1700, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1701, loss:0.74253881\n",
      "step: 1702, loss:0.58477676\n",
      "step: 1703, loss:0.64224321\n",
      "step: 1704, loss:0.52691567\n",
      "step: 1705, loss:0.60847867\n",
      "step: 1706, loss:0.78626961\n",
      "step: 1707, loss:0.59790623\n",
      "step: 1708, loss:0.68507308\n",
      "step: 1709, loss:0.60626972\n",
      "step: 1710, loss:0.56743866\n",
      "step: 1711, loss:0.70888370\n",
      "step: 1712, loss:0.51300436\n",
      "step: 1713, loss:0.50813365\n",
      "step: 1714, loss:0.50221813\n",
      "step: 1715, loss:0.64664823\n",
      "step: 1716, loss:0.60671324\n",
      "step: 1717, loss:0.77374291\n",
      "step: 1718, loss:0.53781414\n",
      "step: 1719, loss:0.64724153\n",
      "step: 1720, loss:0.61656791\n",
      "step: 1721, loss:0.51814836\n",
      "step: 1722, loss:0.56730121\n",
      "step: 1723, loss:0.64112508\n",
      "step: 1724, loss:0.45499113\n",
      "step: 1725, loss:0.50489104\n",
      "step: 1726, loss:0.47820327\n",
      "step: 1727, loss:0.38110074\n",
      "step: 1728, loss:0.43146917\n",
      "step: 1729, loss:0.45614392\n",
      "step: 1730, loss:0.75239187\n",
      "step: 1731, loss:0.76711005\n",
      "step: 1732, loss:0.32255340\n",
      "step: 1733, loss:0.73842108\n",
      "step: 1734, loss:0.81615144\n",
      "step: 1735, loss:0.52146310\n",
      "step: 1736, loss:0.48655859\n",
      "step: 1737, loss:0.86479992\n",
      "step: 1738, loss:0.64220691\n",
      "step: 1739, loss:0.53339946\n",
      "step: 1740, loss:0.62886995\n",
      "step: 1741, loss:0.59659821\n",
      "step: 1742, loss:0.71242791\n",
      "step: 1743, loss:0.62672055\n",
      "step: 1744, loss:0.85864735\n",
      "step: 1745, loss:0.68289030\n",
      "step: 1746, loss:0.78332508\n",
      "step: 1747, loss:0.57123154\n",
      "step: 1748, loss:0.79408264\n",
      "step: 1749, loss:0.64519304\n",
      "step: 1750, loss:0.53400064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:16:30,355 - INFO - step:1750, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1751, loss:0.79050493\n",
      "step: 1752, loss:0.53848267\n",
      "step: 1753, loss:0.61875731\n",
      "step: 1754, loss:0.54447681\n",
      "step: 1755, loss:0.56077129\n",
      "step: 1756, loss:0.57296222\n",
      "step: 1757, loss:0.60270625\n",
      "step: 1758, loss:0.53183609\n",
      "step: 1759, loss:0.63578969\n",
      "step: 1760, loss:0.62098294\n",
      "step: 1761, loss:0.61699933\n",
      "step: 1762, loss:0.59633470\n",
      "step: 1763, loss:0.60039800\n",
      "step: 1764, loss:0.64100194\n",
      "step: 1765, loss:0.57290590\n",
      "step: 1766, loss:0.44721061\n",
      "step: 1767, loss:0.47476268\n",
      "step: 1768, loss:0.66002655\n",
      "step: 1769, loss:0.61243540\n",
      "step: 1770, loss:0.45550948\n",
      "step: 1771, loss:0.39106515\n",
      "step: 1772, loss:0.56144768\n",
      "step: 1773, loss:0.57095230\n",
      "step: 1774, loss:0.79095250\n",
      "step: 1775, loss:0.56742072\n",
      "step: 1776, loss:0.57195407\n",
      "step: 1777, loss:0.73623401\n",
      "step: 1778, loss:0.77710253\n",
      "step: 1779, loss:0.74253094\n",
      "step: 1780, loss:0.46768904\n",
      "step: 1781, loss:0.69405437\n",
      "step: 1782, loss:0.67883104\n",
      "step: 1783, loss:0.57044876\n",
      "step: 1784, loss:0.57058364\n",
      "step: 1785, loss:0.55047089\n",
      "step: 1786, loss:0.44120142\n",
      "step: 1787, loss:0.46257702\n",
      "step: 1788, loss:0.41329193\n",
      "step: 1789, loss:0.47951666\n",
      "step: 1790, loss:0.49087808\n",
      "step: 1791, loss:0.51906335\n",
      "step: 1792, loss:0.51020318\n",
      "step: 1793, loss:0.42358720\n",
      "step: 1794, loss:0.56646878\n",
      "step: 1795, loss:0.56845170\n",
      "step: 1796, loss:0.74863952\n",
      "step: 1797, loss:0.72752875\n",
      "step: 1798, loss:0.52396822\n",
      "step: 1799, loss:0.42572275\n",
      "step: 1800, loss:0.74389881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:16:55,865 - INFO - step:1800, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1801, loss:0.41862473\n",
      "step: 1802, loss:0.52696621\n",
      "step: 1803, loss:0.44935477\n",
      "step: 1804, loss:0.49644607\n",
      "step: 1805, loss:0.25473595\n",
      "step: 1806, loss:0.56139421\n",
      "step: 1807, loss:0.55601722\n",
      "step: 1808, loss:0.40221533\n",
      "step: 1809, loss:0.61838782\n",
      "step: 1810, loss:0.85489625\n",
      "step: 1811, loss:0.43547037\n",
      "step: 1812, loss:0.62117988\n",
      "step: 1813, loss:1.11144590\n",
      "step: 1814, loss:0.56375527\n",
      "step: 1815, loss:0.53312737\n",
      "step: 1816, loss:0.38132522\n",
      "step: 1817, loss:0.27500600\n",
      "step: 1818, loss:0.38704020\n",
      "step: 1819, loss:0.32110730\n",
      "step: 1820, loss:1.07787323\n",
      "step: 1821, loss:0.52759886\n",
      "step: 1822, loss:0.56095022\n",
      "step: 1823, loss:0.53191626\n",
      "step: 1824, loss:0.28108945\n",
      "step: 1825, loss:0.46186876\n",
      "step: 1826, loss:0.30637175\n",
      "step: 1827, loss:0.44807664\n",
      "step: 1828, loss:0.72424561\n",
      "step: 1829, loss:0.60963064\n",
      "step: 1830, loss:0.53208113\n",
      "step: 1831, loss:0.92188090\n",
      "step: 1832, loss:0.40726754\n",
      "step: 1833, loss:0.75887698\n",
      "step: 1834, loss:0.71534467\n",
      "step: 1835, loss:0.39085144\n",
      "step: 1836, loss:0.56050855\n",
      "step: 1837, loss:0.45860198\n",
      "step: 1838, loss:0.62594849\n",
      "step: 1839, loss:0.48751971\n",
      "step: 1840, loss:0.52017719\n",
      "step: 1841, loss:0.73188084\n",
      "step: 1842, loss:0.73468298\n",
      "step: 1843, loss:0.66477424\n",
      "step: 1844, loss:0.75544947\n",
      "step: 1845, loss:0.59217966\n",
      "step: 1846, loss:0.66111052\n",
      "step: 1847, loss:0.55785763\n",
      "step: 1848, loss:0.71170002\n",
      "step: 1849, loss:0.47451964\n",
      "step: 1850, loss:0.53830397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:17:21,378 - INFO - step:1850, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1851, loss:0.56460822\n",
      "step: 1852, loss:0.54232800\n",
      "step: 1853, loss:0.45849124\n",
      "step: 1854, loss:0.48480603\n",
      "step: 1855, loss:0.56497622\n",
      "step: 1856, loss:0.59486806\n",
      "step: 1857, loss:0.56471378\n",
      "step: 1858, loss:0.56481349\n",
      "step: 1859, loss:0.49584907\n",
      "step: 1860, loss:0.76969808\n",
      "step: 1861, loss:0.62878144\n",
      "step: 1862, loss:0.68150234\n",
      "step: 1863, loss:0.63502264\n",
      "step: 1864, loss:0.63281661\n",
      "step: 1865, loss:0.59889907\n",
      "step: 1866, loss:0.59149063\n",
      "step: 1867, loss:0.71599716\n",
      "step: 1868, loss:0.65742040\n",
      "step: 1869, loss:0.63219732\n",
      "step: 1870, loss:0.50649464\n",
      "step: 1871, loss:0.65289032\n",
      "step: 1872, loss:0.69410670\n",
      "step: 1873, loss:0.62442243\n",
      "step: 1874, loss:0.56529105\n",
      "step: 1875, loss:0.56283480\n",
      "step: 1876, loss:0.73363143\n",
      "step: 1877, loss:0.51203454\n",
      "step: 1878, loss:0.62271273\n",
      "step: 1879, loss:0.53877693\n",
      "step: 1880, loss:0.60248291\n",
      "step: 1881, loss:0.83479261\n",
      "step: 1882, loss:0.70624119\n",
      "step: 1883, loss:0.71593076\n",
      "step: 1884, loss:0.56988931\n",
      "step: 1885, loss:0.72576958\n",
      "step: 1886, loss:0.74052638\n",
      "step: 1887, loss:0.57941645\n",
      "step: 1888, loss:0.61621583\n",
      "step: 1889, loss:0.66436827\n",
      "step: 1890, loss:0.69264603\n",
      "step: 1891, loss:0.60317564\n",
      "step: 1892, loss:0.60413778\n",
      "step: 1893, loss:0.64100194\n",
      "step: 1894, loss:0.44016495\n",
      "step: 1895, loss:0.71369553\n",
      "step: 1896, loss:0.54007274\n",
      "step: 1897, loss:0.53354341\n",
      "step: 1898, loss:0.62643695\n",
      "step: 1899, loss:0.79946935\n",
      "step: 1900, loss:0.76838434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:17:46,784 - INFO - step:1900, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1901, loss:0.65672910\n",
      "step: 1902, loss:0.71046007\n",
      "step: 1903, loss:0.74236453\n",
      "step: 1904, loss:0.79743069\n",
      "step: 1905, loss:0.70233035\n",
      "step: 1906, loss:0.58423144\n",
      "step: 1907, loss:0.70193803\n",
      "step: 1908, loss:0.55702293\n",
      "step: 1909, loss:0.50592095\n",
      "step: 1910, loss:0.58670735\n",
      "step: 1911, loss:0.64529878\n",
      "step: 1912, loss:0.69985652\n",
      "step: 1913, loss:0.68191308\n",
      "step: 1914, loss:0.61804008\n",
      "step: 1915, loss:0.58282942\n",
      "step: 1916, loss:0.69894111\n",
      "step: 1917, loss:0.70168763\n",
      "step: 1918, loss:0.64645368\n",
      "step: 1919, loss:0.72001314\n",
      "step: 1920, loss:0.68064702\n",
      "step: 1921, loss:0.64653814\n",
      "step: 1922, loss:0.73826563\n",
      "step: 1923, loss:0.55546731\n",
      "step: 1924, loss:0.61185896\n",
      "step: 1925, loss:0.61250556\n",
      "step: 1926, loss:0.58878934\n",
      "step: 1927, loss:0.56265199\n",
      "step: 1928, loss:0.79279184\n",
      "step: 1929, loss:0.71398413\n",
      "step: 1930, loss:0.78741825\n",
      "step: 1931, loss:0.65431190\n",
      "step: 1932, loss:0.66111046\n",
      "step: 1933, loss:0.70368344\n",
      "step: 1934, loss:0.72992498\n",
      "step: 1935, loss:0.67620873\n",
      "step: 1936, loss:0.69444466\n",
      "step: 1937, loss:0.66508198\n",
      "step: 1938, loss:0.68448943\n",
      "step: 1939, loss:0.53617024\n",
      "step: 1940, loss:0.72107828\n",
      "step: 1941, loss:0.60886282\n",
      "step: 1942, loss:0.64914161\n",
      "step: 1943, loss:0.57431412\n",
      "step: 1944, loss:0.63375783\n",
      "step: 1945, loss:0.62829494\n",
      "step: 1946, loss:0.54985750\n",
      "step: 1947, loss:0.56424534\n",
      "step: 1948, loss:0.64893973\n",
      "step: 1949, loss:0.64865315\n",
      "step: 1950, loss:0.64585727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:18:12,559 - INFO - step:1950, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1951, loss:0.54233277\n",
      "step: 1952, loss:0.49516395\n",
      "step: 1953, loss:0.51104409\n",
      "step: 1954, loss:0.55829173\n",
      "step: 1955, loss:0.63997805\n",
      "step: 1956, loss:0.83695966\n",
      "step: 1957, loss:0.72183836\n",
      "step: 1958, loss:0.77896738\n",
      "step: 1959, loss:0.57089281\n",
      "step: 1960, loss:0.72471160\n",
      "step: 1961, loss:0.61864656\n",
      "step: 1962, loss:0.83189452\n",
      "step: 1963, loss:0.64434850\n",
      "step: 1964, loss:0.77729672\n",
      "step: 1965, loss:0.71070033\n",
      "step: 1966, loss:0.50918221\n",
      "step: 1967, loss:0.58791995\n",
      "step: 1968, loss:0.49235091\n",
      "step: 1969, loss:0.74607897\n",
      "step: 1970, loss:0.58033401\n",
      "step: 1971, loss:0.64362073\n",
      "step: 1972, loss:0.52725065\n",
      "step: 1973, loss:0.60137051\n",
      "step: 1974, loss:0.77012140\n",
      "step: 1975, loss:0.60048503\n",
      "step: 1976, loss:0.68150413\n",
      "step: 1977, loss:0.61071867\n",
      "step: 1978, loss:0.57638359\n",
      "step: 1979, loss:0.71337545\n",
      "step: 1980, loss:0.52155769\n",
      "step: 1981, loss:0.51339227\n",
      "step: 1982, loss:0.51262516\n",
      "step: 1983, loss:0.64649081\n",
      "step: 1984, loss:0.60231471\n",
      "step: 1985, loss:0.75685984\n",
      "step: 1986, loss:0.54655778\n",
      "step: 1987, loss:0.64715910\n",
      "step: 1988, loss:0.62261879\n",
      "step: 1989, loss:0.51973289\n",
      "step: 1990, loss:0.56910586\n",
      "step: 1991, loss:0.64752316\n",
      "step: 1992, loss:0.46016097\n",
      "step: 1993, loss:0.51250595\n",
      "step: 1994, loss:0.49328804\n",
      "step: 1995, loss:0.40144312\n",
      "step: 1996, loss:0.44702128\n",
      "step: 1997, loss:0.47703055\n",
      "step: 1998, loss:0.72586673\n",
      "step: 1999, loss:0.72310585\n",
      "step: 2000, loss:0.36040032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:18:38,579 - INFO - step:2000, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 2001, loss:0.70765895\n",
      "step: 2002, loss:0.78147548\n",
      "step: 2003, loss:0.52825725\n",
      "step: 2004, loss:0.49521920\n",
      "step: 2005, loss:0.84508973\n",
      "step: 2006, loss:0.63196993\n",
      "step: 2007, loss:0.53162110\n",
      "step: 2008, loss:0.63351965\n",
      "step: 2009, loss:0.59130466\n",
      "step: 2010, loss:0.72262651\n",
      "step: 2011, loss:0.62592036\n",
      "step: 2012, loss:0.85047477\n",
      "step: 2013, loss:0.68329352\n",
      "step: 2014, loss:0.78813219\n",
      "step: 2015, loss:0.56456935\n",
      "step: 2016, loss:0.80377769\n",
      "step: 2017, loss:0.64092869\n",
      "step: 2018, loss:0.52457350\n",
      "step: 2019, loss:0.80490285\n",
      "step: 2020, loss:0.53891551\n",
      "step: 2021, loss:0.62800092\n",
      "step: 2022, loss:0.54350424\n",
      "step: 2023, loss:0.55854738\n",
      "step: 2024, loss:0.59028345\n",
      "step: 2025, loss:0.60536534\n",
      "step: 2026, loss:0.53149462\n",
      "step: 2027, loss:0.63599235\n",
      "step: 2028, loss:0.61567098\n",
      "step: 2029, loss:0.61983997\n",
      "step: 2030, loss:0.59529275\n",
      "step: 2031, loss:0.60422677\n",
      "step: 2032, loss:0.65051955\n",
      "step: 2033, loss:0.57049894\n",
      "step: 2034, loss:0.45951200\n",
      "step: 2035, loss:0.48544416\n",
      "step: 2036, loss:0.64822793\n",
      "step: 2037, loss:0.63060743\n",
      "step: 2038, loss:0.47695905\n",
      "step: 2039, loss:0.39847252\n",
      "step: 2040, loss:0.56025827\n",
      "step: 2041, loss:0.56356537\n",
      "step: 2042, loss:0.74666744\n",
      "step: 2043, loss:0.56873131\n",
      "step: 2044, loss:0.57364881\n",
      "step: 2045, loss:0.70952874\n",
      "step: 2046, loss:0.78047568\n",
      "step: 2047, loss:0.73547244\n",
      "step: 2048, loss:0.46585846\n",
      "step: 2049, loss:0.69150722\n",
      "step: 2050, loss:0.68628669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:19:04,114 - INFO - step:2050, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 2051, loss:0.56051779\n",
      "step: 2052, loss:0.57173228\n",
      "step: 2053, loss:0.53896189\n",
      "step: 2054, loss:0.40578899\n",
      "step: 2055, loss:0.43575615\n",
      "step: 2056, loss:0.38207451\n",
      "step: 2057, loss:0.46880716\n",
      "step: 2058, loss:0.47916219\n",
      "step: 2059, loss:0.50912404\n",
      "step: 2060, loss:0.50372273\n",
      "step: 2061, loss:0.39983931\n",
      "step: 2062, loss:0.56301326\n",
      "step: 2063, loss:0.56509125\n",
      "step: 2064, loss:0.77951765\n",
      "step: 2065, loss:0.74526030\n",
      "step: 2066, loss:0.51124293\n",
      "step: 2067, loss:0.41219297\n",
      "step: 2068, loss:0.75437009\n",
      "step: 2069, loss:0.41327140\n",
      "step: 2070, loss:0.52101117\n",
      "step: 2071, loss:0.45279151\n",
      "step: 2072, loss:0.50287253\n",
      "step: 2073, loss:0.25644395\n",
      "step: 2074, loss:0.57119071\n",
      "step: 2075, loss:0.57939953\n",
      "step: 2076, loss:0.40406179\n",
      "step: 2077, loss:0.61069405\n",
      "step: 2078, loss:0.83508730\n",
      "step: 2079, loss:0.44295055\n",
      "step: 2080, loss:0.60756075\n",
      "step: 2081, loss:1.07133067\n",
      "step: 2082, loss:0.57477021\n",
      "step: 2083, loss:0.51938605\n",
      "step: 2084, loss:0.37962890\n",
      "step: 2085, loss:0.27679861\n",
      "step: 2086, loss:0.38725391\n",
      "step: 2087, loss:0.31144306\n",
      "step: 2088, loss:1.08441067\n",
      "step: 2089, loss:0.52647233\n",
      "step: 2090, loss:0.56922257\n",
      "step: 2091, loss:0.52870679\n",
      "step: 2092, loss:0.27969331\n",
      "step: 2093, loss:0.45928928\n",
      "step: 2094, loss:0.30971134\n",
      "step: 2095, loss:0.45292932\n",
      "step: 2096, loss:0.71493608\n",
      "step: 2097, loss:0.60367596\n",
      "step: 2098, loss:0.52295893\n",
      "step: 2099, loss:0.91564095\n",
      "step: 2100, loss:0.41502345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:19:29,634 - INFO - step:2100, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 2101, loss:0.75573784\n",
      "step: 2102, loss:0.71045321\n",
      "step: 2103, loss:0.37901479\n",
      "step: 2104, loss:0.55713385\n",
      "step: 2105, loss:0.45906287\n",
      "step: 2106, loss:0.63366359\n",
      "step: 2107, loss:0.48702908\n",
      "step: 2108, loss:0.52700263\n",
      "step: 2109, loss:0.74677914\n",
      "step: 2110, loss:0.72983748\n",
      "step: 2111, loss:0.67262650\n",
      "step: 2112, loss:0.76797563\n",
      "step: 2113, loss:0.59539127\n",
      "step: 2114, loss:0.65291476\n",
      "step: 2115, loss:0.56597412\n",
      "step: 2116, loss:0.72127086\n",
      "step: 2117, loss:0.47561941\n",
      "step: 2118, loss:0.53482950\n",
      "step: 2119, loss:0.56567848\n",
      "step: 2120, loss:0.53599590\n",
      "step: 2121, loss:0.45546418\n",
      "step: 2122, loss:0.48387870\n",
      "step: 2123, loss:0.57040936\n",
      "step: 2124, loss:0.58970666\n",
      "step: 2125, loss:0.56936306\n",
      "step: 2126, loss:0.56540847\n",
      "step: 2127, loss:0.50965661\n",
      "step: 2128, loss:0.77837348\n",
      "step: 2129, loss:0.62617910\n",
      "step: 2130, loss:0.68323082\n",
      "step: 2131, loss:0.62528747\n",
      "step: 2132, loss:0.62862694\n",
      "step: 2133, loss:0.59360296\n",
      "step: 2134, loss:0.59333229\n",
      "step: 2135, loss:0.71549857\n",
      "step: 2136, loss:0.65407544\n",
      "step: 2137, loss:0.61849648\n",
      "step: 2138, loss:0.51060557\n",
      "step: 2139, loss:0.65787095\n",
      "step: 2140, loss:0.71053630\n",
      "step: 2141, loss:0.62987530\n",
      "step: 2142, loss:0.56753963\n",
      "step: 2143, loss:0.55966043\n",
      "step: 2144, loss:0.72801983\n",
      "step: 2145, loss:0.51121807\n",
      "step: 2146, loss:0.62510395\n",
      "step: 2147, loss:0.54640633\n",
      "step: 2148, loss:0.58306694\n",
      "step: 2149, loss:0.83159322\n",
      "step: 2150, loss:0.70270348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:19:55,339 - INFO - step:2150, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 2151, loss:0.71724224\n",
      "step: 2152, loss:0.56910676\n",
      "step: 2153, loss:0.72700137\n",
      "step: 2154, loss:0.74230611\n",
      "step: 2155, loss:0.57484275\n",
      "step: 2156, loss:0.62519461\n",
      "step: 2157, loss:0.66803885\n",
      "step: 2158, loss:0.68950397\n",
      "step: 2159, loss:0.60248685\n",
      "step: 2160, loss:0.60536021\n",
      "step: 2161, loss:0.64197034\n",
      "step: 2162, loss:0.42190063\n",
      "step: 2163, loss:0.73403430\n",
      "step: 2164, loss:0.53994548\n",
      "step: 2165, loss:0.54338408\n",
      "step: 2166, loss:0.61931789\n",
      "step: 2167, loss:0.81137818\n",
      "step: 2168, loss:0.77905160\n",
      "step: 2169, loss:0.66671622\n",
      "step: 2170, loss:0.71048254\n",
      "step: 2171, loss:0.72869349\n",
      "step: 2172, loss:0.79622293\n",
      "step: 2173, loss:0.70136869\n",
      "step: 2174, loss:0.58562559\n",
      "step: 2175, loss:0.70435429\n",
      "step: 2176, loss:0.54810500\n",
      "step: 2177, loss:0.49436975\n",
      "step: 2178, loss:0.59392601\n",
      "step: 2179, loss:0.64109474\n",
      "step: 2180, loss:0.70362914\n",
      "step: 2181, loss:0.67785847\n",
      "step: 2182, loss:0.62621075\n",
      "step: 2183, loss:0.58145881\n",
      "step: 2184, loss:0.70844102\n",
      "step: 2185, loss:0.68597203\n",
      "step: 2186, loss:0.63911581\n",
      "step: 2187, loss:0.72178781\n",
      "step: 2188, loss:0.67766118\n",
      "step: 2189, loss:0.64506578\n",
      "step: 2190, loss:0.74385387\n",
      "step: 2191, loss:0.55240083\n",
      "step: 2192, loss:0.60181266\n",
      "step: 2193, loss:0.60644746\n",
      "step: 2194, loss:0.58039021\n",
      "step: 2195, loss:0.56970149\n",
      "step: 2196, loss:0.79158241\n",
      "step: 2197, loss:0.71617240\n",
      "step: 2198, loss:0.78244847\n",
      "step: 2199, loss:0.66968966\n",
      "step: 2200, loss:0.66440845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:20:21,067 - INFO - step:2200, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 2201, loss:0.70461977\n",
      "step: 2202, loss:0.74000323\n",
      "step: 2203, loss:0.68251407\n",
      "step: 2204, loss:0.69943655\n",
      "step: 2205, loss:0.65846997\n",
      "step: 2206, loss:0.69407797\n",
      "step: 2207, loss:0.53483963\n",
      "step: 2208, loss:0.72363371\n",
      "step: 2209, loss:0.60882926\n",
      "step: 2210, loss:0.64943135\n",
      "step: 2211, loss:0.57088119\n",
      "step: 2212, loss:0.63262105\n",
      "step: 2213, loss:0.63402987\n",
      "step: 2214, loss:0.55137539\n",
      "step: 2215, loss:0.56483048\n",
      "step: 2216, loss:0.64700180\n",
      "step: 2217, loss:0.63519895\n",
      "step: 2218, loss:0.64581150\n",
      "step: 2219, loss:0.54208779\n",
      "step: 2220, loss:0.50864869\n",
      "step: 2221, loss:0.51704150\n",
      "step: 2222, loss:0.55438411\n",
      "step: 2223, loss:0.64799333\n",
      "step: 2224, loss:0.83175898\n",
      "step: 2225, loss:0.71343422\n",
      "step: 2226, loss:0.77281129\n",
      "step: 2227, loss:0.57223308\n",
      "step: 2228, loss:0.72570109\n",
      "step: 2229, loss:0.61596942\n",
      "step: 2230, loss:0.83612317\n",
      "step: 2231, loss:0.64636570\n",
      "step: 2232, loss:0.77662140\n",
      "step: 2233, loss:0.72857815\n",
      "step: 2234, loss:0.49759611\n",
      "step: 2235, loss:0.57664549\n",
      "step: 2236, loss:0.48099074\n",
      "step: 2237, loss:0.74986547\n",
      "step: 2238, loss:0.58046573\n",
      "step: 2239, loss:0.64086074\n",
      "step: 2240, loss:0.51553738\n",
      "step: 2241, loss:0.59796077\n",
      "step: 2242, loss:0.77261013\n",
      "step: 2243, loss:0.59701592\n",
      "step: 2244, loss:0.67614365\n",
      "step: 2245, loss:0.60047483\n",
      "step: 2246, loss:0.58150983\n",
      "step: 2247, loss:0.70971924\n",
      "step: 2248, loss:0.51105380\n",
      "step: 2249, loss:0.50855076\n",
      "step: 2250, loss:0.51489395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:20:46,848 - INFO - step:2250, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 2251, loss:0.64601642\n",
      "step: 2252, loss:0.59415680\n",
      "step: 2253, loss:0.76434547\n",
      "step: 2254, loss:0.55287272\n",
      "step: 2255, loss:0.64010525\n",
      "step: 2256, loss:0.62413985\n",
      "step: 2257, loss:0.51887727\n",
      "step: 2258, loss:0.57372963\n",
      "step: 2259, loss:0.64470661\n",
      "step: 2260, loss:0.46979797\n",
      "step: 2261, loss:0.51482248\n",
      "step: 2262, loss:0.48513219\n",
      "step: 2263, loss:0.41090617\n",
      "step: 2264, loss:0.46342397\n",
      "step: 2265, loss:0.48985395\n",
      "step: 2266, loss:0.71292424\n",
      "step: 2267, loss:0.71805775\n",
      "step: 2268, loss:0.37359169\n",
      "step: 2269, loss:0.68554527\n",
      "step: 2270, loss:0.75286955\n",
      "step: 2271, loss:0.52847451\n",
      "step: 2272, loss:0.49641943\n",
      "step: 2273, loss:0.83200365\n",
      "step: 2274, loss:0.62916279\n",
      "step: 2275, loss:0.52928436\n",
      "step: 2276, loss:0.61715066\n",
      "step: 2277, loss:0.59356230\n",
      "step: 2278, loss:0.71757579\n",
      "step: 2279, loss:0.62511182\n",
      "step: 2280, loss:0.87576509\n",
      "step: 2281, loss:0.68174213\n",
      "step: 2282, loss:0.80801809\n",
      "step: 2283, loss:0.56329149\n",
      "step: 2284, loss:0.79539216\n",
      "step: 2285, loss:0.64179534\n",
      "step: 2286, loss:0.52080631\n",
      "step: 2287, loss:0.81144929\n",
      "step: 2288, loss:0.53447354\n",
      "step: 2289, loss:0.62896782\n",
      "step: 2290, loss:0.53338265\n",
      "step: 2291, loss:0.56238770\n",
      "step: 2292, loss:0.58196962\n",
      "step: 2293, loss:0.59995067\n",
      "step: 2294, loss:0.52940577\n",
      "step: 2295, loss:0.63215584\n",
      "step: 2296, loss:0.62437052\n",
      "step: 2297, loss:0.62463027\n",
      "step: 2298, loss:0.59764522\n",
      "step: 2299, loss:0.59994763\n",
      "step: 2300, loss:0.63508457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:21:12,484 - INFO - step:2300, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 2301, loss:0.56713235\n",
      "step: 2302, loss:0.46734253\n",
      "step: 2303, loss:0.48547286\n",
      "step: 2304, loss:0.65153039\n",
      "step: 2305, loss:0.62224591\n",
      "step: 2306, loss:0.48423165\n",
      "step: 2307, loss:0.41820544\n",
      "step: 2308, loss:0.56579989\n",
      "step: 2309, loss:0.56294137\n",
      "step: 2310, loss:0.71095079\n",
      "step: 2311, loss:0.56188333\n",
      "step: 2312, loss:0.55397874\n",
      "step: 2313, loss:0.70301396\n",
      "step: 2314, loss:0.75927114\n",
      "step: 2315, loss:0.72949702\n",
      "step: 2316, loss:0.47140962\n",
      "step: 2317, loss:0.67967904\n",
      "step: 2318, loss:0.68459916\n",
      "step: 2319, loss:0.56921101\n",
      "step: 2320, loss:0.56563115\n",
      "step: 2321, loss:0.53445768\n",
      "step: 2322, loss:0.39084274\n",
      "step: 2323, loss:0.41783023\n",
      "step: 2324, loss:0.35919169\n",
      "step: 2325, loss:0.43973386\n",
      "step: 2326, loss:0.47497451\n",
      "step: 2327, loss:0.49199697\n",
      "step: 2328, loss:0.50013208\n",
      "step: 2329, loss:0.38315475\n",
      "step: 2330, loss:0.56629014\n",
      "step: 2331, loss:0.56356156\n",
      "step: 2332, loss:0.79851264\n",
      "step: 2333, loss:0.77499193\n",
      "step: 2334, loss:0.52642304\n",
      "step: 2335, loss:0.41532177\n",
      "step: 2336, loss:0.76055634\n",
      "step: 2337, loss:0.41099083\n",
      "step: 2338, loss:0.53268164\n",
      "step: 2339, loss:0.44730484\n",
      "step: 2340, loss:0.49804458\n",
      "step: 2341, loss:0.25378460\n",
      "step: 2342, loss:0.56083995\n",
      "step: 2343, loss:0.56630093\n",
      "step: 2344, loss:0.40195602\n",
      "step: 2345, loss:0.60280371\n",
      "step: 2346, loss:0.83160210\n",
      "step: 2347, loss:0.44367412\n",
      "step: 2348, loss:0.60584456\n",
      "step: 2349, loss:1.05336010\n",
      "step: 2350, loss:0.56127697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:21:38,120 - INFO - step:2350, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 2351, loss:0.52365541\n",
      "step: 2352, loss:0.38671857\n",
      "step: 2353, loss:0.27716705\n",
      "step: 2354, loss:0.38315445\n",
      "step: 2355, loss:0.30816403\n",
      "step: 2356, loss:1.07658696\n",
      "step: 2357, loss:0.52663672\n",
      "step: 2358, loss:0.55247670\n",
      "step: 2359, loss:0.53239572\n",
      "step: 2360, loss:0.27720422\n",
      "step: 2361, loss:0.46082690\n",
      "step: 2362, loss:0.31206682\n",
      "step: 2363, loss:0.45242289\n",
      "step: 2364, loss:0.70883113\n",
      "step: 2365, loss:0.60989118\n",
      "step: 2366, loss:0.52578682\n",
      "step: 2367, loss:0.90640163\n",
      "step: 2368, loss:0.41329011\n",
      "step: 2369, loss:0.75201285\n",
      "step: 2370, loss:0.71404922\n",
      "step: 2371, loss:0.38353670\n",
      "step: 2372, loss:0.55296659\n",
      "step: 2373, loss:0.45117584\n",
      "step: 2374, loss:0.64146668\n",
      "step: 2375, loss:0.48884255\n",
      "step: 2376, loss:0.52403677\n",
      "step: 2377, loss:0.74845952\n",
      "step: 2378, loss:0.73177230\n",
      "step: 2379, loss:0.67532986\n",
      "step: 2380, loss:0.76060969\n",
      "step: 2381, loss:0.58898258\n",
      "step: 2382, loss:0.65811902\n",
      "step: 2383, loss:0.55859441\n",
      "step: 2384, loss:0.71828538\n",
      "step: 2385, loss:0.46925798\n",
      "step: 2386, loss:0.53553838\n",
      "step: 2387, loss:0.55322343\n",
      "step: 2388, loss:0.53454870\n",
      "step: 2389, loss:0.44043666\n",
      "step: 2390, loss:0.49216771\n",
      "step: 2391, loss:0.57113683\n",
      "step: 2392, loss:0.58967054\n",
      "step: 2393, loss:0.58019346\n",
      "step: 2394, loss:0.56325799\n",
      "step: 2395, loss:0.49895024\n",
      "step: 2396, loss:0.79303247\n",
      "step: 2397, loss:0.62362516\n",
      "step: 2398, loss:0.68452603\n",
      "step: 2399, loss:0.62641579\n",
      "step: 2400, loss:0.62777621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:22:03,956 - INFO - step:2400, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 2401, loss:0.59663731\n",
      "step: 2402, loss:0.59270227\n",
      "step: 2403, loss:0.71551043\n",
      "step: 2404, loss:0.65607756\n",
      "step: 2405, loss:0.61661845\n",
      "step: 2406, loss:0.51635402\n",
      "step: 2407, loss:0.65700185\n",
      "step: 2408, loss:0.70788479\n",
      "step: 2409, loss:0.63398784\n",
      "step: 2410, loss:0.56655312\n",
      "step: 2411, loss:0.58265132\n",
      "step: 2412, loss:0.73714060\n",
      "step: 2413, loss:0.51759863\n",
      "step: 2414, loss:0.62332261\n",
      "step: 2415, loss:0.54125977\n",
      "step: 2416, loss:0.59247124\n",
      "step: 2417, loss:0.84774441\n",
      "step: 2418, loss:0.70394856\n",
      "step: 2419, loss:0.72431123\n",
      "step: 2420, loss:0.57087648\n",
      "step: 2421, loss:0.72290105\n",
      "step: 2422, loss:0.73992658\n",
      "step: 2423, loss:0.57770121\n",
      "step: 2424, loss:0.61541182\n",
      "step: 2425, loss:0.66781133\n",
      "step: 2426, loss:0.68492383\n",
      "step: 2427, loss:0.60039473\n",
      "step: 2428, loss:0.59986585\n",
      "step: 2429, loss:0.63262856\n",
      "step: 2430, loss:0.41930124\n",
      "step: 2431, loss:0.71989286\n",
      "step: 2432, loss:0.53577918\n",
      "step: 2433, loss:0.53566182\n",
      "step: 2434, loss:0.61284566\n",
      "step: 2435, loss:0.79208964\n",
      "step: 2436, loss:0.77769184\n",
      "step: 2437, loss:0.66127449\n",
      "step: 2438, loss:0.71192682\n",
      "step: 2439, loss:0.73103112\n",
      "step: 2440, loss:0.79079717\n",
      "step: 2441, loss:0.70972806\n",
      "step: 2442, loss:0.58888352\n",
      "step: 2443, loss:0.70388538\n",
      "step: 2444, loss:0.55450875\n",
      "step: 2445, loss:0.50831550\n",
      "step: 2446, loss:0.59299779\n",
      "step: 2447, loss:0.64473754\n",
      "step: 2448, loss:0.70535898\n",
      "step: 2449, loss:0.68422353\n",
      "step: 2450, loss:0.62361938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:22:29,505 - INFO - step:2450, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 2451, loss:0.58853674\n",
      "step: 2452, loss:0.70253479\n",
      "step: 2453, loss:0.67743146\n",
      "step: 2454, loss:0.64115816\n",
      "step: 2455, loss:0.72348249\n",
      "step: 2456, loss:0.68698424\n",
      "step: 2457, loss:0.64806414\n",
      "step: 2458, loss:0.73042828\n",
      "step: 2459, loss:0.55870777\n",
      "step: 2460, loss:0.61250675\n",
      "step: 2461, loss:0.60133415\n",
      "step: 2462, loss:0.58346057\n",
      "step: 2463, loss:0.56801957\n",
      "step: 2464, loss:0.79676092\n",
      "step: 2465, loss:0.72733927\n",
      "step: 2466, loss:0.78616786\n",
      "step: 2467, loss:0.66172212\n",
      "step: 2468, loss:0.65894014\n",
      "step: 2469, loss:0.69808948\n",
      "step: 2470, loss:0.73516107\n",
      "step: 2471, loss:0.67853487\n",
      "step: 2472, loss:0.69789362\n",
      "step: 2473, loss:0.66364241\n",
      "step: 2474, loss:0.68808836\n",
      "step: 2475, loss:0.53576404\n",
      "step: 2476, loss:0.71484905\n",
      "step: 2477, loss:0.60870069\n",
      "step: 2478, loss:0.64947420\n",
      "step: 2479, loss:0.58238482\n",
      "step: 2480, loss:0.63170540\n",
      "step: 2481, loss:0.63324893\n",
      "step: 2482, loss:0.55011153\n",
      "step: 2483, loss:0.56410712\n",
      "step: 2484, loss:0.64422971\n",
      "step: 2485, loss:0.64659107\n",
      "step: 2486, loss:0.64270175\n",
      "step: 2487, loss:0.54663169\n",
      "step: 2488, loss:0.49331617\n",
      "step: 2489, loss:0.51547706\n",
      "step: 2490, loss:0.55017024\n",
      "step: 2491, loss:0.64709204\n",
      "step: 2492, loss:0.84046715\n",
      "step: 2493, loss:0.73010224\n",
      "step: 2494, loss:0.77006572\n",
      "step: 2495, loss:0.57913744\n",
      "step: 2496, loss:0.71598339\n",
      "step: 2497, loss:0.61912692\n",
      "step: 2498, loss:0.84221286\n",
      "step: 2499, loss:0.64885992\n",
      "step: 2500, loss:0.78913760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:22:55,131 - INFO - step:2500, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 2501, loss:0.73742282\n",
      "step: 2502, loss:0.48460209\n",
      "step: 2503, loss:0.57310200\n",
      "step: 2504, loss:0.46696803\n",
      "step: 2505, loss:0.76491886\n",
      "step: 2506, loss:0.58475119\n",
      "step: 2507, loss:0.64306080\n",
      "step: 2508, loss:0.51851684\n",
      "step: 2509, loss:0.60864800\n",
      "step: 2510, loss:0.78335434\n",
      "step: 2511, loss:0.60493219\n",
      "step: 2512, loss:0.67943603\n",
      "step: 2513, loss:0.59915113\n",
      "step: 2514, loss:0.57392836\n",
      "step: 2515, loss:0.71482712\n",
      "step: 2516, loss:0.51027024\n",
      "step: 2517, loss:0.51605982\n",
      "step: 2518, loss:0.50574440\n",
      "step: 2519, loss:0.64534390\n",
      "step: 2520, loss:0.60040104\n",
      "step: 2521, loss:0.75937289\n",
      "step: 2522, loss:0.54521835\n",
      "step: 2523, loss:0.65115285\n",
      "step: 2524, loss:0.61395526\n",
      "step: 2525, loss:0.52497625\n",
      "step: 2526, loss:0.57694787\n",
      "step: 2527, loss:0.64231801\n",
      "step: 2528, loss:0.47425410\n",
      "step: 2529, loss:0.52001202\n",
      "step: 2530, loss:0.49521902\n",
      "step: 2531, loss:0.40961459\n",
      "step: 2532, loss:0.45671526\n",
      "step: 2533, loss:0.48718202\n",
      "step: 2534, loss:0.70944583\n",
      "step: 2535, loss:0.71378702\n",
      "step: 2536, loss:0.38576299\n",
      "step: 2537, loss:0.68407756\n",
      "step: 2538, loss:0.75180626\n",
      "step: 2539, loss:0.52474070\n",
      "step: 2540, loss:0.49043137\n",
      "step: 2541, loss:0.82321537\n",
      "step: 2542, loss:0.62842548\n",
      "step: 2543, loss:0.53574175\n",
      "step: 2544, loss:0.62707990\n",
      "step: 2545, loss:0.59782922\n",
      "step: 2546, loss:0.73081028\n",
      "step: 2547, loss:0.62473118\n",
      "step: 2548, loss:0.87288749\n",
      "step: 2549, loss:0.68720734\n",
      "step: 2550, loss:0.80554265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:23:20,859 - INFO - step:2550, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 2551, loss:0.57129699\n",
      "step: 2552, loss:0.81591165\n",
      "step: 2553, loss:0.65152931\n",
      "step: 2554, loss:0.51595920\n",
      "step: 2555, loss:0.82255834\n",
      "step: 2556, loss:0.53022033\n",
      "step: 2557, loss:0.62215269\n",
      "step: 2558, loss:0.52020764\n",
      "step: 2559, loss:0.55486917\n",
      "step: 2560, loss:0.56624311\n",
      "step: 2561, loss:0.60209829\n",
      "step: 2562, loss:0.53036398\n",
      "step: 2563, loss:0.63992101\n",
      "step: 2564, loss:0.62263286\n",
      "step: 2565, loss:0.62513041\n",
      "step: 2566, loss:0.60785061\n",
      "step: 2567, loss:0.59923208\n",
      "step: 2568, loss:0.64976084\n",
      "step: 2569, loss:0.56934536\n",
      "step: 2570, loss:0.47723043\n",
      "step: 2571, loss:0.49976638\n",
      "step: 2572, loss:0.64605027\n",
      "step: 2573, loss:0.62163717\n",
      "step: 2574, loss:0.49027804\n",
      "step: 2575, loss:0.44058928\n",
      "step: 2576, loss:0.56555700\n",
      "step: 2577, loss:0.56075275\n",
      "step: 2578, loss:0.71290910\n",
      "step: 2579, loss:0.56444359\n",
      "step: 2580, loss:0.56888688\n",
      "step: 2581, loss:0.68045312\n",
      "step: 2582, loss:0.75334108\n",
      "step: 2583, loss:0.71490890\n",
      "step: 2584, loss:0.48087549\n",
      "step: 2585, loss:0.67310458\n",
      "step: 2586, loss:0.68585527\n",
      "step: 2587, loss:0.56131476\n",
      "step: 2588, loss:0.56099260\n",
      "step: 2589, loss:0.53922987\n",
      "step: 2590, loss:0.39234838\n",
      "step: 2591, loss:0.41630483\n",
      "step: 2592, loss:0.36248645\n",
      "step: 2593, loss:0.45341134\n",
      "step: 2594, loss:0.47418341\n",
      "step: 2595, loss:0.50622094\n",
      "step: 2596, loss:0.49406266\n",
      "step: 2597, loss:0.39248422\n",
      "step: 2598, loss:0.56806719\n",
      "step: 2599, loss:0.57784653\n",
      "step: 2600, loss:0.80112058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:23:46,570 - INFO - step:2600, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 2601, loss:0.76368099\n",
      "step: 2602, loss:0.53222305\n",
      "step: 2603, loss:0.41037521\n",
      "step: 2604, loss:0.75474316\n",
      "step: 2605, loss:0.40961814\n",
      "step: 2606, loss:0.53674144\n",
      "step: 2607, loss:0.44964948\n",
      "step: 2608, loss:0.48866868\n",
      "step: 2609, loss:0.25775626\n",
      "step: 2610, loss:0.55782121\n",
      "step: 2611, loss:0.56763309\n",
      "step: 2612, loss:0.40218225\n",
      "step: 2613, loss:0.60213143\n",
      "step: 2614, loss:0.81779623\n",
      "step: 2615, loss:0.44954345\n",
      "step: 2616, loss:0.61997330\n",
      "step: 2617, loss:1.04645276\n",
      "step: 2618, loss:0.56873041\n",
      "step: 2619, loss:0.53009504\n",
      "step: 2620, loss:0.38011357\n",
      "step: 2621, loss:0.26740533\n",
      "step: 2622, loss:0.37316471\n",
      "step: 2623, loss:0.30103996\n",
      "step: 2624, loss:1.09534907\n",
      "step: 2625, loss:0.52994883\n",
      "step: 2626, loss:0.56450027\n",
      "step: 2627, loss:0.51709569\n",
      "step: 2628, loss:0.27046499\n",
      "step: 2629, loss:0.45166436\n",
      "step: 2630, loss:0.30374071\n",
      "step: 2631, loss:0.44889632\n",
      "step: 2632, loss:0.70818669\n",
      "step: 2633, loss:0.60658848\n",
      "step: 2634, loss:0.52881467\n",
      "step: 2635, loss:0.92499495\n",
      "step: 2636, loss:0.40360510\n",
      "step: 2637, loss:0.76489609\n",
      "step: 2638, loss:0.71891266\n",
      "step: 2639, loss:0.37387633\n",
      "step: 2640, loss:0.55968255\n",
      "step: 2641, loss:0.45640054\n",
      "step: 2642, loss:0.63595420\n",
      "step: 2643, loss:0.49194869\n",
      "step: 2644, loss:0.52827060\n",
      "step: 2645, loss:0.74469805\n",
      "step: 2646, loss:0.74405003\n",
      "step: 2647, loss:0.66685277\n",
      "step: 2648, loss:0.76363456\n",
      "step: 2649, loss:0.60118413\n",
      "step: 2650, loss:0.66624302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:24:12,655 - INFO - step:2650, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 2651, loss:0.55688810\n",
      "step: 2652, loss:0.72196519\n",
      "step: 2653, loss:0.47266129\n",
      "step: 2654, loss:0.53117901\n",
      "step: 2655, loss:0.56788903\n",
      "step: 2656, loss:0.53575355\n",
      "step: 2657, loss:0.44384775\n",
      "step: 2658, loss:0.47246966\n",
      "step: 2659, loss:0.56845450\n",
      "step: 2660, loss:0.59822333\n",
      "step: 2661, loss:0.55947280\n",
      "step: 2662, loss:0.55534410\n",
      "step: 2663, loss:0.51413727\n",
      "step: 2664, loss:0.77141631\n",
      "step: 2665, loss:0.61557811\n",
      "step: 2666, loss:0.68340373\n",
      "step: 2667, loss:0.62541932\n",
      "step: 2668, loss:0.63119972\n",
      "step: 2669, loss:0.59968156\n",
      "step: 2670, loss:0.59173036\n",
      "step: 2671, loss:0.71098542\n",
      "step: 2672, loss:0.66118610\n",
      "step: 2673, loss:0.62218696\n",
      "step: 2674, loss:0.51452971\n",
      "step: 2675, loss:0.64772701\n",
      "step: 2676, loss:0.70824498\n",
      "step: 2677, loss:0.62211156\n",
      "step: 2678, loss:0.56562996\n",
      "step: 2679, loss:0.56807053\n",
      "step: 2680, loss:0.73879665\n",
      "step: 2681, loss:0.51086485\n",
      "step: 2682, loss:0.61714172\n",
      "step: 2683, loss:0.54428041\n",
      "step: 2684, loss:0.59479159\n",
      "step: 2685, loss:0.84139669\n",
      "step: 2686, loss:0.70680624\n",
      "step: 2687, loss:0.72347713\n",
      "step: 2688, loss:0.57109499\n",
      "step: 2689, loss:0.72259963\n",
      "step: 2690, loss:0.75444686\n",
      "step: 2691, loss:0.56512880\n",
      "step: 2692, loss:0.61853391\n",
      "step: 2693, loss:0.66947496\n",
      "step: 2694, loss:0.68879068\n",
      "step: 2695, loss:0.59161168\n",
      "step: 2696, loss:0.60255176\n",
      "step: 2697, loss:0.64146829\n",
      "step: 2698, loss:0.40902743\n",
      "step: 2699, loss:0.74321043\n",
      "step: 2700, loss:0.53188682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:24:38,207 - INFO - step:2700, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 2701, loss:0.53246933\n",
      "step: 2702, loss:0.62734807\n",
      "step: 2703, loss:0.79821718\n",
      "step: 2704, loss:0.77991617\n",
      "step: 2705, loss:0.66669726\n",
      "step: 2706, loss:0.72252029\n",
      "step: 2707, loss:0.74055308\n",
      "step: 2708, loss:0.80462021\n",
      "step: 2709, loss:0.70483148\n",
      "step: 2710, loss:0.58501244\n",
      "step: 2711, loss:0.69594413\n",
      "step: 2712, loss:0.55683911\n",
      "step: 2713, loss:0.49442190\n",
      "step: 2714, loss:0.58920360\n",
      "step: 2715, loss:0.65257531\n",
      "step: 2716, loss:0.70243746\n",
      "step: 2717, loss:0.68749827\n",
      "step: 2718, loss:0.62643087\n",
      "step: 2719, loss:0.58610916\n",
      "step: 2720, loss:0.71148133\n",
      "step: 2721, loss:0.69251049\n",
      "step: 2722, loss:0.64335650\n",
      "step: 2723, loss:0.72526777\n",
      "step: 2724, loss:0.67875236\n",
      "step: 2725, loss:0.64852256\n",
      "step: 2726, loss:0.74135751\n",
      "step: 2727, loss:0.54965514\n",
      "step: 2728, loss:0.60453463\n",
      "step: 2729, loss:0.60592204\n",
      "step: 2730, loss:0.59111440\n",
      "step: 2731, loss:0.57654947\n",
      "step: 2732, loss:0.80222619\n",
      "step: 2733, loss:0.72945207\n",
      "step: 2734, loss:0.78367847\n",
      "step: 2735, loss:0.65855688\n",
      "step: 2736, loss:0.66035718\n",
      "step: 2737, loss:0.69269598\n",
      "step: 2738, loss:0.73493952\n",
      "step: 2739, loss:0.67929357\n",
      "step: 2740, loss:0.69399583\n",
      "step: 2741, loss:0.65539300\n",
      "step: 2742, loss:0.69752562\n",
      "step: 2743, loss:0.52596760\n",
      "step: 2744, loss:0.72372103\n",
      "step: 2745, loss:0.60626572\n",
      "step: 2746, loss:0.64754999\n",
      "step: 2747, loss:0.57773715\n",
      "step: 2748, loss:0.63345915\n",
      "step: 2749, loss:0.61950839\n",
      "step: 2750, loss:0.54414785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:25:03,882 - INFO - step:2750, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 2751, loss:0.55353725\n",
      "step: 2752, loss:0.64538044\n",
      "step: 2753, loss:0.64729041\n",
      "step: 2754, loss:0.65020674\n",
      "step: 2755, loss:0.54424399\n",
      "step: 2756, loss:0.49105728\n",
      "step: 2757, loss:0.50866157\n",
      "step: 2758, loss:0.55747533\n",
      "step: 2759, loss:0.63331038\n",
      "step: 2760, loss:0.82020944\n",
      "step: 2761, loss:0.71691906\n",
      "step: 2762, loss:0.77135390\n",
      "step: 2763, loss:0.57118911\n",
      "step: 2764, loss:0.72213584\n",
      "step: 2765, loss:0.61999524\n",
      "step: 2766, loss:0.83265799\n",
      "step: 2767, loss:0.64790732\n",
      "step: 2768, loss:0.78546727\n",
      "step: 2769, loss:0.73810369\n",
      "step: 2770, loss:0.47852507\n",
      "step: 2771, loss:0.58280480\n",
      "step: 2772, loss:0.46357274\n",
      "step: 2773, loss:0.76006657\n",
      "step: 2774, loss:0.57874411\n",
      "step: 2775, loss:0.65259874\n",
      "step: 2776, loss:0.50964707\n",
      "step: 2777, loss:0.59908026\n",
      "step: 2778, loss:0.78230369\n",
      "step: 2779, loss:0.59567487\n",
      "step: 2780, loss:0.68938369\n",
      "step: 2781, loss:0.60972708\n",
      "step: 2782, loss:0.57530302\n",
      "step: 2783, loss:0.70309103\n",
      "step: 2784, loss:0.51295263\n",
      "step: 2785, loss:0.50495428\n",
      "step: 2786, loss:0.51576161\n",
      "step: 2787, loss:0.64430034\n",
      "step: 2788, loss:0.59731817\n",
      "step: 2789, loss:0.76415074\n",
      "step: 2790, loss:0.55205566\n",
      "step: 2791, loss:0.64909798\n",
      "step: 2792, loss:0.62405866\n",
      "step: 2793, loss:0.52922356\n",
      "step: 2794, loss:0.57913244\n",
      "step: 2795, loss:0.64453065\n",
      "step: 2796, loss:0.47854134\n",
      "step: 2797, loss:0.53558558\n",
      "step: 2798, loss:0.49624038\n",
      "step: 2799, loss:0.42615229\n",
      "step: 2800, loss:0.46859050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:25:29,505 - INFO - step:2800, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 2801, loss:0.48892608\n",
      "step: 2802, loss:0.70079768\n",
      "step: 2803, loss:0.70211607\n",
      "step: 2804, loss:0.40747833\n",
      "step: 2805, loss:0.68134719\n",
      "step: 2806, loss:0.72805345\n",
      "step: 2807, loss:0.53662592\n",
      "step: 2808, loss:0.50924098\n",
      "step: 2809, loss:0.80195332\n",
      "step: 2810, loss:0.61786938\n",
      "step: 2811, loss:0.54471797\n",
      "step: 2812, loss:0.62323081\n",
      "step: 2813, loss:0.59760439\n",
      "step: 2814, loss:0.70772964\n",
      "step: 2815, loss:0.61797923\n",
      "step: 2816, loss:0.86134261\n",
      "step: 2817, loss:0.68500882\n",
      "step: 2818, loss:0.78545570\n",
      "step: 2819, loss:0.56624621\n",
      "step: 2820, loss:0.80980295\n",
      "step: 2821, loss:0.65888160\n",
      "step: 2822, loss:0.51677805\n",
      "step: 2823, loss:0.83905298\n",
      "step: 2824, loss:0.52232528\n",
      "step: 2825, loss:0.62126839\n",
      "step: 2826, loss:0.53108984\n",
      "step: 2827, loss:0.54537892\n",
      "step: 2828, loss:0.56993145\n",
      "step: 2829, loss:0.59556079\n",
      "step: 2830, loss:0.52045208\n",
      "step: 2831, loss:0.65283459\n",
      "step: 2832, loss:0.62496966\n",
      "step: 2833, loss:0.62405068\n",
      "step: 2834, loss:0.59707862\n",
      "step: 2835, loss:0.59059209\n",
      "step: 2836, loss:0.65107697\n",
      "step: 2837, loss:0.56385857\n",
      "step: 2838, loss:0.46786535\n",
      "step: 2839, loss:0.50291741\n",
      "step: 2840, loss:0.64757335\n",
      "step: 2841, loss:0.62575185\n",
      "step: 2842, loss:0.48832068\n",
      "step: 2843, loss:0.43905562\n",
      "step: 2844, loss:0.56658149\n",
      "step: 2845, loss:0.56433713\n",
      "step: 2846, loss:0.70604938\n",
      "step: 2847, loss:0.57232440\n",
      "step: 2848, loss:0.57409465\n",
      "step: 2849, loss:0.67577040\n",
      "step: 2850, loss:0.74128973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:25:55,251 - INFO - step:2850, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 2851, loss:0.70756340\n",
      "step: 2852, loss:0.49097449\n",
      "step: 2853, loss:0.68016207\n",
      "step: 2854, loss:0.67778599\n",
      "step: 2855, loss:0.56185442\n",
      "step: 2856, loss:0.56743670\n",
      "step: 2857, loss:0.54011649\n",
      "step: 2858, loss:0.40300918\n",
      "step: 2859, loss:0.42744336\n",
      "step: 2860, loss:0.36929834\n",
      "step: 2861, loss:0.45137542\n",
      "step: 2862, loss:0.46613091\n",
      "step: 2863, loss:0.50625235\n",
      "step: 2864, loss:0.50545079\n",
      "step: 2865, loss:0.41411155\n",
      "step: 2866, loss:0.55561829\n",
      "step: 2867, loss:0.56524622\n",
      "step: 2868, loss:0.76088923\n",
      "step: 2869, loss:0.72696483\n",
      "step: 2870, loss:0.53040320\n",
      "step: 2871, loss:0.43084377\n",
      "step: 2872, loss:0.73246670\n",
      "step: 2873, loss:0.42817342\n",
      "step: 2874, loss:0.52440578\n",
      "step: 2875, loss:0.46320963\n",
      "step: 2876, loss:0.48860493\n",
      "step: 2877, loss:0.27889442\n",
      "step: 2878, loss:0.57497621\n",
      "step: 2879, loss:0.56336373\n",
      "step: 2880, loss:0.41565377\n",
      "step: 2881, loss:0.60414809\n",
      "step: 2882, loss:0.79927045\n",
      "step: 2883, loss:0.45586586\n",
      "step: 2884, loss:0.59001899\n",
      "step: 2885, loss:1.04151464\n",
      "step: 2886, loss:0.55919540\n",
      "step: 2887, loss:0.52055919\n",
      "step: 2888, loss:0.37394318\n",
      "step: 2889, loss:0.26814401\n",
      "step: 2890, loss:0.37250343\n",
      "step: 2891, loss:0.30079597\n",
      "step: 2892, loss:1.09553254\n",
      "step: 2893, loss:0.51940185\n",
      "step: 2894, loss:0.56910807\n",
      "step: 2895, loss:0.52236265\n",
      "step: 2896, loss:0.26422155\n",
      "step: 2897, loss:0.44610548\n",
      "step: 2898, loss:0.29400587\n",
      "step: 2899, loss:0.44611484\n",
      "step: 2900, loss:0.72107118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:26:21,229 - INFO - step:2900, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 2901, loss:0.61039561\n",
      "step: 2902, loss:0.52241182\n",
      "step: 2903, loss:0.93152839\n",
      "step: 2904, loss:0.41227421\n",
      "step: 2905, loss:0.76435578\n",
      "step: 2906, loss:0.71903431\n",
      "step: 2907, loss:0.37507799\n",
      "step: 2908, loss:0.56960142\n",
      "step: 2909, loss:0.45494530\n",
      "step: 2910, loss:0.64165473\n",
      "step: 2911, loss:0.49871477\n",
      "step: 2912, loss:0.52165234\n",
      "step: 2913, loss:0.73082697\n",
      "step: 2914, loss:0.75160277\n",
      "step: 2915, loss:0.67104477\n",
      "step: 2916, loss:0.77176303\n",
      "step: 2917, loss:0.58215350\n",
      "step: 2918, loss:0.67145467\n",
      "step: 2919, loss:0.56212223\n",
      "step: 2920, loss:0.73583561\n",
      "step: 2921, loss:0.46497750\n",
      "step: 2922, loss:0.53035378\n",
      "step: 2923, loss:0.56445956\n",
      "step: 2924, loss:0.52735573\n",
      "step: 2925, loss:0.43498653\n",
      "step: 2926, loss:0.47233522\n",
      "step: 2927, loss:0.56768250\n",
      "step: 2928, loss:0.59733832\n",
      "step: 2929, loss:0.56339788\n",
      "step: 2930, loss:0.56147850\n",
      "step: 2931, loss:0.49633801\n",
      "step: 2932, loss:0.78724784\n",
      "step: 2933, loss:0.61959177\n",
      "step: 2934, loss:0.68637234\n",
      "step: 2935, loss:0.62426412\n",
      "step: 2936, loss:0.63490027\n",
      "step: 2937, loss:0.59364855\n",
      "step: 2938, loss:0.59192902\n",
      "step: 2939, loss:0.72158211\n",
      "step: 2940, loss:0.66492748\n",
      "step: 2941, loss:0.62551290\n",
      "step: 2942, loss:0.50862259\n",
      "step: 2943, loss:0.66337812\n",
      "step: 2944, loss:0.71464837\n",
      "step: 2945, loss:0.62751186\n",
      "step: 2946, loss:0.56787276\n",
      "step: 2947, loss:0.56403768\n",
      "step: 2948, loss:0.72961223\n",
      "step: 2949, loss:0.50319725\n",
      "step: 2950, loss:0.61946744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:26:46,890 - INFO - step:2950, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 2951, loss:0.53966504\n",
      "step: 2952, loss:0.59899992\n",
      "step: 2953, loss:0.85139310\n",
      "step: 2954, loss:0.71064335\n",
      "step: 2955, loss:0.72512084\n",
      "step: 2956, loss:0.56178051\n",
      "step: 2957, loss:0.72963303\n",
      "step: 2958, loss:0.75309193\n",
      "step: 2959, loss:0.56989974\n",
      "step: 2960, loss:0.62877989\n",
      "step: 2961, loss:0.68043745\n",
      "step: 2962, loss:0.70746291\n",
      "step: 2963, loss:0.59810048\n",
      "step: 2964, loss:0.60322714\n",
      "step: 2965, loss:0.64353788\n",
      "step: 2966, loss:0.38372362\n",
      "step: 2967, loss:0.74198353\n",
      "step: 2968, loss:0.52361488\n",
      "step: 2969, loss:0.53053117\n",
      "step: 2970, loss:0.62135661\n",
      "step: 2971, loss:0.81279218\n",
      "step: 2972, loss:0.79247916\n",
      "step: 2973, loss:0.66596806\n",
      "step: 2974, loss:0.71786040\n",
      "step: 2975, loss:0.73424774\n",
      "step: 2976, loss:0.81063229\n",
      "step: 2977, loss:0.70817989\n",
      "step: 2978, loss:0.58358389\n",
      "step: 2979, loss:0.70052123\n",
      "step: 2980, loss:0.53828752\n",
      "step: 2981, loss:0.48469067\n",
      "step: 2982, loss:0.57815731\n",
      "step: 2983, loss:0.64554179\n",
      "step: 2984, loss:0.69856459\n",
      "step: 2985, loss:0.67901450\n",
      "step: 2986, loss:0.63072854\n",
      "step: 2987, loss:0.59012419\n",
      "step: 2988, loss:0.70022619\n",
      "step: 2989, loss:0.68592221\n",
      "step: 2990, loss:0.64863783\n",
      "step: 2991, loss:0.71527493\n",
      "step: 2992, loss:0.69193649\n",
      "step: 2993, loss:0.63870215\n",
      "step: 2994, loss:0.74642634\n",
      "step: 2995, loss:0.55546629\n",
      "step: 2996, loss:0.61214328\n",
      "step: 2997, loss:0.60882795\n",
      "step: 2998, loss:0.58429998\n",
      "step: 2999, loss:0.58077770\n",
      "step: 3000, loss:0.79789650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:27:12,625 - INFO - step:3000, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 3001, loss:0.72280002\n",
      "step: 3002, loss:0.77434880\n",
      "step: 3003, loss:0.66304165\n",
      "step: 3004, loss:0.67223620\n",
      "step: 3005, loss:0.69679147\n",
      "step: 3006, loss:0.73995525\n",
      "step: 3007, loss:0.67820942\n",
      "step: 3008, loss:0.68592423\n",
      "step: 3009, loss:0.67145181\n",
      "step: 3010, loss:0.69387114\n",
      "step: 3011, loss:0.52904606\n",
      "step: 3012, loss:0.72194898\n",
      "step: 3013, loss:0.60059506\n",
      "step: 3014, loss:0.63791537\n",
      "step: 3015, loss:0.56980908\n",
      "step: 3016, loss:0.63357818\n",
      "step: 3017, loss:0.63088715\n",
      "step: 3018, loss:0.54887670\n",
      "step: 3019, loss:0.56271291\n",
      "step: 3020, loss:0.63456440\n",
      "step: 3021, loss:0.64440763\n",
      "step: 3022, loss:0.64723778\n",
      "step: 3023, loss:0.54809248\n",
      "step: 3024, loss:0.50612569\n",
      "step: 3025, loss:0.51806062\n",
      "step: 3026, loss:0.55815274\n",
      "step: 3027, loss:0.64263368\n",
      "step: 3028, loss:0.83197719\n",
      "step: 3029, loss:0.70401061\n",
      "step: 3030, loss:0.76385576\n",
      "step: 3031, loss:0.58461159\n",
      "step: 3032, loss:0.71242529\n",
      "step: 3033, loss:0.62435037\n",
      "step: 3034, loss:0.83578384\n",
      "step: 3035, loss:0.64032507\n",
      "step: 3036, loss:0.77970350\n",
      "step: 3037, loss:0.74218839\n",
      "step: 3038, loss:0.48540863\n",
      "step: 3039, loss:0.58194947\n",
      "step: 3040, loss:0.47271049\n",
      "step: 3041, loss:0.74794358\n",
      "step: 3042, loss:0.57614893\n",
      "step: 3043, loss:0.65016520\n",
      "step: 3044, loss:0.50802398\n",
      "step: 3045, loss:0.60043913\n",
      "step: 3046, loss:0.77830124\n",
      "step: 3047, loss:0.59687418\n",
      "step: 3048, loss:0.69804996\n",
      "step: 3049, loss:0.59994304\n",
      "step: 3050, loss:0.57441956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:27:38,503 - INFO - step:3050, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 3051, loss:0.71111470\n",
      "step: 3052, loss:0.50752777\n",
      "step: 3053, loss:0.50394595\n",
      "step: 3054, loss:0.50916266\n",
      "step: 3055, loss:0.64723063\n",
      "step: 3056, loss:0.60609239\n",
      "step: 3057, loss:0.75657892\n",
      "step: 3058, loss:0.54695743\n",
      "step: 3059, loss:0.64467013\n",
      "step: 3060, loss:0.62208587\n",
      "step: 3061, loss:0.53159100\n",
      "step: 3062, loss:0.57409221\n",
      "step: 3063, loss:0.63864362\n",
      "step: 3064, loss:0.47726947\n",
      "step: 3065, loss:0.52282876\n",
      "step: 3066, loss:0.50633818\n",
      "step: 3067, loss:0.42473674\n",
      "step: 3068, loss:0.46728796\n",
      "step: 3069, loss:0.48595750\n",
      "step: 3070, loss:0.69306493\n",
      "step: 3071, loss:0.70081520\n",
      "step: 3072, loss:0.40728277\n",
      "step: 3073, loss:0.67266911\n",
      "step: 3074, loss:0.72715926\n",
      "step: 3075, loss:0.54038751\n",
      "step: 3076, loss:0.51309758\n",
      "step: 3077, loss:0.79004019\n",
      "step: 3078, loss:0.62093395\n",
      "step: 3079, loss:0.53866571\n",
      "step: 3080, loss:0.62616801\n",
      "step: 3081, loss:0.59341878\n",
      "step: 3082, loss:0.70478868\n",
      "step: 3083, loss:0.62403917\n",
      "step: 3084, loss:0.84490037\n",
      "step: 3085, loss:0.68345314\n",
      "step: 3086, loss:0.79699856\n",
      "step: 3087, loss:0.57181561\n",
      "step: 3088, loss:0.81251705\n",
      "step: 3089, loss:0.65207946\n",
      "step: 3090, loss:0.51168245\n",
      "step: 3091, loss:0.83112168\n",
      "step: 3092, loss:0.51708496\n",
      "step: 3093, loss:0.62528211\n",
      "step: 3094, loss:0.51666141\n",
      "step: 3095, loss:0.54872257\n",
      "step: 3096, loss:0.57327294\n",
      "step: 3097, loss:0.60041940\n",
      "step: 3098, loss:0.51886094\n",
      "step: 3099, loss:0.64973211\n",
      "step: 3100, loss:0.61642134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:28:04,360 - INFO - step:3100, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 3101, loss:0.61222154\n",
      "step: 3102, loss:0.59225386\n",
      "step: 3103, loss:0.59694272\n",
      "step: 3104, loss:0.64915538\n",
      "step: 3105, loss:0.57053566\n",
      "step: 3106, loss:0.46517816\n",
      "step: 3107, loss:0.49848863\n",
      "step: 3108, loss:0.64949459\n",
      "step: 3109, loss:0.61952955\n",
      "step: 3110, loss:0.48741677\n",
      "step: 3111, loss:0.43741053\n",
      "step: 3112, loss:0.56913763\n",
      "step: 3113, loss:0.56468916\n",
      "step: 3114, loss:0.70878446\n",
      "step: 3115, loss:0.56211179\n",
      "step: 3116, loss:0.56460458\n",
      "step: 3117, loss:0.68341476\n",
      "step: 3118, loss:0.73435563\n",
      "step: 3119, loss:0.70082968\n",
      "step: 3120, loss:0.48491761\n",
      "step: 3121, loss:0.67306054\n",
      "step: 3122, loss:0.67633599\n",
      "step: 3123, loss:0.57057565\n",
      "step: 3124, loss:0.56294328\n",
      "step: 3125, loss:0.54029429\n",
      "step: 3126, loss:0.40398803\n",
      "step: 3127, loss:0.41666898\n",
      "step: 3128, loss:0.37048921\n",
      "step: 3129, loss:0.44556770\n",
      "step: 3130, loss:0.47444099\n",
      "step: 3131, loss:0.50512445\n",
      "step: 3132, loss:0.50652891\n",
      "step: 3133, loss:0.41677031\n",
      "step: 3134, loss:0.56031036\n",
      "step: 3135, loss:0.56254512\n",
      "step: 3136, loss:0.75984502\n",
      "step: 3137, loss:0.73000342\n",
      "step: 3138, loss:0.53158647\n",
      "step: 3139, loss:0.42196530\n",
      "step: 3140, loss:0.73088682\n",
      "step: 3141, loss:0.42914164\n",
      "step: 3142, loss:0.52499646\n",
      "step: 3143, loss:0.46077141\n",
      "step: 3144, loss:0.50632858\n",
      "step: 3145, loss:0.28698412\n",
      "step: 3146, loss:0.56368637\n",
      "step: 3147, loss:0.56503260\n",
      "step: 3148, loss:0.42036059\n",
      "step: 3149, loss:0.58689886\n",
      "step: 3150, loss:0.78279734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:28:30,150 - INFO - step:3150, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 3151, loss:0.46661016\n",
      "step: 3152, loss:0.60324401\n",
      "step: 3153, loss:1.03719020\n",
      "step: 3154, loss:0.57160449\n",
      "step: 3155, loss:0.52343202\n",
      "step: 3156, loss:0.36962610\n",
      "step: 3157, loss:0.27305031\n",
      "step: 3158, loss:0.38975051\n",
      "step: 3159, loss:0.30220199\n",
      "step: 3160, loss:1.09487176\n",
      "step: 3161, loss:0.52174914\n",
      "step: 3162, loss:0.56797463\n",
      "step: 3163, loss:0.52069366\n",
      "step: 3164, loss:0.26815784\n",
      "step: 3165, loss:0.45755747\n",
      "step: 3166, loss:0.30598152\n",
      "step: 3167, loss:0.45504177\n",
      "step: 3168, loss:0.73084819\n",
      "step: 3169, loss:0.61666512\n",
      "step: 3170, loss:0.52764791\n",
      "step: 3171, loss:0.93732542\n",
      "step: 3172, loss:0.40111038\n",
      "step: 3173, loss:0.75045347\n",
      "step: 3174, loss:0.72668791\n",
      "step: 3175, loss:0.36999679\n",
      "step: 3176, loss:0.55752563\n",
      "step: 3177, loss:0.45865765\n",
      "step: 3178, loss:0.63777512\n",
      "step: 3179, loss:0.49446419\n",
      "step: 3180, loss:0.52068371\n",
      "step: 3181, loss:0.73929197\n",
      "step: 3182, loss:0.75250036\n",
      "step: 3183, loss:0.67734903\n",
      "step: 3184, loss:0.78222418\n",
      "step: 3185, loss:0.59182584\n",
      "step: 3186, loss:0.66907144\n",
      "step: 3187, loss:0.57166159\n",
      "step: 3188, loss:0.73523003\n",
      "step: 3189, loss:0.46276787\n",
      "step: 3190, loss:0.53305316\n",
      "step: 3191, loss:0.56100792\n",
      "step: 3192, loss:0.52626079\n",
      "step: 3193, loss:0.42910251\n",
      "step: 3194, loss:0.46971983\n",
      "step: 3195, loss:0.56338382\n",
      "step: 3196, loss:0.59216160\n",
      "step: 3197, loss:0.56434017\n",
      "step: 3198, loss:0.56575400\n",
      "step: 3199, loss:0.50181973\n",
      "step: 3200, loss:0.78834903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:28:56,350 - INFO - step:3200, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 3201, loss:0.62538195\n",
      "step: 3202, loss:0.68694144\n",
      "step: 3203, loss:0.62816674\n",
      "step: 3204, loss:0.62277710\n",
      "step: 3205, loss:0.60050303\n",
      "step: 3206, loss:0.60083985\n",
      "step: 3207, loss:0.70939845\n",
      "step: 3208, loss:0.65508008\n",
      "step: 3209, loss:0.62134379\n",
      "step: 3210, loss:0.50121439\n",
      "step: 3211, loss:0.65332186\n",
      "step: 3212, loss:0.70996141\n",
      "step: 3213, loss:0.63304061\n",
      "step: 3214, loss:0.56779832\n",
      "step: 3215, loss:0.55836964\n",
      "step: 3216, loss:0.74333733\n",
      "step: 3217, loss:0.50694519\n",
      "step: 3218, loss:0.62262148\n",
      "step: 3219, loss:0.54535365\n",
      "step: 3220, loss:0.59109044\n",
      "step: 3221, loss:0.85473812\n",
      "step: 3222, loss:0.71402305\n",
      "step: 3223, loss:0.73112535\n",
      "step: 3224, loss:0.56095123\n",
      "step: 3225, loss:0.73255581\n",
      "step: 3226, loss:0.75815016\n",
      "step: 3227, loss:0.56179321\n",
      "step: 3228, loss:0.61027509\n",
      "step: 3229, loss:0.67327577\n",
      "step: 3230, loss:0.69636244\n",
      "step: 3231, loss:0.59132278\n",
      "step: 3232, loss:0.59605718\n",
      "step: 3233, loss:0.64530700\n",
      "step: 3234, loss:0.37385425\n",
      "step: 3235, loss:0.74769473\n",
      "step: 3236, loss:0.52318233\n",
      "step: 3237, loss:0.52626061\n",
      "step: 3238, loss:0.62862110\n",
      "step: 3239, loss:0.81717908\n",
      "step: 3240, loss:0.78533524\n",
      "step: 3241, loss:0.66428733\n",
      "step: 3242, loss:0.72352177\n",
      "step: 3243, loss:0.73553711\n",
      "step: 3244, loss:0.80991566\n",
      "step: 3245, loss:0.69994944\n",
      "step: 3246, loss:0.58212733\n",
      "step: 3247, loss:0.71277237\n",
      "step: 3248, loss:0.54105401\n",
      "step: 3249, loss:0.48385727\n",
      "step: 3250, loss:0.58772248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:29:22,174 - INFO - step:3250, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 3251, loss:0.64591771\n",
      "step: 3252, loss:0.70180190\n",
      "step: 3253, loss:0.68312633\n",
      "step: 3254, loss:0.62590098\n",
      "step: 3255, loss:0.57941705\n",
      "step: 3256, loss:0.70260352\n",
      "step: 3257, loss:0.67752802\n",
      "step: 3258, loss:0.64005846\n",
      "step: 3259, loss:0.71168596\n",
      "step: 3260, loss:0.68137091\n",
      "step: 3261, loss:0.64749873\n",
      "step: 3262, loss:0.75037730\n",
      "step: 3263, loss:0.55711496\n",
      "step: 3264, loss:0.61644435\n",
      "step: 3265, loss:0.61020082\n",
      "step: 3266, loss:0.60155773\n",
      "step: 3267, loss:0.56605196\n",
      "step: 3268, loss:0.79646105\n",
      "step: 3269, loss:0.72646207\n",
      "step: 3270, loss:0.78452313\n",
      "step: 3271, loss:0.67292476\n",
      "step: 3272, loss:0.66127938\n",
      "step: 3273, loss:0.69620812\n",
      "step: 3274, loss:0.73832792\n",
      "step: 3275, loss:0.66863137\n",
      "step: 3276, loss:0.70048934\n",
      "step: 3277, loss:0.66412872\n",
      "step: 3278, loss:0.69115448\n",
      "step: 3279, loss:0.52120221\n",
      "step: 3280, loss:0.72152025\n",
      "step: 3281, loss:0.60741997\n",
      "step: 3282, loss:0.64983791\n",
      "step: 3283, loss:0.57683587\n",
      "step: 3284, loss:0.64418465\n",
      "step: 3285, loss:0.62011260\n",
      "step: 3286, loss:0.54648405\n",
      "step: 3287, loss:0.57917839\n",
      "step: 3288, loss:0.65063632\n",
      "step: 3289, loss:0.64304554\n",
      "step: 3290, loss:0.65017772\n",
      "step: 3291, loss:0.55125087\n",
      "step: 3292, loss:0.49674034\n",
      "step: 3293, loss:0.51488382\n",
      "step: 3294, loss:0.56330407\n",
      "step: 3295, loss:0.64096057\n",
      "step: 3296, loss:0.83100754\n",
      "step: 3297, loss:0.71335310\n",
      "step: 3298, loss:0.75949049\n",
      "step: 3299, loss:0.56935221\n",
      "step: 3300, loss:0.72649723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:29:48,172 - INFO - step:3300, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 3301, loss:0.62416321\n",
      "step: 3302, loss:0.83554912\n",
      "step: 3303, loss:0.64762378\n",
      "step: 3304, loss:0.77717876\n",
      "step: 3305, loss:0.74287689\n",
      "step: 3306, loss:0.48672324\n",
      "step: 3307, loss:0.57649624\n",
      "step: 3308, loss:0.46730664\n",
      "step: 3309, loss:0.76723510\n",
      "step: 3310, loss:0.57005620\n",
      "step: 3311, loss:0.64608192\n",
      "step: 3312, loss:0.51119769\n",
      "step: 3313, loss:0.59694523\n",
      "step: 3314, loss:0.77904153\n",
      "step: 3315, loss:0.60165322\n",
      "step: 3316, loss:0.70051825\n",
      "step: 3317, loss:0.60302633\n",
      "step: 3318, loss:0.57271653\n",
      "step: 3319, loss:0.71811444\n",
      "step: 3320, loss:0.50565529\n",
      "step: 3321, loss:0.50562763\n",
      "step: 3322, loss:0.50717151\n",
      "step: 3323, loss:0.64311779\n",
      "step: 3324, loss:0.58867300\n",
      "step: 3325, loss:0.76289254\n",
      "step: 3326, loss:0.55035913\n",
      "step: 3327, loss:0.64629167\n",
      "step: 3328, loss:0.62394357\n",
      "step: 3329, loss:0.52736139\n",
      "step: 3330, loss:0.58101410\n",
      "step: 3331, loss:0.64585304\n",
      "step: 3332, loss:0.48016596\n",
      "step: 3333, loss:0.52036864\n",
      "step: 3334, loss:0.50903350\n",
      "step: 3335, loss:0.42646903\n",
      "step: 3336, loss:0.46673292\n",
      "step: 3337, loss:0.49477467\n",
      "step: 3338, loss:0.69612527\n",
      "step: 3339, loss:0.69626915\n",
      "step: 3340, loss:0.41323492\n",
      "step: 3341, loss:0.66562873\n",
      "step: 3342, loss:0.72532207\n",
      "step: 3343, loss:0.54375696\n",
      "step: 3344, loss:0.51290011\n",
      "step: 3345, loss:0.78108615\n",
      "step: 3346, loss:0.62897241\n",
      "step: 3347, loss:0.53578043\n",
      "step: 3348, loss:0.61693555\n",
      "step: 3349, loss:0.59578204\n",
      "step: 3350, loss:0.70102268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:30:14,214 - INFO - step:3350, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 3351, loss:0.62801421\n",
      "step: 3352, loss:0.84466588\n",
      "step: 3353, loss:0.67406911\n",
      "step: 3354, loss:0.79192704\n",
      "step: 3355, loss:0.57037652\n",
      "step: 3356, loss:0.82045400\n",
      "step: 3357, loss:0.65550435\n",
      "step: 3358, loss:0.51912743\n",
      "step: 3359, loss:0.83258206\n",
      "step: 3360, loss:0.52017808\n",
      "step: 3361, loss:0.62768167\n",
      "step: 3362, loss:0.51552838\n",
      "step: 3363, loss:0.54605281\n",
      "step: 3364, loss:0.56782544\n",
      "step: 3365, loss:0.59599417\n",
      "step: 3366, loss:0.51688206\n",
      "step: 3367, loss:0.64555699\n",
      "step: 3368, loss:0.62957573\n",
      "step: 3369, loss:0.62791967\n",
      "step: 3370, loss:0.59525621\n",
      "step: 3371, loss:0.60285103\n",
      "step: 3372, loss:0.65641445\n",
      "step: 3373, loss:0.56910056\n",
      "step: 3374, loss:0.46759379\n",
      "step: 3375, loss:0.49367318\n",
      "step: 3376, loss:0.65089542\n",
      "step: 3377, loss:0.62311691\n",
      "step: 3378, loss:0.48885968\n",
      "step: 3379, loss:0.43443453\n",
      "step: 3380, loss:0.57165360\n",
      "step: 3381, loss:0.56729269\n",
      "step: 3382, loss:0.69787765\n",
      "step: 3383, loss:0.56639558\n",
      "step: 3384, loss:0.56290972\n",
      "step: 3385, loss:0.68240684\n",
      "step: 3386, loss:0.73850465\n",
      "step: 3387, loss:0.70319772\n",
      "step: 3388, loss:0.48175257\n",
      "step: 3389, loss:0.67779028\n",
      "step: 3390, loss:0.67802650\n",
      "step: 3391, loss:0.56983364\n",
      "step: 3392, loss:0.57427657\n",
      "step: 3393, loss:0.54617631\n",
      "step: 3394, loss:0.40160549\n",
      "step: 3395, loss:0.42915982\n",
      "step: 3396, loss:0.38591909\n",
      "step: 3397, loss:0.45637685\n",
      "step: 3398, loss:0.47908184\n",
      "step: 3399, loss:0.50590742\n",
      "step: 3400, loss:0.50978857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:30:40,149 - INFO - step:3400, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 3401, loss:0.42344534\n",
      "step: 3402, loss:0.55444849\n",
      "step: 3403, loss:0.56062341\n",
      "step: 3404, loss:0.75609380\n",
      "step: 3405, loss:0.70665711\n",
      "step: 3406, loss:0.52520192\n",
      "step: 3407, loss:0.44619477\n",
      "step: 3408, loss:0.72020978\n",
      "step: 3409, loss:0.43975264\n",
      "step: 3410, loss:0.53378594\n",
      "step: 3411, loss:0.46928439\n",
      "step: 3412, loss:0.50511450\n",
      "step: 3413, loss:0.31241196\n",
      "step: 3414, loss:0.57113296\n",
      "step: 3415, loss:0.56812817\n",
      "step: 3416, loss:0.44037229\n",
      "step: 3417, loss:0.60033953\n",
      "step: 3418, loss:0.76510274\n",
      "step: 3419, loss:0.46747226\n",
      "step: 3420, loss:0.59926915\n",
      "step: 3421, loss:0.96575582\n",
      "step: 3422, loss:0.56316262\n",
      "step: 3423, loss:0.52649087\n",
      "step: 3424, loss:0.39164615\n",
      "step: 3425, loss:0.29498556\n",
      "step: 3426, loss:0.39370209\n",
      "step: 3427, loss:0.32616967\n",
      "step: 3428, loss:1.06026280\n",
      "step: 3429, loss:0.52769309\n",
      "step: 3430, loss:0.55388349\n",
      "step: 3431, loss:0.53100520\n",
      "step: 3432, loss:0.28455105\n",
      "step: 3433, loss:0.45681870\n",
      "step: 3434, loss:0.31556898\n",
      "step: 3435, loss:0.45977569\n",
      "step: 3436, loss:0.71247816\n",
      "step: 3437, loss:0.59465939\n",
      "step: 3438, loss:0.52356887\n",
      "step: 3439, loss:0.89496851\n",
      "step: 3440, loss:0.41588917\n",
      "step: 3441, loss:0.74942464\n",
      "step: 3442, loss:0.72292250\n",
      "step: 3443, loss:0.38109887\n",
      "step: 3444, loss:0.56523108\n",
      "step: 3445, loss:0.45844549\n",
      "step: 3446, loss:0.64289349\n",
      "step: 3447, loss:0.48663160\n",
      "step: 3448, loss:0.53308892\n",
      "step: 3449, loss:0.73476905\n",
      "step: 3450, loss:0.74294847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:31:06,050 - INFO - step:3450, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 3451, loss:0.65705836\n",
      "step: 3452, loss:0.79408818\n",
      "step: 3453, loss:0.59684777\n",
      "step: 3454, loss:0.66159791\n",
      "step: 3455, loss:0.55832118\n",
      "step: 3456, loss:0.74613678\n",
      "step: 3457, loss:0.45599520\n",
      "step: 3458, loss:0.52560502\n",
      "step: 3459, loss:0.56927520\n",
      "step: 3460, loss:0.52735615\n",
      "step: 3461, loss:0.43171483\n",
      "step: 3462, loss:0.46335244\n",
      "step: 3463, loss:0.55979151\n",
      "step: 3464, loss:0.58826095\n",
      "step: 3465, loss:0.55747682\n",
      "step: 3466, loss:0.56095171\n",
      "step: 3467, loss:0.50161487\n",
      "step: 3468, loss:0.79603767\n",
      "step: 3469, loss:0.63091236\n",
      "step: 3470, loss:0.68945497\n",
      "step: 3471, loss:0.63095868\n",
      "step: 3472, loss:0.63570994\n",
      "step: 3473, loss:0.60431534\n",
      "step: 3474, loss:0.60110259\n",
      "step: 3475, loss:0.74198622\n",
      "step: 3476, loss:0.66017616\n",
      "step: 3477, loss:0.62921053\n",
      "step: 3478, loss:0.50093925\n",
      "step: 3479, loss:0.65276241\n",
      "step: 3480, loss:0.71365654\n",
      "step: 3481, loss:0.62973291\n",
      "step: 3482, loss:0.57318014\n",
      "step: 3483, loss:0.56661582\n",
      "step: 3484, loss:0.75662708\n",
      "step: 3485, loss:0.49976635\n",
      "step: 3486, loss:0.62850636\n",
      "step: 3487, loss:0.53813362\n",
      "step: 3488, loss:0.59189773\n",
      "step: 3489, loss:0.85739517\n",
      "step: 3490, loss:0.71224827\n",
      "step: 3491, loss:0.74438626\n",
      "step: 3492, loss:0.56472421\n",
      "step: 3493, loss:0.73250866\n",
      "step: 3494, loss:0.77232635\n",
      "step: 3495, loss:0.56076211\n",
      "step: 3496, loss:0.62999624\n",
      "step: 3497, loss:0.66872215\n",
      "step: 3498, loss:0.70681423\n",
      "step: 3499, loss:0.59631574\n",
      "step: 3500, loss:0.58815616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:31:31,743 - INFO - step:3500, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 3501, loss:0.65125418\n",
      "step: 3502, loss:0.35361430\n",
      "step: 3503, loss:0.75603312\n",
      "step: 3504, loss:0.50229537\n",
      "step: 3505, loss:0.51871759\n",
      "step: 3506, loss:0.61784220\n",
      "step: 3507, loss:0.83549786\n",
      "step: 3508, loss:0.81145471\n",
      "step: 3509, loss:0.66653728\n",
      "step: 3510, loss:0.72608525\n",
      "step: 3511, loss:0.75250131\n",
      "step: 3512, loss:0.83261174\n",
      "step: 3513, loss:0.72157949\n",
      "step: 3514, loss:0.57480961\n",
      "step: 3515, loss:0.73129463\n",
      "step: 3516, loss:0.51972741\n",
      "step: 3517, loss:0.45324218\n",
      "step: 3518, loss:0.56721091\n",
      "step: 3519, loss:0.64737713\n",
      "step: 3520, loss:0.71480638\n",
      "step: 3521, loss:0.68879151\n",
      "step: 3522, loss:0.62859952\n",
      "step: 3523, loss:0.56889439\n",
      "step: 3524, loss:0.71964025\n",
      "step: 3525, loss:0.68844944\n",
      "step: 3526, loss:0.63916361\n",
      "step: 3527, loss:0.74210864\n",
      "step: 3528, loss:0.69656616\n",
      "step: 3529, loss:0.64312845\n",
      "step: 3530, loss:0.75294584\n",
      "step: 3531, loss:0.52961999\n",
      "step: 3532, loss:0.59363210\n",
      "step: 3533, loss:0.59744859\n",
      "step: 3534, loss:0.57516247\n",
      "step: 3535, loss:0.55602324\n",
      "step: 3536, loss:0.82364511\n",
      "step: 3537, loss:0.71281403\n",
      "step: 3538, loss:0.78938961\n",
      "step: 3539, loss:0.66338867\n",
      "step: 3540, loss:0.66298866\n",
      "step: 3541, loss:0.70419961\n",
      "step: 3542, loss:0.73449033\n",
      "step: 3543, loss:0.68045980\n",
      "step: 3544, loss:0.70123017\n",
      "step: 3545, loss:0.66671520\n",
      "step: 3546, loss:0.70160151\n",
      "step: 3547, loss:0.49966815\n",
      "step: 3548, loss:0.73316324\n",
      "step: 3549, loss:0.59744745\n",
      "step: 3550, loss:0.65575588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:31:57,776 - INFO - step:3550, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 3551, loss:0.56532842\n",
      "step: 3552, loss:0.64015222\n",
      "step: 3553, loss:0.62120211\n",
      "step: 3554, loss:0.53774846\n",
      "step: 3555, loss:0.56098574\n",
      "step: 3556, loss:0.65543616\n",
      "step: 3557, loss:0.64611644\n",
      "step: 3558, loss:0.64019769\n",
      "step: 3559, loss:0.53912419\n",
      "step: 3560, loss:0.51014614\n",
      "step: 3561, loss:0.53102320\n",
      "step: 3562, loss:0.56681538\n",
      "step: 3563, loss:0.63433051\n",
      "step: 3564, loss:0.81851333\n",
      "step: 3565, loss:0.69819313\n",
      "step: 3566, loss:0.75563109\n",
      "step: 3567, loss:0.58354604\n",
      "step: 3568, loss:0.70465690\n",
      "step: 3569, loss:0.60901034\n",
      "step: 3570, loss:0.80967975\n",
      "step: 3571, loss:0.63672107\n",
      "step: 3572, loss:0.78209597\n",
      "step: 3573, loss:0.72120738\n",
      "step: 3574, loss:0.48763448\n",
      "step: 3575, loss:0.58049053\n",
      "step: 3576, loss:0.47668380\n",
      "step: 3577, loss:0.75096488\n",
      "step: 3578, loss:0.57400167\n",
      "step: 3579, loss:0.64656740\n",
      "step: 3580, loss:0.50640047\n",
      "step: 3581, loss:0.59834915\n",
      "step: 3582, loss:0.77863955\n",
      "step: 3583, loss:0.60539013\n",
      "step: 3584, loss:0.68728071\n",
      "step: 3585, loss:0.60235316\n",
      "step: 3586, loss:0.57876068\n",
      "step: 3587, loss:0.70189810\n",
      "step: 3588, loss:0.50926864\n",
      "step: 3589, loss:0.51650536\n",
      "step: 3590, loss:0.50818080\n",
      "step: 3591, loss:0.64807719\n",
      "step: 3592, loss:0.59648609\n",
      "step: 3593, loss:0.76124686\n",
      "step: 3594, loss:0.55000490\n",
      "step: 3595, loss:0.64681524\n",
      "step: 3596, loss:0.62326181\n",
      "step: 3597, loss:0.53270602\n",
      "step: 3598, loss:0.57991946\n",
      "step: 3599, loss:0.64522207\n",
      "step: 3600, loss:0.47122744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:32:23,726 - INFO - step:3600, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 3601, loss:0.53120548\n",
      "step: 3602, loss:0.50401700\n",
      "step: 3603, loss:0.42809445\n",
      "step: 3604, loss:0.47951192\n",
      "step: 3605, loss:0.50144899\n",
      "step: 3606, loss:0.69834751\n",
      "step: 3607, loss:0.69799477\n",
      "step: 3608, loss:0.41875112\n",
      "step: 3609, loss:0.66552204\n",
      "step: 3610, loss:0.71353108\n",
      "step: 3611, loss:0.54709566\n",
      "step: 3612, loss:0.51851308\n",
      "step: 3613, loss:0.77699411\n",
      "step: 3614, loss:0.62473166\n",
      "step: 3615, loss:0.53757054\n",
      "step: 3616, loss:0.62123883\n",
      "step: 3617, loss:0.58915269\n",
      "step: 3618, loss:0.70407808\n",
      "step: 3619, loss:0.62419742\n",
      "step: 3620, loss:0.83324009\n",
      "step: 3621, loss:0.68164265\n",
      "step: 3622, loss:0.77232063\n",
      "step: 3623, loss:0.57218295\n",
      "step: 3624, loss:0.80007339\n",
      "step: 3625, loss:0.64474601\n",
      "step: 3626, loss:0.51470494\n",
      "step: 3627, loss:0.84392035\n",
      "step: 3628, loss:0.52004820\n",
      "step: 3629, loss:0.62084687\n",
      "step: 3630, loss:0.51708949\n",
      "step: 3631, loss:0.54589891\n",
      "step: 3632, loss:0.56993717\n",
      "step: 3633, loss:0.59978056\n",
      "step: 3634, loss:0.51213700\n",
      "step: 3635, loss:0.64557701\n",
      "step: 3636, loss:0.62665981\n",
      "step: 3637, loss:0.61269593\n",
      "step: 3638, loss:0.59635925\n",
      "step: 3639, loss:0.60508883\n",
      "step: 3640, loss:0.64661783\n",
      "step: 3641, loss:0.57442027\n",
      "step: 3642, loss:0.46200177\n",
      "step: 3643, loss:0.48239249\n",
      "step: 3644, loss:0.64831865\n",
      "step: 3645, loss:0.63697225\n",
      "step: 3646, loss:0.50129318\n",
      "step: 3647, loss:0.43696263\n",
      "step: 3648, loss:0.57725269\n",
      "step: 3649, loss:0.56528986\n",
      "step: 3650, loss:0.70288050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:32:49,696 - INFO - step:3650, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 3651, loss:0.56307489\n",
      "step: 3652, loss:0.56619132\n",
      "step: 3653, loss:0.66844207\n",
      "step: 3654, loss:0.73224998\n",
      "step: 3655, loss:0.69672263\n",
      "step: 3656, loss:0.49280915\n",
      "step: 3657, loss:0.68650419\n",
      "step: 3658, loss:0.67324817\n",
      "step: 3659, loss:0.57150155\n",
      "step: 3660, loss:0.57175022\n",
      "step: 3661, loss:0.53908908\n",
      "step: 3662, loss:0.41007665\n",
      "step: 3663, loss:0.43198347\n",
      "step: 3664, loss:0.37481290\n",
      "step: 3665, loss:0.46269366\n",
      "step: 3666, loss:0.47389457\n",
      "step: 3667, loss:0.51699859\n",
      "step: 3668, loss:0.50794810\n",
      "step: 3669, loss:0.42486098\n",
      "step: 3670, loss:0.57298422\n",
      "step: 3671, loss:0.55899131\n",
      "step: 3672, loss:0.74205852\n",
      "step: 3673, loss:0.70908922\n",
      "step: 3674, loss:0.53587580\n",
      "step: 3675, loss:0.44646776\n",
      "step: 3676, loss:0.70890141\n",
      "step: 3677, loss:0.44984317\n",
      "step: 3678, loss:0.53962678\n",
      "step: 3679, loss:0.47005841\n",
      "step: 3680, loss:0.50514370\n",
      "step: 3681, loss:0.32495022\n",
      "step: 3682, loss:0.56940252\n",
      "step: 3683, loss:0.56293488\n",
      "step: 3684, loss:0.44650251\n",
      "step: 3685, loss:0.58421832\n",
      "step: 3686, loss:0.73948520\n",
      "step: 3687, loss:0.48061636\n",
      "step: 3688, loss:0.59598130\n",
      "step: 3689, loss:0.93520498\n",
      "step: 3690, loss:0.56371450\n",
      "step: 3691, loss:0.53534186\n",
      "step: 3692, loss:0.41406113\n",
      "step: 3693, loss:0.31127793\n",
      "step: 3694, loss:0.41477054\n",
      "step: 3695, loss:0.34354079\n",
      "step: 3696, loss:0.99510026\n",
      "step: 3697, loss:0.53093714\n",
      "step: 3698, loss:0.56527728\n",
      "step: 3699, loss:0.52862364\n",
      "step: 3700, loss:0.30941874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:33:15,586 - INFO - step:3700, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 3701, loss:0.47242302\n",
      "step: 3702, loss:0.34407428\n",
      "step: 3703, loss:0.46701753\n",
      "step: 3704, loss:0.70121443\n",
      "step: 3705, loss:0.60615379\n",
      "step: 3706, loss:0.53230065\n",
      "step: 3707, loss:0.86452287\n",
      "step: 3708, loss:0.42958996\n",
      "step: 3709, loss:0.72731930\n",
      "step: 3710, loss:0.70829320\n",
      "step: 3711, loss:0.39250100\n",
      "step: 3712, loss:0.55743355\n",
      "step: 3713, loss:0.46541646\n",
      "step: 3714, loss:0.62883186\n",
      "step: 3715, loss:0.50164676\n",
      "step: 3716, loss:0.53458351\n",
      "step: 3717, loss:0.72908264\n",
      "step: 3718, loss:0.73525828\n",
      "step: 3719, loss:0.66370147\n",
      "step: 3720, loss:0.76228374\n",
      "step: 3721, loss:0.59078836\n",
      "step: 3722, loss:0.66360444\n",
      "step: 3723, loss:0.56923300\n",
      "step: 3724, loss:0.72599697\n",
      "step: 3725, loss:0.46332884\n",
      "step: 3726, loss:0.52915198\n",
      "step: 3727, loss:0.55837083\n",
      "step: 3728, loss:0.53411949\n",
      "step: 3729, loss:0.43373471\n",
      "step: 3730, loss:0.46013337\n",
      "step: 3731, loss:0.56116885\n",
      "step: 3732, loss:0.58299780\n",
      "step: 3733, loss:0.55981660\n",
      "step: 3734, loss:0.56411809\n",
      "step: 3735, loss:0.50092101\n",
      "step: 3736, loss:0.79256642\n",
      "step: 3737, loss:0.62586582\n",
      "step: 3738, loss:0.69185627\n",
      "step: 3739, loss:0.62274653\n",
      "step: 3740, loss:0.63085622\n",
      "step: 3741, loss:0.59558785\n",
      "step: 3742, loss:0.59766299\n",
      "step: 3743, loss:0.73087186\n",
      "step: 3744, loss:0.66440499\n",
      "step: 3745, loss:0.62330496\n",
      "step: 3746, loss:0.49416670\n",
      "step: 3747, loss:0.64871001\n",
      "step: 3748, loss:0.72470737\n",
      "step: 3749, loss:0.62023306\n",
      "step: 3750, loss:0.56143206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:33:41,512 - INFO - step:3750, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 3751, loss:0.55160642\n",
      "step: 3752, loss:0.76473475\n",
      "step: 3753, loss:0.49805239\n",
      "step: 3754, loss:0.62615657\n",
      "step: 3755, loss:0.53951418\n",
      "step: 3756, loss:0.59381306\n",
      "step: 3757, loss:0.87806356\n",
      "step: 3758, loss:0.71924126\n",
      "step: 3759, loss:0.74904019\n",
      "step: 3760, loss:0.56690532\n",
      "step: 3761, loss:0.74421638\n",
      "step: 3762, loss:0.78007174\n",
      "step: 3763, loss:0.56041420\n",
      "step: 3764, loss:0.61196017\n",
      "step: 3765, loss:0.68170780\n",
      "step: 3766, loss:0.70842016\n",
      "step: 3767, loss:0.59714013\n",
      "step: 3768, loss:0.59944040\n",
      "step: 3769, loss:0.66007149\n",
      "step: 3770, loss:0.32840699\n",
      "step: 3771, loss:0.77987820\n",
      "step: 3772, loss:0.50721717\n",
      "step: 3773, loss:0.50688928\n",
      "step: 3774, loss:0.62086123\n",
      "step: 3775, loss:0.85392255\n",
      "step: 3776, loss:0.83269691\n",
      "step: 3777, loss:0.68550515\n",
      "step: 3778, loss:0.73651856\n",
      "step: 3779, loss:0.75846219\n",
      "step: 3780, loss:0.85503262\n",
      "step: 3781, loss:0.73396277\n",
      "step: 3782, loss:0.56641060\n",
      "step: 3783, loss:0.74481112\n",
      "step: 3784, loss:0.50615352\n",
      "step: 3785, loss:0.42717078\n",
      "step: 3786, loss:0.57446074\n",
      "step: 3787, loss:0.64394635\n",
      "step: 3788, loss:0.75174105\n",
      "step: 3789, loss:0.70956892\n",
      "step: 3790, loss:0.62067467\n",
      "step: 3791, loss:0.56626290\n",
      "step: 3792, loss:0.73082912\n",
      "step: 3793, loss:0.71061182\n",
      "step: 3794, loss:0.65057796\n",
      "step: 3795, loss:0.76679909\n",
      "step: 3796, loss:0.71049625\n",
      "step: 3797, loss:0.64563894\n",
      "step: 3798, loss:0.78264767\n",
      "step: 3799, loss:0.51155460\n",
      "step: 3800, loss:0.59399295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:34:07,550 - INFO - step:3800, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 3801, loss:0.59435171\n",
      "step: 3802, loss:0.57138968\n",
      "step: 3803, loss:0.53901696\n",
      "step: 3804, loss:0.87476522\n",
      "step: 3805, loss:0.75535053\n",
      "step: 3806, loss:0.83279854\n",
      "step: 3807, loss:0.67458934\n",
      "step: 3808, loss:0.68114436\n",
      "step: 3809, loss:0.73162889\n",
      "step: 3810, loss:0.78198862\n",
      "step: 3811, loss:0.70355791\n",
      "step: 3812, loss:0.71831799\n",
      "step: 3813, loss:0.67449868\n",
      "step: 3814, loss:0.73605859\n",
      "step: 3815, loss:0.44188416\n",
      "step: 3816, loss:0.77833891\n",
      "step: 3817, loss:0.57454991\n",
      "step: 3818, loss:0.64311081\n",
      "step: 3819, loss:0.52940452\n",
      "step: 3820, loss:0.61140567\n",
      "step: 3821, loss:0.61907381\n",
      "step: 3822, loss:0.49871692\n",
      "step: 3823, loss:0.52503431\n",
      "step: 3824, loss:0.65120041\n",
      "step: 3825, loss:0.63982135\n",
      "step: 3826, loss:0.64829826\n",
      "step: 3827, loss:0.53169578\n",
      "step: 3828, loss:0.47780132\n",
      "step: 3829, loss:0.49771360\n",
      "step: 3830, loss:0.54639262\n",
      "step: 3831, loss:0.65384138\n",
      "step: 3832, loss:0.84937036\n",
      "step: 3833, loss:0.73251027\n",
      "step: 3834, loss:0.76501769\n",
      "step: 3835, loss:0.56831211\n",
      "step: 3836, loss:0.71988595\n",
      "step: 3837, loss:0.62006760\n",
      "step: 3838, loss:0.84890211\n",
      "step: 3839, loss:0.63772964\n",
      "step: 3840, loss:0.78376043\n",
      "step: 3841, loss:0.75443804\n",
      "step: 3842, loss:0.47652590\n",
      "step: 3843, loss:0.57685697\n",
      "step: 3844, loss:0.44737315\n",
      "step: 3845, loss:0.76357740\n",
      "step: 3846, loss:0.56680101\n",
      "step: 3847, loss:0.64862680\n",
      "step: 3848, loss:0.49251938\n",
      "step: 3849, loss:0.60135931\n",
      "step: 3850, loss:0.80180484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:34:33,523 - INFO - step:3850, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 3851, loss:0.60465950\n",
      "step: 3852, loss:0.70188349\n",
      "step: 3853, loss:0.60271990\n",
      "step: 3854, loss:0.57946658\n",
      "step: 3855, loss:0.70761782\n",
      "step: 3856, loss:0.49779651\n",
      "step: 3857, loss:0.50111544\n",
      "step: 3858, loss:0.49837172\n",
      "step: 3859, loss:0.64719510\n",
      "step: 3860, loss:0.58794874\n",
      "step: 3861, loss:0.76959604\n",
      "step: 3862, loss:0.54829055\n",
      "step: 3863, loss:0.64711171\n",
      "step: 3864, loss:0.62374508\n",
      "step: 3865, loss:0.51698226\n",
      "step: 3866, loss:0.56971610\n",
      "step: 3867, loss:0.64605910\n",
      "step: 3868, loss:0.47096094\n",
      "step: 3869, loss:0.52501649\n",
      "step: 3870, loss:0.49115205\n",
      "step: 3871, loss:0.42194092\n",
      "step: 3872, loss:0.47135091\n",
      "step: 3873, loss:0.49897578\n",
      "step: 3874, loss:0.68714714\n",
      "step: 3875, loss:0.69537503\n",
      "step: 3876, loss:0.42262214\n",
      "step: 3877, loss:0.65766436\n",
      "step: 3878, loss:0.71689022\n",
      "step: 3879, loss:0.55088973\n",
      "step: 3880, loss:0.52022809\n",
      "step: 3881, loss:0.76379812\n",
      "step: 3882, loss:0.62158799\n",
      "step: 3883, loss:0.55103368\n",
      "step: 3884, loss:0.62337661\n",
      "step: 3885, loss:0.59834832\n",
      "step: 3886, loss:0.69808429\n",
      "step: 3887, loss:0.62569088\n",
      "step: 3888, loss:0.81157762\n",
      "step: 3889, loss:0.67084306\n",
      "step: 3890, loss:0.78400016\n",
      "step: 3891, loss:0.56707454\n",
      "step: 3892, loss:0.79117453\n",
      "step: 3893, loss:0.64294225\n",
      "step: 3894, loss:0.51621580\n",
      "step: 3895, loss:0.82128280\n",
      "step: 3896, loss:0.52032089\n",
      "step: 3897, loss:0.63459247\n",
      "step: 3898, loss:0.52970445\n",
      "step: 3899, loss:0.54360944\n",
      "step: 3900, loss:0.58218122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:34:59,424 - INFO - step:3900, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 3901, loss:0.60204685\n",
      "step: 3902, loss:0.52112347\n",
      "step: 3903, loss:0.65374964\n",
      "step: 3904, loss:0.62073421\n",
      "step: 3905, loss:0.62827826\n",
      "step: 3906, loss:0.60160834\n",
      "step: 3907, loss:0.59893489\n",
      "step: 3908, loss:0.64026779\n",
      "step: 3909, loss:0.56733865\n",
      "step: 3910, loss:0.47420472\n",
      "step: 3911, loss:0.49171406\n",
      "step: 3912, loss:0.64696908\n",
      "step: 3913, loss:0.62879610\n",
      "step: 3914, loss:0.49318722\n",
      "step: 3915, loss:0.44213614\n",
      "step: 3916, loss:0.56773865\n",
      "step: 3917, loss:0.56535256\n",
      "step: 3918, loss:0.69259936\n",
      "step: 3919, loss:0.55710655\n",
      "step: 3920, loss:0.56739885\n",
      "step: 3921, loss:0.67677963\n",
      "step: 3922, loss:0.72227633\n",
      "step: 3923, loss:0.69838113\n",
      "step: 3924, loss:0.50009018\n",
      "step: 3925, loss:0.67380667\n",
      "step: 3926, loss:0.66967160\n",
      "step: 3927, loss:0.57098705\n",
      "step: 3928, loss:0.56883287\n",
      "step: 3929, loss:0.54166412\n",
      "step: 3930, loss:0.41882643\n",
      "step: 3931, loss:0.43997163\n",
      "step: 3932, loss:0.39250880\n",
      "step: 3933, loss:0.46321982\n",
      "step: 3934, loss:0.49159023\n",
      "step: 3935, loss:0.51934952\n",
      "step: 3936, loss:0.51512218\n",
      "step: 3937, loss:0.43913862\n",
      "step: 3938, loss:0.57224131\n",
      "step: 3939, loss:0.56281781\n",
      "step: 3940, loss:0.71364665\n",
      "step: 3941, loss:0.69756371\n",
      "step: 3942, loss:0.54891998\n",
      "step: 3943, loss:0.46747199\n",
      "step: 3944, loss:0.70217043\n",
      "step: 3945, loss:0.46593419\n",
      "step: 3946, loss:0.54946560\n",
      "step: 3947, loss:0.49044931\n",
      "step: 3948, loss:0.51466709\n",
      "step: 3949, loss:0.35769466\n",
      "step: 3950, loss:0.57155895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:35:25,374 - INFO - step:3950, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 3951, loss:0.57151699\n",
      "step: 3952, loss:0.46727756\n",
      "step: 3953, loss:0.58321941\n",
      "step: 3954, loss:0.73407221\n",
      "step: 3955, loss:0.48778996\n",
      "step: 3956, loss:0.59803212\n",
      "step: 3957, loss:0.88457680\n",
      "step: 3958, loss:0.56756687\n",
      "step: 3959, loss:0.54327530\n",
      "step: 3960, loss:0.43179220\n",
      "step: 3961, loss:0.35694271\n",
      "step: 3962, loss:0.43927544\n",
      "step: 3963, loss:0.38336480\n",
      "step: 3964, loss:0.94475800\n",
      "step: 3965, loss:0.53499657\n",
      "step: 3966, loss:0.56904393\n",
      "step: 3967, loss:0.53725356\n",
      "step: 3968, loss:0.35494062\n",
      "step: 3969, loss:0.48886490\n",
      "step: 3970, loss:0.37649792\n",
      "step: 3971, loss:0.48659286\n",
      "step: 3972, loss:0.68220246\n",
      "step: 3973, loss:0.59070045\n",
      "step: 3974, loss:0.55038768\n",
      "step: 3975, loss:0.81446570\n",
      "step: 3976, loss:0.46575069\n",
      "step: 3977, loss:0.70966923\n",
      "step: 3978, loss:0.66456360\n",
      "step: 3979, loss:0.43579301\n",
      "step: 3980, loss:0.56404030\n",
      "step: 3981, loss:0.48535272\n",
      "step: 3982, loss:0.63189846\n",
      "step: 3983, loss:0.51305985\n",
      "step: 3984, loss:0.54620969\n",
      "step: 3985, loss:0.70714110\n",
      "step: 3986, loss:0.70331949\n",
      "step: 3987, loss:0.65358275\n",
      "step: 3988, loss:0.73918194\n",
      "step: 3989, loss:0.59651971\n",
      "step: 3990, loss:0.65511799\n",
      "step: 3991, loss:0.57004082\n",
      "step: 3992, loss:0.71235037\n",
      "step: 3993, loss:0.49607852\n",
      "step: 3994, loss:0.54178208\n",
      "step: 3995, loss:0.57843578\n",
      "step: 3996, loss:0.53823864\n",
      "step: 3997, loss:0.45976174\n",
      "step: 3998, loss:0.48152298\n",
      "step: 3999, loss:0.57260865\n",
      "step: 4000, loss:0.59185249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-14 22:35:51,286 - INFO - step:4000, matthews_corr:0.000000, Acc:69.127517%, Train: matthews_corr:0.000000, Acc:70.436206%,\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "# loss_mat = np.zeros((len(batch_size_list),len(scheduler_list), len(optimizer_list), len(lr_list),steps))\n",
    "\n",
    " # evaluate test metric each step\n",
    "# metric_mat = np.zeros((len(batch_size_list),len(scheduler_list), len(optimizer_list), len(lr_list),steps//report_step,2))\n",
    "for i,this_batch_size in enumerate(batch_size_list):\n",
    "    for j,this_scheduler in enumerate(scheduler_list):\n",
    "        for k,this_optimizer in enumerate(optimizer_list):\n",
    "            for m, this_lr in enumerate(lr_list):\n",
    "                loss_list = []\n",
    "                metric_list = []\n",
    "                acc_list = []\n",
    "                train_metric_list = []\n",
    "                train_acc_list = []\n",
    "                model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\").to(device)\n",
    "                train_loader = DataLoader(train_dataset, batch_size=this_batch_size)\n",
    "                sche, opt = prepare(this_scheduler, this_optimizer)\n",
    "                optimizer = opt(model.parameters(), lr = this_lr if this_scheduler == 'no' else this_lr*2)\n",
    "                scheduler = sche(optimizer, num_warmup_steps=int(steps/10),num_training_steps=steps)\n",
    "                step = 0\n",
    "\n",
    "                metric,acc = evaluate(model,test_dataset)\n",
    "                # print(i,j,k,m,step//report_step)\n",
    "                metric_list.append(metric)\n",
    "                acc_list.append(acc)\n",
    "                tmetric, tacc = evaluate(model, train_dataset)\n",
    "                train_metric_list.append(tmetric)\n",
    "                train_acc_list.append(tacc)\n",
    "                # metric_mat[i,j,k,m,step//report_step - 1,0] = metric\n",
    "                # metric_mat[i,j,k,m,step//report_step - 1,1] = acc\n",
    "                print(f\"step:{step}, matthews_corr:{metric:.6f}, Acc:{acc*100:4f}%, Train: matthews_corr:{tmetric:.6f}, Acc:{tacc*100:4f}%,\")\n",
    "\n",
    "                # print(f'Start training for: sche:{this_scheduler},opt:{this_optimizer},batchsize:{this_batch_size}, lr:{this_lr}')\n",
    "                logger.info(f'Start training for: sche:{this_scheduler},opt:{this_optimizer},batchsize:{this_batch_size}, lr:{this_lr}')\n",
    "                while True:\n",
    "\n",
    "                    for X in train_loader:\n",
    "                        model.train()\n",
    "                        optimizer.zero_grad()\n",
    "                        batch = {k: v.to(device) for k, v in X.items()}\n",
    "                        loss = model(**batch).loss\n",
    "                        print(f\"step: {step+1}, loss:{loss.item():.8f}\")\n",
    "\n",
    "                        # loss_mat[i,j,k,m,step] = loss.item()\n",
    "                        loss_list.append(loss.item())\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        scheduler.step()\n",
    "                        step += 1\n",
    "\n",
    "                    # valid\n",
    "                        if step % report_step == 0:\n",
    "\n",
    "                            metric,acc = evaluate(model,test_dataset)\n",
    "                            # print(i,j,k,m,step//report_step)\n",
    "                            metric_list.append(metric)\n",
    "                            acc_list.append(acc)\n",
    "                            tmetric, tacc = evaluate(model, train_dataset)\n",
    "                            train_metric_list.append(tmetric)\n",
    "                            train_acc_list.append(tacc)\n",
    "                            # metric_mat[i,j,k,m,step//report_step - 1,0] = metric\n",
    "                            # metric_mat[i,j,k,m,step//report_step - 1,1] = acc\n",
    "                            # print(f\"step:{step}, matthews_corr:{metric:.6f}, Acc:{acc*100:4f}%\")\n",
    "                            logger.info(f\"step:{step}, matthews_corr:{metric:.6f}, Acc:{acc*100:4f}%, Train: matthews_corr:{tmetric:.6f}, Acc:{tacc*100:4f}%,\")\n",
    "\n",
    "                        if step == steps:\n",
    "                            break\n",
    "                    if step == steps:\n",
    "                        break\n",
    "                file_name = dataset_name+\",batchsize\"+str(this_batch_size)+\",scheduler\"+this_scheduler+\",optimizer\"+str(this_optimizer)+\",LR\"+str(this_lr)\n",
    "                np.save(current_path/(file_name+'loss.npy'),np.array(loss_list))\n",
    "                np.save(current_path/(file_name+'metric.npy'),np.array(metric_list))\n",
    "                np.save(current_path/(file_name+'acc.npy'),np.array(acc_list))\n",
    "                np.save(current_path/(file_name+'trainmetric.npy'),np.array(train_metric_list))\n",
    "                np.save(current_path/(file_name+'trainacc.npy'),np.array(train_acc_list))\n",
    "\n",
    "                del model\n",
    "                del optimizer\n",
    "                del scheduler\n",
    "                del train_loader\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
