{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, BertForSequenceClassification, get_linear_schedule_with_warmup,get_polynomial_decay_schedule_with_warmup, Adafactor\n",
    "import torch.nn as nn\n",
    "import logging\n",
    "from lion_pytorch import Lion\n",
    "from torch.utils.data import DataLoader\n",
    "import GLUEforQQP\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from mylion_pytorch import MyLion\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at C:/Users/Xiang/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at C:/Users/Xiang/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('C:/Users/Xiang/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "# tokenizer.save_pretrained(\"./tokenizer\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./tokenizer\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "dataset_name = 'qqp'\n",
    "current_path = Path.cwd().parents[0]/dataset_name\n",
    "current_path.mkdir(exist_ok=True)\n",
    "# lr_list = [3e-5,3e-4,3e-3]\n",
    "# scheduler_list = ['no', 'linear']\n",
    "# optimizer_list = ['Lion', 'AdamW','AdaFactor']\n",
    "# batch_size_list = [32,64,128]\n",
    "# steps = 50*1000\n",
    "lr_list = [3e-4,3e-5,3e-6,3e-7]\n",
    "scheduler_list = ['no', 'linear']\n",
    "optimizer_list = ['Lion','AdamW','AdaFactor']\n",
    "batch_size_list = [16,32,64]\n",
    "\n",
    "lr_list = [3e-6]\n",
    "scheduler_list = ['linear']\n",
    "optimizer_list = ['MyLion']\n",
    "batch_size_list = [64]\n",
    "\n",
    "steps = 20*1000\n",
    "report_step = 1000\n",
    "accum_iter = 4\n",
    "\n",
    "steps *= accum_iter\n",
    "# steps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from C:\\Users\\Xiang\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\mariosasko--glue\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad (last modified on Sat Mar  4 15:45:32 2023) since it couldn't be found locally at mariosasko/glue., or remotely on the Hugging Face Hub.\n",
      "Found cached dataset glue (C:/Users/Xiang/.cache/huggingface/datasets/mariosasko___glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2bc9b61f2a8241dd9b44b6afe54178d3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Xiang\\.cache\\huggingface\\datasets\\mariosasko___glue\\qqp\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-057c3bb79acff26e.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Xiang\\.cache\\huggingface\\datasets\\mariosasko___glue\\qqp\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-97f2e68238528875.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Xiang\\.cache\\huggingface\\datasets\\mariosasko___glue\\qqp\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-f0c873864ea6364f.arrow\n"
     ]
    }
   ],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "train_dataset,valid_dataset,test_dataset = GLUEforQQP.get_torch_dataset(tokenizer, \"qqp\", padding=\"max_length\", truncation=True, max_length = 350)\n",
    "\n",
    "def constant_scheduler(\n",
    "    optimizer, num_warmup_steps, num_training_steps, lr_end=1e-7, power=1.0, last_epoch=-1\n",
    "):\n",
    "    def lambda_func(step:int):\n",
    "        return 1.\n",
    "\n",
    "    return LambdaLR(optimizer, lambda_func, last_epoch)\n",
    "\n",
    "def prepare(sche, opt):\n",
    "    if sche == 'no':\n",
    "        sches = partial(constant_scheduler)\n",
    "    if sche == 'linear':\n",
    "        sches = partial(get_linear_schedule_with_warmup)\n",
    "\n",
    "    if opt == 'Lion':\n",
    "        opts = partial(Lion, betas = (0.95,0.98), weight_decay = 0.01)\n",
    "    if opt == 'AdaFactor':\n",
    "        opts = partial(Adafactor, weight_decay = 0.001, relative_step = False, scale_parameter=False)\n",
    "    if opt == 'AdamW':\n",
    "        opts = partial(torch.optim.AdamW, betas = (0.9,0.99), weight_decay = 0.001)\n",
    "    if opt == 'MyLion':\n",
    "        opts = partial(MyLion, betas = (0.95,0.98), weight_decay = 0.01)\n",
    "\n",
    "\n",
    "    return sches, opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased',cache_dir  = \"C:/Users/Xiang/.cache/huggingface/hub\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_log(file_name):\n",
    "    logger = logging.getLogger('train')  # 设定logger的名字\n",
    "    logger.setLevel(logging.INFO)  # 设定logger得等级\n",
    "\n",
    "    ch = logging.StreamHandler()  # 输出流的hander，用与设定logger的各种信息\n",
    "    ch.setLevel(logging.INFO)  # 设定输出hander的level\n",
    "\n",
    "    fh = logging.FileHandler(file_name, mode='a')  # 文件流的hander，输出得文件名称，以及mode设置为覆盖模式\n",
    "    fh.setLevel(logging.INFO)  # 设定文件hander得lever\n",
    "\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    ch.setFormatter(formatter)  # 两个hander设置个是，输出得信息包括，时间，信息得等级，以及message\n",
    "    fh.setFormatter(formatter)\n",
    "    logger.addHandler(fh)  # 将两个hander添加到我们声明的logger中去\n",
    "    logger.addHandler(ch)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logger = get_log('logQQP3.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test_loader = DataLoader(test_dataset, shuffle = False, batch_size = 32)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dataset):\n",
    "    model.eval()\n",
    "    eval_loader = DataLoader(dataset, shuffle = False, batch_size = 32)\n",
    "    logits = []\n",
    "    labelss = []\n",
    "    with torch.no_grad():\n",
    "        for X in tqdm(eval_loader):\n",
    "            batch = {k: v.to(device) for k, v in X.items()}\n",
    "            logits.append(model(**batch).logits)\n",
    "            labelss.append(batch['labels'])\n",
    "        total_test = torch.concat(logits, dim = 0)\n",
    "        _,predicted = torch.max(total_test,dim = 1)\n",
    "        real_label =torch.concat(labelss,dim=0).cpu().numpy()\n",
    "        predicted = predicted.cpu().numpy()\n",
    "        metric = matthews_corrcoef(real_label, predicted)\n",
    "        acc = np.mean(predicted==real_label)\n",
    "\n",
    "    return metric, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at C:/Users/Xiang/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at C:/Users/Xiang/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 1264/1264 [06:57<00:00,  3.03it/s]\n",
      "2023-04-02 17:00:23,893 - INFO - Start training for: sche:linear,opt:MyLion,batchsize:64, lr:3e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:0, matthews_corr:-0.087809, Acc:61.877319%\n",
      "step: 1.0, loss:0.69457541\n",
      "step: 2.0, loss:0.66951123\n",
      "step: 3.0, loss:0.72107628\n",
      "step: 4.0, loss:0.66609195\n",
      "step: 5.0, loss:0.69289289\n",
      "step: 6.0, loss:0.76290131\n",
      "step: 7.0, loss:0.62860660\n",
      "step: 8.0, loss:0.62008025\n",
      "step: 9.0, loss:0.66127476\n",
      "step: 10.0, loss:0.70026249\n",
      "step: 11.0, loss:0.57559346\n",
      "step: 12.0, loss:0.71797141\n",
      "step: 13.0, loss:0.66444741\n",
      "step: 14.0, loss:0.66161586\n",
      "step: 15.0, loss:0.66304286\n",
      "step: 16.0, loss:0.62998393\n",
      "step: 17.0, loss:0.60902911\n",
      "step: 18.0, loss:0.69519153\n",
      "step: 19.0, loss:0.75949186\n",
      "step: 20.0, loss:0.65871049\n",
      "step: 21.0, loss:0.67188971\n",
      "step: 22.0, loss:0.82529747\n",
      "step: 23.0, loss:0.68327691\n",
      "step: 24.0, loss:0.71733299\n",
      "step: 25.0, loss:0.72185569\n",
      "step: 26.0, loss:0.71056634\n",
      "step: 27.0, loss:0.62732475\n",
      "step: 28.0, loss:0.65906174\n",
      "step: 29.0, loss:0.72335251\n",
      "step: 30.0, loss:0.70343426\n",
      "step: 31.0, loss:0.61322920\n",
      "step: 32.0, loss:0.71272449\n",
      "step: 33.0, loss:0.62153801\n",
      "step: 34.0, loss:0.70439669\n",
      "step: 35.0, loss:0.63770835\n",
      "step: 36.0, loss:0.73164624\n",
      "step: 37.0, loss:0.74614634\n",
      "step: 38.0, loss:0.64561445\n",
      "step: 39.0, loss:0.69889416\n",
      "step: 40.0, loss:0.71168591\n",
      "step: 41.0, loss:0.73253658\n",
      "step: 42.0, loss:0.67656018\n",
      "step: 43.0, loss:0.69877110\n",
      "step: 44.0, loss:0.61706091\n",
      "step: 45.0, loss:0.75686073\n",
      "step: 46.0, loss:0.71411553\n",
      "step: 47.0, loss:0.72343861\n",
      "step: 48.0, loss:0.66007961\n",
      "step: 49.0, loss:0.63239376\n",
      "step: 50.0, loss:0.69457564\n",
      "step: 51.0, loss:0.70845110\n",
      "step: 52.0, loss:0.72780691\n",
      "step: 53.0, loss:0.69981943\n",
      "step: 54.0, loss:0.73027533\n",
      "step: 55.0, loss:0.60886778\n",
      "step: 56.0, loss:0.60662916\n",
      "step: 57.0, loss:0.75568715\n",
      "step: 58.0, loss:0.71266983\n",
      "step: 59.0, loss:0.69775005\n",
      "step: 60.0, loss:0.59696896\n",
      "step: 61.0, loss:0.61880948\n",
      "step: 62.0, loss:0.76831397\n",
      "step: 63.0, loss:0.69465783\n",
      "step: 64.0, loss:0.67691981\n",
      "step: 65.0, loss:0.76023281\n",
      "step: 66.0, loss:0.75854778\n",
      "step: 67.0, loss:0.71945632\n",
      "step: 68.0, loss:0.63511489\n",
      "step: 69.0, loss:0.73043744\n",
      "step: 70.0, loss:0.74476661\n",
      "step: 71.0, loss:0.66659501\n",
      "step: 72.0, loss:0.71559255\n",
      "step: 73.0, loss:0.66806348\n",
      "step: 74.0, loss:0.69518453\n",
      "step: 75.0, loss:0.68358542\n",
      "step: 76.0, loss:0.68138069\n",
      "step: 77.0, loss:0.65240470\n",
      "step: 78.0, loss:0.71244092\n",
      "step: 79.0, loss:0.73417294\n",
      "step: 80.0, loss:0.71283934\n",
      "step: 81.0, loss:0.74279238\n",
      "step: 82.0, loss:0.64103165\n",
      "step: 83.0, loss:0.67451774\n",
      "step: 84.0, loss:0.68598126\n",
      "step: 85.0, loss:0.67603633\n",
      "step: 86.0, loss:0.75525492\n",
      "step: 87.0, loss:0.64830773\n",
      "step: 88.0, loss:0.59203359\n",
      "step: 89.0, loss:0.67834222\n",
      "step: 90.0, loss:0.71101870\n",
      "step: 91.0, loss:0.68425408\n",
      "step: 92.0, loss:0.74786589\n",
      "step: 93.0, loss:0.70180386\n",
      "step: 94.0, loss:0.75148687\n",
      "step: 95.0, loss:0.70545904\n",
      "step: 96.0, loss:0.70285144\n",
      "step: 97.0, loss:0.68519339\n",
      "step: 98.0, loss:0.60407116\n",
      "step: 99.0, loss:0.63338239\n",
      "step: 100.0, loss:0.73469512\n",
      "step: 101.0, loss:0.64409842\n",
      "step: 102.0, loss:0.65923917\n",
      "step: 103.0, loss:0.74732335\n",
      "step: 104.0, loss:0.73983507\n",
      "step: 105.0, loss:0.71242088\n",
      "step: 106.0, loss:0.75418755\n",
      "step: 107.0, loss:0.66642083\n",
      "step: 108.0, loss:0.66935021\n",
      "step: 109.0, loss:0.76309600\n",
      "step: 110.0, loss:0.65018317\n",
      "step: 111.0, loss:0.63948429\n",
      "step: 112.0, loss:0.64940862\n",
      "step: 113.0, loss:0.69601397\n",
      "step: 114.0, loss:0.82278407\n",
      "step: 115.0, loss:0.82091877\n",
      "step: 116.0, loss:0.61299019\n",
      "step: 117.0, loss:0.60212238\n",
      "step: 118.0, loss:0.60496272\n",
      "step: 119.0, loss:0.67263365\n",
      "step: 120.0, loss:0.72211936\n",
      "step: 121.0, loss:0.74271889\n",
      "step: 122.0, loss:0.67885952\n",
      "step: 123.0, loss:0.64557452\n",
      "step: 124.0, loss:0.66695331\n",
      "step: 125.0, loss:0.68232103\n",
      "step: 126.0, loss:0.71971963\n",
      "step: 127.0, loss:0.68422094\n",
      "step: 128.0, loss:0.62307811\n",
      "step: 129.0, loss:0.67446458\n",
      "step: 130.0, loss:0.73545857\n",
      "step: 131.0, loss:0.57246552\n",
      "step: 132.0, loss:0.71802239\n",
      "step: 133.0, loss:0.63118967\n",
      "step: 134.0, loss:0.63554364\n",
      "step: 135.0, loss:0.69162627\n",
      "step: 136.0, loss:0.72056499\n",
      "step: 137.0, loss:0.62613364\n",
      "step: 138.0, loss:0.63725670\n",
      "step: 139.0, loss:0.57772882\n",
      "step: 140.0, loss:0.75017008\n",
      "step: 141.0, loss:0.71579444\n",
      "step: 142.0, loss:0.72900499\n",
      "step: 143.0, loss:0.71378113\n",
      "step: 144.0, loss:0.66969091\n",
      "step: 145.0, loss:0.66180007\n",
      "step: 146.0, loss:0.70804854\n",
      "step: 147.0, loss:0.69631630\n",
      "step: 148.0, loss:0.79599586\n",
      "step: 149.0, loss:0.80070192\n",
      "step: 150.0, loss:0.74571832\n",
      "step: 151.0, loss:0.68481752\n",
      "step: 152.0, loss:0.68893951\n",
      "step: 153.0, loss:0.59846234\n",
      "step: 154.0, loss:0.67971340\n",
      "step: 155.0, loss:0.65004681\n",
      "step: 156.0, loss:0.65929720\n",
      "step: 157.0, loss:0.64390562\n",
      "step: 158.0, loss:0.66533548\n",
      "step: 159.0, loss:0.72106989\n",
      "step: 160.0, loss:0.69720508\n",
      "step: 161.0, loss:0.73484482\n",
      "step: 162.0, loss:0.64094648\n",
      "step: 163.0, loss:0.74006419\n",
      "step: 164.0, loss:0.63197558\n",
      "step: 165.0, loss:0.71015085\n",
      "step: 166.0, loss:0.76946904\n",
      "step: 167.0, loss:0.64713298\n",
      "step: 168.0, loss:0.63620573\n",
      "step: 169.0, loss:0.69244766\n",
      "step: 170.0, loss:0.75301749\n",
      "step: 171.0, loss:0.59421459\n",
      "step: 172.0, loss:0.66445743\n",
      "step: 173.0, loss:0.72358924\n",
      "step: 174.0, loss:0.71589495\n",
      "step: 175.0, loss:0.72937445\n",
      "step: 176.0, loss:0.63046701\n",
      "step: 177.0, loss:0.63294780\n",
      "step: 178.0, loss:0.68388791\n",
      "step: 179.0, loss:0.64810272\n",
      "step: 180.0, loss:0.63926943\n",
      "step: 181.0, loss:0.69229035\n",
      "step: 182.0, loss:0.70483759\n",
      "step: 183.0, loss:0.70082489\n",
      "step: 184.0, loss:0.67968698\n",
      "step: 185.0, loss:0.68217440\n",
      "step: 186.0, loss:0.63088295\n",
      "step: 187.0, loss:0.72246179\n",
      "step: 188.0, loss:0.67451811\n",
      "step: 189.0, loss:0.64618342\n",
      "step: 190.0, loss:0.73675846\n",
      "step: 191.0, loss:0.66912284\n",
      "step: 192.0, loss:0.74244492\n",
      "step: 193.0, loss:0.66048735\n",
      "step: 194.0, loss:0.66234350\n",
      "step: 195.0, loss:0.63338731\n",
      "step: 196.0, loss:0.67945360\n",
      "step: 197.0, loss:0.69388944\n",
      "step: 198.0, loss:0.68175417\n",
      "step: 199.0, loss:0.74688402\n",
      "step: 200.0, loss:0.64185712\n",
      "step: 201.0, loss:0.72096960\n",
      "step: 202.0, loss:0.58602488\n",
      "step: 203.0, loss:0.73534299\n",
      "step: 204.0, loss:0.73087488\n",
      "step: 205.0, loss:0.62461787\n",
      "step: 206.0, loss:0.62848722\n",
      "step: 207.0, loss:0.71285698\n",
      "step: 208.0, loss:0.61851223\n",
      "step: 209.0, loss:0.70790513\n",
      "step: 210.0, loss:0.67260414\n",
      "step: 211.0, loss:0.66194348\n",
      "step: 212.0, loss:0.70598438\n",
      "step: 213.0, loss:0.66272303\n",
      "step: 214.0, loss:0.73355380\n",
      "step: 215.0, loss:0.68797542\n",
      "step: 216.0, loss:0.70649478\n",
      "step: 217.0, loss:0.65843144\n",
      "step: 218.0, loss:0.70058821\n",
      "step: 219.0, loss:0.66737749\n",
      "step: 220.0, loss:0.62443388\n",
      "step: 221.0, loss:0.69750319\n",
      "step: 222.0, loss:0.67900349\n",
      "step: 223.0, loss:0.67386679\n",
      "step: 224.0, loss:0.57864929\n",
      "step: 225.0, loss:0.70290710\n",
      "step: 226.0, loss:0.69815378\n",
      "step: 227.0, loss:0.73348446\n",
      "step: 228.0, loss:0.73944972\n",
      "step: 229.0, loss:0.71202593\n",
      "step: 230.0, loss:0.71284400\n",
      "step: 231.0, loss:0.58657159\n",
      "step: 232.0, loss:0.63557570\n",
      "step: 233.0, loss:0.66000427\n",
      "step: 234.0, loss:0.63752304\n",
      "step: 235.0, loss:0.65662402\n",
      "step: 236.0, loss:0.72266552\n",
      "step: 237.0, loss:0.68829592\n",
      "step: 238.0, loss:0.65152551\n",
      "step: 239.0, loss:0.73312904\n",
      "step: 240.0, loss:0.62468676\n",
      "step: 241.0, loss:0.66885398\n",
      "step: 242.0, loss:0.65246648\n",
      "step: 243.0, loss:0.67902841\n",
      "step: 244.0, loss:0.68597834\n",
      "step: 245.0, loss:0.66007671\n",
      "step: 246.0, loss:0.63386662\n",
      "step: 247.0, loss:0.71617393\n",
      "step: 248.0, loss:0.69195282\n",
      "step: 249.0, loss:0.67813495\n",
      "step: 250.0, loss:0.71960159\n",
      "step: 251.0, loss:0.71585059\n",
      "step: 252.0, loss:0.69523707\n",
      "step: 253.0, loss:0.67837514\n",
      "step: 254.0, loss:0.60698688\n",
      "step: 255.0, loss:0.66140248\n",
      "step: 256.0, loss:0.65923926\n",
      "step: 257.0, loss:0.65117876\n",
      "step: 258.0, loss:0.65970120\n",
      "step: 259.0, loss:0.74415168\n",
      "step: 260.0, loss:0.67301005\n",
      "step: 261.0, loss:0.70249315\n",
      "step: 262.0, loss:0.68243827\n",
      "step: 263.0, loss:0.61816023\n",
      "step: 264.0, loss:0.73384804\n",
      "step: 265.0, loss:0.61779618\n",
      "step: 266.0, loss:0.70155051\n",
      "step: 267.0, loss:0.69682980\n",
      "step: 268.0, loss:0.68396692\n",
      "step: 269.0, loss:0.63016027\n",
      "step: 270.0, loss:0.67131238\n",
      "step: 271.0, loss:0.65010132\n",
      "step: 272.0, loss:0.56728125\n",
      "step: 273.0, loss:0.70068292\n",
      "step: 274.0, loss:0.62777932\n",
      "step: 275.0, loss:0.63503738\n",
      "step: 276.0, loss:0.66625303\n",
      "step: 277.0, loss:0.55748467\n",
      "step: 278.0, loss:0.65626858\n",
      "step: 279.0, loss:0.64809452\n",
      "step: 280.0, loss:0.65052205\n",
      "step: 281.0, loss:0.62608017\n",
      "step: 282.0, loss:0.65517557\n",
      "step: 283.0, loss:0.68639858\n",
      "step: 284.0, loss:0.61788630\n",
      "step: 285.0, loss:0.76531148\n",
      "step: 286.0, loss:0.62652215\n",
      "step: 287.0, loss:0.76765867\n",
      "step: 288.0, loss:0.72438906\n",
      "step: 289.0, loss:0.70936508\n",
      "step: 290.0, loss:0.74800158\n",
      "step: 291.0, loss:0.69977489\n",
      "step: 292.0, loss:0.65424098\n",
      "step: 293.0, loss:0.71622355\n",
      "step: 294.0, loss:0.69359374\n",
      "step: 295.0, loss:0.67787400\n",
      "step: 296.0, loss:0.56698103\n",
      "step: 297.0, loss:0.63574091\n",
      "step: 298.0, loss:0.71071620\n",
      "step: 299.0, loss:0.60507531\n",
      "step: 300.0, loss:0.67106496\n",
      "step: 301.0, loss:0.64756230\n",
      "step: 302.0, loss:0.69668843\n",
      "step: 303.0, loss:0.71110402\n",
      "step: 304.0, loss:0.70605773\n",
      "step: 305.0, loss:0.62927919\n",
      "step: 306.0, loss:0.63877702\n",
      "step: 307.0, loss:0.70790640\n",
      "step: 308.0, loss:0.72912671\n",
      "step: 309.0, loss:0.63658933\n",
      "step: 310.0, loss:0.64380455\n",
      "step: 311.0, loss:0.61065958\n",
      "step: 312.0, loss:0.63277972\n",
      "step: 313.0, loss:0.63239393\n",
      "step: 314.0, loss:0.76340011\n",
      "step: 315.0, loss:0.70308711\n",
      "step: 316.0, loss:0.70309323\n",
      "step: 317.0, loss:0.68390448\n",
      "step: 318.0, loss:0.68042500\n",
      "step: 319.0, loss:0.64720860\n",
      "step: 320.0, loss:0.64798287\n",
      "step: 321.0, loss:0.69671884\n",
      "step: 322.0, loss:0.70844957\n",
      "step: 323.0, loss:0.67145731\n",
      "step: 324.0, loss:0.67181990\n",
      "step: 325.0, loss:0.71250613\n",
      "step: 326.0, loss:0.69023782\n",
      "step: 327.0, loss:0.66578771\n",
      "step: 328.0, loss:0.73874314\n",
      "step: 329.0, loss:0.68733720\n",
      "step: 330.0, loss:0.59435220\n",
      "step: 331.0, loss:0.65739253\n",
      "step: 332.0, loss:0.69691625\n",
      "step: 333.0, loss:0.63535976\n",
      "step: 334.0, loss:0.68914516\n",
      "step: 335.0, loss:0.60057794\n",
      "step: 336.0, loss:0.67868918\n",
      "step: 337.0, loss:0.60600096\n",
      "step: 338.0, loss:0.74639259\n",
      "step: 339.0, loss:0.68680818\n",
      "step: 340.0, loss:0.70170616\n",
      "step: 341.0, loss:0.65102436\n",
      "step: 342.0, loss:0.69548416\n",
      "step: 343.0, loss:0.61583243\n",
      "step: 344.0, loss:0.67535034\n",
      "step: 345.0, loss:0.68062593\n",
      "step: 346.0, loss:0.64059320\n",
      "step: 347.0, loss:0.69871208\n",
      "step: 348.0, loss:0.68076400\n",
      "step: 349.0, loss:0.67001592\n",
      "step: 350.0, loss:0.64748685\n",
      "step: 351.0, loss:0.63153203\n",
      "step: 352.0, loss:0.70340803\n",
      "step: 353.0, loss:0.65460531\n",
      "step: 354.0, loss:0.64357167\n",
      "step: 355.0, loss:0.65613145\n",
      "step: 356.0, loss:0.69054337\n",
      "step: 357.0, loss:0.61560880\n",
      "step: 358.0, loss:0.67146324\n",
      "step: 359.0, loss:0.59991696\n",
      "step: 360.0, loss:0.70506175\n",
      "step: 361.0, loss:0.67127445\n",
      "step: 362.0, loss:0.66402324\n",
      "step: 363.0, loss:0.67246643\n",
      "step: 364.0, loss:0.59564137\n",
      "step: 365.0, loss:0.60855843\n",
      "step: 366.0, loss:0.64974287\n",
      "step: 367.0, loss:0.64773993\n",
      "step: 368.0, loss:0.65402722\n",
      "step: 369.0, loss:0.68548274\n",
      "step: 370.0, loss:0.73302092\n",
      "step: 371.0, loss:0.70842792\n",
      "step: 372.0, loss:0.66152902\n",
      "step: 373.0, loss:0.67185359\n",
      "step: 374.0, loss:0.66543740\n",
      "step: 375.0, loss:0.58800082\n",
      "step: 376.0, loss:0.69035448\n",
      "step: 377.0, loss:0.64357154\n",
      "step: 378.0, loss:0.69323704\n",
      "step: 379.0, loss:0.67873974\n",
      "step: 380.0, loss:0.63102838\n",
      "step: 381.0, loss:0.69931568\n",
      "step: 382.0, loss:0.66454642\n",
      "step: 383.0, loss:0.64300188\n",
      "step: 384.0, loss:0.67359823\n",
      "step: 385.0, loss:0.69165760\n",
      "step: 386.0, loss:0.71108596\n",
      "step: 387.0, loss:0.64001691\n",
      "step: 388.0, loss:0.70154011\n",
      "step: 389.0, loss:0.66598904\n",
      "step: 390.0, loss:0.63963681\n",
      "step: 391.0, loss:0.62712990\n",
      "step: 392.0, loss:0.69760789\n",
      "step: 393.0, loss:0.66348889\n",
      "step: 394.0, loss:0.65452382\n",
      "step: 395.0, loss:0.73225719\n",
      "step: 396.0, loss:0.64897908\n",
      "step: 397.0, loss:0.65464632\n",
      "step: 398.0, loss:0.63136710\n",
      "step: 399.0, loss:0.64755318\n",
      "step: 400.0, loss:0.61931312\n",
      "step: 401.0, loss:0.65386631\n",
      "step: 402.0, loss:0.68916582\n",
      "step: 403.0, loss:0.63965291\n",
      "step: 404.0, loss:0.58867183\n",
      "step: 405.0, loss:0.66488771\n",
      "step: 406.0, loss:0.63045704\n",
      "step: 407.0, loss:0.60980292\n",
      "step: 408.0, loss:0.66702111\n",
      "step: 409.0, loss:0.67222102\n",
      "step: 410.0, loss:0.61128063\n",
      "step: 411.0, loss:0.62707463\n",
      "step: 412.0, loss:0.65312129\n",
      "step: 413.0, loss:0.63997777\n",
      "step: 414.0, loss:0.62645221\n",
      "step: 415.0, loss:0.58287634\n",
      "step: 416.0, loss:0.66165307\n",
      "step: 417.0, loss:0.71133201\n",
      "step: 418.0, loss:0.74840312\n",
      "step: 419.0, loss:0.58224387\n",
      "step: 420.0, loss:0.64977263\n",
      "step: 421.0, loss:0.64060457\n",
      "step: 422.0, loss:0.66472697\n",
      "step: 423.0, loss:0.63433760\n",
      "step: 424.0, loss:0.72929323\n",
      "step: 425.0, loss:0.61308514\n",
      "step: 426.0, loss:0.69561714\n",
      "step: 427.0, loss:0.69546740\n",
      "step: 428.0, loss:0.71750833\n",
      "step: 429.0, loss:0.68534471\n",
      "step: 430.0, loss:0.66615696\n",
      "step: 431.0, loss:0.60380284\n",
      "step: 432.0, loss:0.65870176\n",
      "step: 433.0, loss:0.58540598\n",
      "step: 434.0, loss:0.63933085\n",
      "step: 435.0, loss:0.66212654\n",
      "step: 436.0, loss:0.72879644\n",
      "step: 437.0, loss:0.68526915\n",
      "step: 438.0, loss:0.66143134\n",
      "step: 439.0, loss:0.65301356\n",
      "step: 440.0, loss:0.71616775\n",
      "step: 441.0, loss:0.63877144\n",
      "step: 442.0, loss:0.61121100\n",
      "step: 443.0, loss:0.66392533\n",
      "step: 444.0, loss:0.66353860\n",
      "step: 445.0, loss:0.65348671\n",
      "step: 446.0, loss:0.60538630\n",
      "step: 447.0, loss:0.59452757\n",
      "step: 448.0, loss:0.68060431\n",
      "step: 449.0, loss:0.61962995\n",
      "step: 450.0, loss:0.62818395\n",
      "step: 451.0, loss:0.69527125\n",
      "step: 452.0, loss:0.64521474\n",
      "step: 453.0, loss:0.68307248\n",
      "step: 454.0, loss:0.69777046\n",
      "step: 455.0, loss:0.64861003\n",
      "step: 456.0, loss:0.64258260\n",
      "step: 457.0, loss:0.61545123\n",
      "step: 458.0, loss:0.64174798\n",
      "step: 459.0, loss:0.61466123\n",
      "step: 460.0, loss:0.68199638\n",
      "step: 461.0, loss:0.63990472\n",
      "step: 462.0, loss:0.70534880\n",
      "step: 463.0, loss:0.65199484\n",
      "step: 464.0, loss:0.61763373\n",
      "step: 465.0, loss:0.64566812\n",
      "step: 466.0, loss:0.61380398\n",
      "step: 467.0, loss:0.61513454\n",
      "step: 468.0, loss:0.63761160\n",
      "step: 469.0, loss:0.67277701\n",
      "step: 470.0, loss:0.71765730\n",
      "step: 471.0, loss:0.64521015\n",
      "step: 472.0, loss:0.63035977\n",
      "step: 473.0, loss:0.69015805\n",
      "step: 474.0, loss:0.66960859\n",
      "step: 475.0, loss:0.60089070\n",
      "step: 476.0, loss:0.67991798\n",
      "step: 477.0, loss:0.63705447\n",
      "step: 478.0, loss:0.69248500\n",
      "step: 479.0, loss:0.66390470\n",
      "step: 480.0, loss:0.69350578\n",
      "step: 481.0, loss:0.64965549\n",
      "step: 482.0, loss:0.63112625\n",
      "step: 483.0, loss:0.63478471\n",
      "step: 484.0, loss:0.68435530\n",
      "step: 485.0, loss:0.64456101\n",
      "step: 486.0, loss:0.63064441\n",
      "step: 487.0, loss:0.62501051\n",
      "step: 488.0, loss:0.66414803\n",
      "step: 489.0, loss:0.63961767\n",
      "step: 490.0, loss:0.61077516\n",
      "step: 491.0, loss:0.65563485\n",
      "step: 492.0, loss:0.63802296\n",
      "step: 493.0, loss:0.67550595\n",
      "step: 494.0, loss:0.66885065\n",
      "step: 495.0, loss:0.62499630\n",
      "step: 496.0, loss:0.63084418\n",
      "step: 497.0, loss:0.64793374\n",
      "step: 498.0, loss:0.62254110\n",
      "step: 499.0, loss:0.64140359\n",
      "step: 500.0, loss:0.67381221\n",
      "step: 501.0, loss:0.60719213\n",
      "step: 502.0, loss:0.60971958\n",
      "step: 503.0, loss:0.66717933\n",
      "step: 504.0, loss:0.63451950\n",
      "step: 505.0, loss:0.58572827\n",
      "step: 506.0, loss:0.65870485\n",
      "step: 507.0, loss:0.68130794\n",
      "step: 508.0, loss:0.61376487\n",
      "step: 509.0, loss:0.62526399\n",
      "step: 510.0, loss:0.66747697\n",
      "step: 511.0, loss:0.64080833\n",
      "step: 512.0, loss:0.65478477\n",
      "step: 513.0, loss:0.63985069\n",
      "step: 514.0, loss:0.62740207\n",
      "step: 515.0, loss:0.58706021\n",
      "step: 516.0, loss:0.65114394\n",
      "step: 517.0, loss:0.62116469\n",
      "step: 518.0, loss:0.64576237\n",
      "step: 519.0, loss:0.63057742\n",
      "step: 520.0, loss:0.64321636\n",
      "step: 521.0, loss:0.54773135\n",
      "step: 522.0, loss:0.64154156\n",
      "step: 523.0, loss:0.63317682\n",
      "step: 524.0, loss:0.64892748\n",
      "step: 525.0, loss:0.66451825\n",
      "step: 526.0, loss:0.63068615\n",
      "step: 527.0, loss:0.55242195\n",
      "step: 528.0, loss:0.59907249\n",
      "step: 529.0, loss:0.63891055\n",
      "step: 530.0, loss:0.63403346\n",
      "step: 531.0, loss:0.57066621\n",
      "step: 532.0, loss:0.60786894\n",
      "step: 533.0, loss:0.63213636\n",
      "step: 534.0, loss:0.62660832\n",
      "step: 535.0, loss:0.63317509\n",
      "step: 536.0, loss:0.58646594\n",
      "step: 537.0, loss:0.65544598\n",
      "step: 538.0, loss:0.64776751\n",
      "step: 539.0, loss:0.63550782\n",
      "step: 540.0, loss:0.62091036\n",
      "step: 541.0, loss:0.66417058\n",
      "step: 542.0, loss:0.64152648\n",
      "step: 543.0, loss:0.68739244\n",
      "step: 544.0, loss:0.64963543\n",
      "step: 545.0, loss:0.66527914\n",
      "step: 546.0, loss:0.68360035\n",
      "step: 547.0, loss:0.60793562\n",
      "step: 548.0, loss:0.66515261\n",
      "step: 549.0, loss:0.63692488\n",
      "step: 550.0, loss:0.59729318\n",
      "step: 551.0, loss:0.63663544\n",
      "step: 552.0, loss:0.61851920\n",
      "step: 553.0, loss:0.60101785\n",
      "step: 554.0, loss:0.62155452\n",
      "step: 555.0, loss:0.64083308\n",
      "step: 556.0, loss:0.61836191\n",
      "step: 557.0, loss:0.61750257\n",
      "step: 558.0, loss:0.65502432\n",
      "step: 559.0, loss:0.65776095\n",
      "step: 560.0, loss:0.65250267\n",
      "step: 561.0, loss:0.61832012\n",
      "step: 562.0, loss:0.60912803\n",
      "step: 563.0, loss:0.64521670\n",
      "step: 564.0, loss:0.64719783\n",
      "step: 565.0, loss:0.64697315\n",
      "step: 566.0, loss:0.65432245\n",
      "step: 567.0, loss:0.63154493\n",
      "step: 568.0, loss:0.59366661\n",
      "step: 569.0, loss:0.64454460\n",
      "step: 570.0, loss:0.66438648\n",
      "step: 571.0, loss:0.60786013\n",
      "step: 572.0, loss:0.61567168\n",
      "step: 573.0, loss:0.63824938\n",
      "step: 574.0, loss:0.61674444\n",
      "step: 575.0, loss:0.58129628\n",
      "step: 576.0, loss:0.62653875\n",
      "step: 577.0, loss:0.60176776\n",
      "step: 578.0, loss:0.60240747\n",
      "step: 579.0, loss:0.60556959\n",
      "step: 580.0, loss:0.64691302\n",
      "step: 581.0, loss:0.59071712\n",
      "step: 582.0, loss:0.58372574\n",
      "step: 583.0, loss:0.60426378\n",
      "step: 584.0, loss:0.60934904\n",
      "step: 585.0, loss:0.60091276\n",
      "step: 586.0, loss:0.61101437\n",
      "step: 587.0, loss:0.54546348\n",
      "step: 588.0, loss:0.60730146\n",
      "step: 589.0, loss:0.62768015\n",
      "step: 590.0, loss:0.59058669\n",
      "step: 591.0, loss:0.65334535\n",
      "step: 592.0, loss:0.61007310\n",
      "step: 593.0, loss:0.62683053\n",
      "step: 594.0, loss:0.60228279\n",
      "step: 595.0, loss:0.63790151\n",
      "step: 596.0, loss:0.59385283\n",
      "step: 597.0, loss:0.59165065\n",
      "step: 598.0, loss:0.63120838\n",
      "step: 599.0, loss:0.62820913\n",
      "step: 600.0, loss:0.60098156\n",
      "step: 601.0, loss:0.59905678\n",
      "step: 602.0, loss:0.58275779\n",
      "step: 603.0, loss:0.67013843\n",
      "step: 604.0, loss:0.61633103\n",
      "step: 605.0, loss:0.62860423\n",
      "step: 606.0, loss:0.63053912\n",
      "step: 607.0, loss:0.60460496\n",
      "step: 608.0, loss:0.57608977\n",
      "step: 609.0, loss:0.60259733\n",
      "step: 610.0, loss:0.63503513\n",
      "step: 611.0, loss:0.60133500\n",
      "step: 612.0, loss:0.60206796\n",
      "step: 613.0, loss:0.55461483\n",
      "step: 614.0, loss:0.59573072\n",
      "step: 615.0, loss:0.63904910\n",
      "step: 616.0, loss:0.61092019\n",
      "step: 617.0, loss:0.59133962\n",
      "step: 618.0, loss:0.68239233\n",
      "step: 619.0, loss:0.63924493\n",
      "step: 620.0, loss:0.60572298\n",
      "step: 621.0, loss:0.66546261\n",
      "step: 622.0, loss:0.61482619\n",
      "step: 623.0, loss:0.56366296\n",
      "step: 624.0, loss:0.59982628\n",
      "step: 625.0, loss:0.60796273\n",
      "step: 626.0, loss:0.63726966\n",
      "step: 627.0, loss:0.58842526\n",
      "step: 628.0, loss:0.63413045\n",
      "step: 629.0, loss:0.60826899\n",
      "step: 630.0, loss:0.55096020\n",
      "step: 631.0, loss:0.59032267\n",
      "step: 632.0, loss:0.61533728\n",
      "step: 633.0, loss:0.60136282\n",
      "step: 634.0, loss:0.62022611\n",
      "step: 635.0, loss:0.65487625\n",
      "step: 636.0, loss:0.57056443\n",
      "step: 637.0, loss:0.55147152\n",
      "step: 638.0, loss:0.60183664\n",
      "step: 639.0, loss:0.57286111\n",
      "step: 640.0, loss:0.61487716\n",
      "step: 641.0, loss:0.61436205\n",
      "step: 642.0, loss:0.61969167\n",
      "step: 643.0, loss:0.58278090\n",
      "step: 644.0, loss:0.61887056\n",
      "step: 645.0, loss:0.56291310\n",
      "step: 646.0, loss:0.55888541\n",
      "step: 647.0, loss:0.61936291\n",
      "step: 648.0, loss:0.59869194\n",
      "step: 649.0, loss:0.58079977\n",
      "step: 650.0, loss:0.59466738\n",
      "step: 651.0, loss:0.60331669\n",
      "step: 652.0, loss:0.64540860\n",
      "step: 653.0, loss:0.60037585\n",
      "step: 654.0, loss:0.62678243\n",
      "step: 655.0, loss:0.56914574\n",
      "step: 656.0, loss:0.61150727\n",
      "step: 657.0, loss:0.61280504\n",
      "step: 658.0, loss:0.59692590\n",
      "step: 659.0, loss:0.59669228\n",
      "step: 660.0, loss:0.57332598\n",
      "step: 661.0, loss:0.60258588\n",
      "step: 662.0, loss:0.60072151\n",
      "step: 663.0, loss:0.59860595\n",
      "step: 664.0, loss:0.56027721\n",
      "step: 665.0, loss:0.60228197\n",
      "step: 666.0, loss:0.58450738\n",
      "step: 667.0, loss:0.54205473\n",
      "step: 668.0, loss:0.60327469\n",
      "step: 669.0, loss:0.53825749\n",
      "step: 670.0, loss:0.58031768\n",
      "step: 671.0, loss:0.57722503\n",
      "step: 672.0, loss:0.68433452\n",
      "step: 673.0, loss:0.61340649\n",
      "step: 674.0, loss:0.51737292\n",
      "step: 675.0, loss:0.61164001\n",
      "step: 676.0, loss:0.48907807\n",
      "step: 677.0, loss:0.59140201\n",
      "step: 678.0, loss:0.58198321\n",
      "step: 679.0, loss:0.64382532\n",
      "step: 680.0, loss:0.58539025\n",
      "step: 681.0, loss:0.62176482\n",
      "step: 682.0, loss:0.56032446\n",
      "step: 683.0, loss:0.58373981\n",
      "step: 684.0, loss:0.57773909\n",
      "step: 685.0, loss:0.52494810\n",
      "step: 686.0, loss:0.58089308\n",
      "step: 687.0, loss:0.53255667\n",
      "step: 688.0, loss:0.59922813\n",
      "step: 689.0, loss:0.62678915\n",
      "step: 690.0, loss:0.57937984\n",
      "step: 691.0, loss:0.62410092\n",
      "step: 692.0, loss:0.56599484\n",
      "step: 693.0, loss:0.59938279\n",
      "step: 694.0, loss:0.57688700\n",
      "step: 695.0, loss:0.56800357\n",
      "step: 696.0, loss:0.62928890\n",
      "step: 697.0, loss:0.56655252\n",
      "step: 698.0, loss:0.54384012\n",
      "step: 699.0, loss:0.66726492\n",
      "step: 700.0, loss:0.64554346\n",
      "step: 701.0, loss:0.56478809\n",
      "step: 702.0, loss:0.53869143\n",
      "step: 703.0, loss:0.49922263\n",
      "step: 704.0, loss:0.58559133\n",
      "step: 705.0, loss:0.54811119\n",
      "step: 706.0, loss:0.52569529\n",
      "step: 707.0, loss:0.52705212\n",
      "step: 708.0, loss:0.53280071\n",
      "step: 709.0, loss:0.61997849\n",
      "step: 710.0, loss:0.57774670\n",
      "step: 711.0, loss:0.58757210\n",
      "step: 712.0, loss:0.59923489\n",
      "step: 713.0, loss:0.59375344\n",
      "step: 714.0, loss:0.52581588\n",
      "step: 715.0, loss:0.59504478\n",
      "step: 716.0, loss:0.54282275\n",
      "step: 717.0, loss:0.58290904\n",
      "step: 718.0, loss:0.57261435\n",
      "step: 719.0, loss:0.56669591\n",
      "step: 720.0, loss:0.57083982\n",
      "step: 721.0, loss:0.54709850\n",
      "step: 722.0, loss:0.55011679\n",
      "step: 723.0, loss:0.54758042\n",
      "step: 724.0, loss:0.58958928\n",
      "step: 725.0, loss:0.53053617\n",
      "step: 726.0, loss:0.58498302\n",
      "step: 727.0, loss:0.50336591\n",
      "step: 728.0, loss:0.48625056\n",
      "step: 729.0, loss:0.54872963\n",
      "step: 730.0, loss:0.58824957\n",
      "step: 731.0, loss:0.59371683\n",
      "step: 732.0, loss:0.52518833\n",
      "step: 733.0, loss:0.51600596\n",
      "step: 734.0, loss:0.49241804\n",
      "step: 735.0, loss:0.56719006\n",
      "step: 736.0, loss:0.51949120\n",
      "step: 737.0, loss:0.54213769\n",
      "step: 738.0, loss:0.55404807\n",
      "step: 739.0, loss:0.50594159\n",
      "step: 740.0, loss:0.55351555\n",
      "step: 741.0, loss:0.52520677\n",
      "step: 742.0, loss:0.52799404\n",
      "step: 743.0, loss:0.55839200\n",
      "step: 744.0, loss:0.53502098\n",
      "step: 745.0, loss:0.47155679\n",
      "step: 746.0, loss:0.55226398\n",
      "step: 747.0, loss:0.52511295\n",
      "step: 748.0, loss:0.57865396\n",
      "step: 749.0, loss:0.46986459\n",
      "step: 750.0, loss:0.54354495\n",
      "step: 751.0, loss:0.43587204\n",
      "step: 752.0, loss:0.52017856\n",
      "step: 753.0, loss:0.51121161\n",
      "step: 754.0, loss:0.48564415\n",
      "step: 755.0, loss:0.59044360\n",
      "step: 756.0, loss:0.46407166\n",
      "step: 757.0, loss:0.50291337\n",
      "step: 758.0, loss:0.54861335\n",
      "step: 759.0, loss:0.56613462\n",
      "step: 760.0, loss:0.46785425\n",
      "step: 761.0, loss:0.54408067\n",
      "step: 762.0, loss:0.46276693\n",
      "step: 763.0, loss:0.58081655\n",
      "step: 764.0, loss:0.48538234\n",
      "step: 765.0, loss:0.52939170\n",
      "step: 766.0, loss:0.50228261\n",
      "step: 767.0, loss:0.60639723\n",
      "step: 768.0, loss:0.52194811\n",
      "step: 769.0, loss:0.59823710\n",
      "step: 770.0, loss:0.48918480\n",
      "step: 771.0, loss:0.50533879\n",
      "step: 772.0, loss:0.61282880\n",
      "step: 773.0, loss:0.52471759\n",
      "step: 774.0, loss:0.55966415\n",
      "step: 775.0, loss:0.54306434\n",
      "step: 776.0, loss:0.51834318\n",
      "step: 777.0, loss:0.44154894\n",
      "step: 778.0, loss:0.46487149\n",
      "step: 779.0, loss:0.43963572\n",
      "step: 780.0, loss:0.56645647\n",
      "step: 781.0, loss:0.56933341\n",
      "step: 782.0, loss:0.57789171\n",
      "step: 783.0, loss:0.45736671\n",
      "step: 784.0, loss:0.62114307\n",
      "step: 785.0, loss:0.60548916\n",
      "step: 786.0, loss:0.45794834\n",
      "step: 787.0, loss:0.60224377\n",
      "step: 788.0, loss:0.50931850\n",
      "step: 789.0, loss:0.55123909\n",
      "step: 790.0, loss:0.51197850\n",
      "step: 791.0, loss:0.49647589\n",
      "step: 792.0, loss:0.56563512\n",
      "step: 793.0, loss:0.51683462\n",
      "step: 794.0, loss:0.54114792\n",
      "step: 795.0, loss:0.50138421\n",
      "step: 796.0, loss:0.45588898\n",
      "step: 797.0, loss:0.47097393\n",
      "step: 798.0, loss:0.56252706\n",
      "step: 799.0, loss:0.46375249\n",
      "step: 800.0, loss:0.51112679\n",
      "step: 801.0, loss:0.55750391\n",
      "step: 802.0, loss:0.51935398\n",
      "step: 803.0, loss:0.55075676\n",
      "step: 804.0, loss:0.42430416\n",
      "step: 805.0, loss:0.54124767\n",
      "step: 806.0, loss:0.57922231\n",
      "step: 807.0, loss:0.46074077\n",
      "step: 808.0, loss:0.56741095\n",
      "step: 809.0, loss:0.50863955\n",
      "step: 810.0, loss:0.47027872\n",
      "step: 811.0, loss:0.50114062\n",
      "step: 812.0, loss:0.42654129\n",
      "step: 813.0, loss:0.44244468\n",
      "step: 814.0, loss:0.55881334\n",
      "step: 815.0, loss:0.57456046\n",
      "step: 816.0, loss:0.54065507\n",
      "step: 817.0, loss:0.48389255\n",
      "step: 818.0, loss:0.44065221\n",
      "step: 819.0, loss:0.44837937\n",
      "step: 820.0, loss:0.44679260\n",
      "step: 821.0, loss:0.53066647\n",
      "step: 822.0, loss:0.47371586\n",
      "step: 823.0, loss:0.41379220\n",
      "step: 824.0, loss:0.48770164\n",
      "step: 825.0, loss:0.41804668\n",
      "step: 826.0, loss:0.59428489\n",
      "step: 827.0, loss:0.49557225\n",
      "step: 828.0, loss:0.39666215\n",
      "step: 829.0, loss:0.47337990\n",
      "step: 830.0, loss:0.49072759\n",
      "step: 831.0, loss:0.53491823\n",
      "step: 832.0, loss:0.45632952\n",
      "step: 833.0, loss:0.50879611\n",
      "step: 834.0, loss:0.48114602\n",
      "step: 835.0, loss:0.49755520\n",
      "step: 836.0, loss:0.54540059\n",
      "step: 837.0, loss:0.50060356\n",
      "step: 838.0, loss:0.52108636\n",
      "step: 839.0, loss:0.53334339\n",
      "step: 840.0, loss:0.57349002\n",
      "step: 841.0, loss:0.44820806\n",
      "step: 842.0, loss:0.50531180\n",
      "step: 843.0, loss:0.46255364\n",
      "step: 844.0, loss:0.56572157\n",
      "step: 845.0, loss:0.50551811\n",
      "step: 846.0, loss:0.47304796\n",
      "step: 847.0, loss:0.44965630\n",
      "step: 848.0, loss:0.48336983\n",
      "step: 849.0, loss:0.44149549\n",
      "step: 850.0, loss:0.50777493\n",
      "step: 851.0, loss:0.55322748\n",
      "step: 852.0, loss:0.45550545\n",
      "step: 853.0, loss:0.45265086\n",
      "step: 854.0, loss:0.46886703\n",
      "step: 855.0, loss:0.51069620\n",
      "step: 856.0, loss:0.53078162\n",
      "step: 857.0, loss:0.55376044\n",
      "step: 858.0, loss:0.44420109\n",
      "step: 859.0, loss:0.43595216\n",
      "step: 860.0, loss:0.49018932\n",
      "step: 861.0, loss:0.55731083\n",
      "step: 862.0, loss:0.46432039\n",
      "step: 863.0, loss:0.44321767\n",
      "step: 864.0, loss:0.48816387\n",
      "step: 865.0, loss:0.50639629\n",
      "step: 866.0, loss:0.56139400\n",
      "step: 867.0, loss:0.51379846\n",
      "step: 868.0, loss:0.55496637\n",
      "step: 869.0, loss:0.46861146\n",
      "step: 870.0, loss:0.48812243\n",
      "step: 871.0, loss:0.55183855\n",
      "step: 872.0, loss:0.34333499\n",
      "step: 873.0, loss:0.40433396\n",
      "step: 874.0, loss:0.44328623\n",
      "step: 875.0, loss:0.51084828\n",
      "step: 876.0, loss:0.52102061\n",
      "step: 877.0, loss:0.52800065\n",
      "step: 878.0, loss:0.45683140\n",
      "step: 879.0, loss:0.45524336\n",
      "step: 880.0, loss:0.53866073\n",
      "step: 881.0, loss:0.62213944\n",
      "step: 882.0, loss:0.41929872\n",
      "step: 883.0, loss:0.54873059\n",
      "step: 884.0, loss:0.49842896\n",
      "step: 885.0, loss:0.49769296\n",
      "step: 886.0, loss:0.49538549\n",
      "step: 887.0, loss:0.51385218\n",
      "step: 888.0, loss:0.53838873\n",
      "step: 889.0, loss:0.51362775\n",
      "step: 890.0, loss:0.45151556\n",
      "step: 891.0, loss:0.59240250\n",
      "step: 892.0, loss:0.49676686\n",
      "step: 893.0, loss:0.46817339\n",
      "step: 894.0, loss:0.44589899\n",
      "step: 895.0, loss:0.33654270\n",
      "step: 896.0, loss:0.51886694\n",
      "step: 897.0, loss:0.46296607\n",
      "step: 898.0, loss:0.43927595\n",
      "step: 899.0, loss:0.43309225\n",
      "step: 900.0, loss:0.40878575\n",
      "step: 901.0, loss:0.44767164\n",
      "step: 902.0, loss:0.56643658\n",
      "step: 903.0, loss:0.37484699\n",
      "step: 904.0, loss:0.41132949\n",
      "step: 905.0, loss:0.45625966\n",
      "step: 906.0, loss:0.40771403\n",
      "step: 907.0, loss:0.37534514\n",
      "step: 908.0, loss:0.49081279\n",
      "step: 909.0, loss:0.44933259\n",
      "step: 910.0, loss:0.47497137\n",
      "step: 911.0, loss:0.47878783\n",
      "step: 912.0, loss:0.47635853\n",
      "step: 913.0, loss:0.51533230\n",
      "step: 914.0, loss:0.48534952\n",
      "step: 915.0, loss:0.39702440\n",
      "step: 916.0, loss:0.40327705\n",
      "step: 917.0, loss:0.45879009\n",
      "step: 918.0, loss:0.49182463\n",
      "step: 919.0, loss:0.48055013\n",
      "step: 920.0, loss:0.44000412\n",
      "step: 921.0, loss:0.44608858\n",
      "step: 922.0, loss:0.56478418\n",
      "step: 923.0, loss:0.57220694\n",
      "step: 924.0, loss:0.47382224\n",
      "step: 925.0, loss:0.47208252\n",
      "step: 926.0, loss:0.47235870\n",
      "step: 927.0, loss:0.48465004\n",
      "step: 928.0, loss:0.49150707\n",
      "step: 929.0, loss:0.46918571\n",
      "step: 930.0, loss:0.49689641\n",
      "step: 931.0, loss:0.53481706\n",
      "step: 932.0, loss:0.46799321\n",
      "step: 933.0, loss:0.29378938\n",
      "step: 934.0, loss:0.42128719\n",
      "step: 935.0, loss:0.46706425\n",
      "step: 936.0, loss:0.50230308\n",
      "step: 937.0, loss:0.44419572\n",
      "step: 938.0, loss:0.47554206\n",
      "step: 939.0, loss:0.40066420\n",
      "step: 940.0, loss:0.46065390\n",
      "step: 941.0, loss:0.52815327\n",
      "step: 942.0, loss:0.45482702\n",
      "step: 943.0, loss:0.40308963\n",
      "step: 944.0, loss:0.45386707\n",
      "step: 945.0, loss:0.51726364\n",
      "step: 946.0, loss:0.44164516\n",
      "step: 947.0, loss:0.53279386\n",
      "step: 948.0, loss:0.45794424\n",
      "step: 949.0, loss:0.52492043\n",
      "step: 950.0, loss:0.37786982\n",
      "step: 951.0, loss:0.44445565\n",
      "step: 952.0, loss:0.49490137\n",
      "step: 953.0, loss:0.44595843\n",
      "step: 954.0, loss:0.33013236\n",
      "step: 955.0, loss:0.40248927\n",
      "step: 956.0, loss:0.55431493\n",
      "step: 957.0, loss:0.43827921\n",
      "step: 958.0, loss:0.40120400\n",
      "step: 959.0, loss:0.43202536\n",
      "step: 960.0, loss:0.48621131\n",
      "step: 961.0, loss:0.38268624\n",
      "step: 962.0, loss:0.44229241\n",
      "step: 963.0, loss:0.56102908\n",
      "step: 964.0, loss:0.51151137\n",
      "step: 965.0, loss:0.44742940\n",
      "step: 966.0, loss:0.55476061\n",
      "step: 967.0, loss:0.47139545\n",
      "step: 968.0, loss:0.61052057\n",
      "step: 969.0, loss:0.37131550\n",
      "step: 970.0, loss:0.41398487\n",
      "step: 971.0, loss:0.44686211\n",
      "step: 972.0, loss:0.57587888\n",
      "step: 973.0, loss:0.53399581\n",
      "step: 974.0, loss:0.54844435\n",
      "step: 975.0, loss:0.44763546\n",
      "step: 976.0, loss:0.59524271\n",
      "step: 977.0, loss:0.35423156\n",
      "step: 978.0, loss:0.45204858\n",
      "step: 979.0, loss:0.50866728\n",
      "step: 980.0, loss:0.47687680\n",
      "step: 981.0, loss:0.44390158\n",
      "step: 982.0, loss:0.51802692\n",
      "step: 983.0, loss:0.49416637\n",
      "step: 984.0, loss:0.34570935\n",
      "step: 985.0, loss:0.53807820\n",
      "step: 986.0, loss:0.37668570\n",
      "step: 987.0, loss:0.45308629\n",
      "step: 988.0, loss:0.48902014\n",
      "step: 989.0, loss:0.40540408\n",
      "step: 990.0, loss:0.47722269\n",
      "step: 991.0, loss:0.41304194\n",
      "step: 992.0, loss:0.51279075\n",
      "step: 993.0, loss:0.51367792\n",
      "step: 994.0, loss:0.44366721\n",
      "step: 995.0, loss:0.44283675\n",
      "step: 996.0, loss:0.50067146\n",
      "step: 997.0, loss:0.45002177\n",
      "step: 998.0, loss:0.41306688\n",
      "step: 999.0, loss:0.47647960\n",
      "step: 1000.0, loss:0.43429137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1264/1264 [06:57<00:00,  3.03it/s]\n",
      "2023-04-02 17:43:17,661 - INFO - step:1000.0, matthews_corr:0.566281, Acc:76.126639%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1001.0, loss:0.50377335\n",
      "step: 1002.0, loss:0.42402694\n",
      "step: 1003.0, loss:0.43730822\n",
      "step: 1004.0, loss:0.44255953\n",
      "step: 1005.0, loss:0.38275766\n",
      "step: 1006.0, loss:0.34251319\n",
      "step: 1007.0, loss:0.34425051\n",
      "step: 1008.0, loss:0.42033891\n",
      "step: 1009.0, loss:0.34891225\n",
      "step: 1010.0, loss:0.55529603\n",
      "step: 1011.0, loss:0.49168870\n",
      "step: 1012.0, loss:0.48958986\n",
      "step: 1013.0, loss:0.46754875\n",
      "step: 1014.0, loss:0.52816667\n",
      "step: 1015.0, loss:0.53051329\n",
      "step: 1016.0, loss:0.38417477\n",
      "step: 1017.0, loss:0.48614062\n",
      "step: 1018.0, loss:0.38896070\n",
      "step: 1019.0, loss:0.46323124\n",
      "step: 1020.0, loss:0.43898649\n",
      "step: 1021.0, loss:0.44183081\n",
      "step: 1022.0, loss:0.38663483\n",
      "step: 1023.0, loss:0.31583992\n",
      "step: 1024.0, loss:0.46292890\n",
      "step: 1025.0, loss:0.44986677\n",
      "step: 1026.0, loss:0.41096546\n",
      "step: 1027.0, loss:0.41264919\n",
      "step: 1028.0, loss:0.36960481\n",
      "step: 1029.0, loss:0.43715471\n",
      "step: 1030.0, loss:0.34854306\n",
      "step: 1031.0, loss:0.48332861\n",
      "step: 1032.0, loss:0.55227780\n",
      "step: 1033.0, loss:0.42992652\n",
      "step: 1034.0, loss:0.38136519\n",
      "step: 1035.0, loss:0.39234110\n",
      "step: 1036.0, loss:0.40021949\n",
      "step: 1037.0, loss:0.47704708\n",
      "step: 1038.0, loss:0.43612810\n",
      "step: 1039.0, loss:0.50686172\n",
      "step: 1040.0, loss:0.40073737\n",
      "step: 1041.0, loss:0.45102217\n",
      "step: 1042.0, loss:0.47505735\n",
      "step: 1043.0, loss:0.47813798\n",
      "step: 1044.0, loss:0.35341536\n",
      "step: 1045.0, loss:0.43023370\n",
      "step: 1046.0, loss:0.47819843\n",
      "step: 1047.0, loss:0.57048099\n",
      "step: 1048.0, loss:0.41470812\n",
      "step: 1049.0, loss:0.33039673\n",
      "step: 1050.0, loss:0.34253393\n",
      "step: 1051.0, loss:0.34241461\n",
      "step: 1052.0, loss:0.48130351\n",
      "step: 1053.0, loss:0.41253794\n",
      "step: 1054.0, loss:0.44880180\n",
      "step: 1055.0, loss:0.57080498\n",
      "step: 1056.0, loss:0.38241800\n",
      "step: 1057.0, loss:0.44359571\n",
      "step: 1058.0, loss:0.51763502\n",
      "step: 1059.0, loss:0.44554411\n",
      "step: 1060.0, loss:0.42345417\n",
      "step: 1061.0, loss:0.46076249\n",
      "step: 1062.0, loss:0.46898650\n",
      "step: 1063.0, loss:0.42731972\n",
      "step: 1064.0, loss:0.55251680\n",
      "step: 1065.0, loss:0.38738046\n",
      "step: 1066.0, loss:0.48253199\n",
      "step: 1067.0, loss:0.38276305\n",
      "step: 1068.0, loss:0.40126808\n",
      "step: 1069.0, loss:0.48321206\n",
      "step: 1070.0, loss:0.39982994\n",
      "step: 1071.0, loss:0.45395675\n",
      "step: 1072.0, loss:0.46340211\n",
      "step: 1073.0, loss:0.40843039\n",
      "step: 1074.0, loss:0.39816315\n",
      "step: 1075.0, loss:0.41357628\n",
      "step: 1076.0, loss:0.57073494\n",
      "step: 1077.0, loss:0.39402859\n",
      "step: 1078.0, loss:0.44129290\n",
      "step: 1079.0, loss:0.46263131\n",
      "step: 1080.0, loss:0.56231601\n",
      "step: 1081.0, loss:0.50251218\n",
      "step: 1082.0, loss:0.49037427\n",
      "step: 1083.0, loss:0.48519405\n",
      "step: 1084.0, loss:0.47667978\n",
      "step: 1085.0, loss:0.43924624\n",
      "step: 1086.0, loss:0.48722223\n",
      "step: 1087.0, loss:0.42567510\n",
      "step: 1088.0, loss:0.49080568\n",
      "step: 1089.0, loss:0.35809752\n",
      "step: 1090.0, loss:0.46010152\n",
      "step: 1091.0, loss:0.42410576\n",
      "step: 1092.0, loss:0.39721526\n",
      "step: 1093.0, loss:0.41241190\n",
      "step: 1094.0, loss:0.41596350\n",
      "step: 1095.0, loss:0.43157034\n",
      "step: 1096.0, loss:0.42923903\n",
      "step: 1097.0, loss:0.44457800\n",
      "step: 1098.0, loss:0.46322549\n",
      "step: 1099.0, loss:0.45121549\n",
      "step: 1100.0, loss:0.40215012\n",
      "step: 1101.0, loss:0.43699192\n",
      "step: 1102.0, loss:0.51605003\n",
      "step: 1103.0, loss:0.47646406\n",
      "step: 1104.0, loss:0.30957216\n",
      "step: 1105.0, loss:0.44656573\n",
      "step: 1106.0, loss:0.46630181\n",
      "step: 1107.0, loss:0.44673312\n",
      "step: 1108.0, loss:0.48781990\n",
      "step: 1109.0, loss:0.42093534\n",
      "step: 1110.0, loss:0.46735249\n",
      "step: 1111.0, loss:0.35773830\n",
      "step: 1112.0, loss:0.51389041\n",
      "step: 1113.0, loss:0.44900310\n",
      "step: 1114.0, loss:0.51042906\n",
      "step: 1115.0, loss:0.54018992\n",
      "step: 1116.0, loss:0.41531937\n",
      "step: 1117.0, loss:0.42630412\n",
      "step: 1118.0, loss:0.48198968\n",
      "step: 1119.0, loss:0.37309919\n",
      "step: 1120.0, loss:0.34901511\n",
      "step: 1121.0, loss:0.56028833\n",
      "step: 1122.0, loss:0.49493762\n",
      "step: 1123.0, loss:0.35425497\n",
      "step: 1124.0, loss:0.35669485\n",
      "step: 1125.0, loss:0.52157248\n",
      "step: 1126.0, loss:0.39568575\n",
      "step: 1127.0, loss:0.40006422\n",
      "step: 1128.0, loss:0.30715325\n",
      "step: 1129.0, loss:0.46169930\n",
      "step: 1130.0, loss:0.45763236\n",
      "step: 1131.0, loss:0.51823421\n",
      "step: 1132.0, loss:0.37026113\n",
      "step: 1133.0, loss:0.40807663\n",
      "step: 1134.0, loss:0.39254251\n",
      "step: 1135.0, loss:0.41356090\n",
      "step: 1136.0, loss:0.38221062\n",
      "step: 1137.0, loss:0.42664650\n",
      "step: 1138.0, loss:0.44081332\n",
      "step: 1139.0, loss:0.38041384\n",
      "step: 1140.0, loss:0.39728656\n",
      "step: 1141.0, loss:0.48511001\n",
      "step: 1142.0, loss:0.44831501\n",
      "step: 1143.0, loss:0.43984698\n",
      "step: 1144.0, loss:0.43538968\n",
      "step: 1145.0, loss:0.34546700\n",
      "step: 1146.0, loss:0.41399095\n",
      "step: 1147.0, loss:0.34606164\n",
      "step: 1148.0, loss:0.34167222\n",
      "step: 1149.0, loss:0.42768195\n",
      "step: 1150.0, loss:0.38952700\n",
      "step: 1151.0, loss:0.49211868\n",
      "step: 1152.0, loss:0.33491985\n",
      "step: 1153.0, loss:0.41402277\n",
      "step: 1154.0, loss:0.41351568\n",
      "step: 1155.0, loss:0.46138339\n",
      "step: 1156.0, loss:0.43618337\n",
      "step: 1157.0, loss:0.32918921\n",
      "step: 1158.0, loss:0.41840008\n",
      "step: 1159.0, loss:0.45605686\n",
      "step: 1160.0, loss:0.38923173\n",
      "step: 1161.0, loss:0.49772990\n",
      "step: 1162.0, loss:0.35706150\n",
      "step: 1163.0, loss:0.42710827\n",
      "step: 1164.0, loss:0.47074205\n",
      "step: 1165.0, loss:0.38759113\n",
      "step: 1166.0, loss:0.39302028\n",
      "step: 1167.0, loss:0.44416341\n",
      "step: 1168.0, loss:0.34038362\n",
      "step: 1169.0, loss:0.34769002\n",
      "step: 1170.0, loss:0.50370364\n",
      "step: 1171.0, loss:0.39302586\n",
      "step: 1172.0, loss:0.46476894\n",
      "step: 1173.0, loss:0.50079938\n",
      "step: 1174.0, loss:0.40089057\n",
      "step: 1175.0, loss:0.43514941\n",
      "step: 1176.0, loss:0.55027730\n",
      "step: 1177.0, loss:0.52659804\n",
      "step: 1178.0, loss:0.47588274\n",
      "step: 1179.0, loss:0.51552300\n",
      "step: 1180.0, loss:0.50322313\n",
      "step: 1181.0, loss:0.46825955\n",
      "step: 1182.0, loss:0.42092808\n",
      "step: 1183.0, loss:0.43253289\n",
      "step: 1184.0, loss:0.44471523\n",
      "step: 1185.0, loss:0.52084199\n",
      "step: 1186.0, loss:0.44334165\n",
      "step: 1187.0, loss:0.41174045\n",
      "step: 1188.0, loss:0.47273146\n",
      "step: 1189.0, loss:0.42346149\n",
      "step: 1190.0, loss:0.46694810\n",
      "step: 1191.0, loss:0.41615532\n",
      "step: 1192.0, loss:0.48059988\n",
      "step: 1193.0, loss:0.44835621\n",
      "step: 1194.0, loss:0.36668035\n",
      "step: 1195.0, loss:0.50111225\n",
      "step: 1196.0, loss:0.34573409\n",
      "step: 1197.0, loss:0.40563369\n",
      "step: 1198.0, loss:0.49922294\n",
      "step: 1199.0, loss:0.45321022\n",
      "step: 1200.0, loss:0.37740259\n",
      "step: 1201.0, loss:0.44681907\n",
      "step: 1202.0, loss:0.46360569\n",
      "step: 1203.0, loss:0.44596495\n",
      "step: 1204.0, loss:0.37959934\n",
      "step: 1205.0, loss:0.45452961\n",
      "step: 1206.0, loss:0.28203768\n",
      "step: 1207.0, loss:0.51278628\n",
      "step: 1208.0, loss:0.49660296\n",
      "step: 1209.0, loss:0.37656683\n",
      "step: 1210.0, loss:0.40813004\n",
      "step: 1211.0, loss:0.50837657\n",
      "step: 1212.0, loss:0.43776733\n",
      "step: 1213.0, loss:0.40299805\n",
      "step: 1214.0, loss:0.38322026\n",
      "step: 1215.0, loss:0.41388024\n",
      "step: 1216.0, loss:0.40344860\n",
      "step: 1217.0, loss:0.46783864\n",
      "step: 1218.0, loss:0.46961953\n",
      "step: 1219.0, loss:0.39686839\n",
      "step: 1220.0, loss:0.29533316\n",
      "step: 1221.0, loss:0.50537749\n",
      "step: 1222.0, loss:0.41765271\n",
      "step: 1223.0, loss:0.43687058\n",
      "step: 1224.0, loss:0.31570564\n",
      "step: 1225.0, loss:0.36660088\n",
      "step: 1226.0, loss:0.30663349\n",
      "step: 1227.0, loss:0.46790124\n",
      "step: 1228.0, loss:0.42594828\n",
      "step: 1229.0, loss:0.47825164\n",
      "step: 1230.0, loss:0.45441964\n",
      "step: 1231.0, loss:0.38931737\n",
      "step: 1232.0, loss:0.36197978\n",
      "step: 1233.0, loss:0.38962319\n",
      "step: 1234.0, loss:0.40863109\n",
      "step: 1235.0, loss:0.44091494\n",
      "step: 1236.0, loss:0.38291290\n",
      "step: 1237.0, loss:0.39556417\n",
      "step: 1238.0, loss:0.41344202\n",
      "step: 1239.0, loss:0.46666577\n",
      "step: 1240.0, loss:0.40456327\n",
      "step: 1241.0, loss:0.28600801\n",
      "step: 1242.0, loss:0.36848511\n",
      "step: 1243.0, loss:0.35375163\n",
      "step: 1244.0, loss:0.37183650\n",
      "step: 1245.0, loss:0.45870198\n",
      "step: 1246.0, loss:0.44678111\n",
      "step: 1247.0, loss:0.31733950\n",
      "step: 1248.0, loss:0.39688225\n",
      "step: 1249.0, loss:0.37656130\n",
      "step: 1250.0, loss:0.37942042\n",
      "step: 1251.0, loss:0.31780193\n",
      "step: 1252.0, loss:0.36613437\n",
      "step: 1253.0, loss:0.45171279\n",
      "step: 1254.0, loss:0.38395370\n",
      "step: 1255.0, loss:0.40044259\n",
      "step: 1256.0, loss:0.35989788\n",
      "step: 1257.0, loss:0.43421853\n",
      "step: 1258.0, loss:0.41621827\n",
      "step: 1259.0, loss:0.33970187\n",
      "step: 1260.0, loss:0.26946178\n",
      "step: 1261.0, loss:0.43388478\n",
      "step: 1262.0, loss:0.38479522\n",
      "step: 1263.0, loss:0.44618192\n",
      "step: 1264.0, loss:0.43103095\n",
      "step: 1265.0, loss:0.47003209\n",
      "step: 1266.0, loss:0.36651019\n",
      "step: 1267.0, loss:0.36916754\n",
      "step: 1268.0, loss:0.50503253\n",
      "step: 1269.0, loss:0.43760029\n",
      "step: 1270.0, loss:0.44932808\n",
      "step: 1271.0, loss:0.49150668\n",
      "step: 1272.0, loss:0.41137907\n",
      "step: 1273.0, loss:0.50248311\n",
      "step: 1274.0, loss:0.44006986\n",
      "step: 1275.0, loss:0.32287654\n",
      "step: 1276.0, loss:0.47081701\n",
      "step: 1277.0, loss:0.39130280\n",
      "step: 1278.0, loss:0.43813674\n",
      "step: 1279.0, loss:0.53823040\n",
      "step: 1280.0, loss:0.52527346\n",
      "step: 1281.0, loss:0.36463774\n",
      "step: 1282.0, loss:0.34568503\n",
      "step: 1283.0, loss:0.32165259\n",
      "step: 1284.0, loss:0.37502264\n",
      "step: 1285.0, loss:0.35366929\n",
      "step: 1286.0, loss:0.49600315\n",
      "step: 1287.0, loss:0.41192828\n",
      "step: 1288.0, loss:0.43919989\n",
      "step: 1289.0, loss:0.32852965\n",
      "step: 1290.0, loss:0.41862470\n",
      "step: 1291.0, loss:0.28867215\n",
      "step: 1292.0, loss:0.43510548\n",
      "step: 1293.0, loss:0.52612960\n",
      "step: 1294.0, loss:0.46392778\n",
      "step: 1295.0, loss:0.40182801\n",
      "step: 1296.0, loss:0.40330029\n",
      "step: 1297.0, loss:0.39433302\n",
      "step: 1298.0, loss:0.34350396\n",
      "step: 1299.0, loss:0.33214386\n",
      "step: 1300.0, loss:0.38925622\n",
      "step: 1301.0, loss:0.34950332\n",
      "step: 1302.0, loss:0.46827211\n",
      "step: 1303.0, loss:0.40553797\n",
      "step: 1304.0, loss:0.54918517\n",
      "step: 1305.0, loss:0.45300654\n",
      "step: 1306.0, loss:0.35287070\n",
      "step: 1307.0, loss:0.41968957\n",
      "step: 1308.0, loss:0.36218571\n",
      "step: 1309.0, loss:0.40217728\n",
      "step: 1310.0, loss:0.41714413\n",
      "step: 1311.0, loss:0.44028769\n",
      "step: 1312.0, loss:0.31969708\n",
      "step: 1313.0, loss:0.35728430\n",
      "step: 1314.0, loss:0.46296197\n",
      "step: 1315.0, loss:0.49977567\n",
      "step: 1316.0, loss:0.43784387\n",
      "step: 1317.0, loss:0.46256349\n",
      "step: 1318.0, loss:0.47230726\n",
      "step: 1319.0, loss:0.38722789\n",
      "step: 1320.0, loss:0.44200099\n",
      "step: 1321.0, loss:0.49271969\n",
      "step: 1322.0, loss:0.37908133\n",
      "step: 1323.0, loss:0.49729951\n",
      "step: 1324.0, loss:0.47424357\n",
      "step: 1325.0, loss:0.43421129\n",
      "step: 1326.0, loss:0.42012224\n",
      "step: 1327.0, loss:0.36909793\n",
      "step: 1328.0, loss:0.42945611\n",
      "step: 1329.0, loss:0.37707693\n",
      "step: 1330.0, loss:0.46839492\n",
      "step: 1331.0, loss:0.50797334\n",
      "step: 1332.0, loss:0.43799735\n",
      "step: 1333.0, loss:0.41989972\n",
      "step: 1334.0, loss:0.42022751\n",
      "step: 1335.0, loss:0.32118572\n",
      "step: 1336.0, loss:0.39725243\n",
      "step: 1337.0, loss:0.38198546\n",
      "step: 1338.0, loss:0.47079384\n",
      "step: 1339.0, loss:0.52091552\n",
      "step: 1340.0, loss:0.39115463\n",
      "step: 1341.0, loss:0.41179298\n",
      "step: 1342.0, loss:0.52759665\n",
      "step: 1343.0, loss:0.51695030\n",
      "step: 1344.0, loss:0.31295170\n",
      "step: 1345.0, loss:0.47906753\n",
      "step: 1346.0, loss:0.39046957\n",
      "step: 1347.0, loss:0.39815211\n",
      "step: 1348.0, loss:0.35174371\n",
      "step: 1349.0, loss:0.48757809\n",
      "step: 1350.0, loss:0.32081135\n",
      "step: 1351.0, loss:0.38630785\n",
      "step: 1352.0, loss:0.52690919\n",
      "step: 1353.0, loss:0.43136225\n",
      "step: 1354.0, loss:0.48739152\n",
      "step: 1355.0, loss:0.35660589\n",
      "step: 1356.0, loss:0.37988101\n",
      "step: 1357.0, loss:0.33974916\n",
      "step: 1358.0, loss:0.48818629\n",
      "step: 1359.0, loss:0.34363902\n",
      "step: 1360.0, loss:0.32855090\n",
      "step: 1361.0, loss:0.34511909\n",
      "step: 1362.0, loss:0.47994134\n",
      "step: 1363.0, loss:0.44400821\n",
      "step: 1364.0, loss:0.45526096\n",
      "step: 1365.0, loss:0.56065769\n",
      "step: 1366.0, loss:0.39134773\n",
      "step: 1367.0, loss:0.50077662\n",
      "step: 1368.0, loss:0.35685216\n",
      "step: 1369.0, loss:0.46432837\n",
      "step: 1370.0, loss:0.55819376\n",
      "step: 1371.0, loss:0.43239303\n",
      "step: 1372.0, loss:0.40677547\n",
      "step: 1373.0, loss:0.47550343\n",
      "step: 1374.0, loss:0.51241035\n",
      "step: 1375.0, loss:0.53175691\n",
      "step: 1376.0, loss:0.28063415\n",
      "step: 1377.0, loss:0.38744421\n",
      "step: 1378.0, loss:0.51403761\n",
      "step: 1379.0, loss:0.50997398\n",
      "step: 1380.0, loss:0.38901857\n",
      "step: 1381.0, loss:0.45978487\n",
      "step: 1382.0, loss:0.49193637\n",
      "step: 1383.0, loss:0.54030459\n",
      "step: 1384.0, loss:0.37397270\n",
      "step: 1385.0, loss:0.37925544\n",
      "step: 1386.0, loss:0.43836918\n",
      "step: 1387.0, loss:0.45208699\n",
      "step: 1388.0, loss:0.41396038\n",
      "step: 1389.0, loss:0.42499095\n",
      "step: 1390.0, loss:0.32652627\n",
      "step: 1391.0, loss:0.39219286\n",
      "step: 1392.0, loss:0.47021613\n",
      "step: 1393.0, loss:0.39450356\n",
      "step: 1394.0, loss:0.34075092\n",
      "step: 1395.0, loss:0.38587274\n",
      "step: 1396.0, loss:0.39315051\n",
      "step: 1397.0, loss:0.37963174\n",
      "step: 1398.0, loss:0.44458564\n",
      "step: 1399.0, loss:0.37684215\n",
      "step: 1400.0, loss:0.52875447\n",
      "step: 1401.0, loss:0.50741631\n",
      "step: 1402.0, loss:0.37151086\n",
      "step: 1403.0, loss:0.42786310\n",
      "step: 1404.0, loss:0.39998597\n",
      "step: 1405.0, loss:0.40467624\n",
      "step: 1406.0, loss:0.42895702\n",
      "step: 1407.0, loss:0.35750426\n",
      "step: 1408.0, loss:0.39344070\n",
      "step: 1409.0, loss:0.49315252\n",
      "step: 1410.0, loss:0.36628925\n",
      "step: 1411.0, loss:0.48806585\n",
      "step: 1412.0, loss:0.40122510\n",
      "step: 1413.0, loss:0.39014080\n",
      "step: 1414.0, loss:0.50388458\n",
      "step: 1415.0, loss:0.32733437\n",
      "step: 1416.0, loss:0.45185623\n",
      "step: 1417.0, loss:0.41144851\n",
      "step: 1418.0, loss:0.45823965\n",
      "step: 1419.0, loss:0.34593860\n",
      "step: 1420.0, loss:0.40105566\n",
      "step: 1421.0, loss:0.35445181\n",
      "step: 1422.0, loss:0.35122772\n",
      "step: 1423.0, loss:0.37082564\n",
      "step: 1424.0, loss:0.42071845\n",
      "step: 1425.0, loss:0.49298434\n",
      "step: 1426.0, loss:0.46852725\n",
      "step: 1427.0, loss:0.46186218\n",
      "step: 1428.0, loss:0.46681839\n",
      "step: 1429.0, loss:0.49855065\n",
      "step: 1430.0, loss:0.34376968\n",
      "step: 1431.0, loss:0.50129040\n",
      "step: 1432.0, loss:0.38558645\n",
      "step: 1433.0, loss:0.36031955\n",
      "step: 1434.0, loss:0.38060622\n",
      "step: 1435.0, loss:0.40993916\n",
      "step: 1436.0, loss:0.35390159\n",
      "step: 1437.0, loss:0.32364505\n",
      "step: 1438.0, loss:0.38638671\n",
      "step: 1439.0, loss:0.36132891\n",
      "step: 1440.0, loss:0.41476624\n",
      "step: 1441.0, loss:0.32845080\n",
      "step: 1442.0, loss:0.31721961\n",
      "step: 1443.0, loss:0.35760161\n",
      "step: 1444.0, loss:0.41345777\n",
      "step: 1445.0, loss:0.49089778\n",
      "step: 1446.0, loss:0.55750384\n",
      "step: 1447.0, loss:0.39436986\n",
      "step: 1448.0, loss:0.48249220\n",
      "step: 1449.0, loss:0.31806286\n",
      "step: 1450.0, loss:0.39354464\n",
      "step: 1451.0, loss:0.39235326\n",
      "step: 1452.0, loss:0.53769662\n",
      "step: 1453.0, loss:0.46475057\n",
      "step: 1454.0, loss:0.52927046\n",
      "step: 1455.0, loss:0.44161040\n",
      "step: 1456.0, loss:0.41636110\n",
      "step: 1457.0, loss:0.50827355\n",
      "step: 1458.0, loss:0.38247582\n",
      "step: 1459.0, loss:0.34863493\n",
      "step: 1460.0, loss:0.46070781\n",
      "step: 1461.0, loss:0.32298562\n",
      "step: 1462.0, loss:0.42246532\n",
      "step: 1463.0, loss:0.42832602\n",
      "step: 1464.0, loss:0.43404896\n",
      "step: 1465.0, loss:0.43998989\n",
      "step: 1466.0, loss:0.40251809\n",
      "step: 1467.0, loss:0.40338051\n",
      "step: 1468.0, loss:0.47953477\n",
      "step: 1469.0, loss:0.43405952\n",
      "step: 1470.0, loss:0.32109459\n",
      "step: 1471.0, loss:0.53105134\n",
      "step: 1472.0, loss:0.48966964\n",
      "step: 1473.0, loss:0.31841018\n",
      "step: 1474.0, loss:0.47570801\n",
      "step: 1475.0, loss:0.34028526\n",
      "step: 1476.0, loss:0.39157216\n",
      "step: 1477.0, loss:0.37380384\n",
      "step: 1478.0, loss:0.48656204\n",
      "step: 1479.0, loss:0.37799294\n",
      "step: 1480.0, loss:0.29348499\n",
      "step: 1481.0, loss:0.39221035\n",
      "step: 1482.0, loss:0.44296202\n",
      "step: 1483.0, loss:0.53220072\n",
      "step: 1484.0, loss:0.37939895\n",
      "step: 1485.0, loss:0.34267344\n",
      "step: 1486.0, loss:0.35627009\n",
      "step: 1487.0, loss:0.33669048\n",
      "step: 1488.0, loss:0.31246977\n",
      "step: 1489.0, loss:0.34654694\n",
      "step: 1490.0, loss:0.34273978\n",
      "step: 1491.0, loss:0.38448495\n",
      "step: 1492.0, loss:0.35285951\n",
      "step: 1493.0, loss:0.48998326\n",
      "step: 1494.0, loss:0.39739452\n",
      "step: 1495.0, loss:0.36744112\n",
      "step: 1496.0, loss:0.46611724\n",
      "step: 1497.0, loss:0.43943612\n",
      "step: 1498.0, loss:0.43488398\n",
      "step: 1499.0, loss:0.43190620\n",
      "step: 1500.0, loss:0.55958185\n",
      "step: 1501.0, loss:0.34117967\n",
      "step: 1502.0, loss:0.43155314\n",
      "step: 1503.0, loss:0.36326098\n",
      "step: 1504.0, loss:0.31801396\n",
      "step: 1505.0, loss:0.39539284\n",
      "step: 1506.0, loss:0.37603316\n",
      "step: 1507.0, loss:0.38369202\n",
      "step: 1508.0, loss:0.62090372\n",
      "step: 1509.0, loss:0.41915035\n",
      "step: 1510.0, loss:0.42381809\n",
      "step: 1511.0, loss:0.44521724\n",
      "step: 1512.0, loss:0.42961410\n",
      "step: 1513.0, loss:0.40697517\n",
      "step: 1514.0, loss:0.38970529\n",
      "step: 1515.0, loss:0.49379560\n",
      "step: 1516.0, loss:0.39845895\n",
      "step: 1517.0, loss:0.45924910\n",
      "step: 1518.0, loss:0.35694271\n",
      "step: 1519.0, loss:0.33573783\n",
      "step: 1520.0, loss:0.38403907\n",
      "step: 1521.0, loss:0.37991703\n",
      "step: 1522.0, loss:0.41001533\n",
      "step: 1523.0, loss:0.47106621\n",
      "step: 1524.0, loss:0.44712093\n",
      "step: 1525.0, loss:0.39568210\n",
      "step: 1526.0, loss:0.37070017\n",
      "step: 1527.0, loss:0.40985882\n",
      "step: 1528.0, loss:0.48229016\n",
      "step: 1529.0, loss:0.34438990\n",
      "step: 1530.0, loss:0.43513346\n",
      "step: 1531.0, loss:0.48215932\n",
      "step: 1532.0, loss:0.41743529\n",
      "step: 1533.0, loss:0.45757065\n",
      "step: 1534.0, loss:0.43895484\n",
      "step: 1535.0, loss:0.32993869\n",
      "step: 1536.0, loss:0.37689741\n",
      "step: 1537.0, loss:0.40025417\n",
      "step: 1538.0, loss:0.31421293\n",
      "step: 1539.0, loss:0.47530398\n",
      "step: 1540.0, loss:0.39124013\n",
      "step: 1541.0, loss:0.40698618\n",
      "step: 1542.0, loss:0.34940998\n",
      "step: 1543.0, loss:0.39827452\n",
      "step: 1544.0, loss:0.34633898\n",
      "step: 1545.0, loss:0.32394717\n",
      "step: 1546.0, loss:0.45884287\n",
      "step: 1547.0, loss:0.47999267\n",
      "step: 1548.0, loss:0.47285364\n",
      "step: 1549.0, loss:0.41322919\n",
      "step: 1550.0, loss:0.42789209\n",
      "step: 1551.0, loss:0.46073258\n",
      "step: 1552.0, loss:0.36589047\n",
      "step: 1553.0, loss:0.27698939\n",
      "step: 1554.0, loss:0.37474837\n",
      "step: 1555.0, loss:0.64347267\n",
      "step: 1556.0, loss:0.35143852\n",
      "step: 1557.0, loss:0.41605657\n",
      "step: 1558.0, loss:0.47084299\n",
      "step: 1559.0, loss:0.36685625\n",
      "step: 1560.0, loss:0.35866182\n",
      "step: 1561.0, loss:0.39066297\n",
      "step: 1562.0, loss:0.37386889\n",
      "step: 1563.0, loss:0.38678246\n",
      "step: 1564.0, loss:0.36203824\n",
      "step: 1565.0, loss:0.45529886\n",
      "step: 1566.0, loss:0.42615443\n",
      "step: 1567.0, loss:0.40852332\n",
      "step: 1568.0, loss:0.44384765\n",
      "step: 1569.0, loss:0.43027573\n",
      "step: 1570.0, loss:0.40748695\n",
      "step: 1571.0, loss:0.39785770\n",
      "step: 1572.0, loss:0.35903645\n",
      "step: 1573.0, loss:0.37345079\n",
      "step: 1574.0, loss:0.38471728\n",
      "step: 1575.0, loss:0.38820451\n",
      "step: 1576.0, loss:0.24315198\n",
      "step: 1577.0, loss:0.32718470\n",
      "step: 1578.0, loss:0.42851313\n",
      "step: 1579.0, loss:0.43908779\n",
      "step: 1580.0, loss:0.49505313\n",
      "step: 1581.0, loss:0.52428658\n",
      "step: 1582.0, loss:0.40070810\n",
      "step: 1583.0, loss:0.34668523\n",
      "step: 1584.0, loss:0.34955807\n",
      "step: 1585.0, loss:0.51654779\n",
      "step: 1586.0, loss:0.33519498\n",
      "step: 1587.0, loss:0.34646234\n",
      "step: 1588.0, loss:0.46150485\n",
      "step: 1589.0, loss:0.33647261\n",
      "step: 1590.0, loss:0.43271091\n",
      "step: 1591.0, loss:0.37460873\n",
      "step: 1592.0, loss:0.40681735\n",
      "step: 1593.0, loss:0.37441889\n",
      "step: 1594.0, loss:0.29578116\n",
      "step: 1595.0, loss:0.33571912\n",
      "step: 1596.0, loss:0.45022905\n",
      "step: 1597.0, loss:0.29464027\n",
      "step: 1598.0, loss:0.33578830\n",
      "step: 1599.0, loss:0.36230627\n",
      "step: 1600.0, loss:0.41378940\n",
      "step: 1601.0, loss:0.39050820\n",
      "step: 1602.0, loss:0.24623944\n",
      "step: 1603.0, loss:0.30891976\n",
      "step: 1604.0, loss:0.25315836\n",
      "step: 1605.0, loss:0.26961474\n",
      "step: 1606.0, loss:0.31692694\n",
      "step: 1607.0, loss:0.46910738\n",
      "step: 1608.0, loss:0.46495781\n",
      "step: 1609.0, loss:0.42483506\n",
      "step: 1610.0, loss:0.33434549\n",
      "step: 1611.0, loss:0.43654479\n",
      "step: 1612.0, loss:0.42898609\n",
      "step: 1613.0, loss:0.39232092\n",
      "step: 1614.0, loss:0.41308144\n",
      "step: 1615.0, loss:0.26211347\n",
      "step: 1616.0, loss:0.42122100\n",
      "step: 1617.0, loss:0.35838882\n",
      "step: 1618.0, loss:0.38539257\n",
      "step: 1619.0, loss:0.38308423\n",
      "step: 1620.0, loss:0.39416059\n",
      "step: 1621.0, loss:0.38500502\n",
      "step: 1622.0, loss:0.39696369\n",
      "step: 1623.0, loss:0.37739749\n",
      "step: 1624.0, loss:0.35648181\n",
      "step: 1625.0, loss:0.40084995\n",
      "step: 1626.0, loss:0.31576242\n",
      "step: 1627.0, loss:0.27999892\n",
      "step: 1628.0, loss:0.48838216\n",
      "step: 1629.0, loss:0.38351773\n",
      "step: 1630.0, loss:0.45391551\n",
      "step: 1631.0, loss:0.27541480\n",
      "step: 1632.0, loss:0.35387613\n",
      "step: 1633.0, loss:0.42016534\n",
      "step: 1634.0, loss:0.43809883\n",
      "step: 1635.0, loss:0.43061328\n",
      "step: 1636.0, loss:0.34136122\n",
      "step: 1637.0, loss:0.30409828\n",
      "step: 1638.0, loss:0.55943443\n",
      "step: 1639.0, loss:0.42941387\n",
      "step: 1640.0, loss:0.34935893\n",
      "step: 1641.0, loss:0.37629590\n",
      "step: 1642.0, loss:0.44681880\n",
      "step: 1643.0, loss:0.41324335\n",
      "step: 1644.0, loss:0.38166309\n",
      "step: 1645.0, loss:0.32164941\n",
      "step: 1646.0, loss:0.33907266\n",
      "step: 1647.0, loss:0.40671630\n",
      "step: 1648.0, loss:0.36380833\n",
      "step: 1649.0, loss:0.40606224\n",
      "step: 1650.0, loss:0.38679976\n",
      "step: 1651.0, loss:0.45144595\n",
      "step: 1652.0, loss:0.49887080\n",
      "step: 1653.0, loss:0.39219274\n",
      "step: 1654.0, loss:0.35877332\n",
      "step: 1655.0, loss:0.36083355\n",
      "step: 1656.0, loss:0.36991739\n",
      "step: 1657.0, loss:0.35579221\n",
      "step: 1658.0, loss:0.31277587\n",
      "step: 1659.0, loss:0.31841280\n",
      "step: 1660.0, loss:0.39523314\n",
      "step: 1661.0, loss:0.26335461\n",
      "step: 1662.0, loss:0.37548528\n",
      "step: 1663.0, loss:0.43865474\n",
      "step: 1664.0, loss:0.37930335\n",
      "step: 1665.0, loss:0.44191923\n",
      "step: 1666.0, loss:0.44146775\n",
      "step: 1667.0, loss:0.51563288\n",
      "step: 1668.0, loss:0.43679727\n",
      "step: 1669.0, loss:0.31259413\n",
      "step: 1670.0, loss:0.49709332\n",
      "step: 1671.0, loss:0.44929846\n",
      "step: 1672.0, loss:0.39637560\n",
      "step: 1673.0, loss:0.46045742\n",
      "step: 1674.0, loss:0.35466522\n",
      "step: 1675.0, loss:0.32601598\n",
      "step: 1676.0, loss:0.33319303\n",
      "step: 1677.0, loss:0.27139853\n",
      "step: 1678.0, loss:0.30955371\n",
      "step: 1679.0, loss:0.37189531\n",
      "step: 1680.0, loss:0.44736198\n",
      "step: 1681.0, loss:0.46383820\n",
      "step: 1682.0, loss:0.30379696\n",
      "step: 1683.0, loss:0.45404805\n",
      "step: 1684.0, loss:0.36063512\n",
      "step: 1685.0, loss:0.45551760\n",
      "step: 1686.0, loss:0.52471016\n",
      "step: 1687.0, loss:0.30797688\n",
      "step: 1688.0, loss:0.36139680\n",
      "step: 1689.0, loss:0.33976284\n",
      "step: 1690.0, loss:0.41491368\n",
      "step: 1691.0, loss:0.32983957\n",
      "step: 1692.0, loss:0.39560542\n",
      "step: 1693.0, loss:0.43668191\n",
      "step: 1694.0, loss:0.39720879\n",
      "step: 1695.0, loss:0.38571471\n",
      "step: 1696.0, loss:0.31863976\n",
      "step: 1697.0, loss:0.41632111\n",
      "step: 1698.0, loss:0.35807029\n",
      "step: 1699.0, loss:0.41433395\n",
      "step: 1700.0, loss:0.37125634\n",
      "step: 1701.0, loss:0.48589304\n",
      "step: 1702.0, loss:0.27232014\n",
      "step: 1703.0, loss:0.27388487\n",
      "step: 1704.0, loss:0.38257884\n",
      "step: 1705.0, loss:0.39616781\n",
      "step: 1706.0, loss:0.48450186\n",
      "step: 1707.0, loss:0.44275098\n",
      "step: 1708.0, loss:0.31919956\n",
      "step: 1709.0, loss:0.40209899\n",
      "step: 1710.0, loss:0.39291459\n",
      "step: 1711.0, loss:0.37925896\n",
      "step: 1712.0, loss:0.34682177\n",
      "step: 1713.0, loss:0.24355217\n",
      "step: 1714.0, loss:0.30814848\n",
      "step: 1715.0, loss:0.38650683\n",
      "step: 1716.0, loss:0.34558947\n",
      "step: 1717.0, loss:0.42860914\n",
      "step: 1718.0, loss:0.35851631\n",
      "step: 1719.0, loss:0.26193213\n",
      "step: 1720.0, loss:0.37767084\n",
      "step: 1721.0, loss:0.38234713\n",
      "step: 1722.0, loss:0.35039055\n",
      "step: 1723.0, loss:0.41116631\n",
      "step: 1724.0, loss:0.34697037\n",
      "step: 1725.0, loss:0.52893147\n",
      "step: 1726.0, loss:0.43747346\n",
      "step: 1727.0, loss:0.28232965\n",
      "step: 1728.0, loss:0.38237129\n",
      "step: 1729.0, loss:0.43674107\n",
      "step: 1730.0, loss:0.34906618\n",
      "step: 1731.0, loss:0.42842539\n",
      "step: 1732.0, loss:0.33528031\n",
      "step: 1733.0, loss:0.37299372\n",
      "step: 1734.0, loss:0.43563137\n",
      "step: 1735.0, loss:0.33976405\n",
      "step: 1736.0, loss:0.30211807\n",
      "step: 1737.0, loss:0.51488630\n",
      "step: 1738.0, loss:0.38591949\n",
      "step: 1739.0, loss:0.31821360\n",
      "step: 1740.0, loss:0.37872456\n",
      "step: 1741.0, loss:0.39317879\n",
      "step: 1742.0, loss:0.43676329\n",
      "step: 1743.0, loss:0.40574956\n",
      "step: 1744.0, loss:0.38362207\n",
      "step: 1745.0, loss:0.34709239\n",
      "step: 1746.0, loss:0.46023136\n",
      "step: 1747.0, loss:0.29965304\n",
      "step: 1748.0, loss:0.46025022\n",
      "step: 1749.0, loss:0.42750480\n",
      "step: 1750.0, loss:0.35557933\n",
      "step: 1751.0, loss:0.33525361\n",
      "step: 1752.0, loss:0.41687484\n",
      "step: 1753.0, loss:0.38917093\n",
      "step: 1754.0, loss:0.37395884\n",
      "step: 1755.0, loss:0.31165142\n",
      "step: 1756.0, loss:0.30414720\n",
      "step: 1757.0, loss:0.38906576\n",
      "step: 1758.0, loss:0.47608781\n",
      "step: 1759.0, loss:0.35277645\n",
      "step: 1760.0, loss:0.33310758\n",
      "step: 1761.0, loss:0.39291029\n",
      "step: 1762.0, loss:0.35143327\n",
      "step: 1763.0, loss:0.38100216\n",
      "step: 1764.0, loss:0.36346883\n",
      "step: 1765.0, loss:0.36215833\n",
      "step: 1766.0, loss:0.40411645\n",
      "step: 1767.0, loss:0.39802742\n",
      "step: 1768.0, loss:0.34628420\n",
      "step: 1769.0, loss:0.33765225\n",
      "step: 1770.0, loss:0.45044357\n",
      "step: 1771.0, loss:0.37267362\n",
      "step: 1772.0, loss:0.40953515\n",
      "step: 1773.0, loss:0.41228874\n",
      "step: 1774.0, loss:0.41038898\n",
      "step: 1775.0, loss:0.38013045\n",
      "step: 1776.0, loss:0.30174040\n",
      "step: 1777.0, loss:0.33118339\n",
      "step: 1778.0, loss:0.45281876\n",
      "step: 1779.0, loss:0.38740426\n",
      "step: 1780.0, loss:0.41871540\n",
      "step: 1781.0, loss:0.37005592\n",
      "step: 1782.0, loss:0.32355628\n",
      "step: 1783.0, loss:0.46289799\n",
      "step: 1784.0, loss:0.37895104\n",
      "step: 1785.0, loss:0.55768638\n",
      "step: 1786.0, loss:0.24060487\n",
      "step: 1787.0, loss:0.41276302\n",
      "step: 1788.0, loss:0.51535208\n",
      "step: 1789.0, loss:0.45287935\n",
      "step: 1790.0, loss:0.41910571\n",
      "step: 1791.0, loss:0.41783527\n",
      "step: 1792.0, loss:0.44184811\n",
      "step: 1793.0, loss:0.46050606\n",
      "step: 1794.0, loss:0.39659587\n",
      "step: 1795.0, loss:0.35024383\n",
      "step: 1796.0, loss:0.45522151\n",
      "step: 1797.0, loss:0.39684709\n",
      "step: 1798.0, loss:0.39681907\n",
      "step: 1799.0, loss:0.39445014\n",
      "step: 1800.0, loss:0.48194133\n",
      "step: 1801.0, loss:0.38636132\n",
      "step: 1802.0, loss:0.39413048\n",
      "step: 1803.0, loss:0.49197369\n",
      "step: 1804.0, loss:0.35133559\n",
      "step: 1805.0, loss:0.34484407\n",
      "step: 1806.0, loss:0.44230415\n",
      "step: 1807.0, loss:0.31797363\n",
      "step: 1808.0, loss:0.38552842\n",
      "step: 1809.0, loss:0.38851104\n",
      "step: 1810.0, loss:0.47937678\n",
      "step: 1811.0, loss:0.39110160\n",
      "step: 1812.0, loss:0.27057505\n",
      "step: 1813.0, loss:0.35785189\n",
      "step: 1814.0, loss:0.49106425\n",
      "step: 1815.0, loss:0.43452093\n",
      "step: 1816.0, loss:0.46490041\n",
      "step: 1817.0, loss:0.37764851\n",
      "step: 1818.0, loss:0.34910613\n",
      "step: 1819.0, loss:0.36318631\n",
      "step: 1820.0, loss:0.38079194\n",
      "step: 1821.0, loss:0.36043778\n",
      "step: 1822.0, loss:0.36554641\n",
      "step: 1823.0, loss:0.34208905\n",
      "step: 1824.0, loss:0.36118228\n",
      "step: 1825.0, loss:0.29493850\n",
      "step: 1826.0, loss:0.33569295\n",
      "step: 1827.0, loss:0.47061417\n",
      "step: 1828.0, loss:0.42340481\n",
      "step: 1829.0, loss:0.36846481\n",
      "step: 1830.0, loss:0.31919504\n",
      "step: 1831.0, loss:0.37171448\n",
      "step: 1832.0, loss:0.32595071\n",
      "step: 1833.0, loss:0.42702495\n",
      "step: 1834.0, loss:0.40570456\n",
      "step: 1835.0, loss:0.27835884\n",
      "step: 1836.0, loss:0.44261760\n",
      "step: 1837.0, loss:0.35715260\n",
      "step: 1838.0, loss:0.41666875\n",
      "step: 1839.0, loss:0.33631689\n",
      "step: 1840.0, loss:0.42200154\n",
      "step: 1841.0, loss:0.41083458\n",
      "step: 1842.0, loss:0.29146130\n",
      "step: 1843.0, loss:0.39054029\n",
      "step: 1844.0, loss:0.39398941\n",
      "step: 1845.0, loss:0.25857100\n",
      "step: 1846.0, loss:0.39827720\n",
      "step: 1847.0, loss:0.36969040\n",
      "step: 1848.0, loss:0.40232131\n",
      "step: 1849.0, loss:0.30815008\n",
      "step: 1850.0, loss:0.45989674\n",
      "step: 1851.0, loss:0.56535653\n",
      "step: 1852.0, loss:0.42155430\n",
      "step: 1853.0, loss:0.30392729\n",
      "step: 1854.0, loss:0.36882302\n",
      "step: 1855.0, loss:0.39686725\n",
      "step: 1856.0, loss:0.34762206\n",
      "step: 1857.0, loss:0.52894385\n",
      "step: 1858.0, loss:0.23383558\n",
      "step: 1859.0, loss:0.41674950\n",
      "step: 1860.0, loss:0.36458232\n",
      "step: 1861.0, loss:0.42474155\n",
      "step: 1862.0, loss:0.47854055\n",
      "step: 1863.0, loss:0.36778006\n",
      "step: 1864.0, loss:0.34196156\n",
      "step: 1865.0, loss:0.41942367\n",
      "step: 1866.0, loss:0.36994328\n",
      "step: 1867.0, loss:0.51487869\n",
      "step: 1868.0, loss:0.42581207\n",
      "step: 1869.0, loss:0.39966577\n",
      "step: 1870.0, loss:0.36585218\n",
      "step: 1871.0, loss:0.42298207\n",
      "step: 1872.0, loss:0.33053071\n",
      "step: 1873.0, loss:0.30316211\n",
      "step: 1874.0, loss:0.43537570\n",
      "step: 1875.0, loss:0.35352235\n",
      "step: 1876.0, loss:0.50183237\n",
      "step: 1877.0, loss:0.47329022\n",
      "step: 1878.0, loss:0.40403734\n",
      "step: 1879.0, loss:0.37058229\n",
      "step: 1880.0, loss:0.31306729\n",
      "step: 1881.0, loss:0.38120485\n",
      "step: 1882.0, loss:0.35783049\n",
      "step: 1883.0, loss:0.39520162\n",
      "step: 1884.0, loss:0.40929547\n",
      "step: 1885.0, loss:0.31934620\n",
      "step: 1886.0, loss:0.32227390\n",
      "step: 1887.0, loss:0.37749767\n",
      "step: 1888.0, loss:0.41568928\n",
      "step: 1889.0, loss:0.44660237\n",
      "step: 1890.0, loss:0.37141307\n",
      "step: 1891.0, loss:0.35872783\n",
      "step: 1892.0, loss:0.37414999\n",
      "step: 1893.0, loss:0.33588817\n",
      "step: 1894.0, loss:0.37955787\n",
      "step: 1895.0, loss:0.41338993\n",
      "step: 1896.0, loss:0.39455487\n",
      "step: 1897.0, loss:0.33923172\n",
      "step: 1898.0, loss:0.31962987\n",
      "step: 1899.0, loss:0.34068609\n",
      "step: 1900.0, loss:0.44658212\n",
      "step: 1901.0, loss:0.26091648\n",
      "step: 1902.0, loss:0.38750286\n",
      "step: 1903.0, loss:0.35671891\n",
      "step: 1904.0, loss:0.34908715\n",
      "step: 1905.0, loss:0.33993001\n",
      "step: 1906.0, loss:0.41642935\n",
      "step: 1907.0, loss:0.40057325\n",
      "step: 1908.0, loss:0.38314475\n",
      "step: 1909.0, loss:0.35217065\n",
      "step: 1910.0, loss:0.34944147\n",
      "step: 1911.0, loss:0.43544257\n",
      "step: 1912.0, loss:0.33735114\n",
      "step: 1913.0, loss:0.38760315\n",
      "step: 1914.0, loss:0.48695137\n",
      "step: 1915.0, loss:0.40379978\n",
      "step: 1916.0, loss:0.38860316\n",
      "step: 1917.0, loss:0.45121348\n",
      "step: 1918.0, loss:0.41835647\n",
      "step: 1919.0, loss:0.41933048\n",
      "step: 1920.0, loss:0.45895299\n",
      "step: 1921.0, loss:0.34354829\n",
      "step: 1922.0, loss:0.31425584\n",
      "step: 1923.0, loss:0.39042521\n",
      "step: 1924.0, loss:0.31873281\n",
      "step: 1925.0, loss:0.46422134\n",
      "step: 1926.0, loss:0.33642847\n",
      "step: 1927.0, loss:0.34400753\n",
      "step: 1928.0, loss:0.34856469\n",
      "step: 1929.0, loss:0.31613570\n",
      "step: 1930.0, loss:0.38693234\n",
      "step: 1931.0, loss:0.41187872\n",
      "step: 1932.0, loss:0.58701219\n",
      "step: 1933.0, loss:0.48146211\n",
      "step: 1934.0, loss:0.39289633\n",
      "step: 1935.0, loss:0.29675860\n",
      "step: 1936.0, loss:0.25626536\n",
      "step: 1937.0, loss:0.36446511\n",
      "step: 1938.0, loss:0.38834071\n",
      "step: 1939.0, loss:0.39315793\n",
      "step: 1940.0, loss:0.38200726\n",
      "step: 1941.0, loss:0.28992061\n",
      "step: 1942.0, loss:0.51352259\n",
      "step: 1943.0, loss:0.36517432\n",
      "step: 1944.0, loss:0.45914264\n",
      "step: 1945.0, loss:0.38089091\n",
      "step: 1946.0, loss:0.40541571\n",
      "step: 1947.0, loss:0.38173792\n",
      "step: 1948.0, loss:0.39270537\n",
      "step: 1949.0, loss:0.41170038\n",
      "step: 1950.0, loss:0.36013919\n",
      "step: 1951.0, loss:0.29880879\n",
      "step: 1952.0, loss:0.35170158\n",
      "step: 1953.0, loss:0.38342937\n",
      "step: 1954.0, loss:0.35393598\n",
      "step: 1955.0, loss:0.44903684\n",
      "step: 1956.0, loss:0.41021642\n",
      "step: 1957.0, loss:0.40849736\n",
      "step: 1958.0, loss:0.34298316\n",
      "step: 1959.0, loss:0.42470262\n",
      "step: 1960.0, loss:0.34267306\n",
      "step: 1961.0, loss:0.36834868\n",
      "step: 1962.0, loss:0.36527422\n",
      "step: 1963.0, loss:0.38241915\n",
      "step: 1964.0, loss:0.26935221\n",
      "step: 1965.0, loss:0.35837633\n",
      "step: 1966.0, loss:0.51913133\n",
      "step: 1967.0, loss:0.48894795\n",
      "step: 1968.0, loss:0.29143052\n",
      "step: 1969.0, loss:0.28873271\n",
      "step: 1970.0, loss:0.36004055\n",
      "step: 1971.0, loss:0.40622529\n",
      "step: 1972.0, loss:0.36053685\n",
      "step: 1973.0, loss:0.35789981\n",
      "step: 1974.0, loss:0.37402297\n",
      "step: 1975.0, loss:0.30903444\n",
      "step: 1976.0, loss:0.24417217\n",
      "step: 1977.0, loss:0.27488405\n",
      "step: 1978.0, loss:0.33236443\n",
      "step: 1979.0, loss:0.32559518\n",
      "step: 1980.0, loss:0.41906524\n",
      "step: 1981.0, loss:0.43331911\n",
      "step: 1982.0, loss:0.40521456\n",
      "step: 1983.0, loss:0.42064288\n",
      "step: 1984.0, loss:0.31490267\n",
      "step: 1985.0, loss:0.33328966\n",
      "step: 1986.0, loss:0.31242047\n",
      "step: 1987.0, loss:0.31710518\n",
      "step: 1988.0, loss:0.36003181\n",
      "step: 1989.0, loss:0.23164658\n",
      "step: 1990.0, loss:0.35954514\n",
      "step: 1991.0, loss:0.42239203\n",
      "step: 1992.0, loss:0.38189787\n",
      "step: 1993.0, loss:0.38314229\n",
      "step: 1994.0, loss:0.39072037\n",
      "step: 1995.0, loss:0.43501829\n",
      "step: 1996.0, loss:0.24315995\n",
      "step: 1997.0, loss:0.36210151\n",
      "step: 1998.0, loss:0.32462249\n",
      "step: 1999.0, loss:0.33531858\n",
      "step: 2000.0, loss:0.34357143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1264/1264 [08:02<00:00,  2.62it/s]\n",
      "2023-04-02 18:26:36,595 - INFO - step:2000.0, matthews_corr:0.669273, Acc:83.200594%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 2001.0, loss:0.33496895\n",
      "step: 2002.0, loss:0.32968026\n",
      "step: 2003.0, loss:0.39086918\n",
      "step: 2004.0, loss:0.39915298\n",
      "step: 2005.0, loss:0.34120699\n",
      "step: 2006.0, loss:0.39004531\n",
      "step: 2007.0, loss:0.29739303\n",
      "step: 2008.0, loss:0.39611794\n",
      "step: 2009.0, loss:0.38117813\n",
      "step: 2010.0, loss:0.30535319\n",
      "step: 2011.0, loss:0.38611850\n",
      "step: 2012.0, loss:0.37188563\n",
      "step: 2013.0, loss:0.27978465\n",
      "step: 2014.0, loss:0.34673442\n",
      "step: 2015.0, loss:0.31736818\n",
      "step: 2016.0, loss:0.36667809\n",
      "step: 2017.0, loss:0.32161395\n",
      "step: 2018.0, loss:0.35573068\n",
      "step: 2019.0, loss:0.30400101\n",
      "step: 2020.0, loss:0.35273781\n",
      "step: 2021.0, loss:0.33065603\n",
      "step: 2022.0, loss:0.43828553\n",
      "step: 2023.0, loss:0.36511338\n",
      "step: 2024.0, loss:0.35348642\n",
      "step: 2025.0, loss:0.29477504\n",
      "step: 2026.0, loss:0.44368461\n",
      "step: 2027.0, loss:0.34018554\n",
      "step: 2028.0, loss:0.38048676\n",
      "step: 2029.0, loss:0.36240481\n",
      "step: 2030.0, loss:0.34082209\n",
      "step: 2031.0, loss:0.43512475\n",
      "step: 2032.0, loss:0.41048520\n",
      "step: 2033.0, loss:0.34155459\n",
      "step: 2034.0, loss:0.32575245\n",
      "step: 2035.0, loss:0.30937830\n",
      "step: 2036.0, loss:0.35975326\n",
      "step: 2037.0, loss:0.49373744\n",
      "step: 2038.0, loss:0.34045699\n",
      "step: 2039.0, loss:0.32704801\n",
      "step: 2040.0, loss:0.36408471\n",
      "step: 2041.0, loss:0.31335839\n",
      "step: 2042.0, loss:0.31652184\n",
      "step: 2043.0, loss:0.23233344\n",
      "step: 2044.0, loss:0.41343922\n",
      "step: 2045.0, loss:0.30888393\n",
      "step: 2046.0, loss:0.29325856\n",
      "step: 2047.0, loss:0.33849695\n",
      "step: 2048.0, loss:0.38121558\n",
      "step: 2049.0, loss:0.40056404\n",
      "step: 2050.0, loss:0.39446411\n",
      "step: 2051.0, loss:0.39458237\n",
      "step: 2052.0, loss:0.32376185\n",
      "step: 2053.0, loss:0.22479641\n",
      "step: 2054.0, loss:0.29740226\n",
      "step: 2055.0, loss:0.36576283\n",
      "step: 2056.0, loss:0.31042794\n",
      "step: 2057.0, loss:0.38164890\n",
      "step: 2058.0, loss:0.40854886\n",
      "step: 2059.0, loss:0.39194970\n",
      "step: 2060.0, loss:0.47294905\n",
      "step: 2061.0, loss:0.35958315\n",
      "step: 2062.0, loss:0.34503766\n",
      "step: 2063.0, loss:0.45730605\n",
      "step: 2064.0, loss:0.33262458\n",
      "step: 2065.0, loss:0.29846945\n",
      "step: 2066.0, loss:0.49489170\n",
      "step: 2067.0, loss:0.33506187\n",
      "step: 2068.0, loss:0.39423459\n",
      "step: 2069.0, loss:0.32037226\n",
      "step: 2070.0, loss:0.40728197\n",
      "step: 2071.0, loss:0.33693193\n",
      "step: 2072.0, loss:0.37201606\n",
      "step: 2073.0, loss:0.30424017\n",
      "step: 2074.0, loss:0.39385324\n",
      "step: 2075.0, loss:0.39083009\n",
      "step: 2076.0, loss:0.48657692\n",
      "step: 2077.0, loss:0.48407826\n",
      "step: 2078.0, loss:0.44071507\n",
      "step: 2079.0, loss:0.35099486\n",
      "step: 2080.0, loss:0.41396086\n",
      "step: 2081.0, loss:0.31378217\n",
      "step: 2082.0, loss:0.34064490\n",
      "step: 2083.0, loss:0.34392725\n",
      "step: 2084.0, loss:0.27262270\n",
      "step: 2085.0, loss:0.34431557\n",
      "step: 2086.0, loss:0.36922157\n",
      "step: 2087.0, loss:0.31017146\n",
      "step: 2088.0, loss:0.28412539\n",
      "step: 2089.0, loss:0.34866216\n",
      "step: 2090.0, loss:0.39352603\n",
      "step: 2091.0, loss:0.27577802\n",
      "step: 2092.0, loss:0.48628369\n",
      "step: 2093.0, loss:0.36136295\n",
      "step: 2094.0, loss:0.38614357\n",
      "step: 2095.0, loss:0.34763068\n",
      "step: 2096.0, loss:0.37279435\n",
      "step: 2097.0, loss:0.27437387\n",
      "step: 2098.0, loss:0.40126235\n",
      "step: 2099.0, loss:0.36599103\n",
      "step: 2100.0, loss:0.40719450\n",
      "step: 2101.0, loss:0.40188313\n",
      "step: 2102.0, loss:0.30539368\n",
      "step: 2103.0, loss:0.32579445\n",
      "step: 2104.0, loss:0.29949862\n",
      "step: 2105.0, loss:0.29883778\n",
      "step: 2106.0, loss:0.30242939\n",
      "step: 2107.0, loss:0.27784426\n",
      "step: 2108.0, loss:0.45462777\n",
      "step: 2109.0, loss:0.42149859\n",
      "step: 2110.0, loss:0.40123326\n",
      "step: 2111.0, loss:0.34913208\n",
      "step: 2112.0, loss:0.43174389\n",
      "step: 2113.0, loss:0.26718643\n",
      "step: 2114.0, loss:0.35016235\n",
      "step: 2115.0, loss:0.32614094\n",
      "step: 2116.0, loss:0.34580214\n",
      "step: 2117.0, loss:0.29723847\n",
      "step: 2118.0, loss:0.36417383\n",
      "step: 2119.0, loss:0.41391997\n",
      "step: 2120.0, loss:0.34756721\n",
      "step: 2121.0, loss:0.36522768\n",
      "step: 2122.0, loss:0.48955821\n",
      "step: 2123.0, loss:0.35643505\n",
      "step: 2124.0, loss:0.41372647\n",
      "step: 2125.0, loss:0.37478812\n",
      "step: 2126.0, loss:0.47865263\n",
      "step: 2127.0, loss:0.46702939\n",
      "step: 2128.0, loss:0.29530887\n",
      "step: 2129.0, loss:0.46751753\n",
      "step: 2130.0, loss:0.37755200\n",
      "step: 2131.0, loss:0.43939724\n",
      "step: 2132.0, loss:0.34551547\n",
      "step: 2133.0, loss:0.42315788\n",
      "step: 2134.0, loss:0.37043597\n",
      "step: 2135.0, loss:0.39710902\n",
      "step: 2136.0, loss:0.43205952\n",
      "step: 2137.0, loss:0.26828163\n",
      "step: 2138.0, loss:0.30344831\n",
      "step: 2139.0, loss:0.42229925\n",
      "step: 2140.0, loss:0.62933737\n",
      "step: 2141.0, loss:0.29563304\n",
      "step: 2142.0, loss:0.33322453\n",
      "step: 2143.0, loss:0.49246038\n",
      "step: 2144.0, loss:0.51391326\n",
      "step: 2145.0, loss:0.37081809\n",
      "step: 2146.0, loss:0.35579950\n",
      "step: 2147.0, loss:0.37602798\n",
      "step: 2148.0, loss:0.33296866\n",
      "step: 2149.0, loss:0.27749320\n",
      "step: 2150.0, loss:0.31773783\n",
      "step: 2151.0, loss:0.34641587\n",
      "step: 2152.0, loss:0.38049065\n",
      "step: 2153.0, loss:0.45831649\n",
      "step: 2154.0, loss:0.32880713\n",
      "step: 2155.0, loss:0.50176319\n",
      "step: 2156.0, loss:0.28543755\n",
      "step: 2157.0, loss:0.26657799\n",
      "step: 2158.0, loss:0.38204788\n",
      "step: 2159.0, loss:0.28383295\n",
      "step: 2160.0, loss:0.30067352\n",
      "step: 2161.0, loss:0.35721391\n",
      "step: 2162.0, loss:0.37920628\n",
      "step: 2163.0, loss:0.28899060\n",
      "step: 2164.0, loss:0.39742079\n",
      "step: 2165.0, loss:0.33023779\n",
      "step: 2166.0, loss:0.37562554\n",
      "step: 2167.0, loss:0.42368039\n",
      "step: 2168.0, loss:0.37076199\n",
      "step: 2169.0, loss:0.37605511\n",
      "step: 2170.0, loss:0.38815570\n",
      "step: 2171.0, loss:0.37461656\n",
      "step: 2172.0, loss:0.30902524\n",
      "step: 2173.0, loss:0.32742408\n",
      "step: 2174.0, loss:0.29151540\n",
      "step: 2175.0, loss:0.33459853\n",
      "step: 2176.0, loss:0.42820491\n",
      "step: 2177.0, loss:0.32146926\n",
      "step: 2178.0, loss:0.35005775\n",
      "step: 2179.0, loss:0.25181737\n",
      "step: 2180.0, loss:0.43106640\n",
      "step: 2181.0, loss:0.28802342\n",
      "step: 2182.0, loss:0.42628171\n",
      "step: 2183.0, loss:0.28539327\n",
      "step: 2184.0, loss:0.42549393\n",
      "step: 2185.0, loss:0.43640316\n",
      "step: 2186.0, loss:0.48495251\n",
      "step: 2187.0, loss:0.25992803\n",
      "step: 2188.0, loss:0.28721472\n",
      "step: 2189.0, loss:0.32324781\n",
      "step: 2190.0, loss:0.25922112\n",
      "step: 2191.0, loss:0.31889167\n",
      "step: 2192.0, loss:0.38472910\n",
      "step: 2193.0, loss:0.41506552\n",
      "step: 2194.0, loss:0.52814064\n",
      "step: 2195.0, loss:0.37965415\n",
      "step: 2196.0, loss:0.37560903\n",
      "step: 2197.0, loss:0.33182326\n",
      "step: 2198.0, loss:0.46554260\n",
      "step: 2199.0, loss:0.34692076\n",
      "step: 2200.0, loss:0.31858359\n",
      "step: 2201.0, loss:0.35637389\n",
      "step: 2202.0, loss:0.30845268\n",
      "step: 2203.0, loss:0.41934903\n",
      "step: 2204.0, loss:0.33213845\n",
      "step: 2205.0, loss:0.43750255\n",
      "step: 2206.0, loss:0.36502905\n",
      "step: 2207.0, loss:0.35275673\n",
      "step: 2208.0, loss:0.27546163\n",
      "step: 2209.0, loss:0.53071478\n",
      "step: 2210.0, loss:0.27775146\n",
      "step: 2211.0, loss:0.36723884\n",
      "step: 2212.0, loss:0.30146269\n",
      "step: 2213.0, loss:0.46856301\n",
      "step: 2214.0, loss:0.24822401\n",
      "step: 2215.0, loss:0.26925532\n",
      "step: 2216.0, loss:0.31051809\n",
      "step: 2217.0, loss:0.47616393\n",
      "step: 2218.0, loss:0.34232569\n",
      "step: 2219.0, loss:0.33754285\n",
      "step: 2220.0, loss:0.33426196\n",
      "step: 2221.0, loss:0.34248171\n",
      "step: 2222.0, loss:0.34809350\n",
      "step: 2223.0, loss:0.37197198\n",
      "step: 2224.0, loss:0.30577314\n",
      "step: 2225.0, loss:0.37032253\n",
      "step: 2226.0, loss:0.40096775\n",
      "step: 2227.0, loss:0.29861363\n",
      "step: 2228.0, loss:0.38974249\n",
      "step: 2229.0, loss:0.37224492\n",
      "step: 2230.0, loss:0.33256043\n",
      "step: 2231.0, loss:0.35464085\n",
      "step: 2232.0, loss:0.36204058\n",
      "step: 2233.0, loss:0.32491249\n",
      "step: 2234.0, loss:0.32200910\n",
      "step: 2235.0, loss:0.35103595\n",
      "step: 2236.0, loss:0.30764559\n",
      "step: 2237.0, loss:0.32832868\n",
      "step: 2238.0, loss:0.38596288\n",
      "step: 2239.0, loss:0.45020124\n",
      "step: 2240.0, loss:0.33431776\n",
      "step: 2241.0, loss:0.30537533\n",
      "step: 2242.0, loss:0.40781039\n",
      "step: 2243.0, loss:0.36903054\n",
      "step: 2244.0, loss:0.33492654\n",
      "step: 2245.0, loss:0.36221458\n",
      "step: 2246.0, loss:0.30577375\n",
      "step: 2247.0, loss:0.43609092\n",
      "step: 2248.0, loss:0.31331888\n",
      "step: 2249.0, loss:0.32251774\n",
      "step: 2250.0, loss:0.49252529\n",
      "step: 2251.0, loss:0.39180445\n",
      "step: 2252.0, loss:0.36354401\n",
      "step: 2253.0, loss:0.33942239\n",
      "step: 2254.0, loss:0.39039109\n",
      "step: 2255.0, loss:0.36193766\n",
      "step: 2256.0, loss:0.34226834\n",
      "step: 2257.0, loss:0.39292435\n",
      "step: 2258.0, loss:0.27908082\n",
      "step: 2259.0, loss:0.40842239\n",
      "step: 2260.0, loss:0.22773771\n",
      "step: 2261.0, loss:0.35764290\n",
      "step: 2262.0, loss:0.28217040\n",
      "step: 2263.0, loss:0.40856697\n",
      "step: 2264.0, loss:0.31781293\n",
      "step: 2265.0, loss:0.29896028\n",
      "step: 2266.0, loss:0.34814789\n",
      "step: 2267.0, loss:0.29863026\n",
      "step: 2268.0, loss:0.41431949\n",
      "step: 2269.0, loss:0.31019152\n",
      "step: 2270.0, loss:0.36512882\n",
      "step: 2271.0, loss:0.49899899\n",
      "step: 2272.0, loss:0.28290175\n",
      "step: 2273.0, loss:0.37569106\n",
      "step: 2274.0, loss:0.38806161\n",
      "step: 2275.0, loss:0.36252729\n",
      "step: 2276.0, loss:0.43486545\n",
      "step: 2277.0, loss:0.33037493\n",
      "step: 2278.0, loss:0.35028108\n",
      "step: 2279.0, loss:0.28365865\n",
      "step: 2280.0, loss:0.34577976\n",
      "step: 2281.0, loss:0.28339292\n",
      "step: 2282.0, loss:0.30430535\n",
      "step: 2283.0, loss:0.40864470\n",
      "step: 2284.0, loss:0.28349873\n",
      "step: 2285.0, loss:0.29283756\n",
      "step: 2286.0, loss:0.32629583\n",
      "step: 2287.0, loss:0.30965413\n",
      "step: 2288.0, loss:0.29059659\n",
      "step: 2289.0, loss:0.37959970\n",
      "step: 2290.0, loss:0.43524709\n",
      "step: 2291.0, loss:0.35327185\n",
      "step: 2292.0, loss:0.27636219\n",
      "step: 2293.0, loss:0.39911393\n",
      "step: 2294.0, loss:0.41259192\n",
      "step: 2295.0, loss:0.28667611\n",
      "step: 2296.0, loss:0.29718556\n",
      "step: 2297.0, loss:0.43473257\n",
      "step: 2298.0, loss:0.36477664\n",
      "step: 2299.0, loss:0.32945250\n",
      "step: 2300.0, loss:0.36525426\n",
      "step: 2301.0, loss:0.39450102\n",
      "step: 2302.0, loss:0.35066616\n",
      "step: 2303.0, loss:0.41383611\n",
      "step: 2304.0, loss:0.41972700\n",
      "step: 2305.0, loss:0.33061532\n",
      "step: 2306.0, loss:0.51199682\n",
      "step: 2307.0, loss:0.35520734\n",
      "step: 2308.0, loss:0.28777327\n",
      "step: 2309.0, loss:0.32834485\n",
      "step: 2310.0, loss:0.49545992\n",
      "step: 2311.0, loss:0.27893101\n",
      "step: 2312.0, loss:0.39990538\n",
      "step: 2313.0, loss:0.29589481\n",
      "step: 2314.0, loss:0.28087241\n",
      "step: 2315.0, loss:0.27742022\n",
      "step: 2316.0, loss:0.38335429\n",
      "step: 2317.0, loss:0.29799581\n",
      "step: 2318.0, loss:0.32341490\n",
      "step: 2319.0, loss:0.30786373\n",
      "step: 2320.0, loss:0.43160785\n",
      "step: 2321.0, loss:0.29742200\n",
      "step: 2322.0, loss:0.40745798\n",
      "step: 2323.0, loss:0.35290340\n",
      "step: 2324.0, loss:0.28590471\n",
      "step: 2325.0, loss:0.34951339\n",
      "step: 2326.0, loss:0.28042219\n",
      "step: 2327.0, loss:0.38329268\n",
      "step: 2328.0, loss:0.33691981\n",
      "step: 2329.0, loss:0.34139272\n",
      "step: 2330.0, loss:0.28288649\n",
      "step: 2331.0, loss:0.35441995\n",
      "step: 2332.0, loss:0.42043773\n",
      "step: 2333.0, loss:0.35182697\n",
      "step: 2334.0, loss:0.35129861\n",
      "step: 2335.0, loss:0.26543543\n",
      "step: 2336.0, loss:0.43553106\n",
      "step: 2337.0, loss:0.32604712\n",
      "step: 2338.0, loss:0.34926467\n",
      "step: 2339.0, loss:0.27633065\n",
      "step: 2340.0, loss:0.41823732\n",
      "step: 2341.0, loss:0.37693688\n",
      "step: 2342.0, loss:0.34213744\n",
      "step: 2343.0, loss:0.30511025\n",
      "step: 2344.0, loss:0.36289446\n",
      "step: 2345.0, loss:0.33192287\n",
      "step: 2346.0, loss:0.34867074\n",
      "step: 2347.0, loss:0.33384249\n",
      "step: 2348.0, loss:0.45926362\n",
      "step: 2349.0, loss:0.50023768\n",
      "step: 2350.0, loss:0.38873168\n",
      "step: 2351.0, loss:0.43780825\n",
      "step: 2352.0, loss:0.29264031\n",
      "step: 2353.0, loss:0.40299268\n",
      "step: 2354.0, loss:0.29278638\n",
      "step: 2355.0, loss:0.24340477\n",
      "step: 2356.0, loss:0.55662683\n",
      "step: 2357.0, loss:0.39943991\n",
      "step: 2358.0, loss:0.35441029\n",
      "step: 2359.0, loss:0.36511327\n",
      "step: 2360.0, loss:0.26119839\n",
      "step: 2361.0, loss:0.29871088\n",
      "step: 2362.0, loss:0.24640724\n",
      "step: 2363.0, loss:0.36442290\n",
      "step: 2364.0, loss:0.39905624\n",
      "step: 2365.0, loss:0.40662991\n",
      "step: 2366.0, loss:0.40711786\n",
      "step: 2367.0, loss:0.23385772\n",
      "step: 2368.0, loss:0.22705046\n",
      "step: 2369.0, loss:0.30719285\n",
      "step: 2370.0, loss:0.32867052\n",
      "step: 2371.0, loss:0.28540314\n",
      "step: 2372.0, loss:0.37318493\n",
      "step: 2373.0, loss:0.27603588\n",
      "step: 2374.0, loss:0.38736689\n",
      "step: 2375.0, loss:0.35282206\n",
      "step: 2376.0, loss:0.33031951\n",
      "step: 2377.0, loss:0.36504625\n",
      "step: 2378.0, loss:0.31946722\n",
      "step: 2379.0, loss:0.46321658\n",
      "step: 2380.0, loss:0.30710440\n",
      "step: 2381.0, loss:0.42310869\n",
      "step: 2382.0, loss:0.26044396\n",
      "step: 2383.0, loss:0.47979078\n",
      "step: 2384.0, loss:0.33619929\n",
      "step: 2385.0, loss:0.35152083\n",
      "step: 2386.0, loss:0.42847593\n",
      "step: 2387.0, loss:0.38429713\n",
      "step: 2388.0, loss:0.38642202\n",
      "step: 2389.0, loss:0.43996162\n",
      "step: 2390.0, loss:0.29909411\n",
      "step: 2391.0, loss:0.42704545\n",
      "step: 2392.0, loss:0.33862311\n",
      "step: 2393.0, loss:0.38707317\n",
      "step: 2394.0, loss:0.39459048\n",
      "step: 2395.0, loss:0.39900164\n",
      "step: 2396.0, loss:0.41821724\n",
      "step: 2397.0, loss:0.35129360\n",
      "step: 2398.0, loss:0.43246270\n",
      "step: 2399.0, loss:0.30439198\n",
      "step: 2400.0, loss:0.37989237\n",
      "step: 2401.0, loss:0.41985037\n",
      "step: 2402.0, loss:0.32810987\n",
      "step: 2403.0, loss:0.31224934\n",
      "step: 2404.0, loss:0.28866733\n",
      "step: 2405.0, loss:0.37282696\n",
      "step: 2406.0, loss:0.30449928\n",
      "step: 2407.0, loss:0.26589099\n",
      "step: 2408.0, loss:0.27262261\n",
      "step: 2409.0, loss:0.32608655\n",
      "step: 2410.0, loss:0.30931980\n",
      "step: 2411.0, loss:0.38781950\n",
      "step: 2412.0, loss:0.39413475\n",
      "step: 2413.0, loss:0.47948916\n",
      "step: 2414.0, loss:0.30850446\n",
      "step: 2415.0, loss:0.54921883\n",
      "step: 2416.0, loss:0.30083570\n",
      "step: 2417.0, loss:0.39037913\n",
      "step: 2418.0, loss:0.41258112\n",
      "step: 2419.0, loss:0.29669468\n",
      "step: 2420.0, loss:0.32549570\n",
      "step: 2421.0, loss:0.32964952\n",
      "step: 2422.0, loss:0.36830936\n",
      "step: 2423.0, loss:0.40401316\n",
      "step: 2424.0, loss:0.39640369\n",
      "step: 2425.0, loss:0.17091915\n",
      "step: 2426.0, loss:0.41369040\n",
      "step: 2427.0, loss:0.56840777\n",
      "step: 2428.0, loss:0.33255294\n",
      "step: 2429.0, loss:0.25241745\n",
      "step: 2430.0, loss:0.25716261\n",
      "step: 2431.0, loss:0.31537169\n",
      "step: 2432.0, loss:0.37214898\n",
      "step: 2433.0, loss:0.36281579\n",
      "step: 2434.0, loss:0.33057377\n",
      "step: 2435.0, loss:0.47638697\n",
      "step: 2436.0, loss:0.33378715\n",
      "step: 2437.0, loss:0.41405231\n",
      "step: 2438.0, loss:0.41877257\n",
      "step: 2439.0, loss:0.36029297\n",
      "step: 2440.0, loss:0.34131493\n",
      "step: 2441.0, loss:0.26196038\n",
      "step: 2442.0, loss:0.22369436\n",
      "step: 2443.0, loss:0.42868288\n",
      "step: 2444.0, loss:0.42782439\n",
      "step: 2445.0, loss:0.41871569\n",
      "step: 2446.0, loss:0.45803347\n",
      "step: 2447.0, loss:0.25615455\n",
      "step: 2448.0, loss:0.40204886\n",
      "step: 2449.0, loss:0.25745484\n",
      "step: 2450.0, loss:0.34980827\n",
      "step: 2451.0, loss:0.35942690\n",
      "step: 2452.0, loss:0.34582108\n",
      "step: 2453.0, loss:0.29737896\n",
      "step: 2454.0, loss:0.30182227\n",
      "step: 2455.0, loss:0.30242813\n",
      "step: 2456.0, loss:0.26720827\n",
      "step: 2457.0, loss:0.47135036\n",
      "step: 2458.0, loss:0.33402857\n",
      "step: 2459.0, loss:0.44443693\n",
      "step: 2460.0, loss:0.37522131\n",
      "step: 2461.0, loss:0.37917835\n",
      "step: 2462.0, loss:0.40692019\n",
      "step: 2463.0, loss:0.39184332\n",
      "step: 2464.0, loss:0.53865494\n",
      "step: 2465.0, loss:0.36449231\n",
      "step: 2466.0, loss:0.25607780\n",
      "step: 2467.0, loss:0.34785427\n",
      "step: 2468.0, loss:0.25239803\n",
      "step: 2469.0, loss:0.33539389\n",
      "step: 2470.0, loss:0.44412699\n",
      "step: 2471.0, loss:0.34075605\n",
      "step: 2472.0, loss:0.43052127\n",
      "step: 2473.0, loss:0.44940044\n",
      "step: 2474.0, loss:0.29651207\n",
      "step: 2475.0, loss:0.32535253\n",
      "step: 2476.0, loss:0.31116005\n",
      "step: 2477.0, loss:0.28607886\n",
      "step: 2478.0, loss:0.47818554\n",
      "step: 2479.0, loss:0.32306960\n",
      "step: 2480.0, loss:0.29490117\n",
      "step: 2481.0, loss:0.33983721\n",
      "step: 2482.0, loss:0.42162894\n",
      "step: 2483.0, loss:0.33135518\n",
      "step: 2484.0, loss:0.30928136\n",
      "step: 2485.0, loss:0.26108640\n",
      "step: 2486.0, loss:0.35965859\n",
      "step: 2487.0, loss:0.38378205\n",
      "step: 2488.0, loss:0.29930923\n",
      "step: 2489.0, loss:0.46900495\n",
      "step: 2490.0, loss:0.34603395\n",
      "step: 2491.0, loss:0.30191565\n",
      "step: 2492.0, loss:0.31576184\n",
      "step: 2493.0, loss:0.33572275\n",
      "step: 2494.0, loss:0.34967005\n",
      "step: 2495.0, loss:0.33860677\n",
      "step: 2496.0, loss:0.43244237\n",
      "step: 2497.0, loss:0.29970021\n",
      "step: 2498.0, loss:0.35178425\n",
      "step: 2499.0, loss:0.46893169\n",
      "step: 2500.0, loss:0.36720328\n",
      "step: 2501.0, loss:0.35484054\n",
      "step: 2502.0, loss:0.25689414\n",
      "step: 2503.0, loss:0.28034931\n",
      "step: 2504.0, loss:0.30262196\n",
      "step: 2505.0, loss:0.29155375\n",
      "step: 2506.0, loss:0.46639469\n",
      "step: 2507.0, loss:0.45803448\n",
      "step: 2508.0, loss:0.32145816\n",
      "step: 2509.0, loss:0.46724880\n",
      "step: 2510.0, loss:0.39468698\n",
      "step: 2511.0, loss:0.40064273\n",
      "step: 2512.0, loss:0.41311277\n",
      "step: 2513.0, loss:0.29059814\n",
      "step: 2514.0, loss:0.24303934\n",
      "step: 2515.0, loss:0.44923627\n",
      "step: 2516.0, loss:0.32882322\n",
      "step: 2517.0, loss:0.34877048\n",
      "step: 2518.0, loss:0.40111570\n",
      "step: 2519.0, loss:0.27559420\n",
      "step: 2520.0, loss:0.32311261\n",
      "step: 2521.0, loss:0.33905136\n",
      "step: 2522.0, loss:0.26008585\n",
      "step: 2523.0, loss:0.44568246\n",
      "step: 2524.0, loss:0.39597725\n",
      "step: 2525.0, loss:0.35262226\n",
      "step: 2526.0, loss:0.34322159\n",
      "step: 2527.0, loss:0.31641722\n",
      "step: 2528.0, loss:0.39109543\n",
      "step: 2529.0, loss:0.24244785\n",
      "step: 2530.0, loss:0.32711655\n",
      "step: 2531.0, loss:0.38467553\n",
      "step: 2532.0, loss:0.22551249\n",
      "step: 2533.0, loss:0.35534038\n",
      "step: 2534.0, loss:0.40788225\n",
      "step: 2535.0, loss:0.35445162\n",
      "step: 2536.0, loss:0.41028704\n",
      "step: 2537.0, loss:0.24324009\n",
      "step: 2538.0, loss:0.35719476\n",
      "step: 2539.0, loss:0.26318756\n",
      "step: 2540.0, loss:0.37501568\n",
      "step: 2541.0, loss:0.35409838\n",
      "step: 2542.0, loss:0.31022986\n",
      "step: 2543.0, loss:0.36665805\n",
      "step: 2544.0, loss:0.28153624\n",
      "step: 2545.0, loss:0.19088641\n",
      "step: 2546.0, loss:0.35535763\n",
      "step: 2547.0, loss:0.37929534\n",
      "step: 2548.0, loss:0.31796784\n",
      "step: 2549.0, loss:0.32356541\n",
      "step: 2550.0, loss:0.22316627\n",
      "step: 2551.0, loss:0.47180148\n",
      "step: 2552.0, loss:0.46755665\n",
      "step: 2553.0, loss:0.24669999\n",
      "step: 2554.0, loss:0.47480400\n",
      "step: 2555.0, loss:0.26222687\n",
      "step: 2556.0, loss:0.29875902\n",
      "step: 2557.0, loss:0.51155306\n",
      "step: 2558.0, loss:0.38235334\n",
      "step: 2559.0, loss:0.34368216\n",
      "step: 2560.0, loss:0.36570976\n",
      "step: 2561.0, loss:0.37679931\n",
      "step: 2562.0, loss:0.27320555\n",
      "step: 2563.0, loss:0.32472919\n",
      "step: 2564.0, loss:0.36087611\n",
      "step: 2565.0, loss:0.40679196\n",
      "step: 2566.0, loss:0.38819885\n",
      "step: 2567.0, loss:0.37223549\n",
      "step: 2568.0, loss:0.31218767\n",
      "step: 2569.0, loss:0.34643853\n",
      "step: 2570.0, loss:0.35557663\n",
      "step: 2571.0, loss:0.33698161\n",
      "step: 2572.0, loss:0.33197417\n",
      "step: 2573.0, loss:0.35585365\n",
      "step: 2574.0, loss:0.34739731\n",
      "step: 2575.0, loss:0.32034798\n",
      "step: 2576.0, loss:0.38319460\n",
      "step: 2577.0, loss:0.32364474\n",
      "step: 2578.0, loss:0.33285300\n",
      "step: 2579.0, loss:0.33704693\n",
      "step: 2580.0, loss:0.22458378\n",
      "step: 2581.0, loss:0.25562429\n",
      "step: 2582.0, loss:0.39597557\n",
      "step: 2583.0, loss:0.28803824\n",
      "step: 2584.0, loss:0.32481689\n",
      "step: 2585.0, loss:0.31521896\n",
      "step: 2586.0, loss:0.29400925\n",
      "step: 2587.0, loss:0.28280756\n",
      "step: 2588.0, loss:0.36580483\n",
      "step: 2589.0, loss:0.27884118\n",
      "step: 2590.0, loss:0.33480756\n",
      "step: 2591.0, loss:0.37753226\n",
      "step: 2592.0, loss:0.33071844\n",
      "step: 2593.0, loss:0.28207199\n",
      "step: 2594.0, loss:0.44166913\n",
      "step: 2595.0, loss:0.31023777\n",
      "step: 2596.0, loss:0.36431745\n",
      "step: 2597.0, loss:0.40753254\n",
      "step: 2598.0, loss:0.42091200\n",
      "step: 2599.0, loss:0.36573371\n",
      "step: 2600.0, loss:0.33323551\n",
      "step: 2601.0, loss:0.40772299\n",
      "step: 2602.0, loss:0.32455184\n",
      "step: 2603.0, loss:0.31067005\n",
      "step: 2604.0, loss:0.40467464\n",
      "step: 2605.0, loss:0.42200313\n",
      "step: 2606.0, loss:0.36751208\n",
      "step: 2607.0, loss:0.36064421\n",
      "step: 2608.0, loss:0.29963313\n",
      "step: 2609.0, loss:0.40159198\n",
      "step: 2610.0, loss:0.44327059\n",
      "step: 2611.0, loss:0.35623242\n",
      "step: 2612.0, loss:0.29857621\n",
      "step: 2613.0, loss:0.43272797\n",
      "step: 2614.0, loss:0.43277407\n",
      "step: 2615.0, loss:0.40669040\n",
      "step: 2616.0, loss:0.24454229\n",
      "step: 2617.0, loss:0.25759969\n",
      "step: 2618.0, loss:0.40563887\n",
      "step: 2619.0, loss:0.50598377\n",
      "step: 2620.0, loss:0.35319699\n",
      "step: 2621.0, loss:0.26532789\n",
      "step: 2622.0, loss:0.42721178\n",
      "step: 2623.0, loss:0.33855356\n",
      "step: 2624.0, loss:0.27954945\n",
      "step: 2625.0, loss:0.39523429\n",
      "step: 2626.0, loss:0.36937901\n",
      "step: 2627.0, loss:0.39476405\n",
      "step: 2628.0, loss:0.29308423\n",
      "step: 2629.0, loss:0.41483273\n",
      "step: 2630.0, loss:0.40432381\n",
      "step: 2631.0, loss:0.33662084\n",
      "step: 2632.0, loss:0.42649692\n",
      "step: 2633.0, loss:0.33734577\n",
      "step: 2634.0, loss:0.35349786\n",
      "step: 2635.0, loss:0.47666968\n",
      "step: 2636.0, loss:0.40729257\n",
      "step: 2637.0, loss:0.46100527\n",
      "step: 2638.0, loss:0.34308503\n",
      "step: 2639.0, loss:0.39840684\n",
      "step: 2640.0, loss:0.30645102\n",
      "step: 2641.0, loss:0.42582231\n",
      "step: 2642.0, loss:0.40529790\n",
      "step: 2643.0, loss:0.41345838\n",
      "step: 2644.0, loss:0.42621835\n",
      "step: 2645.0, loss:0.34400110\n",
      "step: 2646.0, loss:0.35627141\n",
      "step: 2647.0, loss:0.36846077\n",
      "step: 2648.0, loss:0.40061840\n",
      "step: 2649.0, loss:0.29944575\n",
      "step: 2650.0, loss:0.30803370\n",
      "step: 2651.0, loss:0.37294197\n",
      "step: 2652.0, loss:0.42958051\n",
      "step: 2653.0, loss:0.33975753\n",
      "step: 2654.0, loss:0.31859704\n",
      "step: 2655.0, loss:0.25865044\n",
      "step: 2656.0, loss:0.35601297\n",
      "step: 2657.0, loss:0.25739061\n",
      "step: 2658.0, loss:0.26178529\n",
      "step: 2659.0, loss:0.39919855\n",
      "step: 2660.0, loss:0.40573160\n",
      "step: 2661.0, loss:0.38219889\n",
      "step: 2662.0, loss:0.20397048\n",
      "step: 2663.0, loss:0.42845633\n",
      "step: 2664.0, loss:0.25899089\n",
      "step: 2665.0, loss:0.34179725\n",
      "step: 2666.0, loss:0.28406888\n",
      "step: 2667.0, loss:0.32915910\n",
      "step: 2668.0, loss:0.36794911\n",
      "step: 2669.0, loss:0.25632293\n",
      "step: 2670.0, loss:0.58563504\n",
      "step: 2671.0, loss:0.38366468\n",
      "step: 2672.0, loss:0.39442820\n",
      "step: 2673.0, loss:0.34958982\n",
      "step: 2674.0, loss:0.22530697\n",
      "step: 2675.0, loss:0.34168253\n",
      "step: 2676.0, loss:0.27537899\n",
      "step: 2677.0, loss:0.43263170\n",
      "step: 2678.0, loss:0.40907375\n",
      "step: 2679.0, loss:0.30050786\n",
      "step: 2680.0, loss:0.38712846\n",
      "step: 2681.0, loss:0.36064499\n",
      "step: 2682.0, loss:0.29460562\n",
      "step: 2683.0, loss:0.35752537\n",
      "step: 2684.0, loss:0.44075351\n",
      "step: 2685.0, loss:0.32521091\n",
      "step: 2686.0, loss:0.28357462\n",
      "step: 2687.0, loss:0.24020531\n",
      "step: 2688.0, loss:0.34363921\n",
      "step: 2689.0, loss:0.43780746\n",
      "step: 2690.0, loss:0.38990169\n",
      "step: 2691.0, loss:0.39513769\n",
      "step: 2692.0, loss:0.31651319\n",
      "step: 2693.0, loss:0.37987647\n",
      "step: 2694.0, loss:0.22230726\n",
      "step: 2695.0, loss:0.30084957\n",
      "step: 2696.0, loss:0.37404784\n",
      "step: 2697.0, loss:0.47601099\n",
      "step: 2698.0, loss:0.44386851\n",
      "step: 2699.0, loss:0.20434600\n",
      "step: 2700.0, loss:0.27235574\n",
      "step: 2701.0, loss:0.34725957\n",
      "step: 2702.0, loss:0.43494345\n",
      "step: 2703.0, loss:0.44302284\n",
      "step: 2704.0, loss:0.36146278\n",
      "step: 2705.0, loss:0.36272262\n",
      "step: 2706.0, loss:0.33534732\n",
      "step: 2707.0, loss:0.27113484\n",
      "step: 2708.0, loss:0.28640029\n",
      "step: 2709.0, loss:0.39091596\n",
      "step: 2710.0, loss:0.27801711\n",
      "step: 2711.0, loss:0.49146359\n",
      "step: 2712.0, loss:0.33484708\n",
      "step: 2713.0, loss:0.37522261\n",
      "step: 2714.0, loss:0.42212208\n",
      "step: 2715.0, loss:0.29976071\n",
      "step: 2716.0, loss:0.41929661\n",
      "step: 2717.0, loss:0.54581419\n",
      "step: 2718.0, loss:0.29801937\n",
      "step: 2719.0, loss:0.44134402\n",
      "step: 2720.0, loss:0.35722470\n",
      "step: 2721.0, loss:0.23111078\n",
      "step: 2722.0, loss:0.28595113\n",
      "step: 2723.0, loss:0.19579871\n",
      "step: 2724.0, loss:0.26627770\n",
      "step: 2725.0, loss:0.41743931\n",
      "step: 2726.0, loss:0.34034701\n",
      "step: 2727.0, loss:0.33887631\n",
      "step: 2728.0, loss:0.42231086\n",
      "step: 2729.0, loss:0.25329857\n",
      "step: 2730.0, loss:0.38226533\n",
      "step: 2731.0, loss:0.41128530\n",
      "step: 2732.0, loss:0.42716741\n",
      "step: 2733.0, loss:0.33965008\n",
      "step: 2734.0, loss:0.35849318\n",
      "step: 2735.0, loss:0.33654150\n",
      "step: 2736.0, loss:0.34488641\n",
      "step: 2737.0, loss:0.37912070\n",
      "step: 2738.0, loss:0.39741810\n",
      "step: 2739.0, loss:0.30673501\n",
      "step: 2740.0, loss:0.41027042\n",
      "step: 2741.0, loss:0.25908021\n",
      "step: 2742.0, loss:0.27440640\n",
      "step: 2743.0, loss:0.31100278\n",
      "step: 2744.0, loss:0.34082840\n",
      "step: 2745.0, loss:0.28263013\n",
      "step: 2746.0, loss:0.45761193\n",
      "step: 2747.0, loss:0.38092297\n",
      "step: 2748.0, loss:0.33203159\n",
      "step: 2749.0, loss:0.42186482\n",
      "step: 2750.0, loss:0.37612133\n",
      "step: 2751.0, loss:0.30702773\n",
      "step: 2752.0, loss:0.40175244\n",
      "step: 2753.0, loss:0.33457940\n",
      "step: 2754.0, loss:0.32245339\n",
      "step: 2755.0, loss:0.35936019\n",
      "step: 2756.0, loss:0.38228578\n",
      "step: 2757.0, loss:0.30502327\n",
      "step: 2758.0, loss:0.31794654\n",
      "step: 2759.0, loss:0.44717198\n",
      "step: 2760.0, loss:0.26998563\n",
      "step: 2761.0, loss:0.33343641\n",
      "step: 2762.0, loss:0.40176003\n",
      "step: 2763.0, loss:0.24640311\n",
      "step: 2764.0, loss:0.38777408\n",
      "step: 2765.0, loss:0.37499727\n",
      "step: 2766.0, loss:0.41264039\n",
      "step: 2767.0, loss:0.34947836\n",
      "step: 2768.0, loss:0.31623166\n",
      "step: 2769.0, loss:0.36928992\n",
      "step: 2770.0, loss:0.38949738\n",
      "step: 2771.0, loss:0.43422361\n",
      "step: 2772.0, loss:0.37871985\n",
      "step: 2773.0, loss:0.30778030\n",
      "step: 2774.0, loss:0.29708212\n",
      "step: 2775.0, loss:0.37627724\n",
      "step: 2776.0, loss:0.34624022\n",
      "step: 2777.0, loss:0.30536387\n",
      "step: 2778.0, loss:0.32028958\n",
      "step: 2779.0, loss:0.25075599\n",
      "step: 2780.0, loss:0.33924246\n",
      "step: 2781.0, loss:0.28937695\n",
      "step: 2782.0, loss:0.42299762\n",
      "step: 2783.0, loss:0.37255429\n",
      "step: 2784.0, loss:0.28789395\n",
      "step: 2785.0, loss:0.27659957\n",
      "step: 2786.0, loss:0.23634146\n",
      "step: 2787.0, loss:0.25846461\n",
      "step: 2788.0, loss:0.31225317\n",
      "step: 2789.0, loss:0.22764698\n",
      "step: 2790.0, loss:0.40369172\n",
      "step: 2791.0, loss:0.34543206\n",
      "step: 2792.0, loss:0.35906617\n",
      "step: 2793.0, loss:0.34072239\n",
      "step: 2794.0, loss:0.36002997\n",
      "step: 2795.0, loss:0.28420930\n",
      "step: 2796.0, loss:0.31985530\n",
      "step: 2797.0, loss:0.29752262\n",
      "step: 2798.0, loss:0.27718456\n",
      "step: 2799.0, loss:0.37049764\n",
      "step: 2800.0, loss:0.34330955\n",
      "step: 2801.0, loss:0.25657664\n",
      "step: 2802.0, loss:0.37728601\n",
      "step: 2803.0, loss:0.37033297\n",
      "step: 2804.0, loss:0.48725307\n",
      "step: 2805.0, loss:0.42059142\n",
      "step: 2806.0, loss:0.34170354\n",
      "step: 2807.0, loss:0.25958709\n",
      "step: 2808.0, loss:0.28737615\n",
      "step: 2809.0, loss:0.48652627\n",
      "step: 2810.0, loss:0.30192335\n",
      "step: 2811.0, loss:0.38910650\n",
      "step: 2812.0, loss:0.19825288\n",
      "step: 2813.0, loss:0.24021756\n",
      "step: 2814.0, loss:0.29481006\n",
      "step: 2815.0, loss:0.40925200\n",
      "step: 2816.0, loss:0.32039351\n",
      "step: 2817.0, loss:0.31125586\n",
      "step: 2818.0, loss:0.29452378\n",
      "step: 2819.0, loss:0.24244815\n",
      "step: 2820.0, loss:0.49196867\n",
      "step: 2821.0, loss:0.33413263\n",
      "step: 2822.0, loss:0.35101914\n",
      "step: 2823.0, loss:0.42525041\n",
      "step: 2824.0, loss:0.28517750\n",
      "step: 2825.0, loss:0.29747128\n",
      "step: 2826.0, loss:0.32089834\n",
      "step: 2827.0, loss:0.39912348\n",
      "step: 2828.0, loss:0.31707129\n",
      "step: 2829.0, loss:0.29449181\n",
      "step: 2830.0, loss:0.26491841\n",
      "step: 2831.0, loss:0.25505212\n",
      "step: 2832.0, loss:0.33337492\n",
      "step: 2833.0, loss:0.24432319\n",
      "step: 2834.0, loss:0.35023976\n",
      "step: 2835.0, loss:0.24304870\n",
      "step: 2836.0, loss:0.32106158\n",
      "step: 2837.0, loss:0.34714649\n",
      "step: 2838.0, loss:0.35316898\n",
      "step: 2839.0, loss:0.40373017\n",
      "step: 2840.0, loss:0.41522457\n",
      "step: 2841.0, loss:0.22315640\n",
      "step: 2842.0, loss:0.35419394\n",
      "step: 2843.0, loss:0.40629986\n",
      "step: 2844.0, loss:0.40722939\n",
      "step: 2845.0, loss:0.45745053\n",
      "step: 2846.0, loss:0.35253634\n",
      "step: 2847.0, loss:0.30118831\n",
      "step: 2848.0, loss:0.30075048\n",
      "step: 2849.0, loss:0.28596352\n",
      "step: 2850.0, loss:0.31067336\n",
      "step: 2851.0, loss:0.41438279\n",
      "step: 2852.0, loss:0.39252623\n",
      "step: 2853.0, loss:0.24268363\n",
      "step: 2854.0, loss:0.36457122\n",
      "step: 2855.0, loss:0.26924515\n",
      "step: 2856.0, loss:0.32779339\n",
      "step: 2857.0, loss:0.21549555\n",
      "step: 2858.0, loss:0.45271085\n",
      "step: 2859.0, loss:0.32733385\n",
      "step: 2860.0, loss:0.42764864\n",
      "step: 2861.0, loss:0.31435483\n",
      "step: 2862.0, loss:0.29260449\n",
      "step: 2863.0, loss:0.30347913\n",
      "step: 2864.0, loss:0.33235609\n",
      "step: 2865.0, loss:0.29530128\n",
      "step: 2866.0, loss:0.33292256\n",
      "step: 2867.0, loss:0.37737443\n",
      "step: 2868.0, loss:0.29589443\n",
      "step: 2869.0, loss:0.30958891\n",
      "step: 2870.0, loss:0.30074708\n",
      "step: 2871.0, loss:0.30324303\n",
      "step: 2872.0, loss:0.49606127\n",
      "step: 2873.0, loss:0.36727286\n",
      "step: 2874.0, loss:0.25773004\n",
      "step: 2875.0, loss:0.36314902\n",
      "step: 2876.0, loss:0.31193193\n",
      "step: 2877.0, loss:0.29114213\n",
      "step: 2878.0, loss:0.46313431\n",
      "step: 2879.0, loss:0.27933825\n",
      "step: 2880.0, loss:0.28048063\n",
      "step: 2881.0, loss:0.22505867\n",
      "step: 2882.0, loss:0.38388213\n",
      "step: 2883.0, loss:0.36094995\n",
      "step: 2884.0, loss:0.24110842\n",
      "step: 2885.0, loss:0.39173268\n",
      "step: 2886.0, loss:0.37775181\n",
      "step: 2887.0, loss:0.27491905\n",
      "step: 2888.0, loss:0.34332167\n",
      "step: 2889.0, loss:0.25078873\n",
      "step: 2890.0, loss:0.42196997\n",
      "step: 2891.0, loss:0.37751437\n",
      "step: 2892.0, loss:0.30444950\n",
      "step: 2893.0, loss:0.29557483\n",
      "step: 2894.0, loss:0.37904462\n",
      "step: 2895.0, loss:0.38825465\n",
      "step: 2896.0, loss:0.34903154\n",
      "step: 2897.0, loss:0.25264727\n",
      "step: 2898.0, loss:0.23610107\n",
      "step: 2899.0, loss:0.30796591\n",
      "step: 2900.0, loss:0.26729961\n",
      "step: 2901.0, loss:0.26185780\n",
      "step: 2902.0, loss:0.29595523\n",
      "step: 2903.0, loss:0.32957057\n",
      "step: 2904.0, loss:0.20240183\n",
      "step: 2905.0, loss:0.26815294\n",
      "step: 2906.0, loss:0.28124283\n",
      "step: 2907.0, loss:0.43764593\n",
      "step: 2908.0, loss:0.36254605\n",
      "step: 2909.0, loss:0.33669819\n",
      "step: 2910.0, loss:0.29761127\n",
      "step: 2911.0, loss:0.27714721\n",
      "step: 2912.0, loss:0.32803886\n",
      "step: 2913.0, loss:0.30322198\n",
      "step: 2914.0, loss:0.16614847\n",
      "step: 2915.0, loss:0.26001817\n",
      "step: 2916.0, loss:0.30081869\n",
      "step: 2917.0, loss:0.37871290\n",
      "step: 2918.0, loss:0.45097571\n",
      "step: 2919.0, loss:0.44329202\n",
      "step: 2920.0, loss:0.29494488\n",
      "step: 2921.0, loss:0.42477029\n",
      "step: 2922.0, loss:0.35875327\n",
      "step: 2923.0, loss:0.27831710\n",
      "step: 2924.0, loss:0.31849162\n",
      "step: 2925.0, loss:0.23739218\n",
      "step: 2926.0, loss:0.31018997\n",
      "step: 2927.0, loss:0.36968019\n",
      "step: 2928.0, loss:0.29773325\n",
      "step: 2929.0, loss:0.51294591\n",
      "step: 2930.0, loss:0.29443397\n",
      "step: 2931.0, loss:0.28421207\n",
      "step: 2932.0, loss:0.30695185\n",
      "step: 2933.0, loss:0.45876981\n",
      "step: 2934.0, loss:0.29634497\n",
      "step: 2935.0, loss:0.32499043\n",
      "step: 2936.0, loss:0.48499629\n",
      "step: 2937.0, loss:0.39262728\n",
      "step: 2938.0, loss:0.24622449\n",
      "step: 2939.0, loss:0.41243542\n",
      "step: 2940.0, loss:0.45005174\n",
      "step: 2941.0, loss:0.28114431\n",
      "step: 2942.0, loss:0.30502002\n",
      "step: 2943.0, loss:0.30558886\n",
      "step: 2944.0, loss:0.30491387\n",
      "step: 2945.0, loss:0.24231407\n",
      "step: 2946.0, loss:0.38750829\n",
      "step: 2947.0, loss:0.32686313\n",
      "step: 2948.0, loss:0.25031692\n",
      "step: 2949.0, loss:0.28102164\n",
      "step: 2950.0, loss:0.34845132\n",
      "step: 2951.0, loss:0.23668275\n",
      "step: 2952.0, loss:0.24525369\n",
      "step: 2953.0, loss:0.28730760\n",
      "step: 2954.0, loss:0.26743188\n",
      "step: 2955.0, loss:0.32644868\n",
      "step: 2956.0, loss:0.28494776\n",
      "step: 2957.0, loss:0.40641280\n",
      "step: 2958.0, loss:0.49830467\n",
      "step: 2959.0, loss:0.32801437\n",
      "step: 2960.0, loss:0.35618145\n",
      "step: 2961.0, loss:0.25358665\n",
      "step: 2962.0, loss:0.32207642\n",
      "step: 2963.0, loss:0.34273937\n",
      "step: 2964.0, loss:0.35267183\n",
      "step: 2965.0, loss:0.28962453\n",
      "step: 2966.0, loss:0.35237037\n",
      "step: 2967.0, loss:0.38570265\n",
      "step: 2968.0, loss:0.24787105\n",
      "step: 2969.0, loss:0.27437224\n",
      "step: 2970.0, loss:0.32047597\n",
      "step: 2971.0, loss:0.32959285\n",
      "step: 2972.0, loss:0.25600389\n",
      "step: 2973.0, loss:0.30953629\n",
      "step: 2974.0, loss:0.32514601\n",
      "step: 2975.0, loss:0.35165316\n",
      "step: 2976.0, loss:0.37997607\n",
      "step: 2977.0, loss:0.33846359\n",
      "step: 2978.0, loss:0.34485664\n",
      "step: 2979.0, loss:0.35812658\n",
      "step: 2980.0, loss:0.45577591\n",
      "step: 2981.0, loss:0.34839284\n",
      "step: 2982.0, loss:0.37851603\n",
      "step: 2983.0, loss:0.29296053\n",
      "step: 2984.0, loss:0.25120417\n",
      "step: 2985.0, loss:0.31842742\n",
      "step: 2986.0, loss:0.22010334\n",
      "step: 2987.0, loss:0.25310224\n",
      "step: 2988.0, loss:0.41988123\n",
      "step: 2989.0, loss:0.28411676\n",
      "step: 2990.0, loss:0.35748419\n",
      "step: 2991.0, loss:0.35334989\n",
      "step: 2992.0, loss:0.28429516\n",
      "step: 2993.0, loss:0.27398520\n",
      "step: 2994.0, loss:0.26802589\n",
      "step: 2995.0, loss:0.34715632\n",
      "step: 2996.0, loss:0.37729742\n",
      "step: 2997.0, loss:0.49691406\n",
      "step: 2998.0, loss:0.24503215\n",
      "step: 2999.0, loss:0.44768494\n",
      "step: 3000.0, loss:0.31477266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1264/1264 [07:54<00:00,  2.67it/s]\n",
      "2023-04-02 19:10:05,964 - INFO - step:3000.0, matthews_corr:0.688588, Acc:85.617116%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 3001.0, loss:0.33976227\n",
      "step: 3002.0, loss:0.23352003\n",
      "step: 3003.0, loss:0.42447279\n",
      "step: 3004.0, loss:0.40799197\n",
      "step: 3005.0, loss:0.26748992\n",
      "step: 3006.0, loss:0.24457529\n",
      "step: 3007.0, loss:0.41827543\n",
      "step: 3008.0, loss:0.33232026\n",
      "step: 3009.0, loss:0.29643602\n",
      "step: 3010.0, loss:0.29964104\n",
      "step: 3011.0, loss:0.29280100\n",
      "step: 3012.0, loss:0.29699195\n",
      "step: 3013.0, loss:0.38956558\n",
      "step: 3014.0, loss:0.34967925\n",
      "step: 3015.0, loss:0.27411675\n",
      "step: 3016.0, loss:0.33897915\n",
      "step: 3017.0, loss:0.34352574\n",
      "step: 3018.0, loss:0.31554066\n",
      "step: 3019.0, loss:0.39236242\n",
      "step: 3020.0, loss:0.26957819\n",
      "step: 3021.0, loss:0.45218144\n",
      "step: 3022.0, loss:0.36184190\n",
      "step: 3023.0, loss:0.26290724\n",
      "step: 3024.0, loss:0.30007397\n",
      "step: 3025.0, loss:0.23561225\n",
      "step: 3026.0, loss:0.25697454\n",
      "step: 3027.0, loss:0.32160354\n",
      "step: 3028.0, loss:0.37544681\n",
      "step: 3029.0, loss:0.37142320\n",
      "step: 3030.0, loss:0.44507611\n",
      "step: 3031.0, loss:0.38708803\n",
      "step: 3032.0, loss:0.41258133\n",
      "step: 3033.0, loss:0.30578585\n",
      "step: 3034.0, loss:0.32713189\n",
      "step: 3035.0, loss:0.41828287\n",
      "step: 3036.0, loss:0.32633867\n",
      "step: 3037.0, loss:0.40712199\n",
      "step: 3038.0, loss:0.35787211\n",
      "step: 3039.0, loss:0.36611940\n",
      "step: 3040.0, loss:0.35936197\n",
      "step: 3041.0, loss:0.30489720\n",
      "step: 3042.0, loss:0.22938416\n",
      "step: 3043.0, loss:0.33074787\n",
      "step: 3044.0, loss:0.37077469\n",
      "step: 3045.0, loss:0.40609471\n",
      "step: 3046.0, loss:0.29816242\n",
      "step: 3047.0, loss:0.30636455\n",
      "step: 3048.0, loss:0.22571723\n",
      "step: 3049.0, loss:0.42700832\n",
      "step: 3050.0, loss:0.39585445\n",
      "step: 3051.0, loss:0.35091113\n",
      "step: 3052.0, loss:0.38049215\n",
      "step: 3053.0, loss:0.21789243\n",
      "step: 3054.0, loss:0.31829576\n",
      "step: 3055.0, loss:0.24315080\n",
      "step: 3056.0, loss:0.39585016\n",
      "step: 3057.0, loss:0.28530775\n",
      "step: 3058.0, loss:0.29668664\n",
      "step: 3059.0, loss:0.27956293\n",
      "step: 3060.0, loss:0.29280753\n",
      "step: 3061.0, loss:0.34113923\n",
      "step: 3062.0, loss:0.20719185\n",
      "step: 3063.0, loss:0.31882120\n",
      "step: 3064.0, loss:0.26656674\n",
      "step: 3065.0, loss:0.50956602\n",
      "step: 3066.0, loss:0.26736786\n",
      "step: 3067.0, loss:0.31906742\n",
      "step: 3068.0, loss:0.45647039\n",
      "step: 3069.0, loss:0.32138526\n",
      "step: 3070.0, loss:0.32152692\n",
      "step: 3071.0, loss:0.20649406\n",
      "step: 3072.0, loss:0.37152005\n",
      "step: 3073.0, loss:0.36334714\n",
      "step: 3074.0, loss:0.30016606\n",
      "step: 3075.0, loss:0.43963539\n",
      "step: 3076.0, loss:0.32869672\n",
      "step: 3077.0, loss:0.33545086\n",
      "step: 3078.0, loss:0.29359454\n",
      "step: 3079.0, loss:0.32412690\n",
      "step: 3080.0, loss:0.32946429\n",
      "step: 3081.0, loss:0.29740579\n",
      "step: 3082.0, loss:0.30819586\n",
      "step: 3083.0, loss:0.46525664\n",
      "step: 3084.0, loss:0.29649318\n",
      "step: 3085.0, loss:0.28841403\n",
      "step: 3086.0, loss:0.33224620\n",
      "step: 3087.0, loss:0.34064352\n",
      "step: 3088.0, loss:0.40070585\n",
      "step: 3089.0, loss:0.35287740\n",
      "step: 3090.0, loss:0.25749375\n",
      "step: 3091.0, loss:0.41135909\n",
      "step: 3092.0, loss:0.25760770\n",
      "step: 3093.0, loss:0.24556262\n",
      "step: 3094.0, loss:0.28736016\n",
      "step: 3095.0, loss:0.23033413\n",
      "step: 3096.0, loss:0.27611213\n",
      "step: 3097.0, loss:0.40806067\n",
      "step: 3098.0, loss:0.30394904\n",
      "step: 3099.0, loss:0.28087404\n",
      "step: 3100.0, loss:0.40668295\n",
      "step: 3101.0, loss:0.39243350\n",
      "step: 3102.0, loss:0.32692398\n",
      "step: 3103.0, loss:0.35128404\n",
      "step: 3104.0, loss:0.34073020\n",
      "step: 3105.0, loss:0.28692552\n",
      "step: 3106.0, loss:0.42044795\n",
      "step: 3107.0, loss:0.22217200\n",
      "step: 3108.0, loss:0.24327274\n",
      "step: 3109.0, loss:0.29453193\n",
      "step: 3110.0, loss:0.19083701\n",
      "step: 3111.0, loss:0.31680430\n",
      "step: 3112.0, loss:0.26200400\n",
      "step: 3113.0, loss:0.27435073\n",
      "step: 3114.0, loss:0.28203021\n",
      "step: 3115.0, loss:0.42033357\n",
      "step: 3116.0, loss:0.33359906\n",
      "step: 3117.0, loss:0.41591457\n",
      "step: 3118.0, loss:0.27307088\n",
      "step: 3119.0, loss:0.38696351\n",
      "step: 3120.0, loss:0.23255996\n",
      "step: 3121.0, loss:0.39454151\n",
      "step: 3122.0, loss:0.18933723\n",
      "step: 3123.0, loss:0.28916436\n",
      "step: 3124.0, loss:0.28189134\n",
      "step: 3125.0, loss:0.36193999\n",
      "step: 3126.0, loss:0.30349123\n",
      "step: 3127.0, loss:0.31685187\n",
      "step: 3128.0, loss:0.27743180\n",
      "step: 3129.0, loss:0.43667683\n",
      "step: 3130.0, loss:0.23356475\n",
      "step: 3131.0, loss:0.21641954\n",
      "step: 3132.0, loss:0.21395595\n",
      "step: 3133.0, loss:0.33751757\n",
      "step: 3134.0, loss:0.30979469\n",
      "step: 3135.0, loss:0.29418515\n",
      "step: 3136.0, loss:0.24235363\n",
      "step: 3137.0, loss:0.27469807\n",
      "step: 3138.0, loss:0.28298818\n",
      "step: 3139.0, loss:0.20789429\n",
      "step: 3140.0, loss:0.29884564\n",
      "step: 3141.0, loss:0.32353179\n",
      "step: 3142.0, loss:0.32875877\n",
      "step: 3143.0, loss:0.32603912\n",
      "step: 3144.0, loss:0.22299973\n",
      "step: 3145.0, loss:0.29305446\n",
      "step: 3146.0, loss:0.35704816\n",
      "step: 3147.0, loss:0.43817297\n",
      "step: 3148.0, loss:0.36910426\n",
      "step: 3149.0, loss:0.33727187\n",
      "step: 3150.0, loss:0.36590034\n",
      "step: 3151.0, loss:0.50981148\n",
      "step: 3152.0, loss:0.43276916\n",
      "step: 3153.0, loss:0.42319696\n",
      "step: 3154.0, loss:0.32165725\n",
      "step: 3155.0, loss:0.27349362\n",
      "step: 3156.0, loss:0.31122128\n",
      "step: 3157.0, loss:0.28078378\n",
      "step: 3158.0, loss:0.29119472\n",
      "step: 3159.0, loss:0.44362216\n",
      "step: 3160.0, loss:0.32136196\n",
      "step: 3161.0, loss:0.39313837\n",
      "step: 3162.0, loss:0.34050366\n",
      "step: 3163.0, loss:0.34455151\n",
      "step: 3164.0, loss:0.37680955\n",
      "step: 3165.0, loss:0.38689528\n",
      "step: 3166.0, loss:0.27662549\n",
      "step: 3167.0, loss:0.40812331\n",
      "step: 3168.0, loss:0.38547977\n",
      "step: 3169.0, loss:0.26039982\n",
      "step: 3170.0, loss:0.31180722\n",
      "step: 3171.0, loss:0.40252140\n",
      "step: 3172.0, loss:0.29713298\n",
      "step: 3173.0, loss:0.29317093\n",
      "step: 3174.0, loss:0.23137949\n",
      "step: 3175.0, loss:0.33827648\n",
      "step: 3176.0, loss:0.29995516\n",
      "step: 3177.0, loss:0.35253707\n",
      "step: 3178.0, loss:0.38856287\n",
      "step: 3179.0, loss:0.27566636\n",
      "step: 3180.0, loss:0.18797557\n",
      "step: 3181.0, loss:0.27939481\n",
      "step: 3182.0, loss:0.38414558\n",
      "step: 3183.0, loss:0.33664449\n",
      "step: 3184.0, loss:0.38720981\n",
      "step: 3185.0, loss:0.44880646\n",
      "step: 3186.0, loss:0.28885495\n",
      "step: 3187.0, loss:0.32793677\n",
      "step: 3188.0, loss:0.32804481\n",
      "step: 3189.0, loss:0.33864869\n",
      "step: 3190.0, loss:0.29338019\n",
      "step: 3191.0, loss:0.32440557\n",
      "step: 3192.0, loss:0.29937999\n",
      "step: 3193.0, loss:0.26338007\n",
      "step: 3194.0, loss:0.20817235\n",
      "step: 3195.0, loss:0.35274500\n",
      "step: 3196.0, loss:0.39452233\n",
      "step: 3197.0, loss:0.26007798\n",
      "step: 3198.0, loss:0.26094868\n",
      "step: 3199.0, loss:0.23908474\n",
      "step: 3200.0, loss:0.30008557\n",
      "step: 3201.0, loss:0.23986945\n",
      "step: 3202.0, loss:0.36524582\n",
      "step: 3203.0, loss:0.50528998\n",
      "step: 3204.0, loss:0.39293339\n",
      "step: 3205.0, loss:0.34613124\n",
      "step: 3206.0, loss:0.35019259\n",
      "step: 3207.0, loss:0.41657637\n",
      "step: 3208.0, loss:0.30037271\n",
      "step: 3209.0, loss:0.35492722\n",
      "step: 3210.0, loss:0.28373446\n",
      "step: 3211.0, loss:0.32220038\n",
      "step: 3212.0, loss:0.30552908\n",
      "step: 3213.0, loss:0.22794675\n",
      "step: 3214.0, loss:0.36573641\n",
      "step: 3215.0, loss:0.51126304\n",
      "step: 3216.0, loss:0.37509059\n",
      "step: 3217.0, loss:0.34402132\n",
      "step: 3218.0, loss:0.35009813\n",
      "step: 3219.0, loss:0.33087578\n",
      "step: 3220.0, loss:0.16910445\n",
      "step: 3221.0, loss:0.46714082\n",
      "step: 3222.0, loss:0.38045656\n",
      "step: 3223.0, loss:0.32375126\n",
      "step: 3224.0, loss:0.31432473\n",
      "step: 3225.0, loss:0.32869498\n",
      "step: 3226.0, loss:0.24225606\n",
      "step: 3227.0, loss:0.33547283\n",
      "step: 3228.0, loss:0.22266622\n",
      "step: 3229.0, loss:0.35545062\n",
      "step: 3230.0, loss:0.30787138\n",
      "step: 3231.0, loss:0.29694900\n",
      "step: 3232.0, loss:0.38498225\n",
      "step: 3233.0, loss:0.46866610\n",
      "step: 3234.0, loss:0.37219818\n",
      "step: 3235.0, loss:0.46976689\n",
      "step: 3236.0, loss:0.26267538\n",
      "step: 3237.0, loss:0.35888930\n",
      "step: 3238.0, loss:0.35077979\n",
      "step: 3239.0, loss:0.33004299\n",
      "step: 3240.0, loss:0.42477217\n",
      "step: 3241.0, loss:0.38642442\n",
      "step: 3242.0, loss:0.30750788\n",
      "step: 3243.0, loss:0.33200780\n",
      "step: 3244.0, loss:0.47642457\n",
      "step: 3245.0, loss:0.28808681\n",
      "step: 3246.0, loss:0.33899408\n",
      "step: 3247.0, loss:0.44126085\n",
      "step: 3248.0, loss:0.30509271\n",
      "step: 3249.0, loss:0.34958702\n",
      "step: 3250.0, loss:0.41374846\n",
      "step: 3251.0, loss:0.34499285\n",
      "step: 3252.0, loss:0.18286229\n",
      "step: 3253.0, loss:0.29341583\n",
      "step: 3254.0, loss:0.30499901\n",
      "step: 3255.0, loss:0.34166397\n",
      "step: 3256.0, loss:0.39290149\n",
      "step: 3257.0, loss:0.27119695\n",
      "step: 3258.0, loss:0.38929872\n",
      "step: 3259.0, loss:0.23463594\n",
      "step: 3260.0, loss:0.40000902\n",
      "step: 3261.0, loss:0.43720023\n",
      "step: 3262.0, loss:0.34975230\n",
      "step: 3263.0, loss:0.43363259\n",
      "step: 3264.0, loss:0.41503448\n",
      "step: 3265.0, loss:0.31568326\n",
      "step: 3266.0, loss:0.41915470\n",
      "step: 3267.0, loss:0.40632141\n",
      "step: 3268.0, loss:0.32208732\n",
      "step: 3269.0, loss:0.39338721\n",
      "step: 3270.0, loss:0.20233148\n",
      "step: 3271.0, loss:0.31954111\n",
      "step: 3272.0, loss:0.36258313\n",
      "step: 3273.0, loss:0.35629631\n",
      "step: 3274.0, loss:0.35639349\n",
      "step: 3275.0, loss:0.37214738\n",
      "step: 3276.0, loss:0.38855862\n",
      "step: 3277.0, loss:0.36232648\n",
      "step: 3278.0, loss:0.38022660\n",
      "step: 3279.0, loss:0.32431095\n",
      "step: 3280.0, loss:0.31346124\n",
      "step: 3281.0, loss:0.30958767\n",
      "step: 3282.0, loss:0.33868133\n",
      "step: 3283.0, loss:0.21898574\n",
      "step: 3284.0, loss:0.36409016\n",
      "step: 3285.0, loss:0.29901788\n",
      "step: 3286.0, loss:0.24667432\n",
      "step: 3287.0, loss:0.25149057\n",
      "step: 3288.0, loss:0.35050548\n",
      "step: 3289.0, loss:0.23811748\n",
      "step: 3290.0, loss:0.31257086\n",
      "step: 3291.0, loss:0.27527915\n",
      "step: 3292.0, loss:0.33565720\n",
      "step: 3293.0, loss:0.27072056\n",
      "step: 3294.0, loss:0.46885116\n",
      "step: 3295.0, loss:0.28073802\n",
      "step: 3296.0, loss:0.28588156\n",
      "step: 3297.0, loss:0.27418918\n",
      "step: 3298.0, loss:0.36866256\n",
      "step: 3299.0, loss:0.27561070\n",
      "step: 3300.0, loss:0.28757641\n",
      "step: 3301.0, loss:0.24426460\n",
      "step: 3302.0, loss:0.30693514\n",
      "step: 3303.0, loss:0.26993876\n",
      "step: 3304.0, loss:0.27639300\n",
      "step: 3305.0, loss:0.31431159\n",
      "step: 3306.0, loss:0.40710675\n",
      "step: 3307.0, loss:0.28842135\n",
      "step: 3308.0, loss:0.40076181\n",
      "step: 3309.0, loss:0.35662909\n",
      "step: 3310.0, loss:0.36406427\n",
      "step: 3311.0, loss:0.33557124\n",
      "step: 3312.0, loss:0.42519709\n",
      "step: 3313.0, loss:0.33590142\n",
      "step: 3314.0, loss:0.26278889\n",
      "step: 3315.0, loss:0.46823825\n",
      "step: 3316.0, loss:0.36068127\n",
      "step: 3317.0, loss:0.36501459\n",
      "step: 3318.0, loss:0.36761191\n",
      "step: 3319.0, loss:0.24880411\n",
      "step: 3320.0, loss:0.35812480\n",
      "step: 3321.0, loss:0.32922686\n",
      "step: 3322.0, loss:0.24285199\n",
      "step: 3323.0, loss:0.29031269\n",
      "step: 3324.0, loss:0.38955405\n",
      "step: 3325.0, loss:0.31203917\n",
      "step: 3326.0, loss:0.31582308\n",
      "step: 3327.0, loss:0.38535387\n",
      "step: 3328.0, loss:0.40201416\n",
      "step: 3329.0, loss:0.36894456\n",
      "step: 3330.0, loss:0.32568633\n",
      "step: 3331.0, loss:0.48069471\n",
      "step: 3332.0, loss:0.25677961\n",
      "step: 3333.0, loss:0.21475274\n",
      "step: 3334.0, loss:0.37304992\n",
      "step: 3335.0, loss:0.27013030\n",
      "step: 3336.0, loss:0.30382972\n",
      "step: 3337.0, loss:0.32826425\n",
      "step: 3338.0, loss:0.26284304\n",
      "step: 3339.0, loss:0.26700297\n",
      "step: 3340.0, loss:0.28882221\n",
      "step: 3341.0, loss:0.34735716\n",
      "step: 3342.0, loss:0.38716324\n",
      "step: 3343.0, loss:0.36203144\n",
      "step: 3344.0, loss:0.19420459\n",
      "step: 3345.0, loss:0.29066746\n",
      "step: 3346.0, loss:0.43451979\n",
      "step: 3347.0, loss:0.36231855\n",
      "step: 3348.0, loss:0.33570750\n",
      "step: 3349.0, loss:0.33358181\n",
      "step: 3350.0, loss:0.24479057\n",
      "step: 3351.0, loss:0.30290956\n",
      "step: 3352.0, loss:0.49475001\n",
      "step: 3353.0, loss:0.29157202\n",
      "step: 3354.0, loss:0.34150559\n",
      "step: 3355.0, loss:0.32031602\n",
      "step: 3356.0, loss:0.31924235\n",
      "step: 3357.0, loss:0.27067494\n",
      "step: 3358.0, loss:0.31408821\n",
      "step: 3359.0, loss:0.31970193\n",
      "step: 3360.0, loss:0.31259590\n",
      "step: 3361.0, loss:0.36255191\n",
      "step: 3362.0, loss:0.30869806\n",
      "step: 3363.0, loss:0.28841923\n",
      "step: 3364.0, loss:0.23753621\n",
      "step: 3365.0, loss:0.22686524\n",
      "step: 3366.0, loss:0.36977108\n",
      "step: 3367.0, loss:0.37482752\n",
      "step: 3368.0, loss:0.30467293\n",
      "step: 3369.0, loss:0.34677123\n",
      "step: 3370.0, loss:0.31390997\n",
      "step: 3371.0, loss:0.34170738\n",
      "step: 3372.0, loss:0.41863906\n",
      "step: 3373.0, loss:0.38230420\n",
      "step: 3374.0, loss:0.20405060\n",
      "step: 3375.0, loss:0.26115778\n",
      "step: 3376.0, loss:0.20529097\n",
      "step: 3377.0, loss:0.31319510\n",
      "step: 3378.0, loss:0.27764316\n",
      "step: 3379.0, loss:0.30517771\n",
      "step: 3380.0, loss:0.32926862\n",
      "step: 3381.0, loss:0.29096315\n",
      "step: 3382.0, loss:0.21871020\n",
      "step: 3383.0, loss:0.33543534\n",
      "step: 3384.0, loss:0.34595955\n",
      "step: 3385.0, loss:0.22525921\n",
      "step: 3386.0, loss:0.32596434\n",
      "step: 3387.0, loss:0.32936138\n",
      "step: 3388.0, loss:0.39941029\n",
      "step: 3389.0, loss:0.22814612\n",
      "step: 3390.0, loss:0.44236761\n",
      "step: 3391.0, loss:0.42369841\n",
      "step: 3392.0, loss:0.31409968\n",
      "step: 3393.0, loss:0.43394428\n",
      "step: 3394.0, loss:0.31263740\n",
      "step: 3395.0, loss:0.35741385\n",
      "step: 3396.0, loss:0.41706070\n",
      "step: 3397.0, loss:0.27042880\n",
      "step: 3398.0, loss:0.35086118\n",
      "step: 3399.0, loss:0.24185883\n",
      "step: 3400.0, loss:0.40766935\n",
      "step: 3401.0, loss:0.32222763\n",
      "step: 3402.0, loss:0.23175727\n",
      "step: 3403.0, loss:0.37668447\n",
      "step: 3404.0, loss:0.25709377\n",
      "step: 3405.0, loss:0.34182057\n",
      "step: 3406.0, loss:0.37385294\n",
      "step: 3407.0, loss:0.32723968\n",
      "step: 3408.0, loss:0.21089102\n",
      "step: 3409.0, loss:0.35670774\n",
      "step: 3410.0, loss:0.40402409\n",
      "step: 3411.0, loss:0.47675800\n",
      "step: 3412.0, loss:0.28763693\n",
      "step: 3413.0, loss:0.30922164\n",
      "step: 3414.0, loss:0.37916305\n",
      "step: 3415.0, loss:0.40668839\n",
      "step: 3416.0, loss:0.28006906\n",
      "step: 3417.0, loss:0.36870514\n",
      "step: 3418.0, loss:0.31243052\n",
      "step: 3419.0, loss:0.32426738\n",
      "step: 3420.0, loss:0.43073307\n",
      "step: 3421.0, loss:0.32912543\n",
      "step: 3422.0, loss:0.25512024\n",
      "step: 3423.0, loss:0.29134888\n",
      "step: 3424.0, loss:0.37380084\n",
      "step: 3425.0, loss:0.35775917\n",
      "step: 3426.0, loss:0.37405362\n",
      "step: 3427.0, loss:0.25624006\n",
      "step: 3428.0, loss:0.35628732\n",
      "step: 3429.0, loss:0.33257109\n",
      "step: 3430.0, loss:0.37132628\n",
      "step: 3431.0, loss:0.41436174\n",
      "step: 3432.0, loss:0.31926971\n",
      "step: 3433.0, loss:0.32793229\n",
      "step: 3434.0, loss:0.26126086\n",
      "step: 3435.0, loss:0.36936574\n",
      "step: 3436.0, loss:0.37886529\n",
      "step: 3437.0, loss:0.23966769\n",
      "step: 3438.0, loss:0.28544603\n",
      "step: 3439.0, loss:0.37191479\n",
      "step: 3440.0, loss:0.30781206\n",
      "step: 3441.0, loss:0.35972666\n",
      "step: 3442.0, loss:0.31774388\n",
      "step: 3443.0, loss:0.35841128\n",
      "step: 3444.0, loss:0.29277780\n",
      "step: 3445.0, loss:0.35888810\n",
      "step: 3446.0, loss:0.27550080\n",
      "step: 3447.0, loss:0.35239449\n",
      "step: 3448.0, loss:0.27147006\n",
      "step: 3449.0, loss:0.33703259\n",
      "step: 3450.0, loss:0.38614354\n",
      "step: 3451.0, loss:0.32854712\n",
      "step: 3452.0, loss:0.30138785\n",
      "step: 3453.0, loss:0.22977465\n",
      "step: 3454.0, loss:0.30606722\n",
      "step: 3455.0, loss:0.44038156\n",
      "step: 3456.0, loss:0.36173145\n",
      "step: 3457.0, loss:0.38605146\n",
      "step: 3458.0, loss:0.39837318\n",
      "step: 3459.0, loss:0.26507695\n",
      "step: 3460.0, loss:0.26924379\n",
      "step: 3461.0, loss:0.25942221\n",
      "step: 3462.0, loss:0.33131587\n",
      "step: 3463.0, loss:0.25208343\n",
      "step: 3464.0, loss:0.34190841\n",
      "step: 3465.0, loss:0.37886595\n",
      "step: 3466.0, loss:0.32428089\n",
      "step: 3467.0, loss:0.26037007\n",
      "step: 3468.0, loss:0.39763454\n",
      "step: 3469.0, loss:0.16261824\n",
      "step: 3470.0, loss:0.19015310\n",
      "step: 3471.0, loss:0.36558251\n",
      "step: 3472.0, loss:0.35537304\n",
      "step: 3473.0, loss:0.33763368\n",
      "step: 3474.0, loss:0.34553208\n",
      "step: 3475.0, loss:0.28973895\n",
      "step: 3476.0, loss:0.31664448\n",
      "step: 3477.0, loss:0.24618880\n",
      "step: 3478.0, loss:0.34349393\n",
      "step: 3479.0, loss:0.32654167\n",
      "step: 3480.0, loss:0.18025962\n",
      "step: 3481.0, loss:0.19701516\n",
      "step: 3482.0, loss:0.34388323\n",
      "step: 3483.0, loss:0.42809118\n",
      "step: 3484.0, loss:0.24929146\n",
      "step: 3485.0, loss:0.41179758\n",
      "step: 3486.0, loss:0.39205573\n",
      "step: 3487.0, loss:0.43298394\n",
      "step: 3488.0, loss:0.26001454\n",
      "step: 3489.0, loss:0.27586939\n",
      "step: 3490.0, loss:0.39594198\n",
      "step: 3491.0, loss:0.37185228\n",
      "step: 3492.0, loss:0.23112805\n",
      "step: 3493.0, loss:0.32856339\n",
      "step: 3494.0, loss:0.34502548\n",
      "step: 3495.0, loss:0.40330513\n",
      "step: 3496.0, loss:0.29963349\n",
      "step: 3497.0, loss:0.34588141\n",
      "step: 3498.0, loss:0.26125150\n",
      "step: 3499.0, loss:0.25980676\n",
      "step: 3500.0, loss:0.34497142\n",
      "step: 3501.0, loss:0.33347027\n",
      "step: 3502.0, loss:0.27379848\n",
      "step: 3503.0, loss:0.40365081\n",
      "step: 3504.0, loss:0.32086090\n",
      "step: 3505.0, loss:0.36140212\n",
      "step: 3506.0, loss:0.24436190\n",
      "step: 3507.0, loss:0.30278257\n",
      "step: 3508.0, loss:0.29468550\n",
      "step: 3509.0, loss:0.25713554\n",
      "step: 3510.0, loss:0.35800696\n",
      "step: 3511.0, loss:0.37311010\n",
      "step: 3512.0, loss:0.21141101\n",
      "step: 3513.0, loss:0.31602313\n",
      "step: 3514.0, loss:0.39519904\n",
      "step: 3515.0, loss:0.41572466\n",
      "step: 3516.0, loss:0.32132164\n",
      "step: 3517.0, loss:0.26884777\n",
      "step: 3518.0, loss:0.23484590\n",
      "step: 3519.0, loss:0.30569416\n",
      "step: 3520.0, loss:0.38232917\n",
      "step: 3521.0, loss:0.35008459\n",
      "step: 3522.0, loss:0.28854812\n",
      "step: 3523.0, loss:0.23248807\n",
      "step: 3524.0, loss:0.30118733\n",
      "step: 3525.0, loss:0.37473223\n",
      "step: 3526.0, loss:0.35262068\n",
      "step: 3527.0, loss:0.26752144\n",
      "step: 3528.0, loss:0.35153396\n",
      "step: 3529.0, loss:0.32093994\n",
      "step: 3530.0, loss:0.34921402\n",
      "step: 3531.0, loss:0.28288904\n",
      "step: 3532.0, loss:0.35264736\n",
      "step: 3533.0, loss:0.31450581\n",
      "step: 3534.0, loss:0.26940825\n",
      "step: 3535.0, loss:0.27838621\n",
      "step: 3536.0, loss:0.19191202\n",
      "step: 3537.0, loss:0.32682862\n",
      "step: 3538.0, loss:0.31834451\n",
      "step: 3539.0, loss:0.47262139\n",
      "step: 3540.0, loss:0.41076827\n",
      "step: 3541.0, loss:0.38803557\n",
      "step: 3542.0, loss:0.22003349\n",
      "step: 3543.0, loss:0.34450569\n",
      "step: 3544.0, loss:0.24770589\n",
      "step: 3545.0, loss:0.30684041\n",
      "step: 3546.0, loss:0.38607011\n",
      "step: 3547.0, loss:0.45414168\n",
      "step: 3548.0, loss:0.35605359\n",
      "step: 3549.0, loss:0.30239145\n",
      "step: 3550.0, loss:0.21732789\n",
      "step: 3551.0, loss:0.26937413\n",
      "step: 3552.0, loss:0.25312929\n",
      "step: 3553.0, loss:0.24582143\n",
      "step: 3554.0, loss:0.37187095\n",
      "step: 3555.0, loss:0.40988789\n",
      "step: 3556.0, loss:0.44476242\n",
      "step: 3557.0, loss:0.32930135\n",
      "step: 3558.0, loss:0.22971106\n",
      "step: 3559.0, loss:0.23216069\n",
      "step: 3560.0, loss:0.35614034\n",
      "step: 3561.0, loss:0.37529492\n",
      "step: 3562.0, loss:0.33098141\n",
      "step: 3563.0, loss:0.26783491\n",
      "step: 3564.0, loss:0.33347256\n",
      "step: 3565.0, loss:0.31564351\n",
      "step: 3566.0, loss:0.31406234\n",
      "step: 3567.0, loss:0.39956326\n",
      "step: 3568.0, loss:0.32650940\n",
      "step: 3569.0, loss:0.28490920\n",
      "step: 3570.0, loss:0.29702166\n",
      "step: 3571.0, loss:0.21700475\n",
      "step: 3572.0, loss:0.32745378\n",
      "step: 3573.0, loss:0.44291486\n",
      "step: 3574.0, loss:0.20730655\n",
      "step: 3575.0, loss:0.28292234\n",
      "step: 3576.0, loss:0.34528529\n",
      "step: 3577.0, loss:0.33022832\n",
      "step: 3578.0, loss:0.39717751\n",
      "step: 3579.0, loss:0.27334588\n",
      "step: 3580.0, loss:0.24038957\n",
      "step: 3581.0, loss:0.36700741\n",
      "step: 3582.0, loss:0.23219555\n",
      "step: 3583.0, loss:0.27381214\n",
      "step: 3584.0, loss:0.26764224\n",
      "step: 3585.0, loss:0.39846700\n",
      "step: 3586.0, loss:0.54746637\n",
      "step: 3587.0, loss:0.22158270\n",
      "step: 3588.0, loss:0.26959352\n",
      "step: 3589.0, loss:0.25516528\n",
      "step: 3590.0, loss:0.39063273\n",
      "step: 3591.0, loss:0.18217051\n",
      "step: 3592.0, loss:0.42403476\n",
      "step: 3593.0, loss:0.31517912\n",
      "step: 3594.0, loss:0.30707531\n",
      "step: 3595.0, loss:0.39780138\n",
      "step: 3596.0, loss:0.30980200\n",
      "step: 3597.0, loss:0.34106014\n",
      "step: 3598.0, loss:0.24777080\n",
      "step: 3599.0, loss:0.38701779\n",
      "step: 3600.0, loss:0.30438784\n",
      "step: 3601.0, loss:0.40320811\n",
      "step: 3602.0, loss:0.36980674\n",
      "step: 3603.0, loss:0.24738612\n",
      "step: 3604.0, loss:0.20867193\n",
      "step: 3605.0, loss:0.28972217\n",
      "step: 3606.0, loss:0.18858572\n",
      "step: 3607.0, loss:0.43048628\n",
      "step: 3608.0, loss:0.25682777\n",
      "step: 3609.0, loss:0.30013952\n",
      "step: 3610.0, loss:0.29607901\n",
      "step: 3611.0, loss:0.29257620\n",
      "step: 3612.0, loss:0.26557849\n",
      "step: 3613.0, loss:0.16274741\n",
      "step: 3614.0, loss:0.29761887\n",
      "step: 3615.0, loss:0.24983230\n",
      "step: 3616.0, loss:0.31342034\n",
      "step: 3617.0, loss:0.28554590\n",
      "step: 3618.0, loss:0.29167373\n",
      "step: 3619.0, loss:0.20163069\n",
      "step: 3620.0, loss:0.35841089\n",
      "step: 3621.0, loss:0.29623861\n",
      "step: 3622.0, loss:0.25093447\n",
      "step: 3623.0, loss:0.32371781\n",
      "step: 3624.0, loss:0.36154035\n",
      "step: 3625.0, loss:0.20146913\n",
      "step: 3626.0, loss:0.34294954\n",
      "step: 3627.0, loss:0.34306463\n",
      "step: 3628.0, loss:0.27099115\n",
      "step: 3629.0, loss:0.36395644\n",
      "step: 3630.0, loss:0.26468820\n",
      "step: 3631.0, loss:0.37142274\n",
      "step: 3632.0, loss:0.39315875\n",
      "step: 3633.0, loss:0.24911756\n",
      "step: 3634.0, loss:0.36400523\n",
      "step: 3635.0, loss:0.30007078\n",
      "step: 3636.0, loss:0.37201820\n",
      "step: 3637.0, loss:0.28215696\n",
      "step: 3638.0, loss:0.24280803\n",
      "step: 3639.0, loss:0.21890733\n",
      "step: 3640.0, loss:0.34928381\n",
      "step: 3641.0, loss:0.30669634\n",
      "step: 3642.0, loss:0.18982268\n",
      "step: 3643.0, loss:0.30499671\n",
      "step: 3644.0, loss:0.33443621\n",
      "step: 3645.0, loss:0.25565922\n",
      "step: 3646.0, loss:0.29519795\n",
      "step: 3647.0, loss:0.44684217\n",
      "step: 3648.0, loss:0.35192494\n",
      "step: 3649.0, loss:0.25017280\n",
      "step: 3650.0, loss:0.33346733\n",
      "step: 3651.0, loss:0.21151348\n",
      "step: 3652.0, loss:0.48723599\n",
      "step: 3653.0, loss:0.36029219\n",
      "step: 3654.0, loss:0.27028081\n",
      "step: 3655.0, loss:0.26626896\n",
      "step: 3656.0, loss:0.17053911\n",
      "step: 3657.0, loss:0.28593608\n",
      "step: 3658.0, loss:0.31546004\n",
      "step: 3659.0, loss:0.34862432\n",
      "step: 3660.0, loss:0.26624775\n",
      "step: 3661.0, loss:0.30047440\n",
      "step: 3662.0, loss:0.23894561\n",
      "step: 3663.0, loss:0.24017606\n",
      "step: 3664.0, loss:0.24159005\n",
      "step: 3665.0, loss:0.38153546\n",
      "step: 3666.0, loss:0.26474114\n",
      "step: 3667.0, loss:0.36869108\n",
      "step: 3668.0, loss:0.19289074\n",
      "step: 3669.0, loss:0.34306939\n",
      "step: 3670.0, loss:0.33839762\n",
      "step: 3671.0, loss:0.36034629\n",
      "step: 3672.0, loss:0.50242776\n",
      "step: 3673.0, loss:0.33768587\n",
      "step: 3674.0, loss:0.40072347\n",
      "step: 3675.0, loss:0.36741010\n",
      "step: 3676.0, loss:0.25057454\n",
      "step: 3677.0, loss:0.44673627\n",
      "step: 3678.0, loss:0.25852869\n",
      "step: 3679.0, loss:0.34196410\n",
      "step: 3680.0, loss:0.27693697\n",
      "step: 3681.0, loss:0.21683037\n",
      "step: 3682.0, loss:0.44738384\n",
      "step: 3683.0, loss:0.36058038\n",
      "step: 3684.0, loss:0.28304153\n",
      "step: 3685.0, loss:0.30199954\n",
      "step: 3686.0, loss:0.41355868\n",
      "step: 3687.0, loss:0.34005713\n",
      "step: 3688.0, loss:0.31341367\n",
      "step: 3689.0, loss:0.39858597\n",
      "step: 3690.0, loss:0.43572009\n",
      "step: 3691.0, loss:0.24597648\n",
      "step: 3692.0, loss:0.30364282\n",
      "step: 3693.0, loss:0.25590106\n",
      "step: 3694.0, loss:0.20653046\n",
      "step: 3695.0, loss:0.26235912\n",
      "step: 3696.0, loss:0.30462423\n",
      "step: 3697.0, loss:0.30830391\n",
      "step: 3698.0, loss:0.31931594\n",
      "step: 3699.0, loss:0.27065673\n",
      "step: 3700.0, loss:0.35368311\n",
      "step: 3701.0, loss:0.37194855\n",
      "step: 3702.0, loss:0.32490684\n",
      "step: 3703.0, loss:0.36787410\n",
      "step: 3704.0, loss:0.32988272\n",
      "step: 3705.0, loss:0.24967274\n",
      "step: 3706.0, loss:0.24082685\n",
      "step: 3707.0, loss:0.29811196\n",
      "step: 3708.0, loss:0.30654037\n",
      "step: 3709.0, loss:0.24846481\n",
      "step: 3710.0, loss:0.30454981\n",
      "step: 3711.0, loss:0.23829326\n",
      "step: 3712.0, loss:0.35237640\n",
      "step: 3713.0, loss:0.35024746\n",
      "step: 3714.0, loss:0.44493061\n",
      "step: 3715.0, loss:0.37262502\n",
      "step: 3716.0, loss:0.27747846\n",
      "step: 3717.0, loss:0.29549257\n",
      "step: 3718.0, loss:0.26462578\n",
      "step: 3719.0, loss:0.42936686\n",
      "step: 3720.0, loss:0.28187171\n",
      "step: 3721.0, loss:0.36565278\n",
      "step: 3722.0, loss:0.24631059\n",
      "step: 3723.0, loss:0.14263594\n",
      "step: 3724.0, loss:0.31921442\n",
      "step: 3725.0, loss:0.29469914\n",
      "step: 3726.0, loss:0.26301065\n",
      "step: 3727.0, loss:0.29912263\n",
      "step: 3728.0, loss:0.25824005\n",
      "step: 3729.0, loss:0.19983559\n",
      "step: 3730.0, loss:0.23638427\n",
      "step: 3731.0, loss:0.36307111\n",
      "step: 3732.0, loss:0.31201160\n",
      "step: 3733.0, loss:0.39834091\n",
      "step: 3734.0, loss:0.26467789\n",
      "step: 3735.0, loss:0.39999052\n",
      "step: 3736.0, loss:0.29866929\n",
      "step: 3737.0, loss:0.33209594\n",
      "step: 3738.0, loss:0.22054075\n",
      "step: 3739.0, loss:0.31783708\n",
      "step: 3740.0, loss:0.35022719\n",
      "step: 3741.0, loss:0.27429724\n",
      "step: 3742.0, loss:0.40690864\n",
      "step: 3743.0, loss:0.29285420\n",
      "step: 3744.0, loss:0.34006745\n",
      "step: 3745.0, loss:0.27445239\n",
      "step: 3746.0, loss:0.29995684\n",
      "step: 3747.0, loss:0.35074942\n",
      "step: 3748.0, loss:0.41383118\n",
      "step: 3749.0, loss:0.20333786\n",
      "step: 3750.0, loss:0.21834482\n",
      "step: 3751.0, loss:0.34485193\n",
      "step: 3752.0, loss:0.22501106\n",
      "step: 3753.0, loss:0.31737299\n",
      "step: 3754.0, loss:0.29125673\n",
      "step: 3755.0, loss:0.21983089\n",
      "step: 3756.0, loss:0.27064579\n",
      "step: 3757.0, loss:0.25852183\n",
      "step: 3758.0, loss:0.24595066\n",
      "step: 3759.0, loss:0.37407673\n",
      "step: 3760.0, loss:0.19604599\n",
      "step: 3761.0, loss:0.32516493\n",
      "step: 3762.0, loss:0.39099871\n",
      "step: 3763.0, loss:0.30952423\n",
      "step: 3764.0, loss:0.32739914\n",
      "step: 3765.0, loss:0.30245845\n",
      "step: 3766.0, loss:0.31252198\n",
      "step: 3767.0, loss:0.20098114\n",
      "step: 3768.0, loss:0.32989654\n",
      "step: 3769.0, loss:0.34448953\n",
      "step: 3770.0, loss:0.30828233\n",
      "step: 3771.0, loss:0.40421442\n",
      "step: 3772.0, loss:0.49945926\n",
      "step: 3773.0, loss:0.33321521\n",
      "step: 3774.0, loss:0.37954156\n",
      "step: 3775.0, loss:0.37031222\n",
      "step: 3776.0, loss:0.37442071\n",
      "step: 3777.0, loss:0.22433094\n",
      "step: 3778.0, loss:0.19191612\n",
      "step: 3779.0, loss:0.30148622\n",
      "step: 3780.0, loss:0.26826580\n",
      "step: 3781.0, loss:0.28385850\n",
      "step: 3782.0, loss:0.24443670\n",
      "step: 3783.0, loss:0.35410254\n",
      "step: 3784.0, loss:0.28738453\n",
      "step: 3785.0, loss:0.37041430\n",
      "step: 3786.0, loss:0.31159625\n",
      "step: 3787.0, loss:0.17070627\n",
      "step: 3788.0, loss:0.32196218\n",
      "step: 3789.0, loss:0.31606792\n",
      "step: 3790.0, loss:0.28527809\n",
      "step: 3791.0, loss:0.29066390\n",
      "step: 3792.0, loss:0.31829222\n",
      "step: 3793.0, loss:0.30241361\n",
      "step: 3794.0, loss:0.24149857\n",
      "step: 3795.0, loss:0.28928616\n",
      "step: 3796.0, loss:0.30847066\n",
      "step: 3797.0, loss:0.31622554\n",
      "step: 3798.0, loss:0.27044914\n",
      "step: 3799.0, loss:0.23258947\n",
      "step: 3800.0, loss:0.50039782\n",
      "step: 3801.0, loss:0.31250307\n",
      "step: 3802.0, loss:0.31306998\n",
      "step: 3803.0, loss:0.25821471\n",
      "step: 3804.0, loss:0.21971624\n",
      "step: 3805.0, loss:0.34303672\n",
      "step: 3806.0, loss:0.29961899\n",
      "step: 3807.0, loss:0.24009335\n",
      "step: 3808.0, loss:0.37162324\n",
      "step: 3809.0, loss:0.29455041\n",
      "step: 3810.0, loss:0.26484972\n",
      "step: 3811.0, loss:0.34516287\n",
      "step: 3812.0, loss:0.26650208\n",
      "step: 3813.0, loss:0.30813593\n",
      "step: 3814.0, loss:0.44764566\n",
      "step: 3815.0, loss:0.21969455\n",
      "step: 3816.0, loss:0.30098339\n",
      "step: 3817.0, loss:0.40103938\n",
      "step: 3818.0, loss:0.35059644\n",
      "step: 3819.0, loss:0.32382378\n",
      "step: 3820.0, loss:0.48607831\n",
      "step: 3821.0, loss:0.29794671\n",
      "step: 3822.0, loss:0.31273399\n",
      "step: 3823.0, loss:0.27181812\n",
      "step: 3824.0, loss:0.32207111\n",
      "step: 3825.0, loss:0.26514557\n",
      "step: 3826.0, loss:0.28040927\n",
      "step: 3827.0, loss:0.35688762\n",
      "step: 3828.0, loss:0.41822536\n",
      "step: 3829.0, loss:0.26423435\n",
      "step: 3830.0, loss:0.27735087\n",
      "step: 3831.0, loss:0.25683368\n",
      "step: 3832.0, loss:0.29612648\n",
      "step: 3833.0, loss:0.25684914\n",
      "step: 3834.0, loss:0.32403925\n",
      "step: 3835.0, loss:0.31770737\n",
      "step: 3836.0, loss:0.23233593\n",
      "step: 3837.0, loss:0.31483841\n",
      "step: 3838.0, loss:0.35793054\n",
      "step: 3839.0, loss:0.29033567\n",
      "step: 3840.0, loss:0.24310634\n",
      "step: 3841.0, loss:0.30981134\n",
      "step: 3842.0, loss:0.19232532\n",
      "step: 3843.0, loss:0.35209092\n",
      "step: 3844.0, loss:0.32457172\n",
      "step: 3845.0, loss:0.31375262\n",
      "step: 3846.0, loss:0.37414760\n",
      "step: 3847.0, loss:0.31878792\n",
      "step: 3848.0, loss:0.26232108\n",
      "step: 3849.0, loss:0.30284207\n",
      "step: 3850.0, loss:0.31823793\n",
      "step: 3851.0, loss:0.24906989\n",
      "step: 3852.0, loss:0.28423888\n",
      "step: 3853.0, loss:0.34058025\n",
      "step: 3854.0, loss:0.23513413\n",
      "step: 3855.0, loss:0.27640441\n",
      "step: 3856.0, loss:0.33908754\n",
      "step: 3857.0, loss:0.30897610\n",
      "step: 3858.0, loss:0.21152644\n",
      "step: 3859.0, loss:0.29164976\n",
      "step: 3860.0, loss:0.28808629\n",
      "step: 3861.0, loss:0.23730255\n",
      "step: 3862.0, loss:0.30294477\n",
      "step: 3863.0, loss:0.25648563\n",
      "step: 3864.0, loss:0.32687750\n",
      "step: 3865.0, loss:0.28999368\n",
      "step: 3866.0, loss:0.25362338\n",
      "step: 3867.0, loss:0.20487099\n",
      "step: 3868.0, loss:0.15852132\n",
      "step: 3869.0, loss:0.28951599\n",
      "step: 3870.0, loss:0.33466469\n",
      "step: 3871.0, loss:0.36769973\n",
      "step: 3872.0, loss:0.28491508\n",
      "step: 3873.0, loss:0.33224983\n",
      "step: 3874.0, loss:0.28249896\n",
      "step: 3875.0, loss:0.25755237\n",
      "step: 3876.0, loss:0.36581608\n",
      "step: 3877.0, loss:0.43356253\n",
      "step: 3878.0, loss:0.19651431\n",
      "step: 3879.0, loss:0.22873309\n",
      "step: 3880.0, loss:0.23027197\n",
      "step: 3881.0, loss:0.47335102\n",
      "step: 3882.0, loss:0.50825422\n",
      "step: 3883.0, loss:0.32667676\n",
      "step: 3884.0, loss:0.31523697\n",
      "step: 3885.0, loss:0.34855917\n",
      "step: 3886.0, loss:0.38413711\n",
      "step: 3887.0, loss:0.24947857\n",
      "step: 3888.0, loss:0.29407904\n",
      "step: 3889.0, loss:0.30842909\n",
      "step: 3890.0, loss:0.23903372\n",
      "step: 3891.0, loss:0.39947559\n",
      "step: 3892.0, loss:0.33146418\n",
      "step: 3893.0, loss:0.31034106\n",
      "step: 3894.0, loss:0.29183239\n",
      "step: 3895.0, loss:0.33439679\n",
      "step: 3896.0, loss:0.37245471\n",
      "step: 3897.0, loss:0.19861074\n",
      "step: 3898.0, loss:0.28312586\n",
      "step: 3899.0, loss:0.29683899\n",
      "step: 3900.0, loss:0.27232525\n",
      "step: 3901.0, loss:0.24966637\n",
      "step: 3902.0, loss:0.25763878\n",
      "step: 3903.0, loss:0.20974423\n",
      "step: 3904.0, loss:0.35437221\n",
      "step: 3905.0, loss:0.29503475\n",
      "step: 3906.0, loss:0.27199232\n",
      "step: 3907.0, loss:0.33673080\n",
      "step: 3908.0, loss:0.35456809\n",
      "step: 3909.0, loss:0.33637624\n",
      "step: 3910.0, loss:0.30397876\n",
      "step: 3911.0, loss:0.27961585\n",
      "step: 3912.0, loss:0.34738128\n",
      "step: 3913.0, loss:0.38502938\n",
      "step: 3914.0, loss:0.30468043\n",
      "step: 3915.0, loss:0.46251870\n",
      "step: 3916.0, loss:0.23077057\n",
      "step: 3917.0, loss:0.31969299\n",
      "step: 3918.0, loss:0.27725084\n",
      "step: 3919.0, loss:0.32410818\n",
      "step: 3920.0, loss:0.22367743\n",
      "step: 3921.0, loss:0.39372703\n",
      "step: 3922.0, loss:0.30060206\n",
      "step: 3923.0, loss:0.28032945\n",
      "step: 3924.0, loss:0.38196218\n",
      "step: 3925.0, loss:0.21605050\n",
      "step: 3926.0, loss:0.28684721\n",
      "step: 3927.0, loss:0.34811791\n",
      "step: 3928.0, loss:0.28371959\n",
      "step: 3929.0, loss:0.30261389\n",
      "step: 3930.0, loss:0.26076781\n",
      "step: 3931.0, loss:0.36112509\n",
      "step: 3932.0, loss:0.27591106\n",
      "step: 3933.0, loss:0.31904127\n",
      "step: 3934.0, loss:0.27403044\n",
      "step: 3935.0, loss:0.38939846\n",
      "step: 3936.0, loss:0.21174269\n",
      "step: 3937.0, loss:0.39093523\n",
      "step: 3938.0, loss:0.27864885\n",
      "step: 3939.0, loss:0.35083932\n",
      "step: 3940.0, loss:0.27970375\n",
      "step: 3941.0, loss:0.32750429\n",
      "step: 3942.0, loss:0.34756552\n",
      "step: 3943.0, loss:0.38593104\n",
      "step: 3944.0, loss:0.29998573\n",
      "step: 3945.0, loss:0.45998704\n",
      "step: 3946.0, loss:0.26549286\n",
      "step: 3947.0, loss:0.17943752\n",
      "step: 3948.0, loss:0.38484691\n",
      "step: 3949.0, loss:0.27114628\n",
      "step: 3950.0, loss:0.28861782\n",
      "step: 3951.0, loss:0.25642842\n",
      "step: 3952.0, loss:0.36508542\n",
      "step: 3953.0, loss:0.46537191\n",
      "step: 3954.0, loss:0.32561615\n",
      "step: 3955.0, loss:0.31407873\n",
      "step: 3956.0, loss:0.22969756\n",
      "step: 3957.0, loss:0.29564346\n",
      "step: 3958.0, loss:0.22622076\n",
      "step: 3959.0, loss:0.27586582\n",
      "step: 3960.0, loss:0.32167822\n",
      "step: 3961.0, loss:0.26175884\n",
      "step: 3962.0, loss:0.27181534\n",
      "step: 3963.0, loss:0.35405290\n",
      "step: 3964.0, loss:0.39616448\n",
      "step: 3965.0, loss:0.25287228\n",
      "step: 3966.0, loss:0.35236732\n",
      "step: 3967.0, loss:0.18100102\n",
      "step: 3968.0, loss:0.31237836\n",
      "step: 3969.0, loss:0.32116209\n",
      "step: 3970.0, loss:0.23839249\n",
      "step: 3971.0, loss:0.31607675\n",
      "step: 3972.0, loss:0.36837517\n",
      "step: 3973.0, loss:0.44535442\n",
      "step: 3974.0, loss:0.34177857\n",
      "step: 3975.0, loss:0.30773098\n",
      "step: 3976.0, loss:0.27262639\n",
      "step: 3977.0, loss:0.31754211\n",
      "step: 3978.0, loss:0.29598370\n",
      "step: 3979.0, loss:0.16656041\n",
      "step: 3980.0, loss:0.28940993\n",
      "step: 3981.0, loss:0.14109772\n",
      "step: 3982.0, loss:0.38758582\n",
      "step: 3983.0, loss:0.26796321\n",
      "step: 3984.0, loss:0.31190747\n",
      "step: 3985.0, loss:0.37398709\n",
      "step: 3986.0, loss:0.48910226\n",
      "step: 3987.0, loss:0.26402263\n",
      "step: 3988.0, loss:0.38122877\n",
      "step: 3989.0, loss:0.26370698\n",
      "step: 3990.0, loss:0.27400141\n",
      "step: 3991.0, loss:0.26526311\n",
      "step: 3992.0, loss:0.34772175\n",
      "step: 3993.0, loss:0.36715536\n",
      "step: 3994.0, loss:0.24928258\n",
      "step: 3995.0, loss:0.21624095\n",
      "step: 3996.0, loss:0.27315379\n",
      "step: 3997.0, loss:0.50376322\n",
      "step: 3998.0, loss:0.23033199\n",
      "step: 3999.0, loss:0.26317247\n",
      "step: 4000.0, loss:0.36419784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1264/1264 [08:07<00:00,  2.59it/s]\n",
      "2023-04-02 19:52:37,175 - INFO - step:4000.0, matthews_corr:0.719693, Acc:86.596587%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 4001.0, loss:0.35527114\n",
      "step: 4002.0, loss:0.21750844\n",
      "step: 4003.0, loss:0.29470764\n",
      "step: 4004.0, loss:0.27609345\n",
      "step: 4005.0, loss:0.27883164\n",
      "step: 4006.0, loss:0.34306963\n",
      "step: 4007.0, loss:0.33376618\n",
      "step: 4008.0, loss:0.20002805\n",
      "step: 4009.0, loss:0.28074441\n",
      "step: 4010.0, loss:0.27418777\n",
      "step: 4011.0, loss:0.33867326\n",
      "step: 4012.0, loss:0.39461842\n",
      "step: 4013.0, loss:0.29002246\n",
      "step: 4014.0, loss:0.23911566\n",
      "step: 4015.0, loss:0.27527401\n",
      "step: 4016.0, loss:0.26131594\n",
      "step: 4017.0, loss:0.38478923\n",
      "step: 4018.0, loss:0.27680232\n",
      "step: 4019.0, loss:0.37767562\n",
      "step: 4020.0, loss:0.30274081\n",
      "step: 4021.0, loss:0.23659349\n",
      "step: 4022.0, loss:0.42184897\n",
      "step: 4023.0, loss:0.32274393\n",
      "step: 4024.0, loss:0.29203681\n",
      "step: 4025.0, loss:0.31198593\n",
      "step: 4026.0, loss:0.23968688\n",
      "step: 4027.0, loss:0.31405085\n",
      "step: 4028.0, loss:0.28502102\n",
      "step: 4029.0, loss:0.38624070\n",
      "step: 4030.0, loss:0.27825428\n",
      "step: 4031.0, loss:0.20079455\n",
      "step: 4032.0, loss:0.26912128\n",
      "step: 4033.0, loss:0.27011287\n",
      "step: 4034.0, loss:0.29673824\n",
      "step: 4035.0, loss:0.13089648\n",
      "step: 4036.0, loss:0.28402084\n",
      "step: 4037.0, loss:0.35383204\n",
      "step: 4038.0, loss:0.39331657\n",
      "step: 4039.0, loss:0.25454621\n",
      "step: 4040.0, loss:0.38186125\n",
      "step: 4041.0, loss:0.26128585\n",
      "step: 4042.0, loss:0.32011351\n",
      "step: 4043.0, loss:0.23254087\n",
      "step: 4044.0, loss:0.18527244\n",
      "step: 4045.0, loss:0.34110709\n",
      "step: 4046.0, loss:0.21324660\n",
      "step: 4047.0, loss:0.29021414\n",
      "step: 4048.0, loss:0.31058054\n",
      "step: 4049.0, loss:0.35590576\n",
      "step: 4050.0, loss:0.24549790\n",
      "step: 4051.0, loss:0.33436435\n",
      "step: 4052.0, loss:0.28092945\n",
      "step: 4053.0, loss:0.39936938\n",
      "step: 4054.0, loss:0.40238047\n",
      "step: 4055.0, loss:0.43608519\n",
      "step: 4056.0, loss:0.32330918\n",
      "step: 4057.0, loss:0.25178031\n",
      "step: 4058.0, loss:0.29367438\n",
      "step: 4059.0, loss:0.38897612\n",
      "step: 4060.0, loss:0.30640310\n",
      "step: 4061.0, loss:0.29740679\n",
      "step: 4062.0, loss:0.31823492\n",
      "step: 4063.0, loss:0.27154764\n",
      "step: 4064.0, loss:0.41736854\n",
      "step: 4065.0, loss:0.38854349\n",
      "step: 4066.0, loss:0.28665086\n",
      "step: 4067.0, loss:0.45180114\n",
      "step: 4068.0, loss:0.47034992\n",
      "step: 4069.0, loss:0.26968902\n",
      "step: 4070.0, loss:0.29733365\n",
      "step: 4071.0, loss:0.24945647\n",
      "step: 4072.0, loss:0.27975102\n",
      "step: 4073.0, loss:0.25171850\n",
      "step: 4074.0, loss:0.35715301\n",
      "step: 4075.0, loss:0.24961140\n",
      "step: 4076.0, loss:0.28596129\n",
      "step: 4077.0, loss:0.31574082\n",
      "step: 4078.0, loss:0.32031083\n",
      "step: 4079.0, loss:0.34536506\n",
      "step: 4080.0, loss:0.28177698\n",
      "step: 4081.0, loss:0.27448586\n",
      "step: 4082.0, loss:0.28226789\n",
      "step: 4083.0, loss:0.25735667\n",
      "step: 4084.0, loss:0.27170877\n",
      "step: 4085.0, loss:0.30215300\n",
      "step: 4086.0, loss:0.40091807\n",
      "step: 4087.0, loss:0.24459079\n",
      "step: 4088.0, loss:0.23495266\n",
      "step: 4089.0, loss:0.20116763\n",
      "step: 4090.0, loss:0.26285869\n",
      "step: 4091.0, loss:0.29464010\n",
      "step: 4092.0, loss:0.33868060\n",
      "step: 4093.0, loss:0.18744507\n",
      "step: 4094.0, loss:0.26287048\n",
      "step: 4095.0, loss:0.32291488\n",
      "step: 4096.0, loss:0.24687662\n",
      "step: 4097.0, loss:0.20836093\n",
      "step: 4098.0, loss:0.25295016\n",
      "step: 4099.0, loss:0.28288456\n",
      "step: 4100.0, loss:0.33760460\n",
      "step: 4101.0, loss:0.34049895\n",
      "step: 4102.0, loss:0.41287378\n",
      "step: 4103.0, loss:0.36104022\n",
      "step: 4104.0, loss:0.29919218\n",
      "step: 4105.0, loss:0.19886680\n",
      "step: 4106.0, loss:0.49422094\n",
      "step: 4107.0, loss:0.32726644\n",
      "step: 4108.0, loss:0.30164358\n",
      "step: 4109.0, loss:0.27757301\n",
      "step: 4110.0, loss:0.26005596\n",
      "step: 4111.0, loss:0.34574917\n",
      "step: 4112.0, loss:0.23468247\n",
      "step: 4113.0, loss:0.33567656\n",
      "step: 4114.0, loss:0.24404891\n",
      "step: 4115.0, loss:0.25485494\n",
      "step: 4116.0, loss:0.23074036\n",
      "step: 4117.0, loss:0.20054457\n",
      "step: 4118.0, loss:0.26579728\n",
      "step: 4119.0, loss:0.31473650\n",
      "step: 4120.0, loss:0.40213306\n",
      "step: 4121.0, loss:0.30348066\n",
      "step: 4122.0, loss:0.26394755\n",
      "step: 4123.0, loss:0.25468174\n",
      "step: 4124.0, loss:0.26979517\n",
      "step: 4125.0, loss:0.21432667\n",
      "step: 4126.0, loss:0.36897638\n",
      "step: 4127.0, loss:0.39571372\n",
      "step: 4128.0, loss:0.22030348\n",
      "step: 4129.0, loss:0.32760502\n",
      "step: 4130.0, loss:0.45121522\n",
      "step: 4131.0, loss:0.46214893\n",
      "step: 4132.0, loss:0.32992611\n",
      "step: 4133.0, loss:0.18426186\n",
      "step: 4134.0, loss:0.30260654\n",
      "step: 4135.0, loss:0.20764884\n",
      "step: 4136.0, loss:0.44508038\n",
      "step: 4137.0, loss:0.37919670\n",
      "step: 4138.0, loss:0.35178084\n",
      "step: 4139.0, loss:0.30596229\n",
      "step: 4140.0, loss:0.31795236\n",
      "step: 4141.0, loss:0.32875339\n",
      "step: 4142.0, loss:0.32402287\n",
      "step: 4143.0, loss:0.17051479\n",
      "step: 4144.0, loss:0.31722677\n",
      "step: 4145.0, loss:0.32447344\n",
      "step: 4146.0, loss:0.34439743\n",
      "step: 4147.0, loss:0.30256701\n",
      "step: 4148.0, loss:0.30742467\n",
      "step: 4149.0, loss:0.27381287\n",
      "step: 4150.0, loss:0.36076059\n",
      "step: 4151.0, loss:0.33972237\n",
      "step: 4152.0, loss:0.33367810\n",
      "step: 4153.0, loss:0.31306188\n",
      "step: 4154.0, loss:0.22552617\n",
      "step: 4155.0, loss:0.30685692\n",
      "step: 4156.0, loss:0.31367476\n",
      "step: 4157.0, loss:0.35197840\n",
      "step: 4158.0, loss:0.44083975\n",
      "step: 4159.0, loss:0.27409227\n",
      "step: 4160.0, loss:0.36526390\n",
      "step: 4161.0, loss:0.28533614\n",
      "step: 4162.0, loss:0.25529061\n",
      "step: 4163.0, loss:0.40625829\n",
      "step: 4164.0, loss:0.27109319\n",
      "step: 4165.0, loss:0.32160871\n",
      "step: 4166.0, loss:0.28631255\n",
      "step: 4167.0, loss:0.33537935\n",
      "step: 4168.0, loss:0.23905130\n",
      "step: 4169.0, loss:0.33737025\n",
      "step: 4170.0, loss:0.23611776\n",
      "step: 4171.0, loss:0.37010186\n",
      "step: 4172.0, loss:0.41073734\n",
      "step: 4173.0, loss:0.40575222\n",
      "step: 4174.0, loss:0.38081223\n",
      "step: 4175.0, loss:0.40401153\n",
      "step: 4176.0, loss:0.26940666\n",
      "step: 4177.0, loss:0.34534822\n",
      "step: 4178.0, loss:0.44027274\n",
      "step: 4179.0, loss:0.24306378\n",
      "step: 4180.0, loss:0.32477933\n",
      "step: 4181.0, loss:0.33388685\n",
      "step: 4182.0, loss:0.31952035\n",
      "step: 4183.0, loss:0.39286760\n",
      "step: 4184.0, loss:0.32804869\n",
      "step: 4185.0, loss:0.30701278\n",
      "step: 4186.0, loss:0.32518225\n",
      "step: 4187.0, loss:0.31838159\n",
      "step: 4188.0, loss:0.36069911\n",
      "step: 4189.0, loss:0.22221038\n",
      "step: 4190.0, loss:0.26966374\n",
      "step: 4191.0, loss:0.23335429\n",
      "step: 4192.0, loss:0.26208670\n",
      "step: 4193.0, loss:0.34059265\n",
      "step: 4194.0, loss:0.26441197\n",
      "step: 4195.0, loss:0.38453715\n",
      "step: 4196.0, loss:0.22464682\n",
      "step: 4197.0, loss:0.29104615\n",
      "step: 4198.0, loss:0.22282976\n",
      "step: 4199.0, loss:0.29883911\n",
      "step: 4200.0, loss:0.26384234\n",
      "step: 4201.0, loss:0.30567038\n",
      "step: 4202.0, loss:0.18867041\n",
      "step: 4203.0, loss:0.29693914\n",
      "step: 4204.0, loss:0.22952658\n",
      "step: 4205.0, loss:0.26926870\n",
      "step: 4206.0, loss:0.23154446\n",
      "step: 4207.0, loss:0.33316536\n",
      "step: 4208.0, loss:0.32951122\n",
      "step: 4209.0, loss:0.37431824\n",
      "step: 4210.0, loss:0.43677498\n",
      "step: 4211.0, loss:0.42243029\n",
      "step: 4212.0, loss:0.35188140\n",
      "step: 4213.0, loss:0.35146260\n",
      "step: 4214.0, loss:0.26796566\n",
      "step: 4215.0, loss:0.38365787\n",
      "step: 4216.0, loss:0.21069704\n",
      "step: 4217.0, loss:0.21930023\n",
      "step: 4218.0, loss:0.26305617\n",
      "step: 4219.0, loss:0.29390889\n",
      "step: 4220.0, loss:0.25258790\n",
      "step: 4221.0, loss:0.31715608\n",
      "step: 4222.0, loss:0.32779798\n",
      "step: 4223.0, loss:0.24597521\n",
      "step: 4224.0, loss:0.45668828\n",
      "step: 4225.0, loss:0.31124599\n",
      "step: 4226.0, loss:0.38145223\n",
      "step: 4227.0, loss:0.28127718\n",
      "step: 4228.0, loss:0.36883627\n",
      "step: 4229.0, loss:0.25667858\n",
      "step: 4230.0, loss:0.47849315\n",
      "step: 4231.0, loss:0.23286790\n",
      "step: 4232.0, loss:0.34978174\n",
      "step: 4233.0, loss:0.26498201\n",
      "step: 4234.0, loss:0.40906931\n",
      "step: 4235.0, loss:0.26904983\n",
      "step: 4236.0, loss:0.24810616\n",
      "step: 4237.0, loss:0.32405068\n",
      "step: 4238.0, loss:0.30735628\n",
      "step: 4239.0, loss:0.28142069\n",
      "step: 4240.0, loss:0.26161962\n",
      "step: 4241.0, loss:0.22368048\n",
      "step: 4242.0, loss:0.22830474\n",
      "step: 4243.0, loss:0.24800997\n",
      "step: 4244.0, loss:0.28091336\n",
      "step: 4245.0, loss:0.28939086\n",
      "step: 4246.0, loss:0.20587981\n",
      "step: 4247.0, loss:0.35661260\n",
      "step: 4248.0, loss:0.23335581\n",
      "step: 4249.0, loss:0.20998784\n",
      "step: 4250.0, loss:0.28783072\n",
      "step: 4251.0, loss:0.24675723\n",
      "step: 4252.0, loss:0.43784991\n",
      "step: 4253.0, loss:0.22977817\n",
      "step: 4254.0, loss:0.23755486\n",
      "step: 4255.0, loss:0.31516120\n",
      "step: 4256.0, loss:0.32865806\n",
      "step: 4257.0, loss:0.31299888\n",
      "step: 4258.0, loss:0.31127011\n",
      "step: 4259.0, loss:0.31349754\n",
      "step: 4260.0, loss:0.30829594\n",
      "step: 4261.0, loss:0.29647196\n",
      "step: 4262.0, loss:0.34051990\n",
      "step: 4263.0, loss:0.40486200\n",
      "step: 4264.0, loss:0.28515496\n",
      "step: 4265.0, loss:0.33708817\n",
      "step: 4266.0, loss:0.26776940\n",
      "step: 4267.0, loss:0.30362659\n",
      "step: 4268.0, loss:0.23142049\n",
      "step: 4269.0, loss:0.27398816\n",
      "step: 4270.0, loss:0.31290485\n",
      "step: 4271.0, loss:0.33624416\n",
      "step: 4272.0, loss:0.21633459\n",
      "step: 4273.0, loss:0.27080512\n",
      "step: 4274.0, loss:0.38789862\n",
      "step: 4275.0, loss:0.19645661\n",
      "step: 4276.0, loss:0.35493856\n",
      "step: 4277.0, loss:0.28726105\n",
      "step: 4278.0, loss:0.30044329\n",
      "step: 4279.0, loss:0.32795512\n",
      "step: 4280.0, loss:0.31395907\n",
      "step: 4281.0, loss:0.29189182\n",
      "step: 4282.0, loss:0.35444315\n",
      "step: 4283.0, loss:0.28843753\n",
      "step: 4284.0, loss:0.41360580\n",
      "step: 4285.0, loss:0.18278325\n",
      "step: 4286.0, loss:0.30090815\n",
      "step: 4287.0, loss:0.28369219\n",
      "step: 4288.0, loss:0.31004605\n",
      "step: 4289.0, loss:0.32143340\n",
      "step: 4290.0, loss:0.25767849\n",
      "step: 4291.0, loss:0.40342804\n",
      "step: 4292.0, loss:0.24814230\n",
      "step: 4293.0, loss:0.20365522\n",
      "step: 4294.0, loss:0.22765481\n",
      "step: 4295.0, loss:0.29032423\n",
      "step: 4296.0, loss:0.27020300\n",
      "step: 4297.0, loss:0.28444149\n",
      "step: 4298.0, loss:0.23099083\n",
      "step: 4299.0, loss:0.29691472\n",
      "step: 4300.0, loss:0.35610014\n",
      "step: 4301.0, loss:0.34877817\n",
      "step: 4302.0, loss:0.21715802\n",
      "step: 4303.0, loss:0.26700295\n",
      "step: 4304.0, loss:0.29828918\n",
      "step: 4305.0, loss:0.29416432\n",
      "step: 4306.0, loss:0.36778712\n",
      "step: 4307.0, loss:0.30607833\n",
      "step: 4308.0, loss:0.39857695\n",
      "step: 4309.0, loss:0.36368858\n",
      "step: 4310.0, loss:0.28982158\n",
      "step: 4311.0, loss:0.28787754\n",
      "step: 4312.0, loss:0.21957393\n",
      "step: 4313.0, loss:0.37475937\n",
      "step: 4314.0, loss:0.46160734\n",
      "step: 4315.0, loss:0.30859626\n",
      "step: 4316.0, loss:0.35834519\n",
      "step: 4317.0, loss:0.29878205\n",
      "step: 4318.0, loss:0.33369699\n",
      "step: 4319.0, loss:0.35561283\n",
      "step: 4320.0, loss:0.34653611\n",
      "step: 4321.0, loss:0.26148502\n",
      "step: 4322.0, loss:0.25208456\n",
      "step: 4323.0, loss:0.26601207\n",
      "step: 4324.0, loss:0.27200732\n",
      "step: 4325.0, loss:0.27922847\n",
      "step: 4326.0, loss:0.31817822\n",
      "step: 4327.0, loss:0.39639533\n",
      "step: 4328.0, loss:0.25472315\n",
      "step: 4329.0, loss:0.38865716\n",
      "step: 4330.0, loss:0.31814056\n",
      "step: 4331.0, loss:0.31367492\n",
      "step: 4332.0, loss:0.19953702\n",
      "step: 4333.0, loss:0.41520553\n",
      "step: 4334.0, loss:0.25027168\n",
      "step: 4335.0, loss:0.24517792\n",
      "step: 4336.0, loss:0.29396467\n",
      "step: 4337.0, loss:0.38214299\n",
      "step: 4338.0, loss:0.23963263\n",
      "step: 4339.0, loss:0.31033418\n",
      "step: 4340.0, loss:0.30813062\n",
      "step: 4341.0, loss:0.26191817\n",
      "step: 4342.0, loss:0.20985883\n",
      "step: 4343.0, loss:0.39862134\n",
      "step: 4344.0, loss:0.22503789\n",
      "step: 4345.0, loss:0.28945003\n",
      "step: 4346.0, loss:0.34607154\n",
      "step: 4347.0, loss:0.26335021\n",
      "step: 4348.0, loss:0.29973787\n",
      "step: 4349.0, loss:0.29559427\n",
      "step: 4350.0, loss:0.28308383\n",
      "step: 4351.0, loss:0.26649779\n",
      "step: 4352.0, loss:0.30802546\n",
      "step: 4353.0, loss:0.25454591\n",
      "step: 4354.0, loss:0.28303937\n",
      "step: 4355.0, loss:0.24359679\n",
      "step: 4356.0, loss:0.30164779\n",
      "step: 4357.0, loss:0.27026556\n",
      "step: 4358.0, loss:0.29921706\n",
      "step: 4359.0, loss:0.27947627\n",
      "step: 4360.0, loss:0.34566506\n",
      "step: 4361.0, loss:0.38590540\n",
      "step: 4362.0, loss:0.35588658\n",
      "step: 4363.0, loss:0.32437866\n",
      "step: 4364.0, loss:0.20419058\n",
      "step: 4365.0, loss:0.30070405\n",
      "step: 4366.0, loss:0.20358830\n",
      "step: 4367.0, loss:0.32352166\n",
      "step: 4368.0, loss:0.37195684\n",
      "step: 4369.0, loss:0.29299675\n",
      "step: 4370.0, loss:0.36828723\n",
      "step: 4371.0, loss:0.28632629\n",
      "step: 4372.0, loss:0.29262910\n",
      "step: 4373.0, loss:0.22165188\n",
      "step: 4374.0, loss:0.32388720\n",
      "step: 4375.0, loss:0.20401544\n",
      "step: 4376.0, loss:0.29253389\n",
      "step: 4377.0, loss:0.37456715\n",
      "step: 4378.0, loss:0.15119582\n",
      "step: 4379.0, loss:0.25847093\n",
      "step: 4380.0, loss:0.35301291\n",
      "step: 4381.0, loss:0.22245695\n",
      "step: 4382.0, loss:0.44788796\n",
      "step: 4383.0, loss:0.27939621\n",
      "step: 4384.0, loss:0.33920007\n",
      "step: 4385.0, loss:0.42270883\n",
      "step: 4386.0, loss:0.36862189\n",
      "step: 4387.0, loss:0.29439420\n",
      "step: 4388.0, loss:0.37865034\n",
      "step: 4389.0, loss:0.15759344\n",
      "step: 4390.0, loss:0.21810447\n",
      "step: 4391.0, loss:0.28792848\n",
      "step: 4392.0, loss:0.25221664\n",
      "step: 4393.0, loss:0.24823255\n",
      "step: 4394.0, loss:0.32378983\n",
      "step: 4395.0, loss:0.30463140\n",
      "step: 4396.0, loss:0.19403388\n",
      "step: 4397.0, loss:0.27065108\n",
      "step: 4398.0, loss:0.25308622\n",
      "step: 4399.0, loss:0.30286185\n",
      "step: 4400.0, loss:0.37808942\n",
      "step: 4401.0, loss:0.24206305\n",
      "step: 4402.0, loss:0.44545415\n",
      "step: 4403.0, loss:0.23490036\n",
      "step: 4404.0, loss:0.31336946\n",
      "step: 4405.0, loss:0.26823771\n",
      "step: 4406.0, loss:0.17608237\n",
      "step: 4407.0, loss:0.45117046\n",
      "step: 4408.0, loss:0.29390598\n",
      "step: 4409.0, loss:0.20581082\n",
      "step: 4410.0, loss:0.22573148\n",
      "step: 4411.0, loss:0.29510446\n",
      "step: 4412.0, loss:0.23916599\n",
      "step: 4413.0, loss:0.39219484\n",
      "step: 4414.0, loss:0.19248544\n",
      "step: 4415.0, loss:0.40616510\n",
      "step: 4416.0, loss:0.35640856\n",
      "step: 4417.0, loss:0.33975948\n",
      "step: 4418.0, loss:0.21890470\n",
      "step: 4419.0, loss:0.20364733\n",
      "step: 4420.0, loss:0.39020250\n",
      "step: 4421.0, loss:0.41744711\n",
      "step: 4422.0, loss:0.37559982\n",
      "step: 4423.0, loss:0.26384723\n",
      "step: 4424.0, loss:0.32979278\n",
      "step: 4425.0, loss:0.20284875\n",
      "step: 4426.0, loss:0.40912128\n",
      "step: 4427.0, loss:0.28522070\n",
      "step: 4428.0, loss:0.35335166\n",
      "step: 4429.0, loss:0.49824490\n",
      "step: 4430.0, loss:0.36988448\n",
      "step: 4431.0, loss:0.31972855\n",
      "step: 4432.0, loss:0.21903425\n",
      "step: 4433.0, loss:0.26843461\n",
      "step: 4434.0, loss:0.25022656\n",
      "step: 4435.0, loss:0.15743037\n",
      "step: 4436.0, loss:0.33117317\n",
      "step: 4437.0, loss:0.28057518\n",
      "step: 4438.0, loss:0.36627260\n",
      "step: 4439.0, loss:0.22201343\n",
      "step: 4440.0, loss:0.24370804\n",
      "step: 4441.0, loss:0.26567196\n",
      "step: 4442.0, loss:0.29629160\n",
      "step: 4443.0, loss:0.30266655\n",
      "step: 4444.0, loss:0.27572301\n",
      "step: 4445.0, loss:0.22690509\n",
      "step: 4446.0, loss:0.19903629\n",
      "step: 4447.0, loss:0.28733917\n",
      "step: 4448.0, loss:0.44278245\n",
      "step: 4449.0, loss:0.22902082\n",
      "step: 4450.0, loss:0.26125756\n",
      "step: 4451.0, loss:0.22626268\n",
      "step: 4452.0, loss:0.24314936\n",
      "step: 4453.0, loss:0.27885501\n",
      "step: 4454.0, loss:0.37582692\n",
      "step: 4455.0, loss:0.34087169\n",
      "step: 4456.0, loss:0.28054643\n",
      "step: 4457.0, loss:0.38064567\n",
      "step: 4458.0, loss:0.28400549\n",
      "step: 4459.0, loss:0.28003317\n",
      "step: 4460.0, loss:0.36091348\n",
      "step: 4461.0, loss:0.26921685\n",
      "step: 4462.0, loss:0.33500230\n",
      "step: 4463.0, loss:0.20968556\n",
      "step: 4464.0, loss:0.35665505\n",
      "step: 4465.0, loss:0.16435230\n",
      "step: 4466.0, loss:0.34371588\n",
      "step: 4467.0, loss:0.15859940\n",
      "step: 4468.0, loss:0.35096619\n",
      "step: 4469.0, loss:0.26864759\n",
      "step: 4470.0, loss:0.27492670\n",
      "step: 4471.0, loss:0.27167574\n",
      "step: 4472.0, loss:0.44852696\n",
      "step: 4473.0, loss:0.32286286\n",
      "step: 4474.0, loss:0.37836318\n",
      "step: 4475.0, loss:0.27166589\n",
      "step: 4476.0, loss:0.35082106\n",
      "step: 4477.0, loss:0.22734950\n",
      "step: 4478.0, loss:0.29135771\n",
      "step: 4479.0, loss:0.33163278\n",
      "step: 4480.0, loss:0.37319981\n",
      "step: 4481.0, loss:0.30964538\n",
      "step: 4482.0, loss:0.32811916\n",
      "step: 4483.0, loss:0.34762414\n",
      "step: 4484.0, loss:0.36379443\n",
      "step: 4485.0, loss:0.27379290\n",
      "step: 4486.0, loss:0.24831483\n",
      "step: 4487.0, loss:0.23807443\n",
      "step: 4488.0, loss:0.32508656\n",
      "step: 4489.0, loss:0.19879775\n",
      "step: 4490.0, loss:0.41376895\n",
      "step: 4491.0, loss:0.32026455\n",
      "step: 4492.0, loss:0.37135418\n",
      "step: 4493.0, loss:0.29375729\n",
      "step: 4494.0, loss:0.36561730\n",
      "step: 4495.0, loss:0.34081757\n",
      "step: 4496.0, loss:0.23663857\n",
      "step: 4497.0, loss:0.36482176\n",
      "step: 4498.0, loss:0.32304572\n",
      "step: 4499.0, loss:0.19367938\n",
      "step: 4500.0, loss:0.16052405\n",
      "step: 4501.0, loss:0.26971957\n",
      "step: 4502.0, loss:0.22749584\n",
      "step: 4503.0, loss:0.14612945\n",
      "step: 4504.0, loss:0.26951232\n",
      "step: 4505.0, loss:0.25820284\n",
      "step: 4506.0, loss:0.21930799\n",
      "step: 4507.0, loss:0.38310144\n",
      "step: 4508.0, loss:0.31733294\n",
      "step: 4509.0, loss:0.30092778\n",
      "step: 4510.0, loss:0.35687195\n",
      "step: 4511.0, loss:0.27168962\n",
      "step: 4512.0, loss:0.35180661\n",
      "step: 4513.0, loss:0.30396230\n",
      "step: 4514.0, loss:0.35698610\n",
      "step: 4515.0, loss:0.24352246\n",
      "step: 4516.0, loss:0.22280508\n",
      "step: 4517.0, loss:0.36396179\n",
      "step: 4518.0, loss:0.36430732\n",
      "step: 4519.0, loss:0.29620318\n",
      "step: 4520.0, loss:0.29836755\n",
      "step: 4521.0, loss:0.17403786\n",
      "step: 4522.0, loss:0.32229067\n",
      "step: 4523.0, loss:0.30292120\n",
      "step: 4524.0, loss:0.26803375\n",
      "step: 4525.0, loss:0.31152667\n",
      "step: 4526.0, loss:0.24707436\n",
      "step: 4527.0, loss:0.31818217\n",
      "step: 4528.0, loss:0.23674672\n",
      "step: 4529.0, loss:0.28246265\n",
      "step: 4530.0, loss:0.23277025\n",
      "step: 4531.0, loss:0.26008516\n",
      "step: 4532.0, loss:0.18805528\n",
      "step: 4533.0, loss:0.34889178\n",
      "step: 4534.0, loss:0.29223842\n",
      "step: 4535.0, loss:0.28228766\n",
      "step: 4536.0, loss:0.28820312\n",
      "step: 4537.0, loss:0.28244474\n",
      "step: 4538.0, loss:0.36481929\n",
      "step: 4539.0, loss:0.34747712\n",
      "step: 4540.0, loss:0.43351237\n",
      "step: 4541.0, loss:0.21918399\n",
      "step: 4542.0, loss:0.39710833\n",
      "step: 4543.0, loss:0.40929034\n",
      "step: 4544.0, loss:0.28064789\n",
      "step: 4545.0, loss:0.29242947\n",
      "step: 4546.0, loss:0.32074727\n",
      "step: 4547.0, loss:0.37452681\n",
      "step: 4548.0, loss:0.21279755\n",
      "step: 4549.0, loss:0.29499307\n",
      "step: 4550.0, loss:0.32666184\n",
      "step: 4551.0, loss:0.38248594\n",
      "step: 4552.0, loss:0.31010602\n",
      "step: 4553.0, loss:0.33230473\n",
      "step: 4554.0, loss:0.33248773\n",
      "step: 4555.0, loss:0.35351083\n",
      "step: 4556.0, loss:0.28994483\n",
      "step: 4557.0, loss:0.45650549\n",
      "step: 4558.0, loss:0.33088306\n",
      "step: 4559.0, loss:0.36856253\n",
      "step: 4560.0, loss:0.24682617\n",
      "step: 4561.0, loss:0.18346389\n",
      "step: 4562.0, loss:0.35060434\n",
      "step: 4563.0, loss:0.28175981\n",
      "step: 4564.0, loss:0.39200369\n",
      "step: 4565.0, loss:0.26108152\n",
      "step: 4566.0, loss:0.24169083\n",
      "step: 4567.0, loss:0.18220115\n",
      "step: 4568.0, loss:0.41040494\n",
      "step: 4569.0, loss:0.31112670\n",
      "step: 4570.0, loss:0.32606212\n",
      "step: 4571.0, loss:0.27514448\n",
      "step: 4572.0, loss:0.16738045\n",
      "step: 4573.0, loss:0.21207469\n",
      "step: 4574.0, loss:0.39382021\n",
      "step: 4575.0, loss:0.25523345\n",
      "step: 4576.0, loss:0.51773871\n",
      "step: 4577.0, loss:0.28504633\n",
      "step: 4578.0, loss:0.29332617\n",
      "step: 4579.0, loss:0.25687322\n",
      "step: 4580.0, loss:0.36120709\n",
      "step: 4581.0, loss:0.34411763\n",
      "step: 4582.0, loss:0.47228272\n",
      "step: 4583.0, loss:0.30193567\n",
      "step: 4584.0, loss:0.25914319\n",
      "step: 4585.0, loss:0.39053807\n",
      "step: 4586.0, loss:0.25824540\n",
      "step: 4587.0, loss:0.37312321\n",
      "step: 4588.0, loss:0.36099302\n",
      "step: 4589.0, loss:0.30032804\n",
      "step: 4590.0, loss:0.23370756\n",
      "step: 4591.0, loss:0.24100925\n",
      "step: 4592.0, loss:0.20948154\n",
      "step: 4593.0, loss:0.27489135\n",
      "step: 4594.0, loss:0.29195742\n",
      "step: 4595.0, loss:0.24539209\n",
      "step: 4596.0, loss:0.31125793\n",
      "step: 4597.0, loss:0.19064036\n",
      "step: 4598.0, loss:0.28718144\n",
      "step: 4599.0, loss:0.40355541\n",
      "step: 4600.0, loss:0.37872989\n",
      "step: 4601.0, loss:0.33195158\n",
      "step: 4602.0, loss:0.33753285\n",
      "step: 4603.0, loss:0.26030159\n",
      "step: 4604.0, loss:0.26367775\n",
      "step: 4605.0, loss:0.28105866\n",
      "step: 4606.0, loss:0.29404707\n",
      "step: 4607.0, loss:0.33823786\n",
      "step: 4608.0, loss:0.39886546\n",
      "step: 4609.0, loss:0.31030797\n",
      "step: 4610.0, loss:0.18749511\n",
      "step: 4611.0, loss:0.31804606\n",
      "step: 4612.0, loss:0.23605518\n",
      "step: 4613.0, loss:0.28643269\n",
      "step: 4614.0, loss:0.29163089\n",
      "step: 4615.0, loss:0.29106705\n",
      "step: 4616.0, loss:0.24029245\n",
      "step: 4617.0, loss:0.37015843\n",
      "step: 4618.0, loss:0.36169308\n",
      "step: 4619.0, loss:0.32920448\n",
      "step: 4620.0, loss:0.29595351\n",
      "step: 4621.0, loss:0.32060109\n",
      "step: 4622.0, loss:0.29837377\n",
      "step: 4623.0, loss:0.33174162\n",
      "step: 4624.0, loss:0.37591271\n",
      "step: 4625.0, loss:0.33238007\n",
      "step: 4626.0, loss:0.35551001\n",
      "step: 4627.0, loss:0.29006612\n",
      "step: 4628.0, loss:0.24989442\n",
      "step: 4629.0, loss:0.21667741\n",
      "step: 4630.0, loss:0.26941308\n",
      "step: 4631.0, loss:0.32642831\n",
      "step: 4632.0, loss:0.41346687\n",
      "step: 4633.0, loss:0.28733751\n",
      "step: 4634.0, loss:0.26628498\n",
      "step: 4635.0, loss:0.27991093\n",
      "step: 4636.0, loss:0.26580816\n",
      "step: 4637.0, loss:0.25364279\n",
      "step: 4638.0, loss:0.34039518\n",
      "step: 4639.0, loss:0.15650481\n",
      "step: 4640.0, loss:0.29466826\n",
      "step: 4641.0, loss:0.47706293\n",
      "step: 4642.0, loss:0.23055554\n",
      "step: 4643.0, loss:0.26636955\n",
      "step: 4644.0, loss:0.28739797\n",
      "step: 4645.0, loss:0.35120778\n",
      "step: 4646.0, loss:0.42234251\n",
      "step: 4647.0, loss:0.23547539\n",
      "step: 4648.0, loss:0.33205008\n",
      "step: 4649.0, loss:0.43922469\n",
      "step: 4650.0, loss:0.22761319\n",
      "step: 4651.0, loss:0.21014912\n",
      "step: 4652.0, loss:0.36969146\n",
      "step: 4653.0, loss:0.27674058\n",
      "step: 4654.0, loss:0.28402576\n",
      "step: 4655.0, loss:0.43406159\n",
      "step: 4656.0, loss:0.54344571\n",
      "step: 4657.0, loss:0.19450851\n",
      "step: 4658.0, loss:0.31510213\n",
      "step: 4659.0, loss:0.30716185\n",
      "step: 4660.0, loss:0.31600214\n",
      "step: 4661.0, loss:0.31721024\n",
      "step: 4662.0, loss:0.18125333\n",
      "step: 4663.0, loss:0.27837797\n",
      "step: 4664.0, loss:0.26353488\n",
      "step: 4665.0, loss:0.28586633\n",
      "step: 4666.0, loss:0.23426750\n",
      "step: 4667.0, loss:0.27653831\n",
      "step: 4668.0, loss:0.30514710\n",
      "step: 4669.0, loss:0.18076806\n",
      "step: 4670.0, loss:0.33282994\n",
      "step: 4671.0, loss:0.36123456\n",
      "step: 4672.0, loss:0.22300366\n",
      "step: 4673.0, loss:0.37434767\n",
      "step: 4674.0, loss:0.41400448\n",
      "step: 4675.0, loss:0.23063578\n",
      "step: 4676.0, loss:0.24650140\n",
      "step: 4677.0, loss:0.34092743\n",
      "step: 4678.0, loss:0.24546256\n",
      "step: 4679.0, loss:0.26885434\n",
      "step: 4680.0, loss:0.26052056\n",
      "step: 4681.0, loss:0.34991141\n",
      "step: 4682.0, loss:0.25806356\n",
      "step: 4683.0, loss:0.23570405\n",
      "step: 4684.0, loss:0.29087808\n",
      "step: 4685.0, loss:0.25010130\n",
      "step: 4686.0, loss:0.29586012\n",
      "step: 4687.0, loss:0.34029466\n",
      "step: 4688.0, loss:0.23425290\n",
      "step: 4689.0, loss:0.31862896\n",
      "step: 4690.0, loss:0.35464736\n",
      "step: 4691.0, loss:0.31835938\n",
      "step: 4692.0, loss:0.29769147\n",
      "step: 4693.0, loss:0.29394552\n",
      "step: 4694.0, loss:0.34466916\n",
      "step: 4695.0, loss:0.26169627\n",
      "step: 4696.0, loss:0.32521171\n",
      "step: 4697.0, loss:0.24336318\n",
      "step: 4698.0, loss:0.32870274\n",
      "step: 4699.0, loss:0.33537208\n",
      "step: 4700.0, loss:0.28557722\n",
      "step: 4701.0, loss:0.34862609\n",
      "step: 4702.0, loss:0.32659002\n",
      "step: 4703.0, loss:0.37255052\n",
      "step: 4704.0, loss:0.11611570\n",
      "step: 4705.0, loss:0.31560936\n",
      "step: 4706.0, loss:0.28510057\n",
      "step: 4707.0, loss:0.28685752\n",
      "step: 4708.0, loss:0.29025235\n",
      "step: 4709.0, loss:0.34469732\n",
      "step: 4710.0, loss:0.33357257\n",
      "step: 4711.0, loss:0.34207920\n",
      "step: 4712.0, loss:0.27942828\n",
      "step: 4713.0, loss:0.38458923\n",
      "step: 4714.0, loss:0.30810405\n",
      "step: 4715.0, loss:0.39290800\n",
      "step: 4716.0, loss:0.25552237\n",
      "step: 4717.0, loss:0.29236838\n",
      "step: 4718.0, loss:0.29493676\n",
      "step: 4719.0, loss:0.44640389\n",
      "step: 4720.0, loss:0.34357075\n",
      "step: 4721.0, loss:0.37887729\n",
      "step: 4722.0, loss:0.33032713\n",
      "step: 4723.0, loss:0.33631241\n",
      "step: 4724.0, loss:0.24548820\n",
      "step: 4725.0, loss:0.31812254\n",
      "step: 4726.0, loss:0.33875470\n",
      "step: 4727.0, loss:0.27887918\n",
      "step: 4728.0, loss:0.24259642\n",
      "step: 4729.0, loss:0.37802792\n",
      "step: 4730.0, loss:0.36472296\n",
      "step: 4731.0, loss:0.31427266\n",
      "step: 4732.0, loss:0.34443566\n",
      "step: 4733.0, loss:0.35110462\n",
      "step: 4734.0, loss:0.29283838\n",
      "step: 4735.0, loss:0.27363161\n",
      "step: 4736.0, loss:0.29150710\n",
      "step: 4737.0, loss:0.27917567\n",
      "step: 4738.0, loss:0.30560354\n",
      "step: 4739.0, loss:0.26455292\n",
      "step: 4740.0, loss:0.34141788\n",
      "step: 4741.0, loss:0.22784768\n",
      "step: 4742.0, loss:0.25617832\n",
      "step: 4743.0, loss:0.25490703\n",
      "step: 4744.0, loss:0.29791667\n",
      "step: 4745.0, loss:0.28019301\n",
      "step: 4746.0, loss:0.26209977\n",
      "step: 4747.0, loss:0.25934443\n",
      "step: 4748.0, loss:0.21212313\n",
      "step: 4749.0, loss:0.12932760\n",
      "step: 4750.0, loss:0.17348909\n",
      "step: 4751.0, loss:0.18702269\n",
      "step: 4752.0, loss:0.41824937\n",
      "step: 4753.0, loss:0.38014551\n",
      "step: 4754.0, loss:0.24786626\n",
      "step: 4755.0, loss:0.28235161\n",
      "step: 4756.0, loss:0.37606099\n",
      "step: 4757.0, loss:0.35145149\n",
      "step: 4758.0, loss:0.33331385\n",
      "step: 4759.0, loss:0.22929456\n",
      "step: 4760.0, loss:0.34880164\n",
      "step: 4761.0, loss:0.27151853\n",
      "step: 4762.0, loss:0.32736750\n",
      "step: 4763.0, loss:0.31233658\n",
      "step: 4764.0, loss:0.29515275\n",
      "step: 4765.0, loss:0.31886430\n",
      "step: 4766.0, loss:0.30417233\n",
      "step: 4767.0, loss:0.44434684\n",
      "step: 4768.0, loss:0.27527665\n",
      "step: 4769.0, loss:0.30999438\n",
      "step: 4770.0, loss:0.30373624\n",
      "step: 4771.0, loss:0.30907651\n",
      "step: 4772.0, loss:0.33139634\n",
      "step: 4773.0, loss:0.41937645\n",
      "step: 4774.0, loss:0.31121695\n",
      "step: 4775.0, loss:0.17893067\n",
      "step: 4776.0, loss:0.33024067\n",
      "step: 4777.0, loss:0.32821210\n",
      "step: 4778.0, loss:0.47581483\n",
      "step: 4779.0, loss:0.27396314\n",
      "step: 4780.0, loss:0.23396007\n",
      "step: 4781.0, loss:0.21124319\n",
      "step: 4782.0, loss:0.23094381\n",
      "step: 4783.0, loss:0.25059658\n",
      "step: 4784.0, loss:0.36601659\n",
      "step: 4785.0, loss:0.17127608\n",
      "step: 4786.0, loss:0.22718528\n",
      "step: 4787.0, loss:0.26324203\n",
      "step: 4788.0, loss:0.24809891\n",
      "step: 4789.0, loss:0.52879588\n",
      "step: 4790.0, loss:0.29904647\n",
      "step: 4791.0, loss:0.28125429\n",
      "step: 4792.0, loss:0.23528411\n",
      "step: 4793.0, loss:0.27093798\n",
      "step: 4794.0, loss:0.30586989\n",
      "step: 4795.0, loss:0.15502149\n",
      "step: 4796.0, loss:0.17836154\n",
      "step: 4797.0, loss:0.25970981\n",
      "step: 4798.0, loss:0.34975913\n",
      "step: 4799.0, loss:0.29721064\n",
      "step: 4800.0, loss:0.36612573\n",
      "step: 4801.0, loss:0.23849176\n",
      "step: 4802.0, loss:0.22432042\n",
      "step: 4803.0, loss:0.26574452\n",
      "step: 4804.0, loss:0.26243021\n",
      "step: 4805.0, loss:0.25806971\n",
      "step: 4806.0, loss:0.43938154\n",
      "step: 4807.0, loss:0.27194081\n",
      "step: 4808.0, loss:0.37616706\n",
      "step: 4809.0, loss:0.35719228\n",
      "step: 4810.0, loss:0.18734719\n",
      "step: 4811.0, loss:0.25979589\n",
      "step: 4812.0, loss:0.17396409\n",
      "step: 4813.0, loss:0.34803145\n",
      "step: 4814.0, loss:0.27082759\n",
      "step: 4815.0, loss:0.22614613\n",
      "step: 4816.0, loss:0.22873683\n",
      "step: 4817.0, loss:0.21847656\n",
      "step: 4818.0, loss:0.23315760\n",
      "step: 4819.0, loss:0.28837520\n",
      "step: 4820.0, loss:0.41496061\n",
      "step: 4821.0, loss:0.17703559\n",
      "step: 4822.0, loss:0.38527843\n",
      "step: 4823.0, loss:0.42512567\n",
      "step: 4824.0, loss:0.32164383\n",
      "step: 4825.0, loss:0.28396077\n",
      "step: 4826.0, loss:0.20875588\n",
      "step: 4827.0, loss:0.30922791\n",
      "step: 4828.0, loss:0.27377567\n",
      "step: 4829.0, loss:0.42859849\n",
      "step: 4830.0, loss:0.23533289\n",
      "step: 4831.0, loss:0.28180475\n",
      "step: 4832.0, loss:0.32900818\n",
      "step: 4833.0, loss:0.23971985\n",
      "step: 4834.0, loss:0.32082704\n",
      "step: 4835.0, loss:0.22448298\n",
      "step: 4836.0, loss:0.33045644\n",
      "step: 4837.0, loss:0.36382698\n",
      "step: 4838.0, loss:0.39470375\n",
      "step: 4839.0, loss:0.25415214\n",
      "step: 4840.0, loss:0.28126886\n",
      "step: 4841.0, loss:0.27375006\n",
      "step: 4842.0, loss:0.44468679\n",
      "step: 4843.0, loss:0.21912725\n",
      "step: 4844.0, loss:0.28391256\n",
      "step: 4845.0, loss:0.22795026\n",
      "step: 4846.0, loss:0.33713769\n",
      "step: 4847.0, loss:0.24425449\n",
      "step: 4848.0, loss:0.33011206\n",
      "step: 4849.0, loss:0.19682679\n",
      "step: 4850.0, loss:0.27655355\n",
      "step: 4851.0, loss:0.42358195\n",
      "step: 4852.0, loss:0.26008200\n",
      "step: 4853.0, loss:0.34996033\n",
      "step: 4854.0, loss:0.31553340\n",
      "step: 4855.0, loss:0.33311706\n",
      "step: 4856.0, loss:0.27996371\n",
      "step: 4857.0, loss:0.38814665\n",
      "step: 4858.0, loss:0.27047982\n",
      "step: 4859.0, loss:0.33796740\n",
      "step: 4860.0, loss:0.24129608\n",
      "step: 4861.0, loss:0.23533935\n",
      "step: 4862.0, loss:0.34730743\n",
      "step: 4863.0, loss:0.28938402\n",
      "step: 4864.0, loss:0.23463318\n",
      "step: 4865.0, loss:0.37432000\n",
      "step: 4866.0, loss:0.32352420\n",
      "step: 4867.0, loss:0.28604646\n",
      "step: 4868.0, loss:0.17987314\n",
      "step: 4869.0, loss:0.29465661\n",
      "step: 4870.0, loss:0.24509546\n",
      "step: 4871.0, loss:0.26142542\n",
      "step: 4872.0, loss:0.29592307\n",
      "step: 4873.0, loss:0.32151819\n",
      "step: 4874.0, loss:0.22538435\n",
      "step: 4875.0, loss:0.24344964\n",
      "step: 4876.0, loss:0.28969484\n",
      "step: 4877.0, loss:0.21455958\n",
      "step: 4878.0, loss:0.29022694\n",
      "step: 4879.0, loss:0.25673850\n",
      "step: 4880.0, loss:0.39450398\n",
      "step: 4881.0, loss:0.23284219\n",
      "step: 4882.0, loss:0.26123700\n",
      "step: 4883.0, loss:0.39568669\n",
      "step: 4884.0, loss:0.47901125\n",
      "step: 4885.0, loss:0.38937752\n",
      "step: 4886.0, loss:0.34140087\n",
      "step: 4887.0, loss:0.34795212\n",
      "step: 4888.0, loss:0.40721277\n",
      "step: 4889.0, loss:0.27753533\n",
      "step: 4890.0, loss:0.27197280\n",
      "step: 4891.0, loss:0.43810051\n",
      "step: 4892.0, loss:0.32975498\n",
      "step: 4893.0, loss:0.25201960\n",
      "step: 4894.0, loss:0.33400809\n",
      "step: 4895.0, loss:0.32759630\n",
      "step: 4896.0, loss:0.34075018\n",
      "step: 4897.0, loss:0.35503504\n",
      "step: 4898.0, loss:0.24969660\n",
      "step: 4899.0, loss:0.28195705\n",
      "step: 4900.0, loss:0.31275683\n",
      "step: 4901.0, loss:0.27850007\n",
      "step: 4902.0, loss:0.29645705\n",
      "step: 4903.0, loss:0.28372725\n",
      "step: 4904.0, loss:0.29488948\n",
      "step: 4905.0, loss:0.26125043\n",
      "step: 4906.0, loss:0.20230708\n",
      "step: 4907.0, loss:0.28591263\n",
      "step: 4908.0, loss:0.36150827\n",
      "step: 4909.0, loss:0.31601541\n",
      "step: 4910.0, loss:0.28135229\n",
      "step: 4911.0, loss:0.30323655\n",
      "step: 4912.0, loss:0.41082195\n",
      "step: 4913.0, loss:0.33274259\n",
      "step: 4914.0, loss:0.27286141\n",
      "step: 4915.0, loss:0.24556931\n",
      "step: 4916.0, loss:0.28585131\n",
      "step: 4917.0, loss:0.37674443\n",
      "step: 4918.0, loss:0.18364254\n",
      "step: 4919.0, loss:0.29325464\n",
      "step: 4920.0, loss:0.28939075\n",
      "step: 4921.0, loss:0.25488121\n",
      "step: 4922.0, loss:0.25192390\n",
      "step: 4923.0, loss:0.33142934\n",
      "step: 4924.0, loss:0.31743605\n",
      "step: 4925.0, loss:0.32524668\n",
      "step: 4926.0, loss:0.23007203\n",
      "step: 4927.0, loss:0.25455717\n",
      "step: 4928.0, loss:0.30581043\n",
      "step: 4929.0, loss:0.40173902\n",
      "step: 4930.0, loss:0.30699890\n",
      "step: 4931.0, loss:0.38231169\n",
      "step: 4932.0, loss:0.49567765\n",
      "step: 4933.0, loss:0.34201666\n",
      "step: 4934.0, loss:0.31624347\n",
      "step: 4935.0, loss:0.33575319\n",
      "step: 4936.0, loss:0.21432940\n",
      "step: 4937.0, loss:0.38700023\n",
      "step: 4938.0, loss:0.32877016\n",
      "step: 4939.0, loss:0.26477525\n",
      "step: 4940.0, loss:0.36150625\n",
      "step: 4941.0, loss:0.21911805\n",
      "step: 4942.0, loss:0.28221751\n",
      "step: 4943.0, loss:0.23168905\n",
      "step: 4944.0, loss:0.25504605\n",
      "step: 4945.0, loss:0.30221780\n",
      "step: 4946.0, loss:0.44919328\n",
      "step: 4947.0, loss:0.26304322\n",
      "step: 4948.0, loss:0.24301967\n",
      "step: 4949.0, loss:0.29041085\n",
      "step: 4950.0, loss:0.26062782\n",
      "step: 4951.0, loss:0.33222909\n",
      "step: 4952.0, loss:0.29535623\n",
      "step: 4953.0, loss:0.36315519\n",
      "step: 4954.0, loss:0.31978631\n",
      "step: 4955.0, loss:0.29042773\n",
      "step: 4956.0, loss:0.37386711\n",
      "step: 4957.0, loss:0.39722604\n",
      "step: 4958.0, loss:0.45986583\n",
      "step: 4959.0, loss:0.16289779\n",
      "step: 4960.0, loss:0.28838969\n",
      "step: 4961.0, loss:0.18383198\n",
      "step: 4962.0, loss:0.29032282\n",
      "step: 4963.0, loss:0.22638367\n",
      "step: 4964.0, loss:0.39683004\n",
      "step: 4965.0, loss:0.34354839\n",
      "step: 4966.0, loss:0.27352385\n",
      "step: 4967.0, loss:0.31140862\n",
      "step: 4968.0, loss:0.26203683\n",
      "step: 4969.0, loss:0.34810719\n",
      "step: 4970.0, loss:0.31412482\n",
      "step: 4971.0, loss:0.43000987\n",
      "step: 4972.0, loss:0.25309236\n",
      "step: 4973.0, loss:0.32440087\n",
      "step: 4974.0, loss:0.22758724\n",
      "step: 4975.0, loss:0.21622517\n",
      "step: 4976.0, loss:0.28216314\n",
      "step: 4977.0, loss:0.22004934\n",
      "step: 4978.0, loss:0.30033793\n",
      "step: 4979.0, loss:0.24557773\n",
      "step: 4980.0, loss:0.32686380\n",
      "step: 4981.0, loss:0.32152923\n",
      "step: 4982.0, loss:0.22145794\n",
      "step: 4983.0, loss:0.22978761\n",
      "step: 4984.0, loss:0.41633820\n",
      "step: 4985.0, loss:0.22780078\n",
      "step: 4986.0, loss:0.33319601\n",
      "step: 4987.0, loss:0.25246481\n",
      "step: 4988.0, loss:0.31555565\n",
      "step: 4989.0, loss:0.31720083\n",
      "step: 4990.0, loss:0.25066901\n",
      "step: 4991.0, loss:0.26779926\n",
      "step: 4992.0, loss:0.28197077\n",
      "step: 4993.0, loss:0.22324068\n",
      "step: 4994.0, loss:0.32072745\n",
      "step: 4995.0, loss:0.29231778\n",
      "step: 4996.0, loss:0.32086441\n",
      "step: 4997.0, loss:0.39243298\n",
      "step: 4998.0, loss:0.31042046\n",
      "step: 4999.0, loss:0.26119628\n",
      "step: 5000.0, loss:0.32214831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1264/1264 [07:53<00:00,  2.67it/s]\n",
      "2023-04-02 20:35:36,479 - INFO - step:5000.0, matthews_corr:0.736317, Acc:87.462280%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 5001.0, loss:0.31005418\n",
      "step: 5002.0, loss:0.31446373\n",
      "step: 5003.0, loss:0.27096460\n",
      "step: 5004.0, loss:0.38570298\n",
      "step: 5005.0, loss:0.26062301\n",
      "step: 5006.0, loss:0.27044846\n",
      "step: 5007.0, loss:0.29794778\n",
      "step: 5008.0, loss:0.28831226\n",
      "step: 5009.0, loss:0.23241251\n",
      "step: 5010.0, loss:0.28802507\n",
      "step: 5011.0, loss:0.20629571\n",
      "step: 5012.0, loss:0.30070278\n",
      "step: 5013.0, loss:0.27871390\n",
      "step: 5014.0, loss:0.42065299\n",
      "step: 5015.0, loss:0.27350770\n",
      "step: 5016.0, loss:0.39820496\n",
      "step: 5017.0, loss:0.30198342\n",
      "step: 5018.0, loss:0.35455313\n",
      "step: 5019.0, loss:0.25867632\n",
      "step: 5020.0, loss:0.34352109\n",
      "step: 5021.0, loss:0.24594231\n",
      "step: 5022.0, loss:0.21580513\n",
      "step: 5023.0, loss:0.31966246\n",
      "step: 5024.0, loss:0.29345105\n",
      "step: 5025.0, loss:0.35844401\n",
      "step: 5026.0, loss:0.22855409\n",
      "step: 5027.0, loss:0.25402122\n",
      "step: 5028.0, loss:0.33605894\n",
      "step: 5029.0, loss:0.24628042\n",
      "step: 5030.0, loss:0.23695092\n",
      "step: 5031.0, loss:0.28584333\n",
      "step: 5032.0, loss:0.33518062\n",
      "step: 5033.0, loss:0.34883627\n",
      "step: 5034.0, loss:0.30492125\n",
      "step: 5035.0, loss:0.41653366\n",
      "step: 5036.0, loss:0.29628639\n",
      "step: 5037.0, loss:0.33713046\n",
      "step: 5038.0, loss:0.29934476\n",
      "step: 5039.0, loss:0.24314848\n",
      "step: 5040.0, loss:0.23550927\n",
      "step: 5041.0, loss:0.33435380\n",
      "step: 5042.0, loss:0.29185894\n",
      "step: 5043.0, loss:0.31880969\n",
      "step: 5044.0, loss:0.29371579\n",
      "step: 5045.0, loss:0.21702955\n",
      "step: 5046.0, loss:0.29733095\n",
      "step: 5047.0, loss:0.34575002\n",
      "step: 5048.0, loss:0.21818866\n",
      "step: 5049.0, loss:0.27067683\n",
      "step: 5050.0, loss:0.31977074\n",
      "step: 5051.0, loss:0.41035882\n",
      "step: 5052.0, loss:0.27080873\n",
      "step: 5053.0, loss:0.31122015\n",
      "step: 5054.0, loss:0.34288926\n",
      "step: 5055.0, loss:0.27191221\n",
      "step: 5056.0, loss:0.17946239\n",
      "step: 5057.0, loss:0.26635831\n",
      "step: 5058.0, loss:0.36283802\n",
      "step: 5059.0, loss:0.33628487\n",
      "step: 5060.0, loss:0.31324039\n",
      "step: 5061.0, loss:0.18703649\n",
      "step: 5062.0, loss:0.26434163\n",
      "step: 5063.0, loss:0.30479876\n",
      "step: 5064.0, loss:0.33670396\n",
      "step: 5065.0, loss:0.21471453\n",
      "step: 5066.0, loss:0.37222510\n",
      "step: 5067.0, loss:0.23805651\n",
      "step: 5068.0, loss:0.26934050\n",
      "step: 5069.0, loss:0.34064357\n",
      "step: 5070.0, loss:0.24080035\n",
      "step: 5071.0, loss:0.28443669\n",
      "step: 5072.0, loss:0.31557601\n",
      "step: 5073.0, loss:0.38334843\n",
      "step: 5074.0, loss:0.40083360\n",
      "step: 5075.0, loss:0.32916641\n",
      "step: 5076.0, loss:0.36739357\n",
      "step: 5077.0, loss:0.41149317\n",
      "step: 5078.0, loss:0.35938970\n",
      "step: 5079.0, loss:0.22671032\n",
      "step: 5080.0, loss:0.25906372\n",
      "step: 5081.0, loss:0.22864911\n",
      "step: 5082.0, loss:0.25967487\n",
      "step: 5083.0, loss:0.29179081\n",
      "step: 5084.0, loss:0.21647574\n",
      "step: 5085.0, loss:0.29922369\n",
      "step: 5086.0, loss:0.23930377\n",
      "step: 5087.0, loss:0.29928864\n",
      "step: 5088.0, loss:0.32335515\n",
      "step: 5089.0, loss:0.25954118\n",
      "step: 5090.0, loss:0.23233413\n",
      "step: 5091.0, loss:0.31905462\n",
      "step: 5092.0, loss:0.27607062\n",
      "step: 5093.0, loss:0.26190258\n",
      "step: 5094.0, loss:0.22942840\n",
      "step: 5095.0, loss:0.25389962\n",
      "step: 5096.0, loss:0.23216715\n",
      "step: 5097.0, loss:0.28302116\n",
      "step: 5098.0, loss:0.26241077\n",
      "step: 5099.0, loss:0.23632576\n",
      "step: 5100.0, loss:0.25382119\n",
      "step: 5101.0, loss:0.26662124\n",
      "step: 5102.0, loss:0.29974278\n",
      "step: 5103.0, loss:0.29077572\n",
      "step: 5104.0, loss:0.45156365\n",
      "step: 5105.0, loss:0.35091207\n",
      "step: 5106.0, loss:0.26256538\n",
      "step: 5107.0, loss:0.41410376\n",
      "step: 5108.0, loss:0.22966919\n",
      "step: 5109.0, loss:0.33553534\n",
      "step: 5110.0, loss:0.23634276\n",
      "step: 5111.0, loss:0.37556295\n",
      "step: 5112.0, loss:0.31572961\n",
      "step: 5113.0, loss:0.29143108\n",
      "step: 5114.0, loss:0.29290031\n",
      "step: 5115.0, loss:0.28835986\n",
      "step: 5116.0, loss:0.37110539\n",
      "step: 5117.0, loss:0.31539206\n",
      "step: 5118.0, loss:0.33578775\n",
      "step: 5119.0, loss:0.36352048\n",
      "step: 5120.0, loss:0.11694590\n",
      "step: 5121.0, loss:0.21439471\n",
      "step: 5122.0, loss:0.27241216\n",
      "step: 5123.0, loss:0.23337650\n",
      "step: 5124.0, loss:0.24177087\n",
      "step: 5125.0, loss:0.20919093\n",
      "step: 5126.0, loss:0.32508324\n",
      "step: 5127.0, loss:0.26924279\n",
      "step: 5128.0, loss:0.24392642\n",
      "step: 5129.0, loss:0.21090529\n",
      "step: 5130.0, loss:0.21400916\n",
      "step: 5131.0, loss:0.36306709\n",
      "step: 5132.0, loss:0.29331457\n",
      "step: 5133.0, loss:0.32683931\n",
      "step: 5134.0, loss:0.37500896\n",
      "step: 5135.0, loss:0.24921390\n",
      "step: 5136.0, loss:0.31869458\n",
      "step: 5137.0, loss:0.38094701\n",
      "step: 5138.0, loss:0.33219006\n",
      "step: 5139.0, loss:0.33195732\n",
      "step: 5140.0, loss:0.21573165\n",
      "step: 5141.0, loss:0.17771443\n",
      "step: 5142.0, loss:0.23123943\n",
      "step: 5143.0, loss:0.21906031\n",
      "step: 5144.0, loss:0.19688423\n",
      "step: 5145.0, loss:0.23382279\n",
      "step: 5146.0, loss:0.33274006\n",
      "step: 5147.0, loss:0.38934565\n",
      "step: 5148.0, loss:0.21392267\n",
      "step: 5149.0, loss:0.37985811\n",
      "step: 5150.0, loss:0.27014780\n",
      "step: 5151.0, loss:0.21293011\n",
      "step: 5152.0, loss:0.39745346\n",
      "step: 5153.0, loss:0.27992129\n",
      "step: 5154.0, loss:0.31786909\n",
      "step: 5155.0, loss:0.28051709\n",
      "step: 5156.0, loss:0.21897583\n",
      "step: 5157.0, loss:0.35258564\n",
      "step: 5158.0, loss:0.25398659\n",
      "step: 5159.0, loss:0.22741229\n",
      "step: 5160.0, loss:0.31115255\n",
      "step: 5161.0, loss:0.14451548\n",
      "step: 5162.0, loss:0.30514776\n",
      "step: 5163.0, loss:0.38911562\n",
      "step: 5164.0, loss:0.23284458\n",
      "step: 5165.0, loss:0.30826686\n",
      "step: 5166.0, loss:0.26751036\n",
      "step: 5167.0, loss:0.30679123\n",
      "step: 5168.0, loss:0.19770686\n",
      "step: 5169.0, loss:0.34773336\n",
      "step: 5170.0, loss:0.29287065\n",
      "step: 5171.0, loss:0.23142649\n",
      "step: 5172.0, loss:0.34332896\n",
      "step: 5173.0, loss:0.17714878\n",
      "step: 5174.0, loss:0.18781275\n",
      "step: 5175.0, loss:0.40886196\n",
      "step: 5176.0, loss:0.30983091\n",
      "step: 5177.0, loss:0.21471412\n",
      "step: 5178.0, loss:0.31748354\n",
      "step: 5179.0, loss:0.25128488\n",
      "step: 5180.0, loss:0.17409002\n",
      "step: 5181.0, loss:0.25994074\n",
      "step: 5182.0, loss:0.33083119\n",
      "step: 5183.0, loss:0.40440866\n",
      "step: 5184.0, loss:0.29020267\n",
      "step: 5185.0, loss:0.39840781\n",
      "step: 5186.0, loss:0.26185892\n",
      "step: 5187.0, loss:0.20668855\n",
      "step: 5188.0, loss:0.23106511\n",
      "step: 5189.0, loss:0.22263755\n",
      "step: 5190.0, loss:0.26262100\n",
      "step: 5191.0, loss:0.31117300\n",
      "step: 5192.0, loss:0.31510630\n",
      "step: 5193.0, loss:0.31225070\n",
      "step: 5194.0, loss:0.19449157\n",
      "step: 5195.0, loss:0.30315509\n",
      "step: 5196.0, loss:0.38236175\n",
      "step: 5197.0, loss:0.25029482\n",
      "step: 5198.0, loss:0.28616489\n",
      "step: 5199.0, loss:0.30529314\n",
      "step: 5200.0, loss:0.20032676\n",
      "step: 5201.0, loss:0.27857589\n",
      "step: 5202.0, loss:0.39134692\n",
      "step: 5203.0, loss:0.22957338\n",
      "step: 5204.0, loss:0.41380015\n",
      "step: 5205.0, loss:0.33689222\n",
      "step: 5206.0, loss:0.25773339\n",
      "step: 5207.0, loss:0.20021429\n",
      "step: 5208.0, loss:0.28327314\n",
      "step: 5209.0, loss:0.31983307\n",
      "step: 5210.0, loss:0.34310577\n",
      "step: 5211.0, loss:0.20608999\n",
      "step: 5212.0, loss:0.23020430\n",
      "step: 5213.0, loss:0.27944668\n",
      "step: 5214.0, loss:0.37667814\n",
      "step: 5215.0, loss:0.23565136\n",
      "step: 5216.0, loss:0.21404086\n",
      "step: 5217.0, loss:0.38579347\n",
      "step: 5218.0, loss:0.30242727\n",
      "step: 5219.0, loss:0.24542366\n",
      "step: 5220.0, loss:0.27984287\n",
      "step: 5221.0, loss:0.30274184\n",
      "step: 5222.0, loss:0.24985430\n",
      "step: 5223.0, loss:0.13314515\n",
      "step: 5224.0, loss:0.28698086\n",
      "step: 5225.0, loss:0.30321538\n",
      "step: 5226.0, loss:0.38222271\n",
      "step: 5227.0, loss:0.23255893\n",
      "step: 5228.0, loss:0.25397495\n",
      "step: 5229.0, loss:0.25477734\n",
      "step: 5230.0, loss:0.38998382\n",
      "step: 5231.0, loss:0.36070802\n",
      "step: 5232.0, loss:0.25945502\n",
      "step: 5233.0, loss:0.30144097\n",
      "step: 5234.0, loss:0.31844408\n",
      "step: 5235.0, loss:0.31281037\n",
      "step: 5236.0, loss:0.20779940\n",
      "step: 5237.0, loss:0.34262785\n",
      "step: 5238.0, loss:0.21632031\n",
      "step: 5239.0, loss:0.24180784\n",
      "step: 5240.0, loss:0.29724915\n",
      "step: 5241.0, loss:0.24828211\n",
      "step: 5242.0, loss:0.30635285\n",
      "step: 5243.0, loss:0.17315182\n",
      "step: 5244.0, loss:0.37200490\n",
      "step: 5245.0, loss:0.43965780\n",
      "step: 5246.0, loss:0.25419984\n",
      "step: 5247.0, loss:0.21645271\n",
      "step: 5248.0, loss:0.22754122\n",
      "step: 5249.0, loss:0.35189249\n",
      "step: 5250.0, loss:0.34232263\n",
      "step: 5251.0, loss:0.38206938\n",
      "step: 5252.0, loss:0.37922169\n",
      "step: 5253.0, loss:0.39718314\n",
      "step: 5254.0, loss:0.32272694\n",
      "step: 5255.0, loss:0.23026015\n",
      "step: 5256.0, loss:0.31903492\n",
      "step: 5257.0, loss:0.26018998\n",
      "step: 5258.0, loss:0.32702510\n",
      "step: 5259.0, loss:0.21557535\n",
      "step: 5260.0, loss:0.33235207\n",
      "step: 5261.0, loss:0.29829987\n",
      "step: 5262.0, loss:0.17581473\n",
      "step: 5263.0, loss:0.16108488\n",
      "step: 5264.0, loss:0.45960660\n",
      "step: 5265.0, loss:0.28794464\n",
      "step: 5266.0, loss:0.22074894\n",
      "step: 5267.0, loss:0.24599555\n",
      "step: 5268.0, loss:0.20996622\n",
      "step: 5269.0, loss:0.37752757\n",
      "step: 5270.0, loss:0.28040615\n",
      "step: 5271.0, loss:0.38450475\n",
      "step: 5272.0, loss:0.29535880\n",
      "step: 5273.0, loss:0.19033460\n",
      "step: 5274.0, loss:0.21041247\n",
      "step: 5275.0, loss:0.33548840\n",
      "step: 5276.0, loss:0.28609355\n",
      "step: 5277.0, loss:0.31209733\n",
      "step: 5278.0, loss:0.31167644\n",
      "step: 5279.0, loss:0.18689591\n",
      "step: 5280.0, loss:0.27562295\n",
      "step: 5281.0, loss:0.21125798\n",
      "step: 5282.0, loss:0.33752267\n",
      "step: 5283.0, loss:0.19240977\n",
      "step: 5284.0, loss:0.24841999\n",
      "step: 5285.0, loss:0.30631401\n",
      "step: 5286.0, loss:0.22588493\n",
      "step: 5287.0, loss:0.42423069\n",
      "step: 5288.0, loss:0.24876912\n",
      "step: 5289.0, loss:0.25577140\n",
      "step: 5290.0, loss:0.24385318\n",
      "step: 5291.0, loss:0.29159968\n",
      "step: 5292.0, loss:0.25610505\n",
      "step: 5293.0, loss:0.30572938\n",
      "step: 5294.0, loss:0.31466459\n",
      "step: 5295.0, loss:0.32313706\n",
      "step: 5296.0, loss:0.36303765\n",
      "step: 5297.0, loss:0.27448167\n",
      "step: 5298.0, loss:0.24987352\n",
      "step: 5299.0, loss:0.20614803\n",
      "step: 5300.0, loss:0.21576618\n",
      "step: 5301.0, loss:0.35052352\n",
      "step: 5302.0, loss:0.27770201\n",
      "step: 5303.0, loss:0.27326252\n",
      "step: 5304.0, loss:0.38343681\n",
      "step: 5305.0, loss:0.21320885\n",
      "step: 5306.0, loss:0.21595398\n",
      "step: 5307.0, loss:0.29912819\n",
      "step: 5308.0, loss:0.24788391\n",
      "step: 5309.0, loss:0.32690983\n",
      "step: 5310.0, loss:0.25471419\n",
      "step: 5311.0, loss:0.40147349\n",
      "step: 5312.0, loss:0.25190623\n",
      "step: 5313.0, loss:0.31275244\n",
      "step: 5314.0, loss:0.21585565\n",
      "step: 5315.0, loss:0.20159917\n",
      "step: 5316.0, loss:0.21340327\n",
      "step: 5317.0, loss:0.24888870\n",
      "step: 5318.0, loss:0.40896225\n",
      "step: 5319.0, loss:0.33282382\n",
      "step: 5320.0, loss:0.41306118\n",
      "step: 5321.0, loss:0.24530705\n",
      "step: 5322.0, loss:0.29283946\n",
      "step: 5323.0, loss:0.37831979\n",
      "step: 5324.0, loss:0.31086384\n",
      "step: 5325.0, loss:0.17596968\n",
      "step: 5326.0, loss:0.16866244\n",
      "step: 5327.0, loss:0.33419837\n",
      "step: 5328.0, loss:0.18708682\n",
      "step: 5329.0, loss:0.34629708\n",
      "step: 5330.0, loss:0.24857893\n",
      "step: 5331.0, loss:0.17119081\n",
      "step: 5332.0, loss:0.24578802\n",
      "step: 5333.0, loss:0.24209060\n",
      "step: 5334.0, loss:0.33812596\n",
      "step: 5335.0, loss:0.36663415\n",
      "step: 5336.0, loss:0.31929856\n",
      "step: 5337.0, loss:0.24452880\n",
      "step: 5338.0, loss:0.21889345\n",
      "step: 5339.0, loss:0.36157739\n",
      "step: 5340.0, loss:0.34783159\n",
      "step: 5341.0, loss:0.20527241\n",
      "step: 5342.0, loss:0.26526378\n",
      "step: 5343.0, loss:0.29459340\n",
      "step: 5344.0, loss:0.37978905\n",
      "step: 5345.0, loss:0.32076428\n",
      "step: 5346.0, loss:0.23598177\n",
      "step: 5347.0, loss:0.17523833\n",
      "step: 5348.0, loss:0.29392008\n",
      "step: 5349.0, loss:0.21282318\n",
      "step: 5350.0, loss:0.18394091\n",
      "step: 5351.0, loss:0.30215755\n",
      "step: 5352.0, loss:0.13962781\n",
      "step: 5353.0, loss:0.28574862\n",
      "step: 5354.0, loss:0.39607842\n",
      "step: 5355.0, loss:0.30909598\n",
      "step: 5356.0, loss:0.22906690\n",
      "step: 5357.0, loss:0.27694464\n",
      "step: 5358.0, loss:0.26835742\n",
      "step: 5359.0, loss:0.40864681\n",
      "step: 5360.0, loss:0.25193624\n",
      "step: 5361.0, loss:0.25472532\n",
      "step: 5362.0, loss:0.33300123\n",
      "step: 5363.0, loss:0.14233652\n",
      "step: 5364.0, loss:0.29315086\n",
      "step: 5365.0, loss:0.25020177\n",
      "step: 5366.0, loss:0.16182657\n",
      "step: 5367.0, loss:0.30015308\n",
      "step: 5368.0, loss:0.28384336\n",
      "step: 5369.0, loss:0.19996493\n",
      "step: 5370.0, loss:0.24759808\n",
      "step: 5371.0, loss:0.17928611\n",
      "step: 5372.0, loss:0.21322981\n",
      "step: 5373.0, loss:0.36376509\n",
      "step: 5374.0, loss:0.25126751\n",
      "step: 5375.0, loss:0.31065791\n",
      "step: 5376.0, loss:0.22161094\n",
      "step: 5377.0, loss:0.27604096\n",
      "step: 5378.0, loss:0.21864619\n",
      "step: 5379.0, loss:0.46753480\n",
      "step: 5380.0, loss:0.37163149\n",
      "step: 5381.0, loss:0.26333591\n",
      "step: 5382.0, loss:0.30680331\n",
      "step: 5383.0, loss:0.21069967\n",
      "step: 5384.0, loss:0.29008391\n",
      "step: 5385.0, loss:0.27024901\n",
      "step: 5386.0, loss:0.26851877\n",
      "step: 5387.0, loss:0.30599445\n",
      "step: 5388.0, loss:0.28265730\n",
      "step: 5389.0, loss:0.27997775\n",
      "step: 5390.0, loss:0.25243451\n",
      "step: 5391.0, loss:0.40705527\n",
      "step: 5392.0, loss:0.24671520\n",
      "step: 5393.0, loss:0.41164779\n",
      "step: 5394.0, loss:0.38037963\n",
      "step: 5395.0, loss:0.18545516\n",
      "step: 5396.0, loss:0.25786951\n",
      "step: 5397.0, loss:0.33197389\n",
      "step: 5398.0, loss:0.16016787\n",
      "step: 5399.0, loss:0.22619597\n",
      "step: 5400.0, loss:0.29057868\n",
      "step: 5401.0, loss:0.26791416\n",
      "step: 5402.0, loss:0.21430575\n",
      "step: 5403.0, loss:0.26328327\n",
      "step: 5404.0, loss:0.40633303\n",
      "step: 5405.0, loss:0.37654652\n",
      "step: 5406.0, loss:0.19823353\n",
      "step: 5407.0, loss:0.36296129\n",
      "step: 5408.0, loss:0.37545925\n",
      "step: 5409.0, loss:0.51306914\n",
      "step: 5410.0, loss:0.19145795\n",
      "step: 5411.0, loss:0.40985388\n",
      "step: 5412.0, loss:0.28674448\n",
      "step: 5413.0, loss:0.26882682\n",
      "step: 5414.0, loss:0.27801268\n",
      "step: 5415.0, loss:0.34690971\n",
      "step: 5416.0, loss:0.13367301\n",
      "step: 5417.0, loss:0.20466929\n",
      "step: 5418.0, loss:0.24791546\n",
      "step: 5419.0, loss:0.22484742\n",
      "step: 5420.0, loss:0.27853047\n",
      "step: 5421.0, loss:0.23689928\n",
      "step: 5422.0, loss:0.36738751\n",
      "step: 5423.0, loss:0.24550765\n",
      "step: 5424.0, loss:0.28888526\n",
      "step: 5425.0, loss:0.25435845\n",
      "step: 5426.0, loss:0.39473633\n",
      "step: 5427.0, loss:0.31567612\n",
      "step: 5428.0, loss:0.32319539\n",
      "step: 5429.0, loss:0.37240273\n",
      "step: 5430.0, loss:0.30578594\n",
      "step: 5431.0, loss:0.20120720\n",
      "step: 5432.0, loss:0.39668927\n",
      "step: 5433.0, loss:0.27124217\n",
      "step: 5434.0, loss:0.28933632\n",
      "step: 5435.0, loss:0.33876749\n",
      "step: 5436.0, loss:0.17298242\n",
      "step: 5437.0, loss:0.27451824\n",
      "step: 5438.0, loss:0.27845750\n",
      "step: 5439.0, loss:0.27591787\n",
      "step: 5440.0, loss:0.29417853\n",
      "step: 5441.0, loss:0.34945358\n",
      "step: 5442.0, loss:0.32866131\n",
      "step: 5443.0, loss:0.25803274\n",
      "step: 5444.0, loss:0.28142079\n",
      "step: 5445.0, loss:0.15027259\n",
      "step: 5446.0, loss:0.23928469\n",
      "step: 5447.0, loss:0.28129517\n",
      "step: 5448.0, loss:0.25365843\n",
      "step: 5449.0, loss:0.25131970\n",
      "step: 5450.0, loss:0.28824767\n",
      "step: 5451.0, loss:0.25596309\n",
      "step: 5452.0, loss:0.24049754\n",
      "step: 5453.0, loss:0.24982942\n",
      "step: 5454.0, loss:0.51328297\n",
      "step: 5455.0, loss:0.25536939\n",
      "step: 5456.0, loss:0.36988400\n",
      "step: 5457.0, loss:0.24674833\n",
      "step: 5458.0, loss:0.37665327\n",
      "step: 5459.0, loss:0.33146672\n",
      "step: 5460.0, loss:0.25051238\n",
      "step: 5461.0, loss:0.15902817\n",
      "step: 5462.0, loss:0.23704519\n",
      "step: 5463.0, loss:0.16392928\n",
      "step: 5464.0, loss:0.28389634\n",
      "step: 5465.0, loss:0.16452774\n",
      "step: 5466.0, loss:0.24171408\n",
      "step: 5467.0, loss:0.36724892\n",
      "step: 5468.0, loss:0.26719656\n",
      "step: 5469.0, loss:0.26545547\n",
      "step: 5470.0, loss:0.27827376\n",
      "step: 5471.0, loss:0.25839557\n",
      "step: 5472.0, loss:0.37620755\n",
      "step: 5473.0, loss:0.25471112\n",
      "step: 5474.0, loss:0.30552869\n",
      "step: 5475.0, loss:0.30246668\n",
      "step: 5476.0, loss:0.38384762\n",
      "step: 5477.0, loss:0.15854536\n",
      "step: 5478.0, loss:0.50344449\n",
      "step: 5479.0, loss:0.19713132\n",
      "step: 5480.0, loss:0.35531715\n",
      "step: 5481.0, loss:0.26057550\n",
      "step: 5482.0, loss:0.48782874\n",
      "step: 5483.0, loss:0.22447187\n",
      "step: 5484.0, loss:0.39842318\n",
      "step: 5485.0, loss:0.40721746\n",
      "step: 5486.0, loss:0.24180284\n",
      "step: 5487.0, loss:0.20609704\n",
      "step: 5488.0, loss:0.28965783\n",
      "step: 5489.0, loss:0.24554716\n",
      "step: 5490.0, loss:0.35152370\n",
      "step: 5491.0, loss:0.20772516\n",
      "step: 5492.0, loss:0.21247577\n",
      "step: 5493.0, loss:0.24108044\n",
      "step: 5494.0, loss:0.29383530\n",
      "step: 5495.0, loss:0.22222123\n",
      "step: 5496.0, loss:0.35825191\n",
      "step: 5497.0, loss:0.30374364\n",
      "step: 5498.0, loss:0.41928560\n",
      "step: 5499.0, loss:0.34438197\n",
      "step: 5500.0, loss:0.26954416\n",
      "step: 5501.0, loss:0.23089149\n",
      "step: 5502.0, loss:0.24808007\n",
      "step: 5503.0, loss:0.35066109\n",
      "step: 5504.0, loss:0.26554720\n",
      "step: 5505.0, loss:0.26418456\n",
      "step: 5506.0, loss:0.37759595\n",
      "step: 5507.0, loss:0.16989093\n",
      "step: 5508.0, loss:0.23288124\n",
      "step: 5509.0, loss:0.25976687\n",
      "step: 5510.0, loss:0.23427280\n",
      "step: 5511.0, loss:0.33882023\n",
      "step: 5512.0, loss:0.25232895\n",
      "step: 5513.0, loss:0.27084724\n",
      "step: 5514.0, loss:0.22307111\n",
      "step: 5515.0, loss:0.23616480\n",
      "step: 5516.0, loss:0.26520562\n",
      "step: 5517.0, loss:0.21931781\n",
      "step: 5518.0, loss:0.19197607\n",
      "step: 5519.0, loss:0.25418289\n",
      "step: 5520.0, loss:0.31041104\n",
      "step: 5521.0, loss:0.38936646\n",
      "step: 5522.0, loss:0.44876496\n",
      "step: 5523.0, loss:0.31500163\n",
      "step: 5524.0, loss:0.23261116\n",
      "step: 5525.0, loss:0.28083143\n",
      "step: 5526.0, loss:0.25099946\n",
      "step: 5527.0, loss:0.29596138\n",
      "step: 5528.0, loss:0.25391986\n",
      "step: 5529.0, loss:0.19116398\n",
      "step: 5530.0, loss:0.18722501\n",
      "step: 5531.0, loss:0.25726562\n",
      "step: 5532.0, loss:0.24381371\n",
      "step: 5533.0, loss:0.33694144\n",
      "step: 5534.0, loss:0.30410702\n",
      "step: 5535.0, loss:0.41298851\n",
      "step: 5536.0, loss:0.31356427\n",
      "step: 5537.0, loss:0.27944302\n",
      "step: 5538.0, loss:0.25454353\n",
      "step: 5539.0, loss:0.16093124\n",
      "step: 5540.0, loss:0.25794146\n",
      "step: 5541.0, loss:0.17601445\n",
      "step: 5542.0, loss:0.28121938\n",
      "step: 5543.0, loss:0.33058821\n",
      "step: 5544.0, loss:0.21308951\n",
      "step: 5545.0, loss:0.29167293\n",
      "step: 5546.0, loss:0.27883557\n",
      "step: 5547.0, loss:0.42971813\n",
      "step: 5548.0, loss:0.13955462\n",
      "step: 5549.0, loss:0.34417656\n",
      "step: 5550.0, loss:0.32209773\n",
      "step: 5551.0, loss:0.29923246\n",
      "step: 5552.0, loss:0.15023182\n",
      "step: 5553.0, loss:0.39266057\n",
      "step: 5554.0, loss:0.15338120\n",
      "step: 5555.0, loss:0.31700549\n",
      "step: 5556.0, loss:0.28709603\n",
      "step: 5557.0, loss:0.32018887\n",
      "step: 5558.0, loss:0.31695537\n",
      "step: 5559.0, loss:0.17837346\n",
      "step: 5560.0, loss:0.25790906\n",
      "step: 5561.0, loss:0.26858997\n",
      "step: 5562.0, loss:0.31398010\n",
      "step: 5563.0, loss:0.22898578\n",
      "step: 5564.0, loss:0.22795357\n",
      "step: 5565.0, loss:0.24803820\n",
      "step: 5566.0, loss:0.22444929\n",
      "step: 5567.0, loss:0.27519807\n",
      "step: 5568.0, loss:0.30222951\n",
      "step: 5569.0, loss:0.28476840\n",
      "step: 5570.0, loss:0.33205685\n",
      "step: 5571.0, loss:0.34685135\n",
      "step: 5572.0, loss:0.16998717\n",
      "step: 5573.0, loss:0.34970491\n",
      "step: 5574.0, loss:0.21826512\n",
      "step: 5575.0, loss:0.35352114\n",
      "step: 5576.0, loss:0.20552359\n",
      "step: 5577.0, loss:0.34579858\n",
      "step: 5578.0, loss:0.22562881\n",
      "step: 5579.0, loss:0.37384783\n",
      "step: 5580.0, loss:0.27410843\n",
      "step: 5581.0, loss:0.18352001\n",
      "step: 5582.0, loss:0.32393655\n",
      "step: 5583.0, loss:0.35844960\n",
      "step: 5584.0, loss:0.27105186\n",
      "step: 5585.0, loss:0.20472806\n",
      "step: 5586.0, loss:0.16323865\n",
      "step: 5587.0, loss:0.40221171\n",
      "step: 5588.0, loss:0.19561521\n",
      "step: 5589.0, loss:0.26007177\n",
      "step: 5590.0, loss:0.30374999\n",
      "step: 5591.0, loss:0.30217888\n",
      "step: 5592.0, loss:0.18172228\n",
      "step: 5593.0, loss:0.35254556\n",
      "step: 5594.0, loss:0.29305311\n",
      "step: 5595.0, loss:0.26756360\n",
      "step: 5596.0, loss:0.34243159\n",
      "step: 5597.0, loss:0.33041678\n",
      "step: 5598.0, loss:0.32504304\n",
      "step: 5599.0, loss:0.13228872\n",
      "step: 5600.0, loss:0.17044565\n",
      "step: 5601.0, loss:0.20383490\n",
      "step: 5602.0, loss:0.39390856\n",
      "step: 5603.0, loss:0.27610407\n",
      "step: 5604.0, loss:0.33428980\n",
      "step: 5605.0, loss:0.24687958\n",
      "step: 5606.0, loss:0.23211246\n",
      "step: 5607.0, loss:0.30026316\n",
      "step: 5608.0, loss:0.24698147\n",
      "step: 5609.0, loss:0.26525103\n",
      "step: 5610.0, loss:0.37214801\n",
      "step: 5611.0, loss:0.21329367\n",
      "step: 5612.0, loss:0.29292391\n",
      "step: 5613.0, loss:0.28619083\n",
      "step: 5614.0, loss:0.30484582\n",
      "step: 5615.0, loss:0.28216091\n",
      "step: 5616.0, loss:0.24481945\n",
      "step: 5617.0, loss:0.16373896\n",
      "step: 5618.0, loss:0.29697302\n",
      "step: 5619.0, loss:0.30109011\n",
      "step: 5620.0, loss:0.28385059\n",
      "step: 5621.0, loss:0.24125788\n",
      "step: 5622.0, loss:0.29638466\n",
      "step: 5623.0, loss:0.28110287\n",
      "step: 5624.0, loss:0.21915087\n",
      "step: 5625.0, loss:0.38879089\n",
      "step: 5626.0, loss:0.24138695\n",
      "step: 5627.0, loss:0.22976861\n",
      "step: 5628.0, loss:0.28723101\n",
      "step: 5629.0, loss:0.32042745\n",
      "step: 5630.0, loss:0.25572708\n",
      "step: 5631.0, loss:0.16317850\n",
      "step: 5632.0, loss:0.22158435\n",
      "step: 5633.0, loss:0.27470065\n",
      "step: 5634.0, loss:0.28892751\n",
      "step: 5635.0, loss:0.37394746\n",
      "step: 5636.0, loss:0.26417814\n",
      "step: 5637.0, loss:0.25509742\n",
      "step: 5638.0, loss:0.26799677\n",
      "step: 5639.0, loss:0.29502680\n",
      "step: 5640.0, loss:0.35051924\n",
      "step: 5641.0, loss:0.24011735\n",
      "step: 5642.0, loss:0.36805122\n",
      "step: 5643.0, loss:0.16913684\n",
      "step: 5644.0, loss:0.16982193\n",
      "step: 5645.0, loss:0.37297373\n",
      "step: 5646.0, loss:0.30110666\n",
      "step: 5647.0, loss:0.23058985\n",
      "step: 5648.0, loss:0.35033817\n",
      "step: 5649.0, loss:0.28070306\n",
      "step: 5650.0, loss:0.23588553\n",
      "step: 5651.0, loss:0.35855814\n",
      "step: 5652.0, loss:0.25852454\n",
      "step: 5653.0, loss:0.46506678\n",
      "step: 5654.0, loss:0.26481817\n",
      "step: 5655.0, loss:0.44080812\n",
      "step: 5656.0, loss:0.28263345\n",
      "step: 5657.0, loss:0.33039171\n",
      "step: 5658.0, loss:0.35254247\n",
      "step: 5659.0, loss:0.32060747\n",
      "step: 5660.0, loss:0.35556985\n",
      "step: 5661.0, loss:0.25062132\n",
      "step: 5662.0, loss:0.28614999\n",
      "step: 5663.0, loss:0.29833581\n",
      "step: 5664.0, loss:0.22145919\n",
      "step: 5665.0, loss:0.23873102\n",
      "step: 5666.0, loss:0.27199488\n",
      "step: 5667.0, loss:0.24844511\n",
      "step: 5668.0, loss:0.31671565\n",
      "step: 5669.0, loss:0.29653652\n",
      "step: 5670.0, loss:0.31673124\n",
      "step: 5671.0, loss:0.23691959\n",
      "step: 5672.0, loss:0.32625667\n",
      "step: 5673.0, loss:0.40604163\n",
      "step: 5674.0, loss:0.30940706\n",
      "step: 5675.0, loss:0.40059560\n",
      "step: 5676.0, loss:0.23232228\n",
      "step: 5677.0, loss:0.24806462\n",
      "step: 5678.0, loss:0.28438004\n",
      "step: 5679.0, loss:0.30117661\n",
      "step: 5680.0, loss:0.31403640\n",
      "step: 5681.0, loss:0.28917768\n",
      "step: 5682.0, loss:0.39895456\n",
      "step: 5683.0, loss:0.23794264\n",
      "step: 5684.0, loss:0.27314533\n",
      "step: 5685.0, loss:0.26967713\n",
      "step: 5686.0, loss:0.39175899\n",
      "step: 5687.0, loss:0.33442973\n",
      "step: 5688.0, loss:0.29205831\n",
      "step: 5689.0, loss:0.31341043\n",
      "step: 5690.0, loss:0.38906933\n",
      "step: 5691.0, loss:0.27769600\n",
      "step: 5692.0, loss:0.38028880\n",
      "step: 5693.0, loss:0.31603612\n",
      "step: 5694.0, loss:0.28274419\n",
      "step: 5695.0, loss:0.28424539\n",
      "step: 5696.0, loss:0.35301815\n",
      "step: 5697.0, loss:0.24561216\n",
      "step: 5698.0, loss:0.27288218\n",
      "step: 5699.0, loss:0.20487707\n",
      "step: 5700.0, loss:0.34352411\n",
      "step: 5701.0, loss:0.23512176\n",
      "step: 5702.0, loss:0.23462309\n",
      "step: 5703.0, loss:0.32769115\n",
      "step: 5704.0, loss:0.21578927\n",
      "step: 5705.0, loss:0.26939700\n",
      "step: 5706.0, loss:0.26830107\n",
      "step: 5707.0, loss:0.26368386\n",
      "step: 5708.0, loss:0.32356606\n",
      "step: 5709.0, loss:0.25965974\n",
      "step: 5710.0, loss:0.28688347\n",
      "step: 5711.0, loss:0.30671977\n",
      "step: 5712.0, loss:0.30163855\n",
      "step: 5713.0, loss:0.16518687\n",
      "step: 5714.0, loss:0.19716836\n",
      "step: 5715.0, loss:0.17349340\n",
      "step: 5716.0, loss:0.35523548\n",
      "step: 5717.0, loss:0.36589795\n",
      "step: 5718.0, loss:0.25246706\n",
      "step: 5719.0, loss:0.34152742\n",
      "step: 5720.0, loss:0.17087414\n",
      "step: 5721.0, loss:0.26028908\n",
      "step: 5722.0, loss:0.32993364\n",
      "step: 5723.0, loss:0.21251936\n",
      "step: 5724.0, loss:0.25558439\n",
      "step: 5725.0, loss:0.29086294\n",
      "step: 5726.0, loss:0.32490770\n",
      "step: 5727.0, loss:0.36464530\n",
      "step: 5728.0, loss:0.30797478\n",
      "step: 5729.0, loss:0.33145355\n",
      "step: 5730.0, loss:0.23581479\n",
      "step: 5731.0, loss:0.32754599\n",
      "step: 5732.0, loss:0.19818695\n",
      "step: 5733.0, loss:0.29771773\n",
      "step: 5734.0, loss:0.38896279\n",
      "step: 5735.0, loss:0.33477030\n",
      "step: 5736.0, loss:0.40132909\n",
      "step: 5737.0, loss:0.40595795\n",
      "step: 5738.0, loss:0.18726845\n",
      "step: 5739.0, loss:0.20019579\n",
      "step: 5740.0, loss:0.22951371\n",
      "step: 5741.0, loss:0.27746706\n",
      "step: 5742.0, loss:0.35814535\n",
      "step: 5743.0, loss:0.36531670\n",
      "step: 5744.0, loss:0.42374713\n",
      "step: 5745.0, loss:0.21607023\n",
      "step: 5746.0, loss:0.26172968\n",
      "step: 5747.0, loss:0.32292809\n",
      "step: 5748.0, loss:0.36054436\n",
      "step: 5749.0, loss:0.33135305\n",
      "step: 5750.0, loss:0.35302702\n",
      "step: 5751.0, loss:0.35413705\n",
      "step: 5752.0, loss:0.15285014\n",
      "step: 5753.0, loss:0.31002958\n",
      "step: 5754.0, loss:0.33450399\n",
      "step: 5755.0, loss:0.26001191\n",
      "step: 5756.0, loss:0.44452189\n",
      "step: 5757.0, loss:0.38173596\n",
      "step: 5758.0, loss:0.29032398\n",
      "step: 5759.0, loss:0.14166967\n",
      "step: 5760.0, loss:0.36752923\n",
      "step: 5761.0, loss:0.38902161\n",
      "step: 5762.0, loss:0.36964620\n",
      "step: 5763.0, loss:0.27169915\n",
      "step: 5764.0, loss:0.38213371\n",
      "step: 5765.0, loss:0.37301835\n",
      "step: 5766.0, loss:0.23388286\n",
      "step: 5767.0, loss:0.31234618\n",
      "step: 5768.0, loss:0.36353820\n",
      "step: 5769.0, loss:0.34396240\n",
      "step: 5770.0, loss:0.20402347\n",
      "step: 5771.0, loss:0.26319423\n",
      "step: 5772.0, loss:0.26864884\n",
      "step: 5773.0, loss:0.41572381\n",
      "step: 5774.0, loss:0.24966182\n",
      "step: 5775.0, loss:0.41638794\n",
      "step: 5776.0, loss:0.44096411\n",
      "step: 5777.0, loss:0.20093450\n",
      "step: 5778.0, loss:0.27590830\n",
      "step: 5779.0, loss:0.26098482\n",
      "step: 5780.0, loss:0.34296240\n",
      "step: 5781.0, loss:0.19648002\n",
      "step: 5782.0, loss:0.23504585\n",
      "step: 5783.0, loss:0.25788877\n",
      "step: 5784.0, loss:0.30971841\n",
      "step: 5785.0, loss:0.37444157\n",
      "step: 5786.0, loss:0.29961326\n",
      "step: 5787.0, loss:0.27154132\n",
      "step: 5788.0, loss:0.28467757\n",
      "step: 5789.0, loss:0.30644163\n",
      "step: 5790.0, loss:0.22920544\n",
      "step: 5791.0, loss:0.24759473\n",
      "step: 5792.0, loss:0.21101648\n",
      "step: 5793.0, loss:0.33954668\n",
      "step: 5794.0, loss:0.34827087\n",
      "step: 5795.0, loss:0.25971892\n",
      "step: 5796.0, loss:0.25539510\n",
      "step: 5797.0, loss:0.24326443\n",
      "step: 5798.0, loss:0.23222959\n",
      "step: 5799.0, loss:0.34963470\n",
      "step: 5800.0, loss:0.37500598\n",
      "step: 5801.0, loss:0.21386671\n",
      "step: 5802.0, loss:0.24604573\n",
      "step: 5803.0, loss:0.28195334\n",
      "step: 5804.0, loss:0.22650209\n",
      "step: 5805.0, loss:0.25763751\n",
      "step: 5806.0, loss:0.32348506\n",
      "step: 5807.0, loss:0.25521833\n",
      "step: 5808.0, loss:0.23688868\n",
      "step: 5809.0, loss:0.34856954\n",
      "step: 5810.0, loss:0.24081755\n",
      "step: 5811.0, loss:0.24281231\n",
      "step: 5812.0, loss:0.31263591\n",
      "step: 5813.0, loss:0.46668494\n",
      "step: 5814.0, loss:0.16366549\n",
      "step: 5815.0, loss:0.27220273\n",
      "step: 5816.0, loss:0.40129296\n",
      "step: 5817.0, loss:0.35270675\n",
      "step: 5818.0, loss:0.19558028\n",
      "step: 5819.0, loss:0.28692237\n",
      "step: 5820.0, loss:0.33291026\n",
      "step: 5821.0, loss:0.43307780\n",
      "step: 5822.0, loss:0.31691365\n",
      "step: 5823.0, loss:0.26424694\n",
      "step: 5824.0, loss:0.23268473\n",
      "step: 5825.0, loss:0.37177240\n",
      "step: 5826.0, loss:0.32735968\n",
      "step: 5827.0, loss:0.29996722\n",
      "step: 5828.0, loss:0.31011706\n",
      "step: 5829.0, loss:0.39571860\n",
      "step: 5830.0, loss:0.37302040\n",
      "step: 5831.0, loss:0.30902976\n",
      "step: 5832.0, loss:0.32985945\n",
      "step: 5833.0, loss:0.31509445\n",
      "step: 5834.0, loss:0.29169697\n",
      "step: 5835.0, loss:0.24146723\n",
      "step: 5836.0, loss:0.24081447\n",
      "step: 5837.0, loss:0.28825168\n",
      "step: 5838.0, loss:0.25876608\n",
      "step: 5839.0, loss:0.23832902\n",
      "step: 5840.0, loss:0.46388093\n",
      "step: 5841.0, loss:0.20763640\n",
      "step: 5842.0, loss:0.36791578\n",
      "step: 5843.0, loss:0.31431315\n",
      "step: 5844.0, loss:0.18556970\n",
      "step: 5845.0, loss:0.23963534\n",
      "step: 5846.0, loss:0.27484953\n",
      "step: 5847.0, loss:0.19411239\n",
      "step: 5848.0, loss:0.30801090\n",
      "step: 5849.0, loss:0.36497686\n",
      "step: 5850.0, loss:0.27484031\n",
      "step: 5851.0, loss:0.31554089\n",
      "step: 5852.0, loss:0.27527573\n",
      "step: 5853.0, loss:0.30551006\n",
      "step: 5854.0, loss:0.29587939\n",
      "step: 5855.0, loss:0.21010802\n",
      "step: 5856.0, loss:0.19087790\n",
      "step: 5857.0, loss:0.24103086\n",
      "step: 5858.0, loss:0.25563391\n",
      "step: 5859.0, loss:0.43257453\n",
      "step: 5860.0, loss:0.40564021\n",
      "step: 5861.0, loss:0.23512424\n",
      "step: 5862.0, loss:0.30151726\n",
      "step: 5863.0, loss:0.34483350\n",
      "step: 5864.0, loss:0.27368439\n",
      "step: 5865.0, loss:0.23203279\n",
      "step: 5866.0, loss:0.30731911\n",
      "step: 5867.0, loss:0.22009505\n",
      "step: 5868.0, loss:0.43839844\n",
      "step: 5869.0, loss:0.25503587\n",
      "step: 5870.0, loss:0.28831327\n",
      "step: 5871.0, loss:0.25571539\n",
      "step: 5872.0, loss:0.32469885\n",
      "step: 5873.0, loss:0.35127990\n",
      "step: 5874.0, loss:0.29125159\n",
      "step: 5875.0, loss:0.23324559\n",
      "step: 5876.0, loss:0.28382969\n",
      "step: 5877.0, loss:0.28235016\n",
      "step: 5878.0, loss:0.31344471\n",
      "step: 5879.0, loss:0.36300059\n",
      "step: 5880.0, loss:0.25283344\n",
      "step: 5881.0, loss:0.32196181\n",
      "step: 5882.0, loss:0.20736821\n",
      "step: 5883.0, loss:0.28757332\n",
      "step: 5884.0, loss:0.28071243\n",
      "step: 5885.0, loss:0.29080851\n",
      "step: 5886.0, loss:0.35714363\n",
      "step: 5887.0, loss:0.26992831\n",
      "step: 5888.0, loss:0.34188147\n",
      "step: 5889.0, loss:0.24860036\n",
      "step: 5890.0, loss:0.27509138\n",
      "step: 5891.0, loss:0.29889991\n",
      "step: 5892.0, loss:0.26388466\n",
      "step: 5893.0, loss:0.33991312\n",
      "step: 5894.0, loss:0.39555074\n",
      "step: 5895.0, loss:0.34611084\n",
      "step: 5896.0, loss:0.26919405\n",
      "step: 5897.0, loss:0.25096455\n",
      "step: 5898.0, loss:0.32345404\n",
      "step: 5899.0, loss:0.21910039\n",
      "step: 5900.0, loss:0.22539005\n",
      "step: 5901.0, loss:0.33717174\n",
      "step: 5902.0, loss:0.17355597\n",
      "step: 5903.0, loss:0.25928619\n",
      "step: 5904.0, loss:0.36205046\n",
      "step: 5905.0, loss:0.26039827\n",
      "step: 5906.0, loss:0.29399895\n",
      "step: 5907.0, loss:0.33730639\n",
      "step: 5908.0, loss:0.41579527\n",
      "step: 5909.0, loss:0.30478492\n",
      "step: 5910.0, loss:0.34041733\n",
      "step: 5911.0, loss:0.37126359\n",
      "step: 5912.0, loss:0.14459161\n",
      "step: 5913.0, loss:0.33073407\n",
      "step: 5914.0, loss:0.29263309\n",
      "step: 5915.0, loss:0.25701414\n",
      "step: 5916.0, loss:0.22385737\n",
      "step: 5917.0, loss:0.34585018\n",
      "step: 5918.0, loss:0.28698662\n",
      "step: 5919.0, loss:0.26330026\n",
      "step: 5920.0, loss:0.24829393\n",
      "step: 5921.0, loss:0.34564732\n",
      "step: 5922.0, loss:0.21505554\n",
      "step: 5923.0, loss:0.25658212\n",
      "step: 5924.0, loss:0.37993637\n",
      "step: 5925.0, loss:0.32119425\n",
      "step: 5926.0, loss:0.26079080\n",
      "step: 5927.0, loss:0.34580248\n",
      "step: 5928.0, loss:0.31992182\n",
      "step: 5929.0, loss:0.30344696\n",
      "step: 5930.0, loss:0.25102360\n",
      "step: 5931.0, loss:0.22894678\n",
      "step: 5932.0, loss:0.34351335\n",
      "step: 5933.0, loss:0.22228972\n",
      "step: 5934.0, loss:0.22614838\n",
      "step: 5935.0, loss:0.25942727\n",
      "step: 5936.0, loss:0.28694829\n",
      "step: 5937.0, loss:0.26906654\n",
      "step: 5938.0, loss:0.25340339\n",
      "step: 5939.0, loss:0.23417101\n",
      "step: 5940.0, loss:0.21035665\n",
      "step: 5941.0, loss:0.34251601\n",
      "step: 5942.0, loss:0.36639141\n",
      "step: 5943.0, loss:0.18377305\n",
      "step: 5944.0, loss:0.24731689\n",
      "step: 5945.0, loss:0.35017253\n",
      "step: 5946.0, loss:0.25963356\n",
      "step: 5947.0, loss:0.30313271\n",
      "step: 5948.0, loss:0.35233474\n",
      "step: 5949.0, loss:0.28874927\n",
      "step: 5950.0, loss:0.30270584\n",
      "step: 5951.0, loss:0.34664037\n",
      "step: 5952.0, loss:0.26857387\n",
      "step: 5953.0, loss:0.24491995\n",
      "step: 5954.0, loss:0.25218584\n",
      "step: 5955.0, loss:0.45921553\n",
      "step: 5956.0, loss:0.27532253\n",
      "step: 5957.0, loss:0.28004499\n",
      "step: 5958.0, loss:0.21087036\n",
      "step: 5959.0, loss:0.17314785\n",
      "step: 5960.0, loss:0.30233857\n",
      "step: 5961.0, loss:0.25427378\n",
      "step: 5962.0, loss:0.33017493\n",
      "step: 5963.0, loss:0.30319819\n",
      "step: 5964.0, loss:0.23529074\n",
      "step: 5965.0, loss:0.27924918\n",
      "step: 5966.0, loss:0.29974787\n",
      "step: 5967.0, loss:0.40083563\n",
      "step: 5968.0, loss:0.29362533\n",
      "step: 5969.0, loss:0.22329951\n",
      "step: 5970.0, loss:0.38691476\n",
      "step: 5971.0, loss:0.27226385\n",
      "step: 5972.0, loss:0.38568350\n",
      "step: 5973.0, loss:0.47802838\n",
      "step: 5974.0, loss:0.26850431\n",
      "step: 5975.0, loss:0.30476177\n",
      "step: 5976.0, loss:0.29494439\n",
      "step: 5977.0, loss:0.28462393\n",
      "step: 5978.0, loss:0.31343038\n",
      "step: 5979.0, loss:0.24517460\n",
      "step: 5980.0, loss:0.23412253\n",
      "step: 5981.0, loss:0.26972843\n",
      "step: 5982.0, loss:0.30483549\n",
      "step: 5983.0, loss:0.32359054\n",
      "step: 5984.0, loss:0.32210224\n",
      "step: 5985.0, loss:0.35465546\n",
      "step: 5986.0, loss:0.26812702\n",
      "step: 5987.0, loss:0.22306728\n",
      "step: 5988.0, loss:0.33133464\n",
      "step: 5989.0, loss:0.31028086\n",
      "step: 5990.0, loss:0.24428479\n",
      "step: 5991.0, loss:0.37325903\n",
      "step: 5992.0, loss:0.27056616\n",
      "step: 5993.0, loss:0.26643580\n",
      "step: 5994.0, loss:0.25014635\n",
      "step: 5995.0, loss:0.17349299\n",
      "step: 5996.0, loss:0.40692867\n",
      "step: 5997.0, loss:0.37525923\n",
      "step: 5998.0, loss:0.30567650\n",
      "step: 5999.0, loss:0.24526659\n",
      "step: 6000.0, loss:0.25565284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1264/1264 [08:30<00:00,  2.47it/s]\n",
      "2023-04-02 21:21:24,152 - INFO - step:6000.0, matthews_corr:0.746339, Acc:87.986644%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 6001.0, loss:0.22365693\n",
      "step: 6002.0, loss:0.31011712\n",
      "step: 6003.0, loss:0.23632000\n",
      "step: 6004.0, loss:0.34487450\n",
      "step: 6005.0, loss:0.30330599\n",
      "step: 6006.0, loss:0.31894572\n",
      "step: 6007.0, loss:0.34519512\n",
      "step: 6008.0, loss:0.29195004\n",
      "step: 6009.0, loss:0.36063461\n",
      "step: 6010.0, loss:0.38908029\n",
      "step: 6011.0, loss:0.23539989\n",
      "step: 6012.0, loss:0.22122382\n",
      "step: 6013.0, loss:0.31917669\n",
      "step: 6014.0, loss:0.25175527\n",
      "step: 6015.0, loss:0.22964648\n",
      "step: 6016.0, loss:0.19879132\n",
      "step: 6017.0, loss:0.22600093\n",
      "step: 6018.0, loss:0.37486309\n",
      "step: 6019.0, loss:0.30044400\n",
      "step: 6020.0, loss:0.36652686\n",
      "step: 6021.0, loss:0.24128764\n",
      "step: 6022.0, loss:0.22241871\n",
      "step: 6023.0, loss:0.28238579\n",
      "step: 6024.0, loss:0.20356168\n",
      "step: 6025.0, loss:0.25286281\n",
      "step: 6026.0, loss:0.25270199\n",
      "step: 6027.0, loss:0.29416374\n",
      "step: 6028.0, loss:0.17045986\n",
      "step: 6029.0, loss:0.25781625\n",
      "step: 6030.0, loss:0.23974070\n",
      "step: 6031.0, loss:0.18794711\n",
      "step: 6032.0, loss:0.32066389\n",
      "step: 6033.0, loss:0.22168339\n",
      "step: 6034.0, loss:0.17409665\n",
      "step: 6035.0, loss:0.25310344\n",
      "step: 6036.0, loss:0.39736271\n",
      "step: 6037.0, loss:0.40324372\n",
      "step: 6038.0, loss:0.20621070\n",
      "step: 6039.0, loss:0.23013917\n",
      "step: 6040.0, loss:0.33007905\n",
      "step: 6041.0, loss:0.33019660\n",
      "step: 6042.0, loss:0.22585477\n",
      "step: 6043.0, loss:0.32272470\n",
      "step: 6044.0, loss:0.15036923\n",
      "step: 6045.0, loss:0.19540247\n",
      "step: 6046.0, loss:0.24796940\n",
      "step: 6047.0, loss:0.39690217\n",
      "step: 6048.0, loss:0.27043507\n",
      "step: 6049.0, loss:0.40516794\n",
      "step: 6050.0, loss:0.22630091\n",
      "step: 6051.0, loss:0.42257198\n",
      "step: 6052.0, loss:0.19281437\n",
      "step: 6053.0, loss:0.30306924\n",
      "step: 6054.0, loss:0.23485621\n",
      "step: 6055.0, loss:0.25222716\n",
      "step: 6056.0, loss:0.40459460\n",
      "step: 6057.0, loss:0.34703350\n",
      "step: 6058.0, loss:0.22004319\n",
      "step: 6059.0, loss:0.22742384\n",
      "step: 6060.0, loss:0.32320695\n",
      "step: 6061.0, loss:0.32477662\n",
      "step: 6062.0, loss:0.24539208\n",
      "step: 6063.0, loss:0.32821170\n",
      "step: 6064.0, loss:0.33559737\n",
      "step: 6065.0, loss:0.35989223\n",
      "step: 6066.0, loss:0.24718960\n",
      "step: 6067.0, loss:0.26683856\n",
      "step: 6068.0, loss:0.18178927\n",
      "step: 6069.0, loss:0.39610261\n",
      "step: 6070.0, loss:0.25715606\n",
      "step: 6071.0, loss:0.39386457\n",
      "step: 6072.0, loss:0.19253121\n",
      "step: 6073.0, loss:0.29204196\n",
      "step: 6074.0, loss:0.17865188\n",
      "step: 6075.0, loss:0.17455870\n",
      "step: 6076.0, loss:0.30389741\n",
      "step: 6077.0, loss:0.15803523\n",
      "step: 6078.0, loss:0.35705953\n",
      "step: 6079.0, loss:0.24178130\n",
      "step: 6080.0, loss:0.30343515\n",
      "step: 6081.0, loss:0.17202263\n",
      "step: 6082.0, loss:0.21856798\n",
      "step: 6083.0, loss:0.39126842\n",
      "step: 6084.0, loss:0.24369750\n",
      "step: 6085.0, loss:0.26684904\n",
      "step: 6086.0, loss:0.31733864\n",
      "step: 6087.0, loss:0.25283636\n",
      "step: 6088.0, loss:0.25441286\n",
      "step: 6089.0, loss:0.30868016\n",
      "step: 6090.0, loss:0.28674000\n",
      "step: 6091.0, loss:0.26737450\n",
      "step: 6092.0, loss:0.17530059\n",
      "step: 6093.0, loss:0.34341193\n",
      "step: 6094.0, loss:0.29869577\n",
      "step: 6095.0, loss:0.43278516\n",
      "step: 6096.0, loss:0.26359232\n",
      "step: 6097.0, loss:0.27596345\n",
      "step: 6098.0, loss:0.19603649\n",
      "step: 6099.0, loss:0.22394946\n",
      "step: 6100.0, loss:0.21331599\n",
      "step: 6101.0, loss:0.41288796\n",
      "step: 6102.0, loss:0.24300756\n",
      "step: 6103.0, loss:0.27728913\n",
      "step: 6104.0, loss:0.27219444\n",
      "step: 6105.0, loss:0.36530988\n",
      "step: 6106.0, loss:0.24173081\n",
      "step: 6107.0, loss:0.28921738\n",
      "step: 6108.0, loss:0.29788043\n",
      "step: 6109.0, loss:0.27309007\n",
      "step: 6110.0, loss:0.23026207\n",
      "step: 6111.0, loss:0.24366777\n",
      "step: 6112.0, loss:0.32560920\n",
      "step: 6113.0, loss:0.34141416\n",
      "step: 6114.0, loss:0.26530041\n",
      "step: 6115.0, loss:0.26291806\n",
      "step: 6116.0, loss:0.29625398\n",
      "step: 6117.0, loss:0.24408986\n",
      "step: 6118.0, loss:0.32319453\n",
      "step: 6119.0, loss:0.36586080\n",
      "step: 6120.0, loss:0.31592288\n",
      "step: 6121.0, loss:0.17982213\n",
      "step: 6122.0, loss:0.30704122\n",
      "step: 6123.0, loss:0.24775589\n",
      "step: 6124.0, loss:0.27014017\n",
      "step: 6125.0, loss:0.31614515\n",
      "step: 6126.0, loss:0.25946963\n",
      "step: 6127.0, loss:0.23281634\n",
      "step: 6128.0, loss:0.27439319\n",
      "step: 6129.0, loss:0.29932616\n",
      "step: 6130.0, loss:0.24549328\n",
      "step: 6131.0, loss:0.29636792\n",
      "step: 6132.0, loss:0.29875285\n",
      "step: 6133.0, loss:0.26665894\n",
      "step: 6134.0, loss:0.32308843\n",
      "step: 6135.0, loss:0.30462294\n",
      "step: 6136.0, loss:0.28128747\n",
      "step: 6137.0, loss:0.22769782\n",
      "step: 6138.0, loss:0.27239694\n",
      "step: 6139.0, loss:0.39922324\n",
      "step: 6140.0, loss:0.27577883\n",
      "step: 6141.0, loss:0.16117974\n",
      "step: 6142.0, loss:0.27943979\n",
      "step: 6143.0, loss:0.18920198\n",
      "step: 6144.0, loss:0.28606339\n",
      "step: 6145.0, loss:0.36375939\n",
      "step: 6146.0, loss:0.21663326\n",
      "step: 6147.0, loss:0.23455428\n",
      "step: 6148.0, loss:0.28290097\n",
      "step: 6149.0, loss:0.20755100\n",
      "step: 6150.0, loss:0.23622038\n",
      "step: 6151.0, loss:0.33225685\n",
      "step: 6152.0, loss:0.21928505\n",
      "step: 6153.0, loss:0.25279046\n",
      "step: 6154.0, loss:0.23853168\n",
      "step: 6155.0, loss:0.27649006\n",
      "step: 6156.0, loss:0.37359829\n",
      "step: 6157.0, loss:0.30905203\n",
      "step: 6158.0, loss:0.21155533\n",
      "step: 6159.0, loss:0.36149716\n",
      "step: 6160.0, loss:0.40991746\n",
      "step: 6161.0, loss:0.24347017\n",
      "step: 6162.0, loss:0.27720864\n",
      "step: 6163.0, loss:0.09895640\n",
      "step: 6164.0, loss:0.32897153\n",
      "step: 6165.0, loss:0.17482089\n",
      "step: 6166.0, loss:0.43899623\n",
      "step: 6167.0, loss:0.15512313\n",
      "step: 6168.0, loss:0.19462309\n",
      "step: 6169.0, loss:0.28269392\n",
      "step: 6170.0, loss:0.29771216\n",
      "step: 6171.0, loss:0.28379653\n",
      "step: 6172.0, loss:0.23591999\n",
      "step: 6173.0, loss:0.18753902\n",
      "step: 6174.0, loss:0.28259710\n",
      "step: 6175.0, loss:0.38767057\n",
      "step: 6176.0, loss:0.36588766\n",
      "step: 6177.0, loss:0.31222652\n",
      "step: 6178.0, loss:0.34033918\n",
      "step: 6179.0, loss:0.25393268\n",
      "step: 6180.0, loss:0.29715130\n",
      "step: 6181.0, loss:0.42867307\n",
      "step: 6182.0, loss:0.27728356\n",
      "step: 6183.0, loss:0.23971165\n",
      "step: 6184.0, loss:0.34252934\n",
      "step: 6185.0, loss:0.18628241\n",
      "step: 6186.0, loss:0.25064254\n",
      "step: 6187.0, loss:0.20512769\n",
      "step: 6188.0, loss:0.24529039\n",
      "step: 6189.0, loss:0.20995886\n",
      "step: 6190.0, loss:0.23431971\n",
      "step: 6191.0, loss:0.20264746\n",
      "step: 6192.0, loss:0.28437905\n",
      "step: 6193.0, loss:0.29020779\n",
      "step: 6194.0, loss:0.30720498\n",
      "step: 6195.0, loss:0.25734035\n",
      "step: 6196.0, loss:0.31986534\n",
      "step: 6197.0, loss:0.31313401\n",
      "step: 6198.0, loss:0.33015004\n",
      "step: 6199.0, loss:0.33731425\n",
      "step: 6200.0, loss:0.20223568\n",
      "step: 6201.0, loss:0.34843032\n",
      "step: 6202.0, loss:0.45208384\n",
      "step: 6203.0, loss:0.28721052\n",
      "step: 6204.0, loss:0.37070301\n",
      "step: 6205.0, loss:0.22066839\n",
      "step: 6206.0, loss:0.32137574\n",
      "step: 6207.0, loss:0.22761482\n",
      "step: 6208.0, loss:0.25931979\n",
      "step: 6209.0, loss:0.23402089\n",
      "step: 6210.0, loss:0.25902372\n",
      "step: 6211.0, loss:0.37297501\n",
      "step: 6212.0, loss:0.33157641\n",
      "step: 6213.0, loss:0.30393949\n",
      "step: 6214.0, loss:0.20578560\n",
      "step: 6215.0, loss:0.26673247\n",
      "step: 6216.0, loss:0.16332805\n",
      "step: 6217.0, loss:0.22268738\n",
      "step: 6218.0, loss:0.19440674\n",
      "step: 6219.0, loss:0.29079519\n",
      "step: 6220.0, loss:0.27319162\n",
      "step: 6221.0, loss:0.19817949\n",
      "step: 6222.0, loss:0.26171839\n",
      "step: 6223.0, loss:0.19917669\n",
      "step: 6224.0, loss:0.23924049\n",
      "step: 6225.0, loss:0.23768103\n",
      "step: 6226.0, loss:0.42194552\n",
      "step: 6227.0, loss:0.30164896\n",
      "step: 6228.0, loss:0.24249311\n",
      "step: 6229.0, loss:0.21550524\n",
      "step: 6230.0, loss:0.33181906\n",
      "step: 6231.0, loss:0.33042955\n",
      "step: 6232.0, loss:0.24031701\n",
      "step: 6233.0, loss:0.36594969\n",
      "step: 6234.0, loss:0.29185937\n",
      "step: 6235.0, loss:0.36195305\n",
      "step: 6236.0, loss:0.38389219\n",
      "step: 6237.0, loss:0.23135721\n",
      "step: 6238.0, loss:0.31834023\n",
      "step: 6239.0, loss:0.36413250\n",
      "step: 6240.0, loss:0.30504187\n",
      "step: 6241.0, loss:0.25928354\n",
      "step: 6242.0, loss:0.29101519\n",
      "step: 6243.0, loss:0.20233311\n",
      "step: 6244.0, loss:0.37281772\n",
      "step: 6245.0, loss:0.27588210\n",
      "step: 6246.0, loss:0.30865233\n",
      "step: 6247.0, loss:0.24809005\n",
      "step: 6248.0, loss:0.26551332\n",
      "step: 6249.0, loss:0.24297781\n",
      "step: 6250.0, loss:0.16867044\n",
      "step: 6251.0, loss:0.29803918\n",
      "step: 6252.0, loss:0.24933835\n",
      "step: 6253.0, loss:0.27899722\n",
      "step: 6254.0, loss:0.28488677\n",
      "step: 6255.0, loss:0.33019957\n",
      "step: 6256.0, loss:0.32085798\n",
      "step: 6257.0, loss:0.20968169\n",
      "step: 6258.0, loss:0.23860628\n",
      "step: 6259.0, loss:0.27687173\n",
      "step: 6260.0, loss:0.26350452\n",
      "step: 6261.0, loss:0.19007982\n",
      "step: 6262.0, loss:0.20018887\n",
      "step: 6263.0, loss:0.27146323\n",
      "step: 6264.0, loss:0.20710429\n",
      "step: 6265.0, loss:0.35698671\n",
      "step: 6266.0, loss:0.22136657\n",
      "step: 6267.0, loss:0.40952438\n",
      "step: 6268.0, loss:0.18116339\n",
      "step: 6269.0, loss:0.28456732\n",
      "step: 6270.0, loss:0.26122439\n",
      "step: 6271.0, loss:0.36748945\n",
      "step: 6272.0, loss:0.22469638\n",
      "step: 6273.0, loss:0.31757963\n",
      "step: 6274.0, loss:0.27380439\n",
      "step: 6275.0, loss:0.28466877\n",
      "step: 6276.0, loss:0.33048462\n",
      "step: 6277.0, loss:0.26559747\n",
      "step: 6278.0, loss:0.16900162\n",
      "step: 6279.0, loss:0.24888728\n",
      "step: 6280.0, loss:0.44392323\n",
      "step: 6281.0, loss:0.35437866\n",
      "step: 6282.0, loss:0.19994795\n",
      "step: 6283.0, loss:0.34030514\n",
      "step: 6284.0, loss:0.21103429\n",
      "step: 6285.0, loss:0.25306763\n",
      "step: 6286.0, loss:0.33971845\n",
      "step: 6287.0, loss:0.25186079\n",
      "step: 6288.0, loss:0.20522815\n",
      "step: 6289.0, loss:0.41389565\n",
      "step: 6290.0, loss:0.20295222\n",
      "step: 6291.0, loss:0.26165194\n",
      "step: 6292.0, loss:0.31533612\n",
      "step: 6293.0, loss:0.22589512\n",
      "step: 6294.0, loss:0.24888280\n",
      "step: 6295.0, loss:0.38977133\n",
      "step: 6296.0, loss:0.22000088\n",
      "step: 6297.0, loss:0.27760043\n",
      "step: 6298.0, loss:0.21402836\n",
      "step: 6299.0, loss:0.22433611\n",
      "step: 6300.0, loss:0.36150594\n",
      "step: 6301.0, loss:0.21816659\n",
      "step: 6302.0, loss:0.24143961\n",
      "step: 6303.0, loss:0.36671268\n",
      "step: 6304.0, loss:0.26225251\n",
      "step: 6305.0, loss:0.41451426\n",
      "step: 6306.0, loss:0.31843984\n",
      "step: 6307.0, loss:0.20953321\n",
      "step: 6308.0, loss:0.37510915\n",
      "step: 6309.0, loss:0.29888547\n",
      "step: 6310.0, loss:0.44032762\n",
      "step: 6311.0, loss:0.33348047\n",
      "step: 6312.0, loss:0.32921932\n",
      "step: 6313.0, loss:0.26167180\n",
      "step: 6314.0, loss:0.35451702\n",
      "step: 6315.0, loss:0.22789550\n",
      "step: 6316.0, loss:0.27848814\n",
      "step: 6317.0, loss:0.30864068\n",
      "step: 6318.0, loss:0.34454489\n",
      "step: 6319.0, loss:0.41392127\n",
      "step: 6320.0, loss:0.27175061\n",
      "step: 6321.0, loss:0.35700862\n",
      "step: 6322.0, loss:0.33740567\n",
      "step: 6323.0, loss:0.26588139\n",
      "step: 6324.0, loss:0.23098137\n",
      "step: 6325.0, loss:0.38939402\n",
      "step: 6326.0, loss:0.25869596\n",
      "step: 6327.0, loss:0.27988143\n",
      "step: 6328.0, loss:0.23594430\n",
      "step: 6329.0, loss:0.30539139\n",
      "step: 6330.0, loss:0.16878890\n",
      "step: 6331.0, loss:0.26549731\n",
      "step: 6332.0, loss:0.39593417\n",
      "step: 6333.0, loss:0.35379908\n",
      "step: 6334.0, loss:0.28831041\n",
      "step: 6335.0, loss:0.25298063\n",
      "step: 6336.0, loss:0.29195090\n",
      "step: 6337.0, loss:0.27889744\n",
      "step: 6338.0, loss:0.30595398\n",
      "step: 6339.0, loss:0.42200495\n",
      "step: 6340.0, loss:0.17638547\n",
      "step: 6341.0, loss:0.25258419\n",
      "step: 6342.0, loss:0.22247387\n",
      "step: 6343.0, loss:0.36703095\n",
      "step: 6344.0, loss:0.42942805\n",
      "step: 6345.0, loss:0.22149486\n",
      "step: 6346.0, loss:0.32913512\n",
      "step: 6347.0, loss:0.37072051\n",
      "step: 6348.0, loss:0.20941076\n",
      "step: 6349.0, loss:0.39526526\n",
      "step: 6350.0, loss:0.19016673\n",
      "step: 6351.0, loss:0.31428687\n",
      "step: 6352.0, loss:0.26941474\n",
      "step: 6353.0, loss:0.29684155\n",
      "step: 6354.0, loss:0.31299669\n",
      "step: 6355.0, loss:0.23934598\n",
      "step: 6356.0, loss:0.29785617\n",
      "step: 6357.0, loss:0.31690666\n",
      "step: 6358.0, loss:0.28312044\n",
      "step: 6359.0, loss:0.29044439\n",
      "step: 6360.0, loss:0.25701727\n",
      "step: 6361.0, loss:0.25540241\n",
      "step: 6362.0, loss:0.34888531\n",
      "step: 6363.0, loss:0.39949889\n",
      "step: 6364.0, loss:0.34183873\n",
      "step: 6365.0, loss:0.35958605\n",
      "step: 6366.0, loss:0.25232084\n",
      "step: 6367.0, loss:0.24259967\n",
      "step: 6368.0, loss:0.34866874\n",
      "step: 6369.0, loss:0.21829550\n",
      "step: 6370.0, loss:0.33397995\n",
      "step: 6371.0, loss:0.19569666\n",
      "step: 6372.0, loss:0.37762137\n",
      "step: 6373.0, loss:0.26188404\n",
      "step: 6374.0, loss:0.24888875\n",
      "step: 6375.0, loss:0.35228383\n",
      "step: 6376.0, loss:0.24448948\n",
      "step: 6377.0, loss:0.32025766\n",
      "step: 6378.0, loss:0.24759331\n",
      "step: 6379.0, loss:0.32271711\n",
      "step: 6380.0, loss:0.26076199\n",
      "step: 6381.0, loss:0.30671574\n",
      "step: 6382.0, loss:0.23106455\n",
      "step: 6383.0, loss:0.31943921\n",
      "step: 6384.0, loss:0.46926669\n",
      "step: 6385.0, loss:0.39344451\n",
      "step: 6386.0, loss:0.32394107\n",
      "step: 6387.0, loss:0.25018446\n",
      "step: 6388.0, loss:0.19763099\n",
      "step: 6389.0, loss:0.24744747\n",
      "step: 6390.0, loss:0.42543386\n",
      "step: 6391.0, loss:0.19529145\n",
      "step: 6392.0, loss:0.42740826\n",
      "step: 6393.0, loss:0.24156339\n",
      "step: 6394.0, loss:0.17653202\n",
      "step: 6395.0, loss:0.27357172\n",
      "step: 6396.0, loss:0.20728297\n",
      "step: 6397.0, loss:0.29416938\n",
      "step: 6398.0, loss:0.23417674\n",
      "step: 6399.0, loss:0.23382165\n",
      "step: 6400.0, loss:0.28185904\n",
      "step: 6401.0, loss:0.19910747\n",
      "step: 6402.0, loss:0.37413971\n",
      "step: 6403.0, loss:0.29471119\n",
      "step: 6404.0, loss:0.34175946\n",
      "step: 6405.0, loss:0.26522424\n",
      "step: 6406.0, loss:0.23155539\n",
      "step: 6407.0, loss:0.22575783\n",
      "step: 6408.0, loss:0.28986381\n",
      "step: 6409.0, loss:0.29741987\n",
      "step: 6410.0, loss:0.27900496\n",
      "step: 6411.0, loss:0.34066895\n",
      "step: 6412.0, loss:0.25650828\n",
      "step: 6413.0, loss:0.31764907\n",
      "step: 6414.0, loss:0.25799740\n",
      "step: 6415.0, loss:0.39369495\n",
      "step: 6416.0, loss:0.32288716\n",
      "step: 6417.0, loss:0.24407423\n",
      "step: 6418.0, loss:0.22394921\n",
      "step: 6419.0, loss:0.21474229\n",
      "step: 6420.0, loss:0.24041122\n",
      "step: 6421.0, loss:0.30571370\n",
      "step: 6422.0, loss:0.34704810\n",
      "step: 6423.0, loss:0.26695976\n",
      "step: 6424.0, loss:0.23103302\n",
      "step: 6425.0, loss:0.24698530\n",
      "step: 6426.0, loss:0.32190206\n",
      "step: 6427.0, loss:0.39606229\n",
      "step: 6428.0, loss:0.21467507\n",
      "step: 6429.0, loss:0.25252129\n",
      "step: 6430.0, loss:0.23935784\n",
      "step: 6431.0, loss:0.21062265\n",
      "step: 6432.0, loss:0.31700835\n",
      "step: 6433.0, loss:0.33390364\n",
      "step: 6434.0, loss:0.26269004\n",
      "step: 6435.0, loss:0.33440376\n",
      "step: 6436.0, loss:0.19971635\n",
      "step: 6437.0, loss:0.32193612\n",
      "step: 6438.0, loss:0.21533661\n",
      "step: 6439.0, loss:0.22543157\n",
      "step: 6440.0, loss:0.25936689\n",
      "step: 6441.0, loss:0.24138748\n",
      "step: 6442.0, loss:0.27677328\n",
      "step: 6443.0, loss:0.25291564\n",
      "step: 6444.0, loss:0.36329186\n",
      "step: 6445.0, loss:0.16399825\n",
      "step: 6446.0, loss:0.36429159\n",
      "step: 6447.0, loss:0.24002270\n",
      "step: 6448.0, loss:0.30095151\n",
      "step: 6449.0, loss:0.16384047\n",
      "step: 6450.0, loss:0.16944665\n",
      "step: 6451.0, loss:0.21725665\n",
      "step: 6452.0, loss:0.30306927\n",
      "step: 6453.0, loss:0.43569582\n",
      "step: 6454.0, loss:0.28166148\n",
      "step: 6455.0, loss:0.17942275\n",
      "step: 6456.0, loss:0.25199310\n",
      "step: 6457.0, loss:0.24565271\n",
      "step: 6458.0, loss:0.22776349\n",
      "step: 6459.0, loss:0.33095255\n",
      "step: 6460.0, loss:0.26108442\n",
      "step: 6461.0, loss:0.31901313\n",
      "step: 6462.0, loss:0.37150201\n",
      "step: 6463.0, loss:0.26309032\n",
      "step: 6464.0, loss:0.22320182\n",
      "step: 6465.0, loss:0.25563016\n",
      "step: 6466.0, loss:0.38957097\n",
      "step: 6467.0, loss:0.38991240\n",
      "step: 6468.0, loss:0.13190725\n",
      "step: 6469.0, loss:0.31742660\n",
      "step: 6470.0, loss:0.26943064\n",
      "step: 6471.0, loss:0.30133835\n",
      "step: 6472.0, loss:0.31497044\n",
      "step: 6473.0, loss:0.32589859\n",
      "step: 6474.0, loss:0.28699042\n",
      "step: 6475.0, loss:0.32403285\n",
      "step: 6476.0, loss:0.14040035\n",
      "step: 6477.0, loss:0.30458765\n",
      "step: 6478.0, loss:0.24019399\n",
      "step: 6479.0, loss:0.24863905\n",
      "step: 6480.0, loss:0.25110568\n",
      "step: 6481.0, loss:0.25181338\n",
      "step: 6482.0, loss:0.26452857\n",
      "step: 6483.0, loss:0.35771536\n",
      "step: 6484.0, loss:0.27031325\n",
      "step: 6485.0, loss:0.40011138\n",
      "step: 6486.0, loss:0.26704392\n",
      "step: 6487.0, loss:0.24321692\n",
      "step: 6488.0, loss:0.37137296\n",
      "step: 6489.0, loss:0.23368084\n",
      "step: 6490.0, loss:0.34586333\n",
      "step: 6491.0, loss:0.43148022\n",
      "step: 6492.0, loss:0.31275731\n",
      "step: 6493.0, loss:0.33631181\n",
      "step: 6494.0, loss:0.25391980\n",
      "step: 6495.0, loss:0.24795405\n",
      "step: 6496.0, loss:0.23720331\n",
      "step: 6497.0, loss:0.30399642\n",
      "step: 6498.0, loss:0.22146759\n",
      "step: 6499.0, loss:0.24856764\n",
      "step: 6500.0, loss:0.28941133\n",
      "step: 6501.0, loss:0.25611912\n",
      "step: 6502.0, loss:0.26388762\n",
      "step: 6503.0, loss:0.24171442\n",
      "step: 6504.0, loss:0.34442995\n",
      "step: 6505.0, loss:0.25804717\n",
      "step: 6506.0, loss:0.24429929\n",
      "step: 6507.0, loss:0.25802182\n",
      "step: 6508.0, loss:0.24926407\n",
      "step: 6509.0, loss:0.27887470\n",
      "step: 6510.0, loss:0.22929019\n",
      "step: 6511.0, loss:0.23042053\n",
      "step: 6512.0, loss:0.36348839\n",
      "step: 6513.0, loss:0.14916027\n",
      "step: 6514.0, loss:0.21729258\n",
      "step: 6515.0, loss:0.30440871\n",
      "step: 6516.0, loss:0.27505292\n",
      "step: 6517.0, loss:0.25125818\n",
      "step: 6518.0, loss:0.25145293\n",
      "step: 6519.0, loss:0.26386138\n",
      "step: 6520.0, loss:0.28957757\n",
      "step: 6521.0, loss:0.24063940\n",
      "step: 6522.0, loss:0.21885193\n",
      "step: 6523.0, loss:0.29751412\n",
      "step: 6524.0, loss:0.27514666\n",
      "step: 6525.0, loss:0.31672866\n",
      "step: 6526.0, loss:0.30825914\n",
      "step: 6527.0, loss:0.32705965\n",
      "step: 6528.0, loss:0.23340217\n",
      "step: 6529.0, loss:0.26580090\n",
      "step: 6530.0, loss:0.24281972\n",
      "step: 6531.0, loss:0.23928615\n",
      "step: 6532.0, loss:0.19929711\n",
      "step: 6533.0, loss:0.35621309\n",
      "step: 6534.0, loss:0.23123909\n",
      "step: 6535.0, loss:0.20060321\n",
      "step: 6536.0, loss:0.17391410\n",
      "step: 6537.0, loss:0.24812795\n",
      "step: 6538.0, loss:0.32617336\n",
      "step: 6539.0, loss:0.29875730\n",
      "step: 6540.0, loss:0.31810401\n",
      "step: 6541.0, loss:0.29906856\n",
      "step: 6542.0, loss:0.33155094\n",
      "step: 6543.0, loss:0.22605306\n",
      "step: 6544.0, loss:0.24544317\n",
      "step: 6545.0, loss:0.33460196\n",
      "step: 6546.0, loss:0.33264258\n",
      "step: 6547.0, loss:0.32358418\n",
      "step: 6548.0, loss:0.18222904\n",
      "step: 6549.0, loss:0.18868041\n",
      "step: 6550.0, loss:0.28376431\n",
      "step: 6551.0, loss:0.21576908\n",
      "step: 6552.0, loss:0.26837567\n",
      "step: 6553.0, loss:0.37813618\n",
      "step: 6554.0, loss:0.39018095\n",
      "step: 6555.0, loss:0.20363997\n",
      "step: 6556.0, loss:0.29207173\n",
      "step: 6557.0, loss:0.17769329\n",
      "step: 6558.0, loss:0.18965519\n",
      "step: 6559.0, loss:0.16924869\n",
      "step: 6560.0, loss:0.32945928\n",
      "step: 6561.0, loss:0.32772902\n",
      "step: 6562.0, loss:0.22559599\n",
      "step: 6563.0, loss:0.31860106\n",
      "step: 6564.0, loss:0.17196103\n",
      "step: 6565.0, loss:0.28348276\n",
      "step: 6566.0, loss:0.28805031\n",
      "step: 6567.0, loss:0.29449925\n",
      "step: 6568.0, loss:0.29514473\n",
      "step: 6569.0, loss:0.23709728\n",
      "step: 6570.0, loss:0.25117505\n",
      "step: 6571.0, loss:0.36156866\n",
      "step: 6572.0, loss:0.26570138\n",
      "step: 6573.0, loss:0.23561364\n",
      "step: 6574.0, loss:0.27416510\n",
      "step: 6575.0, loss:0.32088425\n",
      "step: 6576.0, loss:0.35163122\n",
      "step: 6577.0, loss:0.29620538\n",
      "step: 6578.0, loss:0.34827462\n",
      "step: 6579.0, loss:0.23524822\n",
      "step: 6580.0, loss:0.16245021\n",
      "step: 6581.0, loss:0.31433363\n",
      "step: 6582.0, loss:0.30869794\n",
      "step: 6583.0, loss:0.26486914\n",
      "step: 6584.0, loss:0.21610105\n",
      "step: 6585.0, loss:0.26337031\n",
      "step: 6586.0, loss:0.25846601\n",
      "step: 6587.0, loss:0.29072213\n",
      "step: 6588.0, loss:0.19942499\n",
      "step: 6589.0, loss:0.30440759\n",
      "step: 6590.0, loss:0.30637959\n",
      "step: 6591.0, loss:0.27622698\n",
      "step: 6592.0, loss:0.12230573\n",
      "step: 6593.0, loss:0.28259687\n",
      "step: 6594.0, loss:0.29564630\n",
      "step: 6595.0, loss:0.17730369\n",
      "step: 6596.0, loss:0.21373350\n",
      "step: 6597.0, loss:0.24301577\n",
      "step: 6598.0, loss:0.37211401\n",
      "step: 6599.0, loss:0.36832929\n",
      "step: 6600.0, loss:0.20482007\n",
      "step: 6601.0, loss:0.16506360\n",
      "step: 6602.0, loss:0.16753095\n",
      "step: 6603.0, loss:0.23672357\n",
      "step: 6604.0, loss:0.39149917\n",
      "step: 6605.0, loss:0.24628631\n",
      "step: 6606.0, loss:0.31097796\n",
      "step: 6607.0, loss:0.23322732\n",
      "step: 6608.0, loss:0.33176916\n",
      "step: 6609.0, loss:0.26762784\n",
      "step: 6610.0, loss:0.30840930\n",
      "step: 6611.0, loss:0.21718620\n",
      "step: 6612.0, loss:0.23821134\n",
      "step: 6613.0, loss:0.24578096\n",
      "step: 6614.0, loss:0.30581398\n",
      "step: 6615.0, loss:0.18250345\n",
      "step: 6616.0, loss:0.18984515\n",
      "step: 6617.0, loss:0.31252075\n",
      "step: 6618.0, loss:0.15563878\n",
      "step: 6619.0, loss:0.19498095\n",
      "step: 6620.0, loss:0.31539595\n",
      "step: 6621.0, loss:0.25250248\n",
      "step: 6622.0, loss:0.23468660\n",
      "step: 6623.0, loss:0.27483039\n",
      "step: 6624.0, loss:0.23128359\n",
      "step: 6625.0, loss:0.19376244\n",
      "step: 6626.0, loss:0.39557021\n",
      "step: 6627.0, loss:0.23202223\n",
      "step: 6628.0, loss:0.23241368\n",
      "step: 6629.0, loss:0.39396905\n",
      "step: 6630.0, loss:0.30776788\n",
      "step: 6631.0, loss:0.21525677\n",
      "step: 6632.0, loss:0.23522844\n",
      "step: 6633.0, loss:0.33128654\n",
      "step: 6634.0, loss:0.32278068\n",
      "step: 6635.0, loss:0.20249163\n",
      "step: 6636.0, loss:0.22363409\n",
      "step: 6637.0, loss:0.27639876\n",
      "step: 6638.0, loss:0.19379856\n",
      "step: 6639.0, loss:0.15891799\n",
      "step: 6640.0, loss:0.11908848\n",
      "step: 6641.0, loss:0.30546289\n",
      "step: 6642.0, loss:0.30649492\n",
      "step: 6643.0, loss:0.30647616\n",
      "step: 6644.0, loss:0.30206516\n",
      "step: 6645.0, loss:0.32894237\n",
      "step: 6646.0, loss:0.23086608\n",
      "step: 6647.0, loss:0.20346556\n",
      "step: 6648.0, loss:0.34230436\n",
      "step: 6649.0, loss:0.39859985\n",
      "step: 6650.0, loss:0.26780732\n",
      "step: 6651.0, loss:0.35025942\n",
      "step: 6652.0, loss:0.34088161\n",
      "step: 6653.0, loss:0.26069164\n",
      "step: 6654.0, loss:0.24831234\n",
      "step: 6655.0, loss:0.26371222\n",
      "step: 6656.0, loss:0.21232984\n",
      "step: 6657.0, loss:0.34474512\n",
      "step: 6658.0, loss:0.28474977\n",
      "step: 6659.0, loss:0.44837550\n",
      "step: 6660.0, loss:0.33437622\n",
      "step: 6661.0, loss:0.17527589\n",
      "step: 6662.0, loss:0.20430445\n",
      "step: 6663.0, loss:0.26395990\n",
      "step: 6664.0, loss:0.20650920\n",
      "step: 6665.0, loss:0.22846201\n",
      "step: 6666.0, loss:0.21592362\n",
      "step: 6667.0, loss:0.26187731\n",
      "step: 6668.0, loss:0.27908896\n",
      "step: 6669.0, loss:0.16491267\n",
      "step: 6670.0, loss:0.30146981\n",
      "step: 6671.0, loss:0.21098251\n",
      "step: 6672.0, loss:0.26603603\n",
      "step: 6673.0, loss:0.24242903\n",
      "step: 6674.0, loss:0.28897175\n",
      "step: 6675.0, loss:0.32504602\n",
      "step: 6676.0, loss:0.19703868\n",
      "step: 6677.0, loss:0.29552602\n",
      "step: 6678.0, loss:0.33008462\n",
      "step: 6679.0, loss:0.21320596\n",
      "step: 6680.0, loss:0.20843077\n",
      "step: 6681.0, loss:0.33311310\n",
      "step: 6682.0, loss:0.34194173\n",
      "step: 6683.0, loss:0.30264900\n",
      "step: 6684.0, loss:0.28429421\n",
      "step: 6685.0, loss:0.19770427\n",
      "step: 6686.0, loss:0.38770883\n",
      "step: 6687.0, loss:0.24736463\n",
      "step: 6688.0, loss:0.27735319\n",
      "step: 6689.0, loss:0.30701048\n",
      "step: 6690.0, loss:0.26647466\n",
      "step: 6691.0, loss:0.17773204\n",
      "step: 6692.0, loss:0.17770706\n",
      "step: 6693.0, loss:0.14200472\n",
      "step: 6694.0, loss:0.21681117\n",
      "step: 6695.0, loss:0.35892711\n",
      "step: 6696.0, loss:0.43245342\n",
      "step: 6697.0, loss:0.37833757\n",
      "step: 6698.0, loss:0.29189004\n",
      "step: 6699.0, loss:0.31293738\n",
      "step: 6700.0, loss:0.32759193\n",
      "step: 6701.0, loss:0.25736846\n",
      "step: 6702.0, loss:0.40698197\n",
      "step: 6703.0, loss:0.24696040\n",
      "step: 6704.0, loss:0.22153438\n",
      "step: 6705.0, loss:0.26066013\n",
      "step: 6706.0, loss:0.28929876\n",
      "step: 6707.0, loss:0.23914765\n",
      "step: 6708.0, loss:0.20028098\n",
      "step: 6709.0, loss:0.19510140\n",
      "step: 6710.0, loss:0.22212346\n",
      "step: 6711.0, loss:0.25144401\n",
      "step: 6712.0, loss:0.24161218\n",
      "step: 6713.0, loss:0.25677247\n",
      "step: 6714.0, loss:0.17751556\n",
      "step: 6715.0, loss:0.23131374\n",
      "step: 6716.0, loss:0.15997015\n",
      "step: 6717.0, loss:0.24059454\n",
      "step: 6718.0, loss:0.27673037\n",
      "step: 6719.0, loss:0.24369937\n",
      "step: 6720.0, loss:0.22995298\n",
      "step: 6721.0, loss:0.24409313\n",
      "step: 6722.0, loss:0.24085940\n",
      "step: 6723.0, loss:0.29645010\n",
      "step: 6724.0, loss:0.35551401\n",
      "step: 6725.0, loss:0.18979323\n",
      "step: 6726.0, loss:0.28421838\n",
      "step: 6727.0, loss:0.24937493\n",
      "step: 6728.0, loss:0.26413579\n",
      "step: 6729.0, loss:0.23095794\n",
      "step: 6730.0, loss:0.22150642\n",
      "step: 6731.0, loss:0.19943123\n",
      "step: 6732.0, loss:0.27009687\n",
      "step: 6733.0, loss:0.21473439\n",
      "step: 6734.0, loss:0.31338281\n",
      "step: 6735.0, loss:0.25316787\n",
      "step: 6736.0, loss:0.12648403\n",
      "step: 6737.0, loss:0.19265869\n",
      "step: 6738.0, loss:0.31838794\n",
      "step: 6739.0, loss:0.29083938\n",
      "step: 6740.0, loss:0.28775201\n",
      "step: 6741.0, loss:0.24628198\n",
      "step: 6742.0, loss:0.28149227\n",
      "step: 6743.0, loss:0.27568400\n",
      "step: 6744.0, loss:0.27623550\n",
      "step: 6745.0, loss:0.24290314\n",
      "step: 6746.0, loss:0.14754471\n",
      "step: 6747.0, loss:0.18784117\n",
      "step: 6748.0, loss:0.18036508\n",
      "step: 6749.0, loss:0.22627530\n",
      "step: 6750.0, loss:0.22468204\n",
      "step: 6751.0, loss:0.24393730\n",
      "step: 6752.0, loss:0.30854327\n",
      "step: 6753.0, loss:0.24579683\n",
      "step: 6754.0, loss:0.15868958\n",
      "step: 6755.0, loss:0.23360177\n",
      "step: 6756.0, loss:0.27091630\n",
      "step: 6757.0, loss:0.29229068\n",
      "step: 6758.0, loss:0.24013252\n",
      "step: 6759.0, loss:0.24403770\n",
      "step: 6760.0, loss:0.29162768\n",
      "step: 6761.0, loss:0.20642518\n",
      "step: 6762.0, loss:0.41327110\n",
      "step: 6763.0, loss:0.37327638\n",
      "step: 6764.0, loss:0.28606477\n",
      "step: 6765.0, loss:0.36574833\n",
      "step: 6766.0, loss:0.31071636\n",
      "step: 6767.0, loss:0.31751155\n",
      "step: 6768.0, loss:0.34759988\n",
      "step: 6769.0, loss:0.22662853\n",
      "step: 6770.0, loss:0.34605963\n",
      "step: 6771.0, loss:0.26900910\n",
      "step: 6772.0, loss:0.26698405\n",
      "step: 6773.0, loss:0.19702839\n",
      "step: 6774.0, loss:0.16984590\n",
      "step: 6775.0, loss:0.34603868\n",
      "step: 6776.0, loss:0.30964823\n",
      "step: 6777.0, loss:0.23074502\n",
      "step: 6778.0, loss:0.16929914\n",
      "step: 6779.0, loss:0.24867784\n",
      "step: 6780.0, loss:0.39668197\n",
      "step: 6781.0, loss:0.36374200\n",
      "step: 6782.0, loss:0.13880815\n",
      "step: 6783.0, loss:0.34223241\n",
      "step: 6784.0, loss:0.28880362\n",
      "step: 6785.0, loss:0.21650511\n",
      "step: 6786.0, loss:0.14919535\n",
      "step: 6787.0, loss:0.24268959\n",
      "step: 6788.0, loss:0.22733004\n",
      "step: 6789.0, loss:0.11998633\n",
      "step: 6790.0, loss:0.22192563\n",
      "step: 6791.0, loss:0.40482269\n",
      "step: 6792.0, loss:0.24195200\n",
      "step: 6793.0, loss:0.30613939\n",
      "step: 6794.0, loss:0.26274409\n",
      "step: 6795.0, loss:0.23031193\n",
      "step: 6796.0, loss:0.27051325\n",
      "step: 6797.0, loss:0.22125236\n",
      "step: 6798.0, loss:0.28136096\n",
      "step: 6799.0, loss:0.37533630\n",
      "step: 6800.0, loss:0.43569060\n",
      "step: 6801.0, loss:0.27678665\n",
      "step: 6802.0, loss:0.22670612\n",
      "step: 6803.0, loss:0.36136522\n",
      "step: 6804.0, loss:0.25633073\n",
      "step: 6805.0, loss:0.20607529\n",
      "step: 6806.0, loss:0.40830845\n",
      "step: 6807.0, loss:0.32260367\n",
      "step: 6808.0, loss:0.24029713\n",
      "step: 6809.0, loss:0.25826365\n",
      "step: 6810.0, loss:0.41163654\n",
      "step: 6811.0, loss:0.27928972\n",
      "step: 6812.0, loss:0.26333004\n",
      "step: 6813.0, loss:0.29167996\n",
      "step: 6814.0, loss:0.19647099\n",
      "step: 6815.0, loss:0.38488258\n",
      "step: 6816.0, loss:0.44145723\n",
      "step: 6817.0, loss:0.21860274\n",
      "step: 6818.0, loss:0.20972896\n",
      "step: 6819.0, loss:0.16032050\n",
      "step: 6820.0, loss:0.17504210\n",
      "step: 6821.0, loss:0.23140757\n",
      "step: 6822.0, loss:0.27978968\n",
      "step: 6823.0, loss:0.35355523\n",
      "step: 6824.0, loss:0.22170111\n",
      "step: 6825.0, loss:0.33244831\n",
      "step: 6826.0, loss:0.18066226\n",
      "step: 6827.0, loss:0.24803810\n",
      "step: 6828.0, loss:0.21800737\n",
      "step: 6829.0, loss:0.25655566\n",
      "step: 6830.0, loss:0.32298440\n",
      "step: 6831.0, loss:0.26956739\n",
      "step: 6832.0, loss:0.29059236\n",
      "step: 6833.0, loss:0.15140998\n",
      "step: 6834.0, loss:0.26789521\n",
      "step: 6835.0, loss:0.28040253\n",
      "step: 6836.0, loss:0.22173752\n",
      "step: 6837.0, loss:0.24625739\n",
      "step: 6838.0, loss:0.23085463\n",
      "step: 6839.0, loss:0.34892165\n",
      "step: 6840.0, loss:0.39614547\n",
      "step: 6841.0, loss:0.22245668\n",
      "step: 6842.0, loss:0.17693511\n",
      "step: 6843.0, loss:0.30172900\n",
      "step: 6844.0, loss:0.30594801\n",
      "step: 6845.0, loss:0.15359282\n",
      "step: 6846.0, loss:0.30670160\n",
      "step: 6847.0, loss:0.27333184\n",
      "step: 6848.0, loss:0.35557910\n",
      "step: 6849.0, loss:0.18860016\n",
      "step: 6850.0, loss:0.32473796\n",
      "step: 6851.0, loss:0.20899392\n",
      "step: 6852.0, loss:0.18524856\n",
      "step: 6853.0, loss:0.24469155\n",
      "step: 6854.0, loss:0.14997449\n",
      "step: 6855.0, loss:0.42554219\n",
      "step: 6856.0, loss:0.25233087\n",
      "step: 6857.0, loss:0.30253772\n",
      "step: 6858.0, loss:0.24914855\n",
      "step: 6859.0, loss:0.25985597\n",
      "step: 6860.0, loss:0.26951555\n",
      "step: 6861.0, loss:0.40565714\n",
      "step: 6862.0, loss:0.26008859\n",
      "step: 6863.0, loss:0.41207106\n",
      "step: 6864.0, loss:0.24477389\n",
      "step: 6865.0, loss:0.39962291\n",
      "step: 6866.0, loss:0.22684897\n",
      "step: 6867.0, loss:0.30683065\n",
      "step: 6868.0, loss:0.21844229\n",
      "step: 6869.0, loss:0.31546824\n",
      "step: 6870.0, loss:0.25145014\n",
      "step: 6871.0, loss:0.21431250\n",
      "step: 6872.0, loss:0.37646626\n",
      "step: 6873.0, loss:0.20961059\n",
      "step: 6874.0, loss:0.16763654\n",
      "step: 6875.0, loss:0.17168809\n",
      "step: 6876.0, loss:0.28601167\n",
      "step: 6877.0, loss:0.27611483\n",
      "step: 6878.0, loss:0.33288905\n",
      "step: 6879.0, loss:0.16992217\n",
      "step: 6880.0, loss:0.26134706\n",
      "step: 6881.0, loss:0.17739333\n",
      "step: 6882.0, loss:0.24562206\n",
      "step: 6883.0, loss:0.26408960\n",
      "step: 6884.0, loss:0.26751254\n",
      "step: 6885.0, loss:0.25008161\n",
      "step: 6886.0, loss:0.26832794\n",
      "step: 6887.0, loss:0.19632777\n",
      "step: 6888.0, loss:0.29775001\n",
      "step: 6889.0, loss:0.29135160\n",
      "step: 6890.0, loss:0.21689644\n",
      "step: 6891.0, loss:0.17737914\n",
      "step: 6892.0, loss:0.30973363\n",
      "step: 6893.0, loss:0.33699585\n",
      "step: 6894.0, loss:0.23785200\n",
      "step: 6895.0, loss:0.19879187\n",
      "step: 6896.0, loss:0.40549573\n",
      "step: 6897.0, loss:0.18800317\n",
      "step: 6898.0, loss:0.30712871\n",
      "step: 6899.0, loss:0.19161319\n",
      "step: 6900.0, loss:0.23586574\n",
      "step: 6901.0, loss:0.21443620\n",
      "step: 6902.0, loss:0.26317073\n",
      "step: 6903.0, loss:0.44140008\n",
      "step: 6904.0, loss:0.21229820\n",
      "step: 6905.0, loss:0.18888004\n",
      "step: 6906.0, loss:0.27074973\n",
      "step: 6907.0, loss:0.26543251\n",
      "step: 6908.0, loss:0.25149268\n",
      "step: 6909.0, loss:0.20426467\n",
      "step: 6910.0, loss:0.25886731\n",
      "step: 6911.0, loss:0.22308286\n",
      "step: 6912.0, loss:0.22382066\n",
      "step: 6913.0, loss:0.22996672\n",
      "step: 6914.0, loss:0.30520542\n",
      "step: 6915.0, loss:0.32361303\n",
      "step: 6916.0, loss:0.16949219\n",
      "step: 6917.0, loss:0.25162023\n",
      "step: 6918.0, loss:0.23534552\n",
      "step: 6919.0, loss:0.27900292\n",
      "step: 6920.0, loss:0.27380788\n",
      "step: 6921.0, loss:0.21748750\n",
      "step: 6922.0, loss:0.22242155\n",
      "step: 6923.0, loss:0.21637767\n",
      "step: 6924.0, loss:0.20976366\n",
      "step: 6925.0, loss:0.27976486\n",
      "step: 6926.0, loss:0.16822587\n",
      "step: 6927.0, loss:0.20311908\n",
      "step: 6928.0, loss:0.19800099\n",
      "step: 6929.0, loss:0.22306154\n",
      "step: 6930.0, loss:0.27968836\n",
      "step: 6931.0, loss:0.30686636\n",
      "step: 6932.0, loss:0.37779615\n",
      "step: 6933.0, loss:0.20521564\n",
      "step: 6934.0, loss:0.20424148\n",
      "step: 6935.0, loss:0.27654488\n",
      "step: 6936.0, loss:0.15989521\n",
      "step: 6937.0, loss:0.24510862\n",
      "step: 6938.0, loss:0.28071067\n",
      "step: 6939.0, loss:0.19774788\n",
      "step: 6940.0, loss:0.39949786\n",
      "step: 6941.0, loss:0.13318266\n",
      "step: 6942.0, loss:0.22637263\n",
      "step: 6943.0, loss:0.24041994\n",
      "step: 6944.0, loss:0.21535275\n",
      "step: 6945.0, loss:0.15640956\n",
      "step: 6946.0, loss:0.23986065\n",
      "step: 6947.0, loss:0.21589179\n",
      "step: 6948.0, loss:0.28069470\n",
      "step: 6949.0, loss:0.23650342\n",
      "step: 6950.0, loss:0.23840795\n",
      "step: 6951.0, loss:0.27153857\n",
      "step: 6952.0, loss:0.27603024\n",
      "step: 6953.0, loss:0.30861487\n",
      "step: 6954.0, loss:0.29922029\n",
      "step: 6955.0, loss:0.31722289\n",
      "step: 6956.0, loss:0.31433102\n",
      "step: 6957.0, loss:0.17124245\n",
      "step: 6958.0, loss:0.36707917\n",
      "step: 6959.0, loss:0.20176007\n",
      "step: 6960.0, loss:0.22746539\n",
      "step: 6961.0, loss:0.27454266\n",
      "step: 6962.0, loss:0.21991906\n",
      "step: 6963.0, loss:0.27510757\n",
      "step: 6964.0, loss:0.42568994\n",
      "step: 6965.0, loss:0.39329878\n",
      "step: 6966.0, loss:0.28315542\n",
      "step: 6967.0, loss:0.34778065\n",
      "step: 6968.0, loss:0.16829091\n",
      "step: 6969.0, loss:0.18290925\n",
      "step: 6970.0, loss:0.26348485\n",
      "step: 6971.0, loss:0.34143884\n",
      "step: 6972.0, loss:0.17559759\n",
      "step: 6973.0, loss:0.34252738\n",
      "step: 6974.0, loss:0.18350378\n",
      "step: 6975.0, loss:0.22799643\n",
      "step: 6976.0, loss:0.30966972\n",
      "step: 6977.0, loss:0.37513592\n",
      "step: 6978.0, loss:0.23462054\n",
      "step: 6979.0, loss:0.38512631\n",
      "step: 6980.0, loss:0.30454782\n",
      "step: 6981.0, loss:0.20463883\n",
      "step: 6982.0, loss:0.33202272\n",
      "step: 6983.0, loss:0.22763794\n",
      "step: 6984.0, loss:0.32689573\n",
      "step: 6985.0, loss:0.22105780\n",
      "step: 6986.0, loss:0.19244883\n",
      "step: 6987.0, loss:0.21463294\n",
      "step: 6988.0, loss:0.22989155\n",
      "step: 6989.0, loss:0.32020002\n",
      "step: 6990.0, loss:0.27744222\n",
      "step: 6991.0, loss:0.17414620\n",
      "step: 6992.0, loss:0.24587868\n",
      "step: 6993.0, loss:0.30054864\n",
      "step: 6994.0, loss:0.19192684\n",
      "step: 6995.0, loss:0.25711865\n",
      "step: 6996.0, loss:0.25374407\n",
      "step: 6997.0, loss:0.21601671\n",
      "step: 6998.0, loss:0.15453924\n",
      "step: 6999.0, loss:0.27117573\n",
      "step: 7000.0, loss:0.41640127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1264/1264 [08:02<00:00,  2.62it/s]\n",
      "2023-04-02 22:06:48,936 - INFO - step:7000.0, matthews_corr:0.754809, Acc:88.511007%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 7001.0, loss:0.35038243\n",
      "step: 7002.0, loss:0.20414050\n",
      "step: 7003.0, loss:0.31230167\n",
      "step: 7004.0, loss:0.38401001\n",
      "step: 7005.0, loss:0.30703022\n",
      "step: 7006.0, loss:0.34542938\n",
      "step: 7007.0, loss:0.25991213\n",
      "step: 7008.0, loss:0.38482771\n",
      "step: 7009.0, loss:0.30859314\n",
      "step: 7010.0, loss:0.45879214\n",
      "step: 7011.0, loss:0.27314765\n",
      "step: 7012.0, loss:0.30789661\n",
      "step: 7013.0, loss:0.18644317\n",
      "step: 7014.0, loss:0.35070881\n",
      "step: 7015.0, loss:0.26664345\n",
      "step: 7016.0, loss:0.26218724\n",
      "step: 7017.0, loss:0.34511030\n",
      "step: 7018.0, loss:0.25528227\n",
      "step: 7019.0, loss:0.27118485\n",
      "step: 7020.0, loss:0.19958008\n",
      "step: 7021.0, loss:0.29048696\n",
      "step: 7022.0, loss:0.22333846\n",
      "step: 7023.0, loss:0.37643217\n",
      "step: 7024.0, loss:0.24959296\n",
      "step: 7025.0, loss:0.35748807\n",
      "step: 7026.0, loss:0.18889529\n",
      "step: 7027.0, loss:0.19291925\n",
      "step: 7028.0, loss:0.40376531\n",
      "step: 7029.0, loss:0.37343107\n",
      "step: 7030.0, loss:0.24350080\n",
      "step: 7031.0, loss:0.22706845\n",
      "step: 7032.0, loss:0.29023874\n",
      "step: 7033.0, loss:0.25161058\n",
      "step: 7034.0, loss:0.21548375\n",
      "step: 7035.0, loss:0.26967744\n",
      "step: 7036.0, loss:0.19025866\n",
      "step: 7037.0, loss:0.23526408\n",
      "step: 7038.0, loss:0.28899236\n",
      "step: 7039.0, loss:0.25568151\n",
      "step: 7040.0, loss:0.27079258\n",
      "step: 7041.0, loss:0.21398520\n",
      "step: 7042.0, loss:0.31565740\n",
      "step: 7043.0, loss:0.25164902\n",
      "step: 7044.0, loss:0.18771560\n",
      "step: 7045.0, loss:0.16642582\n",
      "step: 7046.0, loss:0.18496365\n",
      "step: 7047.0, loss:0.33256500\n",
      "step: 7048.0, loss:0.19810896\n",
      "step: 7049.0, loss:0.22305756\n",
      "step: 7050.0, loss:0.31088300\n",
      "step: 7051.0, loss:0.26746686\n",
      "step: 7052.0, loss:0.25225029\n",
      "step: 7053.0, loss:0.18834778\n",
      "step: 7054.0, loss:0.27347478\n",
      "step: 7055.0, loss:0.32517425\n",
      "step: 7056.0, loss:0.27903183\n",
      "step: 7057.0, loss:0.28088294\n",
      "step: 7058.0, loss:0.29052261\n",
      "step: 7059.0, loss:0.43181888\n",
      "step: 7060.0, loss:0.49872626\n",
      "step: 7061.0, loss:0.21463893\n",
      "step: 7062.0, loss:0.24809376\n",
      "step: 7063.0, loss:0.36214284\n",
      "step: 7064.0, loss:0.27204654\n",
      "step: 7065.0, loss:0.26100348\n",
      "step: 7066.0, loss:0.42940126\n",
      "step: 7067.0, loss:0.28054745\n",
      "step: 7068.0, loss:0.26586746\n",
      "step: 7069.0, loss:0.30566174\n",
      "step: 7070.0, loss:0.21283457\n",
      "step: 7071.0, loss:0.25778347\n",
      "step: 7072.0, loss:0.27144755\n",
      "step: 7073.0, loss:0.39496919\n",
      "step: 7074.0, loss:0.22827549\n",
      "step: 7075.0, loss:0.23085386\n",
      "step: 7076.0, loss:0.26991627\n",
      "step: 7077.0, loss:0.27982327\n",
      "step: 7078.0, loss:0.37766585\n",
      "step: 7079.0, loss:0.25666682\n",
      "step: 7080.0, loss:0.35579001\n",
      "step: 7081.0, loss:0.25847283\n",
      "step: 7082.0, loss:0.25352287\n",
      "step: 7083.0, loss:0.17131124\n",
      "step: 7084.0, loss:0.35269700\n",
      "step: 7085.0, loss:0.32027177\n",
      "step: 7086.0, loss:0.30638909\n",
      "step: 7087.0, loss:0.25847470\n",
      "step: 7088.0, loss:0.26341743\n",
      "step: 7089.0, loss:0.29360152\n",
      "step: 7090.0, loss:0.20171567\n",
      "step: 7091.0, loss:0.25537471\n",
      "step: 7092.0, loss:0.28483279\n",
      "step: 7093.0, loss:0.25571084\n",
      "step: 7094.0, loss:0.32737961\n",
      "step: 7095.0, loss:0.38887253\n",
      "step: 7096.0, loss:0.30441178\n",
      "step: 7097.0, loss:0.25966706\n",
      "step: 7098.0, loss:0.22698341\n",
      "step: 7099.0, loss:0.31713349\n",
      "step: 7100.0, loss:0.22054061\n",
      "step: 7101.0, loss:0.33496687\n",
      "step: 7102.0, loss:0.30650383\n",
      "step: 7103.0, loss:0.22113082\n",
      "step: 7104.0, loss:0.24801424\n",
      "step: 7105.0, loss:0.25019678\n",
      "step: 7106.0, loss:0.30870061\n",
      "step: 7107.0, loss:0.27674746\n",
      "step: 7108.0, loss:0.33033770\n",
      "step: 7109.0, loss:0.35070467\n",
      "step: 7110.0, loss:0.17621990\n",
      "step: 7111.0, loss:0.32045978\n",
      "step: 7112.0, loss:0.30325653\n",
      "step: 7113.0, loss:0.31773092\n",
      "step: 7114.0, loss:0.32475973\n",
      "step: 7115.0, loss:0.28528009\n",
      "step: 7116.0, loss:0.33005854\n",
      "step: 7117.0, loss:0.17376003\n",
      "step: 7118.0, loss:0.21030940\n",
      "step: 7119.0, loss:0.31242750\n",
      "step: 7120.0, loss:0.20917139\n",
      "step: 7121.0, loss:0.19123898\n",
      "step: 7122.0, loss:0.23161336\n",
      "step: 7123.0, loss:0.14255188\n",
      "step: 7124.0, loss:0.29492338\n",
      "step: 7125.0, loss:0.37119520\n",
      "step: 7126.0, loss:0.17390896\n",
      "step: 7127.0, loss:0.17242176\n",
      "step: 7128.0, loss:0.20565069\n",
      "step: 7129.0, loss:0.25819593\n",
      "step: 7130.0, loss:0.16665968\n",
      "step: 7131.0, loss:0.45903932\n",
      "step: 7132.0, loss:0.19197257\n",
      "step: 7133.0, loss:0.40271162\n",
      "step: 7134.0, loss:0.18581336\n",
      "step: 7135.0, loss:0.22141215\n",
      "step: 7136.0, loss:0.20380564\n",
      "step: 7137.0, loss:0.36144939\n",
      "step: 7138.0, loss:0.44855053\n",
      "step: 7139.0, loss:0.26110490\n",
      "step: 7140.0, loss:0.18695867\n",
      "step: 7141.0, loss:0.38581313\n",
      "step: 7142.0, loss:0.42695218\n",
      "step: 7143.0, loss:0.29986663\n",
      "step: 7144.0, loss:0.26477931\n",
      "step: 7145.0, loss:0.35336298\n",
      "step: 7146.0, loss:0.28124457\n",
      "step: 7147.0, loss:0.19810170\n",
      "step: 7148.0, loss:0.21479502\n",
      "step: 7149.0, loss:0.31921653\n",
      "step: 7150.0, loss:0.30421695\n",
      "step: 7151.0, loss:0.32510208\n",
      "step: 7152.0, loss:0.23574344\n",
      "step: 7153.0, loss:0.21221344\n",
      "step: 7154.0, loss:0.32567446\n",
      "step: 7155.0, loss:0.26606453\n",
      "step: 7156.0, loss:0.31757092\n",
      "step: 7157.0, loss:0.32522999\n",
      "step: 7158.0, loss:0.23502567\n",
      "step: 7159.0, loss:0.24546123\n",
      "step: 7160.0, loss:0.20475952\n",
      "step: 7161.0, loss:0.24792271\n",
      "step: 7162.0, loss:0.28489130\n",
      "step: 7163.0, loss:0.22005879\n",
      "step: 7164.0, loss:0.26174355\n",
      "step: 7165.0, loss:0.15106699\n",
      "step: 7166.0, loss:0.29796031\n",
      "step: 7167.0, loss:0.21453711\n",
      "step: 7168.0, loss:0.28827534\n",
      "step: 7169.0, loss:0.23466175\n",
      "step: 7170.0, loss:0.12789463\n",
      "step: 7171.0, loss:0.21245793\n",
      "step: 7172.0, loss:0.17475829\n",
      "step: 7173.0, loss:0.15964399\n",
      "step: 7174.0, loss:0.24306930\n",
      "step: 7175.0, loss:0.18447229\n",
      "step: 7176.0, loss:0.30036255\n",
      "step: 7177.0, loss:0.15479084\n",
      "step: 7178.0, loss:0.34708638\n",
      "step: 7179.0, loss:0.25908861\n",
      "step: 7180.0, loss:0.23400236\n",
      "step: 7181.0, loss:0.19183020\n",
      "step: 7182.0, loss:0.28798838\n",
      "step: 7183.0, loss:0.30126177\n",
      "step: 7184.0, loss:0.35059937\n",
      "step: 7185.0, loss:0.44916078\n",
      "step: 7186.0, loss:0.22575795\n",
      "step: 7187.0, loss:0.28019615\n",
      "step: 7188.0, loss:0.19061371\n",
      "step: 7189.0, loss:0.27447366\n",
      "step: 7190.0, loss:0.32801256\n",
      "step: 7191.0, loss:0.25800168\n",
      "step: 7192.0, loss:0.27974827\n",
      "step: 7193.0, loss:0.46556206\n",
      "step: 7194.0, loss:0.29741339\n",
      "step: 7195.0, loss:0.24909694\n",
      "step: 7196.0, loss:0.27553645\n",
      "step: 7197.0, loss:0.36805219\n",
      "step: 7198.0, loss:0.26899989\n",
      "step: 7199.0, loss:0.14550749\n",
      "step: 7200.0, loss:0.40959473\n",
      "step: 7201.0, loss:0.23552666\n",
      "step: 7202.0, loss:0.27908907\n",
      "step: 7203.0, loss:0.26555865\n",
      "step: 7204.0, loss:0.23445922\n",
      "step: 7205.0, loss:0.28783567\n",
      "step: 7206.0, loss:0.20248616\n",
      "step: 7207.0, loss:0.30262079\n",
      "step: 7208.0, loss:0.37678544\n",
      "step: 7209.0, loss:0.35723099\n",
      "step: 7210.0, loss:0.26708558\n",
      "step: 7211.0, loss:0.24089563\n",
      "step: 7212.0, loss:0.35747544\n",
      "step: 7213.0, loss:0.31116151\n",
      "step: 7214.0, loss:0.37407538\n",
      "step: 7215.0, loss:0.27866389\n",
      "step: 7216.0, loss:0.30558794\n",
      "step: 7217.0, loss:0.35821920\n",
      "step: 7218.0, loss:0.29344237\n",
      "step: 7219.0, loss:0.28781493\n",
      "step: 7220.0, loss:0.18844476\n",
      "step: 7221.0, loss:0.31027641\n",
      "step: 7222.0, loss:0.19626118\n",
      "step: 7223.0, loss:0.22329536\n",
      "step: 7224.0, loss:0.33551526\n",
      "step: 7225.0, loss:0.21845260\n",
      "step: 7226.0, loss:0.31606799\n",
      "step: 7227.0, loss:0.18955496\n",
      "step: 7228.0, loss:0.36300517\n",
      "step: 7229.0, loss:0.16314827\n",
      "step: 7230.0, loss:0.19695728\n",
      "step: 7231.0, loss:0.22263081\n",
      "step: 7232.0, loss:0.24698518\n",
      "step: 7233.0, loss:0.35349243\n",
      "step: 7234.0, loss:0.19878775\n",
      "step: 7235.0, loss:0.40505625\n",
      "step: 7236.0, loss:0.25722710\n",
      "step: 7237.0, loss:0.41219389\n",
      "step: 7238.0, loss:0.12864707\n",
      "step: 7239.0, loss:0.25874700\n",
      "step: 7240.0, loss:0.36698660\n",
      "step: 7241.0, loss:0.31469642\n",
      "step: 7242.0, loss:0.22692479\n",
      "step: 7243.0, loss:0.27313400\n",
      "step: 7244.0, loss:0.31092136\n",
      "step: 7245.0, loss:0.25455946\n",
      "step: 7246.0, loss:0.20072103\n",
      "step: 7247.0, loss:0.22265831\n",
      "step: 7248.0, loss:0.32316956\n",
      "step: 7249.0, loss:0.23222046\n",
      "step: 7250.0, loss:0.20705033\n",
      "step: 7251.0, loss:0.28986760\n",
      "step: 7252.0, loss:0.32509850\n",
      "step: 7253.0, loss:0.32040594\n",
      "step: 7254.0, loss:0.25745761\n",
      "step: 7255.0, loss:0.19899554\n",
      "step: 7256.0, loss:0.23228016\n",
      "step: 7257.0, loss:0.28863285\n",
      "step: 7258.0, loss:0.30556822\n",
      "step: 7259.0, loss:0.34734367\n",
      "step: 7260.0, loss:0.26320685\n",
      "step: 7261.0, loss:0.20275158\n",
      "step: 7262.0, loss:0.22374471\n",
      "step: 7263.0, loss:0.26912409\n",
      "step: 7264.0, loss:0.33779416\n",
      "step: 7265.0, loss:0.21384444\n",
      "step: 7266.0, loss:0.39050557\n",
      "step: 7267.0, loss:0.17781615\n",
      "step: 7268.0, loss:0.24798868\n",
      "step: 7269.0, loss:0.27243663\n",
      "step: 7270.0, loss:0.30830970\n",
      "step: 7271.0, loss:0.25412774\n",
      "step: 7272.0, loss:0.27439936\n",
      "step: 7273.0, loss:0.20949778\n",
      "step: 7274.0, loss:0.28168665\n",
      "step: 7275.0, loss:0.18166769\n",
      "step: 7276.0, loss:0.30076859\n",
      "step: 7277.0, loss:0.34856991\n",
      "step: 7278.0, loss:0.22887367\n",
      "step: 7279.0, loss:0.23989321\n",
      "step: 7280.0, loss:0.25184849\n",
      "step: 7281.0, loss:0.32550120\n",
      "step: 7282.0, loss:0.35519765\n",
      "step: 7283.0, loss:0.21261949\n",
      "step: 7284.0, loss:0.27467546\n",
      "step: 7285.0, loss:0.24343756\n",
      "step: 7286.0, loss:0.22359371\n",
      "step: 7287.0, loss:0.18324387\n",
      "step: 7288.0, loss:0.23876512\n",
      "step: 7289.0, loss:0.16575124\n",
      "step: 7290.0, loss:0.22399029\n",
      "step: 7291.0, loss:0.16373898\n",
      "step: 7292.0, loss:0.26309486\n",
      "step: 7293.0, loss:0.28544352\n",
      "step: 7294.0, loss:0.34822575\n",
      "step: 7295.0, loss:0.36129625\n",
      "step: 7296.0, loss:0.30673324\n",
      "step: 7297.0, loss:0.29972987\n",
      "step: 7298.0, loss:0.32518492\n",
      "step: 7299.0, loss:0.15448317\n",
      "step: 7300.0, loss:0.18588408\n",
      "step: 7301.0, loss:0.31957959\n",
      "step: 7302.0, loss:0.25058126\n",
      "step: 7303.0, loss:0.28243447\n",
      "step: 7304.0, loss:0.24422475\n",
      "step: 7305.0, loss:0.29403116\n",
      "step: 7306.0, loss:0.41748726\n",
      "step: 7307.0, loss:0.25018893\n",
      "step: 7308.0, loss:0.22555744\n",
      "step: 7309.0, loss:0.17286010\n",
      "step: 7310.0, loss:0.33755809\n",
      "step: 7311.0, loss:0.22075834\n",
      "step: 7312.0, loss:0.18225363\n",
      "step: 7313.0, loss:0.30469181\n",
      "step: 7314.0, loss:0.26263938\n",
      "step: 7315.0, loss:0.31303465\n",
      "step: 7316.0, loss:0.21842249\n",
      "step: 7317.0, loss:0.18957674\n",
      "step: 7318.0, loss:0.20391557\n",
      "step: 7319.0, loss:0.38151404\n",
      "step: 7320.0, loss:0.17478399\n",
      "step: 7321.0, loss:0.17156397\n",
      "step: 7322.0, loss:0.26816446\n",
      "step: 7323.0, loss:0.29149448\n",
      "step: 7324.0, loss:0.28748266\n",
      "step: 7325.0, loss:0.33505484\n",
      "step: 7326.0, loss:0.23955096\n",
      "step: 7327.0, loss:0.23744920\n",
      "step: 7328.0, loss:0.31610107\n",
      "step: 7329.0, loss:0.42145287\n",
      "step: 7330.0, loss:0.18867786\n",
      "step: 7331.0, loss:0.23625092\n",
      "step: 7332.0, loss:0.20932156\n",
      "step: 7333.0, loss:0.28631555\n",
      "step: 7334.0, loss:0.27244796\n",
      "step: 7335.0, loss:0.23430469\n",
      "step: 7336.0, loss:0.34953979\n",
      "step: 7337.0, loss:0.36533451\n",
      "step: 7338.0, loss:0.22229484\n",
      "step: 7339.0, loss:0.20965994\n",
      "step: 7340.0, loss:0.31973154\n",
      "step: 7341.0, loss:0.20945008\n",
      "step: 7342.0, loss:0.29726131\n",
      "step: 7343.0, loss:0.20369721\n",
      "step: 7344.0, loss:0.18345096\n",
      "step: 7345.0, loss:0.23475906\n",
      "step: 7346.0, loss:0.23730838\n",
      "step: 7347.0, loss:0.35863909\n",
      "step: 7348.0, loss:0.33468255\n",
      "step: 7349.0, loss:0.26859576\n",
      "step: 7350.0, loss:0.29846802\n",
      "step: 7351.0, loss:0.23188778\n",
      "step: 7352.0, loss:0.29482051\n",
      "step: 7353.0, loss:0.25645355\n",
      "step: 7354.0, loss:0.21483052\n",
      "step: 7355.0, loss:0.33365274\n",
      "step: 7356.0, loss:0.35398321\n",
      "step: 7357.0, loss:0.22716281\n",
      "step: 7358.0, loss:0.20559277\n",
      "step: 7359.0, loss:0.15907715\n",
      "step: 7360.0, loss:0.30356973\n",
      "step: 7361.0, loss:0.14604733\n",
      "step: 7362.0, loss:0.18397442\n",
      "step: 7363.0, loss:0.26576919\n",
      "step: 7364.0, loss:0.18618853\n",
      "step: 7365.0, loss:0.21259735\n",
      "step: 7366.0, loss:0.34535588\n",
      "step: 7367.0, loss:0.35922463\n",
      "step: 7368.0, loss:0.42301611\n",
      "step: 7369.0, loss:0.26389670\n",
      "step: 7370.0, loss:0.28684215\n",
      "step: 7371.0, loss:0.31063335\n",
      "step: 7372.0, loss:0.18013070\n",
      "step: 7373.0, loss:0.25497267\n",
      "step: 7374.0, loss:0.18324170\n",
      "step: 7375.0, loss:0.27528573\n",
      "step: 7376.0, loss:0.25615575\n",
      "step: 7377.0, loss:0.25052750\n",
      "step: 7378.0, loss:0.26523590\n",
      "step: 7379.0, loss:0.22100287\n",
      "step: 7380.0, loss:0.30385835\n",
      "step: 7381.0, loss:0.33171595\n",
      "step: 7382.0, loss:0.22234739\n",
      "step: 7383.0, loss:0.19651976\n",
      "step: 7384.0, loss:0.23327325\n",
      "step: 7385.0, loss:0.28305243\n",
      "step: 7386.0, loss:0.23073841\n",
      "step: 7387.0, loss:0.26097720\n",
      "step: 7388.0, loss:0.23398802\n",
      "step: 7389.0, loss:0.18512182\n",
      "step: 7390.0, loss:0.19825461\n",
      "step: 7391.0, loss:0.30203211\n",
      "step: 7392.0, loss:0.28467669\n",
      "step: 7393.0, loss:0.19070920\n",
      "step: 7394.0, loss:0.29220605\n",
      "step: 7395.0, loss:0.23462633\n",
      "step: 7396.0, loss:0.20084815\n",
      "step: 7397.0, loss:0.20310986\n",
      "step: 7398.0, loss:0.16364342\n",
      "step: 7399.0, loss:0.19473380\n",
      "step: 7400.0, loss:0.31078414\n",
      "step: 7401.0, loss:0.23689776\n",
      "step: 7402.0, loss:0.19379059\n",
      "step: 7403.0, loss:0.23817493\n",
      "step: 7404.0, loss:0.21287641\n",
      "step: 7405.0, loss:0.27418108\n",
      "step: 7406.0, loss:0.15199786\n",
      "step: 7407.0, loss:0.16949324\n",
      "step: 7408.0, loss:0.30181606\n",
      "step: 7409.0, loss:0.17742657\n",
      "step: 7410.0, loss:0.33414730\n",
      "step: 7411.0, loss:0.21688650\n",
      "step: 7412.0, loss:0.13034908\n",
      "step: 7413.0, loss:0.21981879\n",
      "step: 7414.0, loss:0.21158710\n",
      "step: 7415.0, loss:0.31048526\n",
      "step: 7416.0, loss:0.25268851\n",
      "step: 7417.0, loss:0.15875533\n",
      "step: 7418.0, loss:0.23623892\n",
      "step: 7419.0, loss:0.26656807\n",
      "step: 7420.0, loss:0.20650093\n",
      "step: 7421.0, loss:0.27472225\n",
      "step: 7422.0, loss:0.32177158\n",
      "step: 7423.0, loss:0.18779768\n",
      "step: 7424.0, loss:0.21770967\n",
      "step: 7425.0, loss:0.23179657\n",
      "step: 7426.0, loss:0.26583628\n",
      "step: 7427.0, loss:0.32713290\n",
      "step: 7428.0, loss:0.28099918\n",
      "step: 7429.0, loss:0.37442709\n",
      "step: 7430.0, loss:0.16267279\n",
      "step: 7431.0, loss:0.31250726\n",
      "step: 7432.0, loss:0.15419116\n",
      "step: 7433.0, loss:0.32260113\n",
      "step: 7434.0, loss:0.44988522\n",
      "step: 7435.0, loss:0.27812991\n",
      "step: 7436.0, loss:0.23957386\n",
      "step: 7437.0, loss:0.29752729\n",
      "step: 7438.0, loss:0.35230172\n",
      "step: 7439.0, loss:0.35956572\n",
      "step: 7440.0, loss:0.13107963\n",
      "step: 7441.0, loss:0.23214533\n",
      "step: 7442.0, loss:0.27035927\n",
      "step: 7443.0, loss:0.34902968\n",
      "step: 7444.0, loss:0.28048729\n",
      "step: 7445.0, loss:0.21557580\n",
      "step: 7446.0, loss:0.25851399\n",
      "step: 7447.0, loss:0.21846397\n",
      "step: 7448.0, loss:0.20452084\n",
      "step: 7449.0, loss:0.31360010\n",
      "step: 7450.0, loss:0.27661481\n",
      "step: 7451.0, loss:0.36311182\n",
      "step: 7452.0, loss:0.16685520\n",
      "step: 7453.0, loss:0.19314175\n",
      "step: 7454.0, loss:0.22393500\n",
      "step: 7455.0, loss:0.23837889\n",
      "step: 7456.0, loss:0.30117121\n",
      "step: 7457.0, loss:0.22968499\n",
      "step: 7458.0, loss:0.35188901\n",
      "step: 7459.0, loss:0.19683596\n",
      "step: 7460.0, loss:0.25257307\n",
      "step: 7461.0, loss:0.17466696\n",
      "step: 7462.0, loss:0.24271020\n",
      "step: 7463.0, loss:0.23894992\n",
      "step: 7464.0, loss:0.35546698\n",
      "step: 7465.0, loss:0.23873149\n",
      "step: 7466.0, loss:0.25497537\n",
      "step: 7467.0, loss:0.17629513\n",
      "step: 7468.0, loss:0.24459967\n",
      "step: 7469.0, loss:0.32110702\n",
      "step: 7470.0, loss:0.41026559\n",
      "step: 7471.0, loss:0.13612997\n",
      "step: 7472.0, loss:0.25180744\n",
      "step: 7473.0, loss:0.35451274\n",
      "step: 7474.0, loss:0.33006279\n",
      "step: 7475.0, loss:0.25335828\n",
      "step: 7476.0, loss:0.29373401\n",
      "step: 7477.0, loss:0.24361828\n",
      "step: 7478.0, loss:0.29214865\n",
      "step: 7479.0, loss:0.18201300\n",
      "step: 7480.0, loss:0.25196070\n",
      "step: 7481.0, loss:0.30629693\n",
      "step: 7482.0, loss:0.18403197\n",
      "step: 7483.0, loss:0.24530261\n",
      "step: 7484.0, loss:0.29796239\n",
      "step: 7485.0, loss:0.34141174\n",
      "step: 7486.0, loss:0.33536807\n",
      "step: 7487.0, loss:0.24857931\n",
      "step: 7488.0, loss:0.31910700\n",
      "step: 7489.0, loss:0.20278578\n",
      "step: 7490.0, loss:0.23609479\n",
      "step: 7491.0, loss:0.26261804\n",
      "step: 7492.0, loss:0.21057692\n",
      "step: 7493.0, loss:0.19306171\n",
      "step: 7494.0, loss:0.24261573\n",
      "step: 7495.0, loss:0.24671541\n",
      "step: 7496.0, loss:0.29035480\n",
      "step: 7497.0, loss:0.17643474\n",
      "step: 7498.0, loss:0.26077957\n",
      "step: 7499.0, loss:0.26645109\n",
      "step: 7500.0, loss:0.29234610\n",
      "step: 7501.0, loss:0.41655679\n",
      "step: 7502.0, loss:0.21253737\n",
      "step: 7503.0, loss:0.18631659\n",
      "step: 7504.0, loss:0.19379700\n",
      "step: 7505.0, loss:0.30310280\n",
      "step: 7506.0, loss:0.24761941\n",
      "step: 7507.0, loss:0.27696801\n",
      "step: 7508.0, loss:0.21045823\n",
      "step: 7509.0, loss:0.19999750\n",
      "step: 7510.0, loss:0.26620073\n",
      "step: 7511.0, loss:0.23733222\n",
      "step: 7512.0, loss:0.22911566\n",
      "step: 7513.0, loss:0.27931509\n",
      "step: 7514.0, loss:0.18389193\n",
      "step: 7515.0, loss:0.26516442\n",
      "step: 7516.0, loss:0.20607154\n",
      "step: 7517.0, loss:0.24211663\n",
      "step: 7518.0, loss:0.29228052\n",
      "step: 7519.0, loss:0.24328292\n",
      "step: 7520.0, loss:0.15244020\n",
      "step: 7521.0, loss:0.34757626\n",
      "step: 7522.0, loss:0.20896067\n",
      "step: 7523.0, loss:0.33738495\n",
      "step: 7524.0, loss:0.21976903\n",
      "step: 7525.0, loss:0.34164871\n",
      "step: 7526.0, loss:0.24071949\n",
      "step: 7527.0, loss:0.19626309\n",
      "step: 7528.0, loss:0.21185352\n",
      "step: 7529.0, loss:0.25427433\n",
      "step: 7530.0, loss:0.19262939\n",
      "step: 7531.0, loss:0.25622583\n",
      "step: 7532.0, loss:0.28638227\n",
      "step: 7533.0, loss:0.27425624\n",
      "step: 7534.0, loss:0.23898796\n",
      "step: 7535.0, loss:0.26398087\n",
      "step: 7536.0, loss:0.30052111\n",
      "step: 7537.0, loss:0.24191507\n",
      "step: 7538.0, loss:0.23693390\n",
      "step: 7539.0, loss:0.26167092\n",
      "step: 7540.0, loss:0.20632045\n",
      "step: 7541.0, loss:0.23774965\n",
      "step: 7542.0, loss:0.35166317\n",
      "step: 7543.0, loss:0.28445486\n",
      "step: 7544.0, loss:0.19329904\n",
      "step: 7545.0, loss:0.26148609\n",
      "step: 7546.0, loss:0.32271982\n",
      "step: 7547.0, loss:0.32935295\n",
      "step: 7548.0, loss:0.23906179\n",
      "step: 7549.0, loss:0.22018521\n",
      "step: 7550.0, loss:0.29457586\n",
      "step: 7551.0, loss:0.31874785\n",
      "step: 7552.0, loss:0.40506549\n",
      "step: 7553.0, loss:0.24805584\n",
      "step: 7554.0, loss:0.22184375\n",
      "step: 7555.0, loss:0.25813472\n",
      "step: 7556.0, loss:0.35822605\n",
      "step: 7557.0, loss:0.20255480\n",
      "step: 7558.0, loss:0.16774957\n",
      "step: 7559.0, loss:0.23103696\n",
      "step: 7560.0, loss:0.29186535\n",
      "step: 7561.0, loss:0.24451237\n",
      "step: 7562.0, loss:0.28817378\n",
      "step: 7563.0, loss:0.31357530\n",
      "step: 7564.0, loss:0.26517690\n",
      "step: 7565.0, loss:0.22600375\n",
      "step: 7566.0, loss:0.19137830\n",
      "step: 7567.0, loss:0.30413282\n",
      "step: 7568.0, loss:0.26807965\n",
      "step: 7569.0, loss:0.16427274\n",
      "step: 7570.0, loss:0.22477517\n",
      "step: 7571.0, loss:0.16790004\n",
      "step: 7572.0, loss:0.24719273\n",
      "step: 7573.0, loss:0.28070128\n",
      "step: 7574.0, loss:0.30438848\n",
      "step: 7575.0, loss:0.21721858\n",
      "step: 7576.0, loss:0.21350076\n",
      "step: 7577.0, loss:0.39004300\n",
      "step: 7578.0, loss:0.24837725\n",
      "step: 7579.0, loss:0.21602882\n",
      "step: 7580.0, loss:0.29590536\n",
      "step: 7581.0, loss:0.28518401\n",
      "step: 7582.0, loss:0.19459786\n",
      "step: 7583.0, loss:0.21710837\n",
      "step: 7584.0, loss:0.17880913\n",
      "step: 7585.0, loss:0.35816627\n",
      "step: 7586.0, loss:0.19715443\n",
      "step: 7587.0, loss:0.21303216\n",
      "step: 7588.0, loss:0.24154089\n",
      "step: 7589.0, loss:0.16462704\n",
      "step: 7590.0, loss:0.25009210\n",
      "step: 7591.0, loss:0.35723757\n",
      "step: 7592.0, loss:0.21189684\n",
      "step: 7593.0, loss:0.21241112\n",
      "step: 7594.0, loss:0.28457808\n",
      "step: 7595.0, loss:0.24163346\n",
      "step: 7596.0, loss:0.19129533\n",
      "step: 7597.0, loss:0.25282468\n",
      "step: 7598.0, loss:0.23542129\n",
      "step: 7599.0, loss:0.31153773\n",
      "step: 7600.0, loss:0.18721392\n",
      "step: 7601.0, loss:0.28489714\n",
      "step: 7602.0, loss:0.33036318\n",
      "step: 7603.0, loss:0.31186344\n",
      "step: 7604.0, loss:0.27919198\n",
      "step: 7605.0, loss:0.34943232\n",
      "step: 7606.0, loss:0.21873519\n",
      "step: 7607.0, loss:0.24725661\n",
      "step: 7608.0, loss:0.38502787\n",
      "step: 7609.0, loss:0.23635980\n",
      "step: 7610.0, loss:0.32580364\n",
      "step: 7611.0, loss:0.21321542\n",
      "step: 7612.0, loss:0.24892115\n",
      "step: 7613.0, loss:0.24061537\n",
      "step: 7614.0, loss:0.22104055\n",
      "step: 7615.0, loss:0.24590247\n",
      "step: 7616.0, loss:0.24912146\n",
      "step: 7617.0, loss:0.34099866\n",
      "step: 7618.0, loss:0.26872144\n",
      "step: 7619.0, loss:0.22896867\n",
      "step: 7620.0, loss:0.22325498\n",
      "step: 7621.0, loss:0.15891307\n",
      "step: 7622.0, loss:0.31415514\n",
      "step: 7623.0, loss:0.23443962\n",
      "step: 7624.0, loss:0.19396454\n",
      "step: 7625.0, loss:0.27411997\n",
      "step: 7626.0, loss:0.21328080\n",
      "step: 7627.0, loss:0.22322456\n",
      "step: 7628.0, loss:0.24266374\n",
      "step: 7629.0, loss:0.34202727\n",
      "step: 7630.0, loss:0.17510458\n",
      "step: 7631.0, loss:0.22968933\n",
      "step: 7632.0, loss:0.30103174\n",
      "step: 7633.0, loss:0.24820081\n",
      "step: 7634.0, loss:0.27701801\n",
      "step: 7635.0, loss:0.33230438\n",
      "step: 7636.0, loss:0.23109599\n",
      "step: 7637.0, loss:0.25389663\n",
      "step: 7638.0, loss:0.28853100\n",
      "step: 7639.0, loss:0.21018858\n",
      "step: 7640.0, loss:0.22985467\n",
      "step: 7641.0, loss:0.37475216\n",
      "step: 7642.0, loss:0.15677680\n",
      "step: 7643.0, loss:0.24767385\n",
      "step: 7644.0, loss:0.41512849\n",
      "step: 7645.0, loss:0.23714661\n",
      "step: 7646.0, loss:0.28100085\n",
      "step: 7647.0, loss:0.24978479\n",
      "step: 7648.0, loss:0.30452153\n",
      "step: 7649.0, loss:0.18763749\n",
      "step: 7650.0, loss:0.22657683\n",
      "step: 7651.0, loss:0.38086937\n",
      "step: 7652.0, loss:0.38715895\n",
      "step: 7653.0, loss:0.18979491\n",
      "step: 7654.0, loss:0.18251525\n",
      "step: 7655.0, loss:0.25669679\n",
      "step: 7656.0, loss:0.28863649\n",
      "step: 7657.0, loss:0.23785184\n",
      "step: 7658.0, loss:0.26832334\n",
      "step: 7659.0, loss:0.28070240\n",
      "step: 7660.0, loss:0.29738223\n",
      "step: 7661.0, loss:0.14935907\n",
      "step: 7662.0, loss:0.16302792\n",
      "step: 7663.0, loss:0.20156856\n",
      "step: 7664.0, loss:0.18021783\n",
      "step: 7665.0, loss:0.29535114\n",
      "step: 7666.0, loss:0.27627865\n",
      "step: 7667.0, loss:0.30801877\n",
      "step: 7668.0, loss:0.28065210\n",
      "step: 7669.0, loss:0.23893571\n",
      "step: 7670.0, loss:0.23279785\n",
      "step: 7671.0, loss:0.18609460\n",
      "step: 7672.0, loss:0.19952347\n",
      "step: 7673.0, loss:0.28135474\n",
      "step: 7674.0, loss:0.19094515\n",
      "step: 7675.0, loss:0.15034829\n",
      "step: 7676.0, loss:0.25947923\n",
      "step: 7677.0, loss:0.31120762\n",
      "step: 7678.0, loss:0.26803540\n",
      "step: 7679.0, loss:0.25201451\n",
      "step: 7680.0, loss:0.23039815\n",
      "step: 7681.0, loss:0.24742947\n",
      "step: 7682.0, loss:0.19324598\n",
      "step: 7683.0, loss:0.17481128\n",
      "step: 7684.0, loss:0.18918629\n",
      "step: 7685.0, loss:0.30776295\n",
      "step: 7686.0, loss:0.23686117\n",
      "step: 7687.0, loss:0.17064727\n",
      "step: 7688.0, loss:0.23893449\n",
      "step: 7689.0, loss:0.31808364\n",
      "step: 7690.0, loss:0.13410558\n",
      "step: 7691.0, loss:0.17082429\n",
      "step: 7692.0, loss:0.25851559\n",
      "step: 7693.0, loss:0.21601480\n",
      "step: 7694.0, loss:0.28779542\n",
      "step: 7695.0, loss:0.12306288\n",
      "step: 7696.0, loss:0.27567287\n",
      "step: 7697.0, loss:0.21591829\n",
      "step: 7698.0, loss:0.19329478\n",
      "step: 7699.0, loss:0.26773242\n",
      "step: 7700.0, loss:0.32569529\n",
      "step: 7701.0, loss:0.27175621\n",
      "step: 7702.0, loss:0.36142315\n",
      "step: 7703.0, loss:0.15841464\n",
      "step: 7704.0, loss:0.21781207\n",
      "step: 7705.0, loss:0.15611090\n",
      "step: 7706.0, loss:0.28298111\n",
      "step: 7707.0, loss:0.30441802\n",
      "step: 7708.0, loss:0.20084346\n",
      "step: 7709.0, loss:0.28534007\n",
      "step: 7710.0, loss:0.18095858\n",
      "step: 7711.0, loss:0.31558852\n",
      "step: 7712.0, loss:0.14561156\n",
      "step: 7713.0, loss:0.24581365\n",
      "step: 7714.0, loss:0.23369408\n",
      "step: 7715.0, loss:0.19793623\n",
      "step: 7716.0, loss:0.23214884\n",
      "step: 7717.0, loss:0.32250662\n",
      "step: 7718.0, loss:0.24336217\n",
      "step: 7719.0, loss:0.15068387\n",
      "step: 7720.0, loss:0.22145159\n",
      "step: 7721.0, loss:0.23081218\n",
      "step: 7722.0, loss:0.38498053\n",
      "step: 7723.0, loss:0.29657247\n",
      "step: 7724.0, loss:0.33420944\n",
      "step: 7725.0, loss:0.18142319\n",
      "step: 7726.0, loss:0.21821583\n",
      "step: 7727.0, loss:0.11655546\n",
      "step: 7728.0, loss:0.24584958\n",
      "step: 7729.0, loss:0.34915695\n",
      "step: 7730.0, loss:0.24949166\n",
      "step: 7731.0, loss:0.20659240\n",
      "step: 7732.0, loss:0.18748853\n",
      "step: 7733.0, loss:0.25828159\n",
      "step: 7734.0, loss:0.25104690\n",
      "step: 7735.0, loss:0.23398455\n",
      "step: 7736.0, loss:0.28745202\n",
      "step: 7737.0, loss:0.19129637\n",
      "step: 7738.0, loss:0.15426443\n",
      "step: 7739.0, loss:0.18744658\n",
      "step: 7740.0, loss:0.21570922\n",
      "step: 7741.0, loss:0.17458944\n",
      "step: 7742.0, loss:0.23055338\n",
      "step: 7743.0, loss:0.29288513\n",
      "step: 7744.0, loss:0.24410585\n",
      "step: 7745.0, loss:0.35283164\n",
      "step: 7746.0, loss:0.24028984\n",
      "step: 7747.0, loss:0.19036338\n",
      "step: 7748.0, loss:0.32881668\n",
      "step: 7749.0, loss:0.29285486\n",
      "step: 7750.0, loss:0.24178977\n",
      "step: 7751.0, loss:0.19647023\n",
      "step: 7752.0, loss:0.27210351\n",
      "step: 7753.0, loss:0.18775941\n",
      "step: 7754.0, loss:0.17716753\n",
      "step: 7755.0, loss:0.27741515\n",
      "step: 7756.0, loss:0.22797712\n",
      "step: 7757.0, loss:0.24236266\n",
      "step: 7758.0, loss:0.18845493\n",
      "step: 7759.0, loss:0.36371309\n",
      "step: 7760.0, loss:0.22838400\n",
      "step: 7761.0, loss:0.39695212\n",
      "step: 7762.0, loss:0.36105328\n",
      "step: 7763.0, loss:0.29513308\n",
      "step: 7764.0, loss:0.27192843\n",
      "step: 7765.0, loss:0.20432289\n",
      "step: 7766.0, loss:0.20172128\n",
      "step: 7767.0, loss:0.24202295\n",
      "step: 7768.0, loss:0.35028594\n",
      "step: 7769.0, loss:0.13007870\n",
      "step: 7770.0, loss:0.16940940\n",
      "step: 7771.0, loss:0.25186640\n",
      "step: 7772.0, loss:0.26146475\n",
      "step: 7773.0, loss:0.23530675\n",
      "step: 7774.0, loss:0.21354140\n",
      "step: 7775.0, loss:0.20044415\n",
      "step: 7776.0, loss:0.21390913\n",
      "step: 7777.0, loss:0.36595481\n",
      "step: 7778.0, loss:0.32414825\n",
      "step: 7779.0, loss:0.25372501\n",
      "step: 7780.0, loss:0.17142393\n",
      "step: 7781.0, loss:0.23339470\n",
      "step: 7782.0, loss:0.18442477\n",
      "step: 7783.0, loss:0.27714506\n",
      "step: 7784.0, loss:0.29003254\n",
      "step: 7785.0, loss:0.27940715\n",
      "step: 7786.0, loss:0.23797318\n",
      "step: 7787.0, loss:0.20108399\n",
      "step: 7788.0, loss:0.20418309\n",
      "step: 7789.0, loss:0.18541627\n",
      "step: 7790.0, loss:0.20488415\n",
      "step: 7791.0, loss:0.17364388\n",
      "step: 7792.0, loss:0.16692658\n",
      "step: 7793.0, loss:0.32864277\n",
      "step: 7794.0, loss:0.26151168\n",
      "step: 7795.0, loss:0.24829296\n",
      "step: 7796.0, loss:0.27124941\n",
      "step: 7797.0, loss:0.29514654\n",
      "step: 7798.0, loss:0.28795981\n",
      "step: 7799.0, loss:0.20359097\n",
      "step: 7800.0, loss:0.21187251\n",
      "step: 7801.0, loss:0.20718030\n",
      "step: 7802.0, loss:0.24148109\n",
      "step: 7803.0, loss:0.27842442\n",
      "step: 7804.0, loss:0.26181287\n",
      "step: 7805.0, loss:0.26860823\n",
      "step: 7806.0, loss:0.24674018\n",
      "step: 7807.0, loss:0.29075260\n",
      "step: 7808.0, loss:0.19741949\n",
      "step: 7809.0, loss:0.23767432\n",
      "step: 7810.0, loss:0.28371039\n",
      "step: 7811.0, loss:0.33188563\n",
      "step: 7812.0, loss:0.27089216\n",
      "step: 7813.0, loss:0.32239365\n",
      "step: 7814.0, loss:0.27556346\n",
      "step: 7815.0, loss:0.28902476\n",
      "step: 7816.0, loss:0.16879397\n",
      "step: 7817.0, loss:0.39869847\n",
      "step: 7818.0, loss:0.24977217\n",
      "step: 7819.0, loss:0.33011153\n",
      "step: 7820.0, loss:0.19091805\n",
      "step: 7821.0, loss:0.34116072\n",
      "step: 7822.0, loss:0.18940974\n",
      "step: 7823.0, loss:0.18254636\n",
      "step: 7824.0, loss:0.28241580\n",
      "step: 7825.0, loss:0.31751206\n",
      "step: 7826.0, loss:0.30240181\n",
      "step: 7827.0, loss:0.22424845\n",
      "step: 7828.0, loss:0.32647387\n",
      "step: 7829.0, loss:0.41028775\n",
      "step: 7830.0, loss:0.23817451\n",
      "step: 7831.0, loss:0.24477045\n",
      "step: 7832.0, loss:0.21919301\n",
      "step: 7833.0, loss:0.28390987\n",
      "step: 7834.0, loss:0.19529658\n",
      "step: 7835.0, loss:0.28810377\n",
      "step: 7836.0, loss:0.17801763\n",
      "step: 7837.0, loss:0.22149142\n",
      "step: 7838.0, loss:0.34668883\n",
      "step: 7839.0, loss:0.18019804\n",
      "step: 7840.0, loss:0.44407687\n",
      "step: 7841.0, loss:0.21076006\n",
      "step: 7842.0, loss:0.15146419\n",
      "step: 7843.0, loss:0.27002819\n",
      "step: 7844.0, loss:0.19184163\n",
      "step: 7845.0, loss:0.20164855\n",
      "step: 7846.0, loss:0.30861689\n",
      "step: 7847.0, loss:0.25062217\n",
      "step: 7848.0, loss:0.16143398\n",
      "step: 7849.0, loss:0.30375281\n",
      "step: 7850.0, loss:0.13919748\n",
      "step: 7851.0, loss:0.31269484\n",
      "step: 7852.0, loss:0.21960116\n",
      "step: 7853.0, loss:0.30036266\n",
      "step: 7854.0, loss:0.25457839\n",
      "step: 7855.0, loss:0.41081953\n",
      "step: 7856.0, loss:0.18902872\n",
      "step: 7857.0, loss:0.24818530\n",
      "step: 7858.0, loss:0.22450741\n",
      "step: 7859.0, loss:0.23412581\n",
      "step: 7860.0, loss:0.16326337\n",
      "step: 7861.0, loss:0.34966307\n",
      "step: 7862.0, loss:0.21692657\n",
      "step: 7863.0, loss:0.24415402\n",
      "step: 7864.0, loss:0.14542417\n",
      "step: 7865.0, loss:0.25848879\n",
      "step: 7866.0, loss:0.23144803\n",
      "step: 7867.0, loss:0.24419642\n",
      "step: 7868.0, loss:0.18439080\n",
      "step: 7869.0, loss:0.30151917\n",
      "step: 7870.0, loss:0.25059146\n",
      "step: 7871.0, loss:0.29146410\n",
      "step: 7872.0, loss:0.34509572\n",
      "step: 7873.0, loss:0.17743969\n",
      "step: 7874.0, loss:0.17072445\n",
      "step: 7875.0, loss:0.15792845\n",
      "step: 7876.0, loss:0.17089692\n",
      "step: 7877.0, loss:0.24064022\n",
      "step: 7878.0, loss:0.28900342\n",
      "step: 7879.0, loss:0.33950781\n",
      "step: 7880.0, loss:0.34545961\n",
      "step: 7881.0, loss:0.26643142\n",
      "step: 7882.0, loss:0.24885852\n",
      "step: 7883.0, loss:0.18609494\n",
      "step: 7884.0, loss:0.18470237\n",
      "step: 7885.0, loss:0.27953385\n",
      "step: 7886.0, loss:0.17591584\n",
      "step: 7887.0, loss:0.32927476\n",
      "step: 7888.0, loss:0.24324453\n",
      "step: 7889.0, loss:0.22508367\n",
      "step: 7890.0, loss:0.28219859\n",
      "step: 7891.0, loss:0.46748640\n",
      "step: 7892.0, loss:0.20324980\n",
      "step: 7893.0, loss:0.20566355\n",
      "step: 7894.0, loss:0.30361461\n",
      "step: 7895.0, loss:0.23601605\n",
      "step: 7896.0, loss:0.20973531\n",
      "step: 7897.0, loss:0.26809395\n",
      "step: 7898.0, loss:0.33782028\n",
      "step: 7899.0, loss:0.29164480\n",
      "step: 7900.0, loss:0.21898409\n",
      "step: 7901.0, loss:0.10785610\n",
      "step: 7902.0, loss:0.46206935\n",
      "step: 7903.0, loss:0.31142171\n",
      "step: 7904.0, loss:0.15603053\n",
      "step: 7905.0, loss:0.18368822\n",
      "step: 7906.0, loss:0.23669099\n",
      "step: 7907.0, loss:0.23832643\n",
      "step: 7908.0, loss:0.26929875\n",
      "step: 7909.0, loss:0.16487823\n",
      "step: 7910.0, loss:0.28743513\n",
      "step: 7911.0, loss:0.21043191\n",
      "step: 7912.0, loss:0.25095223\n",
      "step: 7913.0, loss:0.22667416\n",
      "step: 7914.0, loss:0.24135611\n",
      "step: 7915.0, loss:0.24337020\n",
      "step: 7916.0, loss:0.20809048\n",
      "step: 7917.0, loss:0.15621953\n",
      "step: 7918.0, loss:0.30180683\n",
      "step: 7919.0, loss:0.22832029\n",
      "step: 7920.0, loss:0.20275512\n",
      "step: 7921.0, loss:0.17043772\n",
      "step: 7922.0, loss:0.22761814\n",
      "step: 7923.0, loss:0.17469624\n",
      "step: 7924.0, loss:0.31347284\n",
      "step: 7925.0, loss:0.21825619\n",
      "step: 7926.0, loss:0.20986324\n",
      "step: 7927.0, loss:0.30092389\n",
      "step: 7928.0, loss:0.25810971\n",
      "step: 7929.0, loss:0.31881496\n",
      "step: 7930.0, loss:0.32674048\n",
      "step: 7931.0, loss:0.16889194\n",
      "step: 7932.0, loss:0.39518357\n",
      "step: 7933.0, loss:0.19502195\n",
      "step: 7934.0, loss:0.25891665\n",
      "step: 7935.0, loss:0.23173003\n",
      "step: 7936.0, loss:0.22842844\n",
      "step: 7937.0, loss:0.19223384\n",
      "step: 7938.0, loss:0.26160218\n",
      "step: 7939.0, loss:0.16768677\n",
      "step: 7940.0, loss:0.32898106\n",
      "step: 7941.0, loss:0.21757868\n",
      "step: 7942.0, loss:0.23595293\n",
      "step: 7943.0, loss:0.20214562\n",
      "step: 7944.0, loss:0.23307225\n",
      "step: 7945.0, loss:0.17686836\n",
      "step: 7946.0, loss:0.18218415\n",
      "step: 7947.0, loss:0.24015506\n",
      "step: 7948.0, loss:0.31599531\n",
      "step: 7949.0, loss:0.15637060\n",
      "step: 7950.0, loss:0.21525668\n",
      "step: 7951.0, loss:0.18098557\n",
      "step: 7952.0, loss:0.15196913\n",
      "step: 7953.0, loss:0.23270027\n",
      "step: 7954.0, loss:0.19331682\n",
      "step: 7955.0, loss:0.26802516\n",
      "step: 7956.0, loss:0.47173551\n",
      "step: 7957.0, loss:0.24018607\n",
      "step: 7958.0, loss:0.32667884\n",
      "step: 7959.0, loss:0.21405171\n",
      "step: 7960.0, loss:0.31645735\n",
      "step: 7961.0, loss:0.31294627\n",
      "step: 7962.0, loss:0.20858602\n",
      "step: 7963.0, loss:0.25779587\n",
      "step: 7964.0, loss:0.24015121\n",
      "step: 7965.0, loss:0.26410428\n",
      "step: 7966.0, loss:0.15418572\n",
      "step: 7967.0, loss:0.18915058\n",
      "step: 7968.0, loss:0.30303130\n",
      "step: 7969.0, loss:0.20826153\n",
      "step: 7970.0, loss:0.25474620\n",
      "step: 7971.0, loss:0.19781096\n",
      "step: 7972.0, loss:0.22239711\n",
      "step: 7973.0, loss:0.10563399\n",
      "step: 7974.0, loss:0.22856296\n",
      "step: 7975.0, loss:0.39340107\n",
      "step: 7976.0, loss:0.26711279\n",
      "step: 7977.0, loss:0.16398368\n",
      "step: 7978.0, loss:0.24765036\n",
      "step: 7979.0, loss:0.26149507\n",
      "step: 7980.0, loss:0.34295008\n",
      "step: 7981.0, loss:0.29042333\n",
      "step: 7982.0, loss:0.31030788\n",
      "step: 7983.0, loss:0.26723062\n",
      "step: 7984.0, loss:0.23721169\n",
      "step: 7985.0, loss:0.18555378\n",
      "step: 7986.0, loss:0.31781906\n",
      "step: 7987.0, loss:0.29283988\n",
      "step: 7988.0, loss:0.28353567\n",
      "step: 7989.0, loss:0.25549368\n",
      "step: 7990.0, loss:0.32250428\n",
      "step: 7991.0, loss:0.38210209\n",
      "step: 7992.0, loss:0.28714428\n",
      "step: 7993.0, loss:0.20119617\n",
      "step: 7994.0, loss:0.11786088\n",
      "step: 7995.0, loss:0.22204182\n",
      "step: 7996.0, loss:0.22734899\n",
      "step: 7997.0, loss:0.27586283\n",
      "step: 7998.0, loss:0.22010766\n",
      "step: 7999.0, loss:0.14274474\n",
      "step: 8000.0, loss:0.19216670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1264/1264 [09:40<00:00,  2.18it/s] \n",
      "2023-04-02 22:54:32,576 - INFO - step:8000.0, matthews_corr:0.755988, Acc:88.671778%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 8001.0, loss:0.28648931\n",
      "step: 8002.0, loss:0.21583567\n",
      "step: 8003.0, loss:0.29166084\n",
      "step: 8004.0, loss:0.18512363\n",
      "step: 8005.0, loss:0.21250118\n",
      "step: 8006.0, loss:0.27454739\n",
      "step: 8007.0, loss:0.23847996\n",
      "step: 8008.0, loss:0.28737172\n",
      "step: 8009.0, loss:0.18207473\n",
      "step: 8010.0, loss:0.19126255\n",
      "step: 8011.0, loss:0.14578720\n",
      "step: 8012.0, loss:0.27217434\n",
      "step: 8013.0, loss:0.30568085\n",
      "step: 8014.0, loss:0.17344905\n",
      "step: 8015.0, loss:0.22878789\n",
      "step: 8016.0, loss:0.21483597\n",
      "step: 8017.0, loss:0.24074140\n",
      "step: 8018.0, loss:0.26070863\n",
      "step: 8019.0, loss:0.24869337\n",
      "step: 8020.0, loss:0.20449525\n",
      "step: 8021.0, loss:0.32274193\n",
      "step: 8022.0, loss:0.28416857\n",
      "step: 8023.0, loss:0.25127956\n",
      "step: 8024.0, loss:0.13977785\n",
      "step: 8025.0, loss:0.26250121\n",
      "step: 8026.0, loss:0.22799102\n",
      "step: 8027.0, loss:0.25329082\n",
      "step: 8028.0, loss:0.20760251\n",
      "step: 8029.0, loss:0.20735629\n",
      "step: 8030.0, loss:0.27586788\n",
      "step: 8031.0, loss:0.22848452\n",
      "step: 8032.0, loss:0.22198229\n",
      "step: 8033.0, loss:0.32631429\n",
      "step: 8034.0, loss:0.14220075\n",
      "step: 8035.0, loss:0.26288002\n",
      "step: 8036.0, loss:0.31110471\n",
      "step: 8037.0, loss:0.17289871\n",
      "step: 8038.0, loss:0.25312580\n",
      "step: 8039.0, loss:0.17711200\n",
      "step: 8040.0, loss:0.17629148\n",
      "step: 8041.0, loss:0.37367486\n",
      "step: 8042.0, loss:0.23201288\n",
      "step: 8043.0, loss:0.24236716\n",
      "step: 8044.0, loss:0.32070971\n",
      "step: 8045.0, loss:0.23020107\n",
      "step: 8046.0, loss:0.22313459\n",
      "step: 8047.0, loss:0.15339949\n",
      "step: 8048.0, loss:0.19190881\n",
      "step: 8049.0, loss:0.29030943\n",
      "step: 8050.0, loss:0.20402233\n",
      "step: 8051.0, loss:0.35545587\n",
      "step: 8052.0, loss:0.20894617\n",
      "step: 8053.0, loss:0.15132444\n",
      "step: 8054.0, loss:0.14772700\n",
      "step: 8055.0, loss:0.22921840\n",
      "step: 8056.0, loss:0.13780654\n",
      "step: 8057.0, loss:0.18978564\n",
      "step: 8058.0, loss:0.22486784\n",
      "step: 8059.0, loss:0.35846050\n",
      "step: 8060.0, loss:0.17374185\n",
      "step: 8061.0, loss:0.19479492\n",
      "step: 8062.0, loss:0.27647050\n",
      "step: 8063.0, loss:0.18086517\n",
      "step: 8064.0, loss:0.26101101\n",
      "step: 8065.0, loss:0.18995729\n",
      "step: 8066.0, loss:0.27174347\n",
      "step: 8067.0, loss:0.30695812\n",
      "step: 8068.0, loss:0.28671921\n",
      "step: 8069.0, loss:0.38581521\n",
      "step: 8070.0, loss:0.20935871\n",
      "step: 8071.0, loss:0.30909167\n",
      "step: 8072.0, loss:0.22663202\n",
      "step: 8073.0, loss:0.41648969\n",
      "step: 8074.0, loss:0.37058577\n",
      "step: 8075.0, loss:0.20862548\n",
      "step: 8076.0, loss:0.27057584\n",
      "step: 8077.0, loss:0.23553662\n",
      "step: 8078.0, loss:0.23736563\n",
      "step: 8079.0, loss:0.27337868\n",
      "step: 8080.0, loss:0.36102055\n",
      "step: 8081.0, loss:0.29849894\n",
      "step: 8082.0, loss:0.21572875\n",
      "step: 8083.0, loss:0.31641829\n",
      "step: 8084.0, loss:0.20978935\n",
      "step: 8085.0, loss:0.17992692\n",
      "step: 8086.0, loss:0.28080402\n",
      "step: 8087.0, loss:0.36187167\n",
      "step: 8088.0, loss:0.22379239\n",
      "step: 8089.0, loss:0.19078899\n",
      "step: 8090.0, loss:0.20746719\n",
      "step: 8091.0, loss:0.24163377\n",
      "step: 8092.0, loss:0.22642926\n",
      "step: 8093.0, loss:0.15762015\n",
      "step: 8094.0, loss:0.22837618\n",
      "step: 8095.0, loss:0.15009142\n",
      "step: 8096.0, loss:0.30068960\n",
      "step: 8097.0, loss:0.25321702\n",
      "step: 8098.0, loss:0.37969829\n",
      "step: 8099.0, loss:0.16075282\n",
      "step: 8100.0, loss:0.42449516\n",
      "step: 8101.0, loss:0.20585717\n",
      "step: 8102.0, loss:0.22267644\n",
      "step: 8103.0, loss:0.35006173\n",
      "step: 8104.0, loss:0.17574816\n",
      "step: 8105.0, loss:0.22433103\n",
      "step: 8106.0, loss:0.24396595\n",
      "step: 8107.0, loss:0.30651132\n",
      "step: 8108.0, loss:0.26090311\n",
      "step: 8109.0, loss:0.24920964\n",
      "step: 8110.0, loss:0.18698534\n",
      "step: 8111.0, loss:0.22695059\n",
      "step: 8112.0, loss:0.43274830\n",
      "step: 8113.0, loss:0.23759615\n",
      "step: 8114.0, loss:0.15739992\n",
      "step: 8115.0, loss:0.20979146\n",
      "step: 8116.0, loss:0.30315441\n",
      "step: 8117.0, loss:0.29787407\n",
      "step: 8118.0, loss:0.34675738\n",
      "step: 8119.0, loss:0.22868110\n",
      "step: 8120.0, loss:0.23482646\n",
      "step: 8121.0, loss:0.21686531\n",
      "step: 8122.0, loss:0.36893691\n",
      "step: 8123.0, loss:0.36721714\n",
      "step: 8124.0, loss:0.21877256\n",
      "step: 8125.0, loss:0.19268292\n",
      "step: 8126.0, loss:0.15209436\n",
      "step: 8127.0, loss:0.14057908\n",
      "step: 8128.0, loss:0.19892190\n",
      "step: 8129.0, loss:0.28603440\n",
      "step: 8130.0, loss:0.36814321\n",
      "step: 8131.0, loss:0.28673666\n",
      "step: 8132.0, loss:0.23974621\n",
      "step: 8133.0, loss:0.30628093\n",
      "step: 8134.0, loss:0.26806169\n",
      "step: 8135.0, loss:0.23609097\n",
      "step: 8136.0, loss:0.21908576\n",
      "step: 8137.0, loss:0.14880481\n",
      "step: 8138.0, loss:0.14553580\n",
      "step: 8139.0, loss:0.23289794\n",
      "step: 8140.0, loss:0.20225200\n",
      "step: 8141.0, loss:0.16684427\n",
      "step: 8142.0, loss:0.30303888\n",
      "step: 8143.0, loss:0.24542452\n",
      "step: 8144.0, loss:0.27271061\n",
      "step: 8145.0, loss:0.21854747\n",
      "step: 8146.0, loss:0.26868397\n",
      "step: 8147.0, loss:0.26759744\n",
      "step: 8148.0, loss:0.32158059\n",
      "step: 8149.0, loss:0.38703322\n",
      "step: 8150.0, loss:0.35193568\n",
      "step: 8151.0, loss:0.20619149\n",
      "step: 8152.0, loss:0.29170740\n",
      "step: 8153.0, loss:0.13870354\n",
      "step: 8154.0, loss:0.20251801\n",
      "step: 8155.0, loss:0.36141788\n",
      "step: 8156.0, loss:0.30578765\n",
      "step: 8157.0, loss:0.26199426\n",
      "step: 8158.0, loss:0.48590660\n",
      "step: 8159.0, loss:0.20084095\n",
      "step: 8160.0, loss:0.14745066\n",
      "step: 8161.0, loss:0.19937398\n",
      "step: 8162.0, loss:0.18444729\n",
      "step: 8163.0, loss:0.29866409\n",
      "step: 8164.0, loss:0.28175398\n",
      "step: 8165.0, loss:0.17727652\n",
      "step: 8166.0, loss:0.17300544\n",
      "step: 8167.0, loss:0.37679484\n",
      "step: 8168.0, loss:0.21842242\n",
      "step: 8169.0, loss:0.16844688\n",
      "step: 8170.0, loss:0.25003915\n",
      "step: 8171.0, loss:0.23597631\n",
      "step: 8172.0, loss:0.24257320\n",
      "step: 8173.0, loss:0.16664393\n",
      "step: 8174.0, loss:0.28309677\n",
      "step: 8175.0, loss:0.15793972\n",
      "step: 8176.0, loss:0.21788965\n",
      "step: 8177.0, loss:0.19950949\n",
      "step: 8178.0, loss:0.23450049\n",
      "step: 8179.0, loss:0.20706066\n",
      "step: 8180.0, loss:0.20596237\n",
      "step: 8181.0, loss:0.29909114\n",
      "step: 8182.0, loss:0.40284982\n",
      "step: 8183.0, loss:0.16347159\n",
      "step: 8184.0, loss:0.28831829\n",
      "step: 8185.0, loss:0.35032014\n",
      "step: 8186.0, loss:0.25656950\n",
      "step: 8187.0, loss:0.24305120\n",
      "step: 8188.0, loss:0.18212993\n",
      "step: 8189.0, loss:0.18959754\n",
      "step: 8190.0, loss:0.14637105\n",
      "step: 8191.0, loss:0.33348932\n",
      "step: 8192.0, loss:0.34389669\n",
      "step: 8193.0, loss:0.26235183\n",
      "step: 8194.0, loss:0.37324485\n",
      "step: 8195.0, loss:0.22455844\n",
      "step: 8196.0, loss:0.28861123\n",
      "step: 8197.0, loss:0.26763240\n",
      "step: 8198.0, loss:0.26106610\n",
      "step: 8199.0, loss:0.17817860\n",
      "step: 8200.0, loss:0.41167112\n",
      "step: 8201.0, loss:0.23604723\n",
      "step: 8202.0, loss:0.30946213\n",
      "step: 8203.0, loss:0.29143582\n",
      "step: 8204.0, loss:0.21793038\n",
      "step: 8205.0, loss:0.23965321\n",
      "step: 8206.0, loss:0.20867822\n",
      "step: 8207.0, loss:0.18741838\n",
      "step: 8208.0, loss:0.35227204\n",
      "step: 8209.0, loss:0.21532116\n",
      "step: 8210.0, loss:0.37286944\n",
      "step: 8211.0, loss:0.26466838\n",
      "step: 8212.0, loss:0.17090527\n",
      "step: 8213.0, loss:0.21629317\n",
      "step: 8214.0, loss:0.18071534\n",
      "step: 8215.0, loss:0.22079444\n",
      "step: 8216.0, loss:0.19683283\n",
      "step: 8217.0, loss:0.15241709\n",
      "step: 8218.0, loss:0.27604549\n",
      "step: 8219.0, loss:0.31269613\n",
      "step: 8220.0, loss:0.20846215\n",
      "step: 8221.0, loss:0.28917337\n",
      "step: 8222.0, loss:0.13874257\n",
      "step: 8223.0, loss:0.21338627\n",
      "step: 8224.0, loss:0.23838676\n",
      "step: 8225.0, loss:0.20837003\n",
      "step: 8226.0, loss:0.25548710\n",
      "step: 8227.0, loss:0.18984792\n",
      "step: 8228.0, loss:0.19711275\n",
      "step: 8229.0, loss:0.28722875\n",
      "step: 8230.0, loss:0.15179228\n",
      "step: 8231.0, loss:0.21806436\n",
      "step: 8232.0, loss:0.26101763\n",
      "step: 8233.0, loss:0.19970891\n",
      "step: 8234.0, loss:0.15022665\n",
      "step: 8235.0, loss:0.13858770\n",
      "step: 8236.0, loss:0.32747421\n",
      "step: 8237.0, loss:0.31778931\n",
      "step: 8238.0, loss:0.25906587\n",
      "step: 8239.0, loss:0.27024209\n",
      "step: 8240.0, loss:0.24618356\n",
      "step: 8241.0, loss:0.16631958\n",
      "step: 8242.0, loss:0.16319573\n",
      "step: 8243.0, loss:0.33282183\n",
      "step: 8244.0, loss:0.26135482\n",
      "step: 8245.0, loss:0.11918543\n",
      "step: 8246.0, loss:0.35543376\n",
      "step: 8247.0, loss:0.17023837\n",
      "step: 8248.0, loss:0.25681244\n",
      "step: 8249.0, loss:0.31400001\n",
      "step: 8250.0, loss:0.35196785\n",
      "step: 8251.0, loss:0.19233374\n",
      "step: 8252.0, loss:0.43698293\n",
      "step: 8253.0, loss:0.18015039\n",
      "step: 8254.0, loss:0.31402921\n",
      "step: 8255.0, loss:0.16500752\n",
      "step: 8256.0, loss:0.24890947\n",
      "step: 8257.0, loss:0.19051352\n",
      "step: 8258.0, loss:0.30341825\n",
      "step: 8259.0, loss:0.24211462\n",
      "step: 8260.0, loss:0.17941430\n",
      "step: 8261.0, loss:0.24495677\n",
      "step: 8262.0, loss:0.27215635\n",
      "step: 8263.0, loss:0.24786231\n",
      "step: 8264.0, loss:0.21768276\n",
      "step: 8265.0, loss:0.18861879\n",
      "step: 8266.0, loss:0.26344167\n",
      "step: 8267.0, loss:0.11638043\n",
      "step: 8268.0, loss:0.36081750\n",
      "step: 8269.0, loss:0.12786716\n",
      "step: 8270.0, loss:0.22112076\n",
      "step: 8271.0, loss:0.13620073\n",
      "step: 8272.0, loss:0.19878036\n",
      "step: 8273.0, loss:0.21941553\n",
      "step: 8274.0, loss:0.24920811\n",
      "step: 8275.0, loss:0.24841731\n",
      "step: 8276.0, loss:0.16355038\n",
      "step: 8277.0, loss:0.30918879\n",
      "step: 8278.0, loss:0.29838545\n",
      "step: 8279.0, loss:0.31144806\n",
      "step: 8280.0, loss:0.22918469\n",
      "step: 8281.0, loss:0.20529632\n",
      "step: 8282.0, loss:0.24467476\n",
      "step: 8283.0, loss:0.26469323\n",
      "step: 8284.0, loss:0.31607087\n",
      "step: 8285.0, loss:0.16011437\n",
      "step: 8286.0, loss:0.25183933\n",
      "step: 8287.0, loss:0.22771754\n",
      "step: 8288.0, loss:0.29783906\n",
      "step: 8289.0, loss:0.29396112\n",
      "step: 8290.0, loss:0.29443050\n",
      "step: 8291.0, loss:0.27803946\n",
      "step: 8292.0, loss:0.21664671\n",
      "step: 8293.0, loss:0.23187645\n",
      "step: 8294.0, loss:0.22099913\n",
      "step: 8295.0, loss:0.29263931\n",
      "step: 8296.0, loss:0.27070175\n",
      "step: 8297.0, loss:0.25354623\n",
      "step: 8298.0, loss:0.32293868\n",
      "step: 8299.0, loss:0.38844319\n",
      "step: 8300.0, loss:0.33394153\n",
      "step: 8301.0, loss:0.14125114\n",
      "step: 8302.0, loss:0.21408547\n",
      "step: 8303.0, loss:0.29020821\n",
      "step: 8304.0, loss:0.23975845\n",
      "step: 8305.0, loss:0.31339323\n",
      "step: 8306.0, loss:0.19295637\n",
      "step: 8307.0, loss:0.23061053\n",
      "step: 8308.0, loss:0.29731130\n",
      "step: 8309.0, loss:0.26123778\n",
      "step: 8310.0, loss:0.26993500\n",
      "step: 8311.0, loss:0.31536449\n",
      "step: 8312.0, loss:0.28014650\n",
      "step: 8313.0, loss:0.23604188\n",
      "step: 8314.0, loss:0.23045249\n",
      "step: 8315.0, loss:0.31219681\n",
      "step: 8316.0, loss:0.16914885\n",
      "step: 8317.0, loss:0.35884278\n",
      "step: 8318.0, loss:0.24885716\n",
      "step: 8319.0, loss:0.22049328\n",
      "step: 8320.0, loss:0.33250723\n",
      "step: 8321.0, loss:0.32227857\n",
      "step: 8322.0, loss:0.38132093\n",
      "step: 8323.0, loss:0.29993000\n",
      "step: 8324.0, loss:0.15275520\n",
      "step: 8325.0, loss:0.24261510\n",
      "step: 8326.0, loss:0.28658254\n",
      "step: 8327.0, loss:0.32513648\n",
      "step: 8328.0, loss:0.37124451\n",
      "step: 8329.0, loss:0.36526603\n",
      "step: 8330.0, loss:0.21667446\n",
      "step: 8331.0, loss:0.32487709\n",
      "step: 8332.0, loss:0.26998708\n",
      "step: 8333.0, loss:0.21889203\n",
      "step: 8334.0, loss:0.16967747\n",
      "step: 8335.0, loss:0.20097724\n",
      "step: 8336.0, loss:0.31810822\n",
      "step: 8337.0, loss:0.31624332\n",
      "step: 8338.0, loss:0.21881681\n",
      "step: 8339.0, loss:0.26593235\n",
      "step: 8340.0, loss:0.17532190\n",
      "step: 8341.0, loss:0.26547954\n",
      "step: 8342.0, loss:0.18972561\n",
      "step: 8343.0, loss:0.23988749\n",
      "step: 8344.0, loss:0.21737427\n",
      "step: 8345.0, loss:0.33045613\n",
      "step: 8346.0, loss:0.26771185\n",
      "step: 8347.0, loss:0.12700105\n",
      "step: 8348.0, loss:0.40107557\n",
      "step: 8349.0, loss:0.14520899\n",
      "step: 8350.0, loss:0.25222464\n",
      "step: 8351.0, loss:0.16367572\n",
      "step: 8352.0, loss:0.18153279\n",
      "step: 8353.0, loss:0.29657829\n",
      "step: 8354.0, loss:0.21290468\n",
      "step: 8355.0, loss:0.39585970\n",
      "step: 8356.0, loss:0.36735252\n",
      "step: 8357.0, loss:0.33477422\n",
      "step: 8358.0, loss:0.22092123\n",
      "step: 8359.0, loss:0.20343651\n",
      "step: 8360.0, loss:0.22131106\n",
      "step: 8361.0, loss:0.16402062\n",
      "step: 8362.0, loss:0.31503131\n",
      "step: 8363.0, loss:0.17639096\n",
      "step: 8364.0, loss:0.25681389\n",
      "step: 8365.0, loss:0.32130737\n",
      "step: 8366.0, loss:0.26217148\n",
      "step: 8367.0, loss:0.28639480\n",
      "step: 8368.0, loss:0.16904576\n",
      "step: 8369.0, loss:0.25137520\n",
      "step: 8370.0, loss:0.30139438\n",
      "step: 8371.0, loss:0.21658599\n",
      "step: 8372.0, loss:0.17077420\n",
      "step: 8373.0, loss:0.25662799\n",
      "step: 8374.0, loss:0.28966978\n",
      "step: 8375.0, loss:0.21538967\n",
      "step: 8376.0, loss:0.28828815\n",
      "step: 8377.0, loss:0.25487006\n",
      "step: 8378.0, loss:0.18098948\n",
      "step: 8379.0, loss:0.21615759\n",
      "step: 8380.0, loss:0.21106033\n",
      "step: 8381.0, loss:0.24398792\n",
      "step: 8382.0, loss:0.34804589\n",
      "step: 8383.0, loss:0.27633766\n",
      "step: 8384.0, loss:0.30335314\n",
      "step: 8385.0, loss:0.21471216\n",
      "step: 8386.0, loss:0.22460103\n",
      "step: 8387.0, loss:0.20179433\n",
      "step: 8388.0, loss:0.24329788\n",
      "step: 8389.0, loss:0.40709857\n",
      "step: 8390.0, loss:0.37172003\n",
      "step: 8391.0, loss:0.22029703\n",
      "step: 8392.0, loss:0.11421016\n",
      "step: 8393.0, loss:0.25828182\n",
      "step: 8394.0, loss:0.27912827\n",
      "step: 8395.0, loss:0.14961392\n",
      "step: 8396.0, loss:0.25134547\n",
      "step: 8397.0, loss:0.24129967\n",
      "step: 8398.0, loss:0.25945672\n",
      "step: 8399.0, loss:0.25516763\n",
      "step: 8400.0, loss:0.22263627\n",
      "step: 8401.0, loss:0.30520156\n",
      "step: 8402.0, loss:0.32954337\n",
      "step: 8403.0, loss:0.27820056\n",
      "step: 8404.0, loss:0.32101027\n",
      "step: 8405.0, loss:0.31850083\n",
      "step: 8406.0, loss:0.14944807\n",
      "step: 8407.0, loss:0.16071380\n",
      "step: 8408.0, loss:0.15027037\n",
      "step: 8409.0, loss:0.16018907\n",
      "step: 8410.0, loss:0.32560725\n",
      "step: 8411.0, loss:0.27828985\n",
      "step: 8412.0, loss:0.21821173\n",
      "step: 8413.0, loss:0.30344248\n",
      "step: 8414.0, loss:0.22228985\n",
      "step: 8415.0, loss:0.36560911\n",
      "step: 8416.0, loss:0.19490793\n",
      "step: 8417.0, loss:0.37114559\n",
      "step: 8418.0, loss:0.27371258\n",
      "step: 8419.0, loss:0.26660313\n",
      "step: 8420.0, loss:0.22101606\n",
      "step: 8421.0, loss:0.32020557\n",
      "step: 8422.0, loss:0.24819902\n",
      "step: 8423.0, loss:0.30408868\n",
      "step: 8424.0, loss:0.24288090\n",
      "step: 8425.0, loss:0.18113075\n",
      "step: 8426.0, loss:0.20910289\n",
      "step: 8427.0, loss:0.15538955\n",
      "step: 8428.0, loss:0.16618948\n",
      "step: 8429.0, loss:0.26681769\n",
      "step: 8430.0, loss:0.22106810\n",
      "step: 8431.0, loss:0.45703484\n",
      "step: 8432.0, loss:0.22354987\n",
      "step: 8433.0, loss:0.22606630\n",
      "step: 8434.0, loss:0.27808691\n",
      "step: 8435.0, loss:0.19792935\n",
      "step: 8436.0, loss:0.22692827\n",
      "step: 8437.0, loss:0.29031906\n",
      "step: 8438.0, loss:0.24490634\n",
      "step: 8439.0, loss:0.19326960\n",
      "step: 8440.0, loss:0.14428333\n",
      "step: 8441.0, loss:0.21832356\n",
      "step: 8442.0, loss:0.17299520\n",
      "step: 8443.0, loss:0.21266004\n",
      "step: 8444.0, loss:0.25348617\n",
      "step: 8445.0, loss:0.25762758\n",
      "step: 8446.0, loss:0.24252222\n",
      "step: 8447.0, loss:0.27363368\n",
      "step: 8448.0, loss:0.17480953\n",
      "step: 8449.0, loss:0.26699499\n",
      "step: 8450.0, loss:0.21002976\n",
      "step: 8451.0, loss:0.43667509\n",
      "step: 8452.0, loss:0.21574705\n",
      "step: 8453.0, loss:0.22587423\n",
      "step: 8454.0, loss:0.30645498\n",
      "step: 8455.0, loss:0.29485748\n",
      "step: 8456.0, loss:0.32954818\n",
      "step: 8457.0, loss:0.16771231\n",
      "step: 8458.0, loss:0.24907657\n",
      "step: 8459.0, loss:0.21780063\n",
      "step: 8460.0, loss:0.25879165\n",
      "step: 8461.0, loss:0.20760376\n",
      "step: 8462.0, loss:0.15641716\n",
      "step: 8463.0, loss:0.16035333\n",
      "step: 8464.0, loss:0.22423155\n",
      "step: 8465.0, loss:0.27098529\n",
      "step: 8466.0, loss:0.16927196\n",
      "step: 8467.0, loss:0.28017646\n",
      "step: 8468.0, loss:0.17197096\n",
      "step: 8469.0, loss:0.21021655\n",
      "step: 8470.0, loss:0.17280160\n",
      "step: 8471.0, loss:0.15302102\n",
      "step: 8472.0, loss:0.13607778\n",
      "step: 8473.0, loss:0.20323451\n",
      "step: 8474.0, loss:0.17869803\n",
      "step: 8475.0, loss:0.25948724\n",
      "step: 8476.0, loss:0.35803233\n",
      "step: 8477.0, loss:0.28501152\n",
      "step: 8478.0, loss:0.14836683\n",
      "step: 8479.0, loss:0.26579111\n",
      "step: 8480.0, loss:0.13484188\n",
      "step: 8481.0, loss:0.22129105\n",
      "step: 8482.0, loss:0.20862247\n",
      "step: 8483.0, loss:0.18378394\n",
      "step: 8484.0, loss:0.15593570\n",
      "step: 8485.0, loss:0.23640481\n",
      "step: 8486.0, loss:0.15707593\n",
      "step: 8487.0, loss:0.40988811\n",
      "step: 8488.0, loss:0.29011475\n",
      "step: 8489.0, loss:0.17770466\n",
      "step: 8490.0, loss:0.35819192\n",
      "step: 8491.0, loss:0.35091429\n",
      "step: 8492.0, loss:0.21780680\n",
      "step: 8493.0, loss:0.16616952\n",
      "step: 8494.0, loss:0.28711850\n",
      "step: 8495.0, loss:0.23438454\n",
      "step: 8496.0, loss:0.39572501\n",
      "step: 8497.0, loss:0.11362441\n",
      "step: 8498.0, loss:0.27334349\n",
      "step: 8499.0, loss:0.16689139\n",
      "step: 8500.0, loss:0.28311630\n",
      "step: 8501.0, loss:0.20374804\n",
      "step: 8502.0, loss:0.13869848\n",
      "step: 8503.0, loss:0.22147011\n",
      "step: 8504.0, loss:0.15641179\n",
      "step: 8505.0, loss:0.28322791\n",
      "step: 8506.0, loss:0.34145466\n",
      "step: 8507.0, loss:0.27991506\n",
      "step: 8508.0, loss:0.21755976\n",
      "step: 8509.0, loss:0.13594008\n",
      "step: 8510.0, loss:0.17849741\n",
      "step: 8511.0, loss:0.20219081\n",
      "step: 8512.0, loss:0.28696351\n",
      "step: 8513.0, loss:0.30939800\n",
      "step: 8514.0, loss:0.20172080\n",
      "step: 8515.0, loss:0.28251673\n",
      "step: 8516.0, loss:0.21090480\n",
      "step: 8517.0, loss:0.18695405\n",
      "step: 8518.0, loss:0.21203839\n",
      "step: 8519.0, loss:0.25274854\n",
      "step: 8520.0, loss:0.14987511\n",
      "step: 8521.0, loss:0.19950559\n",
      "step: 8522.0, loss:0.26917014\n",
      "step: 8523.0, loss:0.31877133\n",
      "step: 8524.0, loss:0.27080204\n",
      "step: 8525.0, loss:0.24022176\n",
      "step: 8526.0, loss:0.17041286\n",
      "step: 8527.0, loss:0.25210200\n",
      "step: 8528.0, loss:0.30899352\n",
      "step: 8529.0, loss:0.35324057\n",
      "step: 8530.0, loss:0.33949951\n",
      "step: 8531.0, loss:0.29334284\n",
      "step: 8532.0, loss:0.22678582\n",
      "step: 8533.0, loss:0.19434717\n",
      "step: 8534.0, loss:0.15774869\n",
      "step: 8535.0, loss:0.21678697\n",
      "step: 8536.0, loss:0.22405242\n",
      "step: 8537.0, loss:0.28490990\n",
      "step: 8538.0, loss:0.23330291\n",
      "step: 8539.0, loss:0.20113915\n",
      "step: 8540.0, loss:0.22763759\n",
      "step: 8541.0, loss:0.14540130\n",
      "step: 8542.0, loss:0.16953265\n",
      "step: 8543.0, loss:0.20114626\n",
      "step: 8544.0, loss:0.26429510\n",
      "step: 8545.0, loss:0.32209665\n",
      "step: 8546.0, loss:0.13371943\n",
      "step: 8547.0, loss:0.13089478\n",
      "step: 8548.0, loss:0.22949208\n",
      "step: 8549.0, loss:0.21296381\n",
      "step: 8550.0, loss:0.20091052\n",
      "step: 8551.0, loss:0.27629693\n",
      "step: 8552.0, loss:0.31232433\n",
      "step: 8553.0, loss:0.16186382\n",
      "step: 8554.0, loss:0.15541301\n",
      "step: 8555.0, loss:0.24036922\n",
      "step: 8556.0, loss:0.31181883\n",
      "step: 8557.0, loss:0.28188974\n",
      "step: 8558.0, loss:0.21048266\n",
      "step: 8559.0, loss:0.20184977\n",
      "step: 8560.0, loss:0.21006749\n",
      "step: 8561.0, loss:0.21756316\n",
      "step: 8562.0, loss:0.17779636\n",
      "step: 8563.0, loss:0.25337118\n",
      "step: 8564.0, loss:0.22396527\n",
      "step: 8565.0, loss:0.20646949\n",
      "step: 8566.0, loss:0.13203397\n",
      "step: 8567.0, loss:0.27562021\n",
      "step: 8568.0, loss:0.19518704\n",
      "step: 8569.0, loss:0.14508207\n",
      "step: 8570.0, loss:0.20057762\n",
      "step: 8571.0, loss:0.37105320\n",
      "step: 8572.0, loss:0.12967692\n",
      "step: 8573.0, loss:0.18467375\n",
      "step: 8574.0, loss:0.20493349\n",
      "step: 8575.0, loss:0.25353681\n",
      "step: 8576.0, loss:0.31891076\n",
      "step: 8577.0, loss:0.29336054\n",
      "step: 8578.0, loss:0.29014704\n",
      "step: 8579.0, loss:0.24884192\n",
      "step: 8580.0, loss:0.36853373\n",
      "step: 8581.0, loss:0.28261225\n",
      "step: 8582.0, loss:0.21619954\n",
      "step: 8583.0, loss:0.17412300\n",
      "step: 8584.0, loss:0.25595880\n",
      "step: 8585.0, loss:0.16308067\n",
      "step: 8586.0, loss:0.27691044\n",
      "step: 8587.0, loss:0.11044600\n",
      "step: 8588.0, loss:0.13675698\n",
      "step: 8589.0, loss:0.18599814\n",
      "step: 8590.0, loss:0.14859804\n",
      "step: 8591.0, loss:0.30120750\n",
      "step: 8592.0, loss:0.25925381\n",
      "step: 8593.0, loss:0.25163982\n",
      "step: 8594.0, loss:0.21010972\n",
      "step: 8595.0, loss:0.24279799\n",
      "step: 8596.0, loss:0.24456827\n",
      "step: 8597.0, loss:0.13726030\n",
      "step: 8598.0, loss:0.25998653\n",
      "step: 8599.0, loss:0.12015292\n",
      "step: 8600.0, loss:0.18516914\n",
      "step: 8601.0, loss:0.21229202\n",
      "step: 8602.0, loss:0.28777706\n",
      "step: 8603.0, loss:0.25810430\n",
      "step: 8604.0, loss:0.36410282\n",
      "step: 8605.0, loss:0.23426186\n",
      "step: 8606.0, loss:0.34998364\n",
      "step: 8607.0, loss:0.37065830\n",
      "step: 8608.0, loss:0.18887185\n",
      "step: 8609.0, loss:0.20609273\n",
      "step: 8610.0, loss:0.13436511\n",
      "step: 8611.0, loss:0.27294148\n",
      "step: 8612.0, loss:0.17387668\n",
      "step: 8613.0, loss:0.34471580\n",
      "step: 8614.0, loss:0.29608319\n",
      "step: 8615.0, loss:0.18861952\n",
      "step: 8616.0, loss:0.26188010\n",
      "step: 8617.0, loss:0.17968757\n",
      "step: 8618.0, loss:0.34782352\n",
      "step: 8619.0, loss:0.24599351\n",
      "step: 8620.0, loss:0.20855292\n",
      "step: 8621.0, loss:0.29509332\n",
      "step: 8622.0, loss:0.27440783\n",
      "step: 8623.0, loss:0.20611428\n",
      "step: 8624.0, loss:0.28819228\n",
      "step: 8625.0, loss:0.33542746\n",
      "step: 8626.0, loss:0.18712851\n",
      "step: 8627.0, loss:0.18790703\n",
      "step: 8628.0, loss:0.24968041\n",
      "step: 8629.0, loss:0.27266113\n",
      "step: 8630.0, loss:0.15864293\n",
      "step: 8631.0, loss:0.28003782\n",
      "step: 8632.0, loss:0.32701638\n",
      "step: 8633.0, loss:0.12108761\n",
      "step: 8634.0, loss:0.16657126\n",
      "step: 8635.0, loss:0.24058272\n",
      "step: 8636.0, loss:0.18596315\n",
      "step: 8637.0, loss:0.18496626\n",
      "step: 8638.0, loss:0.17655978\n",
      "step: 8639.0, loss:0.28198409\n",
      "step: 8640.0, loss:0.18246224\n",
      "step: 8641.0, loss:0.14301450\n",
      "step: 8642.0, loss:0.23263062\n",
      "step: 8643.0, loss:0.37973010\n",
      "step: 8644.0, loss:0.24975590\n",
      "step: 8645.0, loss:0.24386647\n",
      "step: 8646.0, loss:0.20193249\n",
      "step: 8647.0, loss:0.23779499\n",
      "step: 8648.0, loss:0.19429368\n",
      "step: 8649.0, loss:0.22352009\n",
      "step: 8650.0, loss:0.20684962\n",
      "step: 8651.0, loss:0.24135785\n",
      "step: 8652.0, loss:0.30536938\n",
      "step: 8653.0, loss:0.22604858\n",
      "step: 8654.0, loss:0.24498018\n",
      "step: 8655.0, loss:0.14805460\n",
      "step: 8656.0, loss:0.23847814\n",
      "step: 8657.0, loss:0.18990405\n",
      "step: 8658.0, loss:0.19891006\n",
      "step: 8659.0, loss:0.27167992\n",
      "step: 8660.0, loss:0.25729451\n",
      "step: 8661.0, loss:0.26808999\n",
      "step: 8662.0, loss:0.20820287\n",
      "step: 8663.0, loss:0.30821107\n",
      "step: 8664.0, loss:0.25888121\n",
      "step: 8665.0, loss:0.27711819\n",
      "step: 8666.0, loss:0.29651963\n",
      "step: 8667.0, loss:0.23332980\n",
      "step: 8668.0, loss:0.19926093\n",
      "step: 8669.0, loss:0.17810277\n",
      "step: 8670.0, loss:0.22671366\n",
      "step: 8671.0, loss:0.12564971\n",
      "step: 8672.0, loss:0.16666297\n",
      "step: 8673.0, loss:0.25500571\n",
      "step: 8674.0, loss:0.19568837\n",
      "step: 8675.0, loss:0.23786471\n",
      "step: 8676.0, loss:0.22594664\n",
      "step: 8677.0, loss:0.16570995\n",
      "step: 8678.0, loss:0.24809106\n",
      "step: 8679.0, loss:0.12765399\n",
      "step: 8680.0, loss:0.23798937\n",
      "step: 8681.0, loss:0.26463362\n",
      "step: 8682.0, loss:0.32385809\n",
      "step: 8683.0, loss:0.20207892\n",
      "step: 8684.0, loss:0.33942335\n",
      "step: 8685.0, loss:0.25151496\n",
      "step: 8686.0, loss:0.15900952\n",
      "step: 8687.0, loss:0.25356444\n",
      "step: 8688.0, loss:0.16305782\n",
      "step: 8689.0, loss:0.25393856\n",
      "step: 8690.0, loss:0.31128371\n",
      "step: 8691.0, loss:0.16108947\n",
      "step: 8692.0, loss:0.26690080\n",
      "step: 8693.0, loss:0.27285883\n",
      "step: 8694.0, loss:0.20401403\n",
      "step: 8695.0, loss:0.19781297\n",
      "step: 8696.0, loss:0.13080302\n",
      "step: 8697.0, loss:0.26088737\n",
      "step: 8698.0, loss:0.20146425\n",
      "step: 8699.0, loss:0.32303569\n",
      "step: 8700.0, loss:0.17200719\n",
      "step: 8701.0, loss:0.25348622\n",
      "step: 8702.0, loss:0.16550684\n",
      "step: 8703.0, loss:0.19218006\n",
      "step: 8704.0, loss:0.30035933\n",
      "step: 8705.0, loss:0.23313448\n",
      "step: 8706.0, loss:0.32314128\n",
      "step: 8707.0, loss:0.24176515\n",
      "step: 8708.0, loss:0.24573043\n",
      "step: 8709.0, loss:0.17266131\n",
      "step: 8710.0, loss:0.21052554\n",
      "step: 8711.0, loss:0.13114097\n",
      "step: 8712.0, loss:0.17660469\n",
      "step: 8713.0, loss:0.15915807\n",
      "step: 8714.0, loss:0.37543070\n",
      "step: 8715.0, loss:0.21954047\n",
      "step: 8716.0, loss:0.27751498\n",
      "step: 8717.0, loss:0.33995024\n",
      "step: 8718.0, loss:0.24664373\n",
      "step: 8719.0, loss:0.29149827\n",
      "step: 8720.0, loss:0.28899589\n",
      "step: 8721.0, loss:0.21954540\n",
      "step: 8722.0, loss:0.38236731\n",
      "step: 8723.0, loss:0.27792178\n",
      "step: 8724.0, loss:0.38794049\n",
      "step: 8725.0, loss:0.16435625\n",
      "step: 8726.0, loss:0.17610476\n",
      "step: 8727.0, loss:0.20412969\n",
      "step: 8728.0, loss:0.16958814\n",
      "step: 8729.0, loss:0.26092506\n",
      "step: 8730.0, loss:0.34824562\n",
      "step: 8731.0, loss:0.31489881\n",
      "step: 8732.0, loss:0.21009688\n",
      "step: 8733.0, loss:0.18352862\n",
      "step: 8734.0, loss:0.36810132\n",
      "step: 8735.0, loss:0.22295783\n",
      "step: 8736.0, loss:0.26023399\n",
      "step: 8737.0, loss:0.21132875\n",
      "step: 8738.0, loss:0.16176504\n",
      "step: 8739.0, loss:0.17989511\n",
      "step: 8740.0, loss:0.12959883\n",
      "step: 8741.0, loss:0.21070501\n",
      "step: 8742.0, loss:0.26112407\n",
      "step: 8743.0, loss:0.14274374\n",
      "step: 8744.0, loss:0.16415199\n",
      "step: 8745.0, loss:0.15377752\n",
      "step: 8746.0, loss:0.25576552\n",
      "step: 8747.0, loss:0.12342698\n",
      "step: 8748.0, loss:0.16635937\n",
      "step: 8749.0, loss:0.18848837\n",
      "step: 8750.0, loss:0.30168635\n",
      "step: 8751.0, loss:0.20744707\n",
      "step: 8752.0, loss:0.22741543\n",
      "step: 8753.0, loss:0.36544383\n",
      "step: 8754.0, loss:0.30708299\n",
      "step: 8755.0, loss:0.23162590\n",
      "step: 8756.0, loss:0.14033017\n",
      "step: 8757.0, loss:0.30494931\n",
      "step: 8758.0, loss:0.31785424\n",
      "step: 8759.0, loss:0.23245971\n",
      "step: 8760.0, loss:0.31896087\n",
      "step: 8761.0, loss:0.21640014\n",
      "step: 8762.0, loss:0.21429162\n",
      "step: 8763.0, loss:0.14640060\n",
      "step: 8764.0, loss:0.24101747\n",
      "step: 8765.0, loss:0.27766777\n",
      "step: 8766.0, loss:0.20603949\n",
      "step: 8767.0, loss:0.24197546\n",
      "step: 8768.0, loss:0.34480138\n",
      "step: 8769.0, loss:0.23122143\n",
      "step: 8770.0, loss:0.24420694\n",
      "step: 8771.0, loss:0.19642824\n",
      "step: 8772.0, loss:0.24709507\n",
      "step: 8773.0, loss:0.29037543\n",
      "step: 8774.0, loss:0.21295702\n",
      "step: 8775.0, loss:0.21642558\n",
      "step: 8776.0, loss:0.26548295\n",
      "step: 8777.0, loss:0.15952872\n",
      "step: 8778.0, loss:0.21152978\n",
      "step: 8779.0, loss:0.22705241\n",
      "step: 8780.0, loss:0.20100646\n",
      "step: 8781.0, loss:0.24834574\n",
      "step: 8782.0, loss:0.21611181\n",
      "step: 8783.0, loss:0.14634056\n",
      "step: 8784.0, loss:0.14365936\n",
      "step: 8785.0, loss:0.26280101\n",
      "step: 8786.0, loss:0.32683847\n",
      "step: 8787.0, loss:0.25310857\n",
      "step: 8788.0, loss:0.26255410\n",
      "step: 8789.0, loss:0.16411534\n",
      "step: 8790.0, loss:0.29771771\n",
      "step: 8791.0, loss:0.25383695\n",
      "step: 8792.0, loss:0.10930146\n",
      "step: 8793.0, loss:0.19415754\n",
      "step: 8794.0, loss:0.24691637\n",
      "step: 8795.0, loss:0.15774613\n",
      "step: 8796.0, loss:0.19752895\n",
      "step: 8797.0, loss:0.18020241\n",
      "step: 8798.0, loss:0.20488852\n",
      "step: 8799.0, loss:0.14161430\n",
      "step: 8800.0, loss:0.21897693\n",
      "step: 8801.0, loss:0.25655630\n",
      "step: 8802.0, loss:0.27919156\n",
      "step: 8803.0, loss:0.14421666\n",
      "step: 8804.0, loss:0.24193407\n",
      "step: 8805.0, loss:0.14515836\n",
      "step: 8806.0, loss:0.28828715\n",
      "step: 8807.0, loss:0.13129864\n",
      "step: 8808.0, loss:0.09430942\n",
      "step: 8809.0, loss:0.23126324\n",
      "step: 8810.0, loss:0.17343061\n",
      "step: 8811.0, loss:0.15118827\n",
      "step: 8812.0, loss:0.16649322\n",
      "step: 8813.0, loss:0.21402249\n",
      "step: 8814.0, loss:0.37598718\n",
      "step: 8815.0, loss:0.26335169\n",
      "step: 8816.0, loss:0.17547771\n",
      "step: 8817.0, loss:0.11447716\n",
      "step: 8818.0, loss:0.26251314\n",
      "step: 8819.0, loss:0.18885741\n",
      "step: 8820.0, loss:0.27175369\n",
      "step: 8821.0, loss:0.17965605\n",
      "step: 8822.0, loss:0.13354717\n",
      "step: 8823.0, loss:0.17519597\n",
      "step: 8824.0, loss:0.17066817\n",
      "step: 8825.0, loss:0.15107138\n",
      "step: 8826.0, loss:0.35842068\n",
      "step: 8827.0, loss:0.25851374\n",
      "step: 8828.0, loss:0.18901697\n",
      "step: 8829.0, loss:0.12055052\n",
      "step: 8830.0, loss:0.14527790\n",
      "step: 8831.0, loss:0.18666558\n",
      "step: 8832.0, loss:0.23638964\n",
      "step: 8833.0, loss:0.42406296\n",
      "step: 8834.0, loss:0.22650868\n",
      "step: 8835.0, loss:0.23843310\n",
      "step: 8836.0, loss:0.34687456\n",
      "step: 8837.0, loss:0.38809018\n",
      "step: 8838.0, loss:0.25034963\n",
      "step: 8839.0, loss:0.20255237\n",
      "step: 8840.0, loss:0.21850784\n",
      "step: 8841.0, loss:0.23323516\n",
      "step: 8842.0, loss:0.16547966\n",
      "step: 8843.0, loss:0.17447188\n",
      "step: 8844.0, loss:0.27889179\n",
      "step: 8845.0, loss:0.27147828\n",
      "step: 8846.0, loss:0.32550701\n",
      "step: 8847.0, loss:0.21957001\n",
      "step: 8848.0, loss:0.17302221\n",
      "step: 8849.0, loss:0.25035556\n",
      "step: 8850.0, loss:0.30499600\n",
      "step: 8851.0, loss:0.30530299\n",
      "step: 8852.0, loss:0.23312974\n",
      "step: 8853.0, loss:0.22897132\n",
      "step: 8854.0, loss:0.19280296\n",
      "step: 8855.0, loss:0.23744765\n",
      "step: 8856.0, loss:0.24981300\n",
      "step: 8857.0, loss:0.24166068\n",
      "step: 8858.0, loss:0.17189848\n",
      "step: 8859.0, loss:0.18288793\n",
      "step: 8860.0, loss:0.19974655\n",
      "step: 8861.0, loss:0.22511533\n",
      "step: 8862.0, loss:0.25248829\n",
      "step: 8863.0, loss:0.29401830\n",
      "step: 8864.0, loss:0.15501770\n",
      "step: 8865.0, loss:0.15627411\n",
      "step: 8866.0, loss:0.15589132\n",
      "step: 8867.0, loss:0.24743974\n",
      "step: 8868.0, loss:0.20830744\n",
      "step: 8869.0, loss:0.26652726\n",
      "step: 8870.0, loss:0.37891886\n",
      "step: 8871.0, loss:0.17656113\n",
      "step: 8872.0, loss:0.20619471\n",
      "step: 8873.0, loss:0.23342715\n",
      "step: 8874.0, loss:0.26843993\n",
      "step: 8875.0, loss:0.24566164\n",
      "step: 8876.0, loss:0.20137772\n",
      "step: 8877.0, loss:0.22704807\n",
      "step: 8878.0, loss:0.24383049\n",
      "step: 8879.0, loss:0.17075746\n",
      "step: 8880.0, loss:0.18470922\n",
      "step: 8881.0, loss:0.28470712\n",
      "step: 8882.0, loss:0.22634823\n",
      "step: 8883.0, loss:0.14865991\n",
      "step: 8884.0, loss:0.20319266\n",
      "step: 8885.0, loss:0.20466985\n",
      "step: 8886.0, loss:0.20683075\n",
      "step: 8887.0, loss:0.17344108\n",
      "step: 8888.0, loss:0.52674656\n",
      "step: 8889.0, loss:0.20764580\n",
      "step: 8890.0, loss:0.28376237\n",
      "step: 8891.0, loss:0.25004979\n",
      "step: 8892.0, loss:0.24969628\n",
      "step: 8893.0, loss:0.20398727\n",
      "step: 8894.0, loss:0.27339736\n",
      "step: 8895.0, loss:0.16449248\n",
      "step: 8896.0, loss:0.23482398\n",
      "step: 8897.0, loss:0.15908990\n",
      "step: 8898.0, loss:0.12566762\n",
      "step: 8899.0, loss:0.18019601\n",
      "step: 8900.0, loss:0.31783790\n",
      "step: 8901.0, loss:0.30198290\n",
      "step: 8902.0, loss:0.23202412\n",
      "step: 8903.0, loss:0.22003278\n",
      "step: 8904.0, loss:0.28033540\n",
      "step: 8905.0, loss:0.15493677\n",
      "step: 8906.0, loss:0.22129268\n",
      "step: 8907.0, loss:0.21505300\n",
      "step: 8908.0, loss:0.25163852\n",
      "step: 8909.0, loss:0.33815976\n",
      "step: 8910.0, loss:0.25281205\n",
      "step: 8911.0, loss:0.18774949\n",
      "step: 8912.0, loss:0.21173178\n",
      "step: 8913.0, loss:0.15938768\n",
      "step: 8914.0, loss:0.27649608\n",
      "step: 8915.0, loss:0.22459831\n",
      "step: 8916.0, loss:0.19034285\n",
      "step: 8917.0, loss:0.36002931\n",
      "step: 8918.0, loss:0.25710238\n",
      "step: 8919.0, loss:0.31383504\n",
      "step: 8920.0, loss:0.34135450\n",
      "step: 8921.0, loss:0.23555175\n",
      "step: 8922.0, loss:0.23927224\n",
      "step: 8923.0, loss:0.21139831\n",
      "step: 8924.0, loss:0.16916537\n",
      "step: 8925.0, loss:0.38015438\n",
      "step: 8926.0, loss:0.19461768\n",
      "step: 8927.0, loss:0.21264334\n",
      "step: 8928.0, loss:0.16310932\n",
      "step: 8929.0, loss:0.36747988\n",
      "step: 8930.0, loss:0.19097170\n",
      "step: 8931.0, loss:0.19958558\n",
      "step: 8932.0, loss:0.17978250\n",
      "step: 8933.0, loss:0.31836311\n",
      "step: 8934.0, loss:0.26478148\n",
      "step: 8935.0, loss:0.34694057\n",
      "step: 8936.0, loss:0.23418094\n",
      "step: 8937.0, loss:0.12887363\n",
      "step: 8938.0, loss:0.17253434\n",
      "step: 8939.0, loss:0.24891671\n",
      "step: 8940.0, loss:0.17081480\n",
      "step: 8941.0, loss:0.27795742\n",
      "step: 8942.0, loss:0.22033336\n",
      "step: 8943.0, loss:0.21808059\n",
      "step: 8944.0, loss:0.24221642\n",
      "step: 8945.0, loss:0.32875370\n",
      "step: 8946.0, loss:0.25295578\n",
      "step: 8947.0, loss:0.29911594\n",
      "step: 8948.0, loss:0.39257372\n",
      "step: 8949.0, loss:0.23349899\n",
      "step: 8950.0, loss:0.32128846\n",
      "step: 8951.0, loss:0.34169124\n",
      "step: 8952.0, loss:0.25410878\n",
      "step: 8953.0, loss:0.16691036\n",
      "step: 8954.0, loss:0.29432483\n",
      "step: 8955.0, loss:0.16671887\n",
      "step: 8956.0, loss:0.19449492\n",
      "step: 8957.0, loss:0.19967367\n",
      "step: 8958.0, loss:0.22087568\n",
      "step: 8959.0, loss:0.29763204\n",
      "step: 8960.0, loss:0.21911259\n",
      "step: 8961.0, loss:0.38118246\n",
      "step: 8962.0, loss:0.26092021\n",
      "step: 8963.0, loss:0.31154025\n",
      "step: 8964.0, loss:0.21552908\n",
      "step: 8965.0, loss:0.12532728\n",
      "step: 8966.0, loss:0.22939729\n",
      "step: 8967.0, loss:0.20576753\n",
      "step: 8968.0, loss:0.17004267\n",
      "step: 8969.0, loss:0.24129725\n",
      "step: 8970.0, loss:0.27631623\n",
      "step: 8971.0, loss:0.15359984\n",
      "step: 8972.0, loss:0.12928158\n",
      "step: 8973.0, loss:0.25453120\n",
      "step: 8974.0, loss:0.25662350\n",
      "step: 8975.0, loss:0.18332483\n",
      "step: 8976.0, loss:0.19138309\n",
      "step: 8977.0, loss:0.21860893\n",
      "step: 8978.0, loss:0.18585294\n",
      "step: 8979.0, loss:0.39841007\n",
      "step: 8980.0, loss:0.29817728\n",
      "step: 8981.0, loss:0.17561950\n",
      "step: 8982.0, loss:0.23911033\n",
      "step: 8983.0, loss:0.32495299\n",
      "step: 8984.0, loss:0.18444746\n",
      "step: 8985.0, loss:0.15267798\n",
      "step: 8986.0, loss:0.23817014\n",
      "step: 8987.0, loss:0.24344436\n",
      "step: 8988.0, loss:0.20834540\n",
      "step: 8989.0, loss:0.21524880\n",
      "step: 8990.0, loss:0.16963413\n",
      "step: 8991.0, loss:0.21437982\n",
      "step: 8992.0, loss:0.25559358\n",
      "step: 8993.0, loss:0.23997166\n",
      "step: 8994.0, loss:0.20806608\n",
      "step: 8995.0, loss:0.23874587\n",
      "step: 8996.0, loss:0.23857631\n",
      "step: 8997.0, loss:0.34876337\n",
      "step: 8998.0, loss:0.17231003\n",
      "step: 8999.0, loss:0.24020769\n",
      "step: 9000.0, loss:0.30325129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1264/1264 [08:04<00:00,  2.61it/s]\n",
      "2023-04-02 23:41:09,346 - INFO - step:9000.0, matthews_corr:0.760712, Acc:88.775662%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 9001.0, loss:0.29897498\n",
      "step: 9002.0, loss:0.20980795\n",
      "step: 9003.0, loss:0.38500284\n",
      "step: 9004.0, loss:0.15304085\n",
      "step: 9005.0, loss:0.25581476\n",
      "step: 9006.0, loss:0.26250578\n",
      "step: 9007.0, loss:0.24207539\n",
      "step: 9008.0, loss:0.17889733\n",
      "step: 9009.0, loss:0.31248484\n",
      "step: 9010.0, loss:0.24703057\n",
      "step: 9011.0, loss:0.22608922\n",
      "step: 9012.0, loss:0.23715323\n",
      "step: 9013.0, loss:0.30828655\n",
      "step: 9014.0, loss:0.33064013\n",
      "step: 9015.0, loss:0.23751748\n",
      "step: 9016.0, loss:0.35999784\n",
      "step: 9017.0, loss:0.19212192\n",
      "step: 9018.0, loss:0.14934384\n",
      "step: 9019.0, loss:0.23941067\n",
      "step: 9020.0, loss:0.28154106\n",
      "step: 9021.0, loss:0.22636625\n",
      "step: 9022.0, loss:0.31694340\n",
      "step: 9023.0, loss:0.12463878\n",
      "step: 9024.0, loss:0.19897063\n",
      "step: 9025.0, loss:0.21092239\n",
      "step: 9026.0, loss:0.21635415\n",
      "step: 9027.0, loss:0.22481424\n",
      "step: 9028.0, loss:0.32519950\n",
      "step: 9029.0, loss:0.18477168\n",
      "step: 9030.0, loss:0.15377792\n",
      "step: 9031.0, loss:0.28264868\n",
      "step: 9032.0, loss:0.21957859\n",
      "step: 9033.0, loss:0.26512314\n",
      "step: 9034.0, loss:0.22737183\n",
      "step: 9035.0, loss:0.21077923\n",
      "step: 9036.0, loss:0.20610490\n",
      "step: 9037.0, loss:0.35335918\n",
      "step: 9038.0, loss:0.25364569\n",
      "step: 9039.0, loss:0.25858025\n",
      "step: 9040.0, loss:0.17522851\n",
      "step: 9041.0, loss:0.19746256\n",
      "step: 9042.0, loss:0.23588651\n",
      "step: 9043.0, loss:0.18627750\n",
      "step: 9044.0, loss:0.28534279\n",
      "step: 9045.0, loss:0.19603549\n",
      "step: 9046.0, loss:0.20882724\n",
      "step: 9047.0, loss:0.32253529\n",
      "step: 9048.0, loss:0.10057868\n",
      "step: 9049.0, loss:0.23119102\n",
      "step: 9050.0, loss:0.16597813\n",
      "step: 9051.0, loss:0.21023840\n",
      "step: 9052.0, loss:0.26584090\n",
      "step: 9053.0, loss:0.17441003\n",
      "step: 9054.0, loss:0.24711554\n",
      "step: 9055.0, loss:0.22006832\n",
      "step: 9056.0, loss:0.23587500\n",
      "step: 9057.0, loss:0.29032199\n",
      "step: 9058.0, loss:0.28930370\n",
      "step: 9059.0, loss:0.11376001\n",
      "step: 9060.0, loss:0.15828252\n",
      "step: 9061.0, loss:0.11714891\n",
      "step: 9062.0, loss:0.34694640\n",
      "step: 9063.0, loss:0.17400531\n",
      "step: 9064.0, loss:0.15831357\n",
      "step: 9065.0, loss:0.22643339\n",
      "step: 9066.0, loss:0.22490902\n",
      "step: 9067.0, loss:0.10496260\n",
      "step: 9068.0, loss:0.16605064\n",
      "step: 9069.0, loss:0.32809445\n",
      "step: 9070.0, loss:0.13318652\n",
      "step: 9071.0, loss:0.22228166\n",
      "step: 9072.0, loss:0.20915793\n",
      "step: 9073.0, loss:0.34639058\n",
      "step: 9074.0, loss:0.25677595\n",
      "step: 9075.0, loss:0.27117448\n",
      "step: 9076.0, loss:0.32653953\n",
      "step: 9077.0, loss:0.22070666\n",
      "step: 9078.0, loss:0.37038533\n",
      "step: 9079.0, loss:0.20276507\n",
      "step: 9080.0, loss:0.33202470\n",
      "step: 9081.0, loss:0.21387457\n",
      "step: 9082.0, loss:0.27753413\n",
      "step: 9083.0, loss:0.19026139\n",
      "step: 9084.0, loss:0.19991713\n",
      "step: 9085.0, loss:0.29165199\n",
      "step: 9086.0, loss:0.12142799\n",
      "step: 9087.0, loss:0.22253734\n",
      "step: 9088.0, loss:0.34941404\n",
      "step: 9089.0, loss:0.18668706\n",
      "step: 9090.0, loss:0.20412088\n",
      "step: 9091.0, loss:0.25573339\n",
      "step: 9092.0, loss:0.21594547\n",
      "step: 9093.0, loss:0.20548778\n",
      "step: 9094.0, loss:0.22571113\n",
      "step: 9095.0, loss:0.28334142\n",
      "step: 9096.0, loss:0.31804540\n",
      "step: 9097.0, loss:0.24660357\n",
      "step: 9098.0, loss:0.22605453\n",
      "step: 9099.0, loss:0.14279247\n",
      "step: 9100.0, loss:0.26748081\n",
      "step: 9101.0, loss:0.16403612\n",
      "step: 9102.0, loss:0.31087250\n",
      "step: 9103.0, loss:0.18456804\n",
      "step: 9104.0, loss:0.28480260\n",
      "step: 9105.0, loss:0.31956379\n",
      "step: 9106.0, loss:0.35519915\n",
      "step: 9107.0, loss:0.17897890\n",
      "step: 9108.0, loss:0.24073464\n",
      "step: 9109.0, loss:0.28243228\n",
      "step: 9110.0, loss:0.21329759\n",
      "step: 9111.0, loss:0.28161563\n",
      "step: 9112.0, loss:0.18726538\n",
      "step: 9113.0, loss:0.19247118\n",
      "step: 9114.0, loss:0.19700897\n",
      "step: 9115.0, loss:0.36068203\n",
      "step: 9116.0, loss:0.36769545\n",
      "step: 9117.0, loss:0.26849063\n",
      "step: 9118.0, loss:0.23978819\n",
      "step: 9119.0, loss:0.15930261\n",
      "step: 9120.0, loss:0.23739563\n",
      "step: 9121.0, loss:0.30197132\n",
      "step: 9122.0, loss:0.23106530\n",
      "step: 9123.0, loss:0.22286759\n",
      "step: 9124.0, loss:0.33213315\n",
      "step: 9125.0, loss:0.19605576\n",
      "step: 9126.0, loss:0.31950472\n",
      "step: 9127.0, loss:0.27201042\n",
      "step: 9128.0, loss:0.21524965\n",
      "step: 9129.0, loss:0.23159884\n",
      "step: 9130.0, loss:0.26222717\n",
      "step: 9131.0, loss:0.14275933\n",
      "step: 9132.0, loss:0.28840100\n",
      "step: 9133.0, loss:0.20009237\n",
      "step: 9134.0, loss:0.21597476\n",
      "step: 9135.0, loss:0.20176172\n",
      "step: 9136.0, loss:0.27720353\n",
      "step: 9137.0, loss:0.25879687\n",
      "step: 9138.0, loss:0.23048146\n",
      "step: 9139.0, loss:0.20582254\n",
      "step: 9140.0, loss:0.20660164\n",
      "step: 9141.0, loss:0.35471148\n",
      "step: 9142.0, loss:0.31429528\n",
      "step: 9143.0, loss:0.30570943\n",
      "step: 9144.0, loss:0.17072024\n",
      "step: 9145.0, loss:0.25409108\n",
      "step: 9146.0, loss:0.23914497\n",
      "step: 9147.0, loss:0.21941654\n",
      "step: 9148.0, loss:0.28917589\n",
      "step: 9149.0, loss:0.26054491\n",
      "step: 9150.0, loss:0.20071915\n",
      "step: 9151.0, loss:0.24585348\n",
      "step: 9152.0, loss:0.20448076\n",
      "step: 9153.0, loss:0.21417566\n",
      "step: 9154.0, loss:0.13942572\n",
      "step: 9155.0, loss:0.13240861\n",
      "step: 9156.0, loss:0.27460878\n",
      "step: 9157.0, loss:0.31377420\n",
      "step: 9158.0, loss:0.20419067\n",
      "step: 9159.0, loss:0.35315083\n",
      "step: 9160.0, loss:0.26220313\n",
      "step: 9161.0, loss:0.18107078\n",
      "step: 9162.0, loss:0.24116070\n",
      "step: 9163.0, loss:0.17731840\n",
      "step: 9164.0, loss:0.20027973\n",
      "step: 9165.0, loss:0.25723537\n",
      "step: 9166.0, loss:0.19061171\n",
      "step: 9167.0, loss:0.15664727\n",
      "step: 9168.0, loss:0.35552948\n",
      "step: 9169.0, loss:0.19439513\n",
      "step: 9170.0, loss:0.22422961\n",
      "step: 9171.0, loss:0.29474104\n",
      "step: 9172.0, loss:0.23942856\n",
      "step: 9173.0, loss:0.16550313\n",
      "step: 9174.0, loss:0.20304418\n",
      "step: 9175.0, loss:0.22932641\n",
      "step: 9176.0, loss:0.30589984\n",
      "step: 9177.0, loss:0.23833458\n",
      "step: 9178.0, loss:0.25852479\n",
      "step: 9179.0, loss:0.20493455\n",
      "step: 9180.0, loss:0.44197399\n",
      "step: 9181.0, loss:0.15801163\n",
      "step: 9182.0, loss:0.19783136\n",
      "step: 9183.0, loss:0.22486071\n",
      "step: 9184.0, loss:0.21582058\n",
      "step: 9185.0, loss:0.30693769\n",
      "step: 9186.0, loss:0.24317839\n",
      "step: 9187.0, loss:0.21746665\n",
      "step: 9188.0, loss:0.29133525\n",
      "step: 9189.0, loss:0.30325081\n",
      "step: 9190.0, loss:0.26786471\n",
      "step: 9191.0, loss:0.22520577\n",
      "step: 9192.0, loss:0.15622191\n",
      "step: 9193.0, loss:0.13843999\n",
      "step: 9194.0, loss:0.21119439\n",
      "step: 9195.0, loss:0.23316832\n",
      "step: 9196.0, loss:0.20646844\n",
      "step: 9197.0, loss:0.19248703\n",
      "step: 9198.0, loss:0.17474134\n",
      "step: 9199.0, loss:0.24213951\n",
      "step: 9200.0, loss:0.28905176\n",
      "step: 9201.0, loss:0.25107966\n",
      "step: 9202.0, loss:0.23979788\n",
      "step: 9203.0, loss:0.19196173\n",
      "step: 9204.0, loss:0.15360933\n",
      "step: 9205.0, loss:0.24594483\n",
      "step: 9206.0, loss:0.30974559\n",
      "step: 9207.0, loss:0.28652975\n",
      "step: 9208.0, loss:0.14902860\n",
      "step: 9209.0, loss:0.18945775\n",
      "step: 9210.0, loss:0.25464986\n",
      "step: 9211.0, loss:0.27810268\n",
      "step: 9212.0, loss:0.18677074\n",
      "step: 9213.0, loss:0.25159901\n",
      "step: 9214.0, loss:0.17964595\n",
      "step: 9215.0, loss:0.32932581\n",
      "step: 9216.0, loss:0.22399805\n",
      "step: 9217.0, loss:0.16653544\n",
      "step: 9218.0, loss:0.18648035\n",
      "step: 9219.0, loss:0.20346860\n",
      "step: 9220.0, loss:0.25105158\n",
      "step: 9221.0, loss:0.17082811\n",
      "step: 9222.0, loss:0.24144802\n",
      "step: 9223.0, loss:0.26826013\n",
      "step: 9224.0, loss:0.27393343\n",
      "step: 9225.0, loss:0.30333002\n",
      "step: 9226.0, loss:0.35938894\n",
      "step: 9227.0, loss:0.20629510\n",
      "step: 9228.0, loss:0.31173962\n",
      "step: 9229.0, loss:0.20046614\n",
      "step: 9230.0, loss:0.24494854\n",
      "step: 9231.0, loss:0.32576361\n",
      "step: 9232.0, loss:0.33520208\n",
      "step: 9233.0, loss:0.23769085\n",
      "step: 9234.0, loss:0.29821949\n",
      "step: 9235.0, loss:0.17118638\n",
      "step: 9236.0, loss:0.16336761\n",
      "step: 9237.0, loss:0.17755369\n",
      "step: 9238.0, loss:0.24036180\n",
      "step: 9239.0, loss:0.21402137\n",
      "step: 9240.0, loss:0.29226322\n",
      "step: 9241.0, loss:0.36538557\n",
      "step: 9242.0, loss:0.42487375\n",
      "step: 9243.0, loss:0.22160372\n",
      "step: 9244.0, loss:0.09193310\n",
      "step: 9245.0, loss:0.34227250\n",
      "step: 9246.0, loss:0.24624756\n",
      "step: 9247.0, loss:0.35114653\n",
      "step: 9248.0, loss:0.24785927\n",
      "step: 9249.0, loss:0.24605826\n",
      "step: 9250.0, loss:0.31067152\n",
      "step: 9251.0, loss:0.18556158\n",
      "step: 9252.0, loss:0.36179579\n",
      "step: 9253.0, loss:0.21586534\n",
      "step: 9254.0, loss:0.15158689\n",
      "step: 9255.0, loss:0.21466647\n",
      "step: 9256.0, loss:0.16184422\n",
      "step: 9257.0, loss:0.16763423\n",
      "step: 9258.0, loss:0.28878535\n",
      "step: 9259.0, loss:0.17986870\n",
      "step: 9260.0, loss:0.19846314\n",
      "step: 9261.0, loss:0.32697804\n",
      "step: 9262.0, loss:0.28685534\n",
      "step: 9263.0, loss:0.28852802\n",
      "step: 9264.0, loss:0.14582083\n",
      "step: 9265.0, loss:0.21069563\n",
      "step: 9266.0, loss:0.29927813\n",
      "step: 9267.0, loss:0.13771267\n",
      "step: 9268.0, loss:0.18417802\n",
      "step: 9269.0, loss:0.19964199\n",
      "step: 9270.0, loss:0.20049979\n",
      "step: 9271.0, loss:0.42322836\n",
      "step: 9272.0, loss:0.18741742\n",
      "step: 9273.0, loss:0.17646015\n",
      "step: 9274.0, loss:0.14745457\n",
      "step: 9275.0, loss:0.27767934\n",
      "step: 9276.0, loss:0.18271373\n",
      "step: 9277.0, loss:0.33230733\n",
      "step: 9278.0, loss:0.19883149\n",
      "step: 9279.0, loss:0.21479142\n",
      "step: 9280.0, loss:0.25566074\n",
      "step: 9281.0, loss:0.20978612\n",
      "step: 9282.0, loss:0.32063355\n",
      "step: 9283.0, loss:0.16826573\n",
      "step: 9284.0, loss:0.24120279\n",
      "step: 9285.0, loss:0.27463806\n",
      "step: 9286.0, loss:0.26541065\n",
      "step: 9287.0, loss:0.32247031\n",
      "step: 9288.0, loss:0.17740421\n",
      "step: 9289.0, loss:0.17248133\n",
      "step: 9290.0, loss:0.25299928\n",
      "step: 9291.0, loss:0.23437733\n",
      "step: 9292.0, loss:0.22547748\n",
      "step: 9293.0, loss:0.29732471\n",
      "step: 9294.0, loss:0.22884971\n",
      "step: 9295.0, loss:0.18054808\n",
      "step: 9296.0, loss:0.20204812\n",
      "step: 9297.0, loss:0.17259155\n",
      "step: 9298.0, loss:0.19617581\n",
      "step: 9299.0, loss:0.13600612\n",
      "step: 9300.0, loss:0.14723816\n",
      "step: 9301.0, loss:0.22992818\n",
      "step: 9302.0, loss:0.20028289\n",
      "step: 9303.0, loss:0.22947488\n",
      "step: 9304.0, loss:0.16650074\n",
      "step: 9305.0, loss:0.31939347\n",
      "step: 9306.0, loss:0.29185451\n",
      "step: 9307.0, loss:0.16834074\n",
      "step: 9308.0, loss:0.18556797\n",
      "step: 9309.0, loss:0.19255818\n",
      "step: 9310.0, loss:0.18238860\n",
      "step: 9311.0, loss:0.18566286\n",
      "step: 9312.0, loss:0.16985127\n",
      "step: 9313.0, loss:0.30546938\n",
      "step: 9314.0, loss:0.24127846\n",
      "step: 9315.0, loss:0.21255204\n",
      "step: 9316.0, loss:0.23870965\n",
      "step: 9317.0, loss:0.30377940\n",
      "step: 9318.0, loss:0.15048718\n",
      "step: 9319.0, loss:0.23366361\n",
      "step: 9320.0, loss:0.19722703\n",
      "step: 9321.0, loss:0.20587677\n",
      "step: 9322.0, loss:0.24980539\n",
      "step: 9323.0, loss:0.20215287\n",
      "step: 9324.0, loss:0.18583768\n",
      "step: 9325.0, loss:0.15535397\n",
      "step: 9326.0, loss:0.27180324\n",
      "step: 9327.0, loss:0.13682959\n",
      "step: 9328.0, loss:0.11835098\n",
      "step: 9329.0, loss:0.34024877\n",
      "step: 9330.0, loss:0.13378971\n",
      "step: 9331.0, loss:0.13199571\n",
      "step: 9332.0, loss:0.24647643\n",
      "step: 9333.0, loss:0.36231495\n",
      "step: 9334.0, loss:0.15378563\n",
      "step: 9335.0, loss:0.18137434\n",
      "step: 9336.0, loss:0.17860286\n",
      "step: 9337.0, loss:0.28731851\n",
      "step: 9338.0, loss:0.33472477\n",
      "step: 9339.0, loss:0.20640221\n",
      "step: 9340.0, loss:0.19085058\n",
      "step: 9341.0, loss:0.09260844\n",
      "step: 9342.0, loss:0.20559539\n",
      "step: 9343.0, loss:0.20881249\n",
      "step: 9344.0, loss:0.21665483\n",
      "step: 9345.0, loss:0.15597973\n",
      "step: 9346.0, loss:0.24085468\n",
      "step: 9347.0, loss:0.10812658\n",
      "step: 9348.0, loss:0.25103506\n",
      "step: 9349.0, loss:0.17237205\n",
      "step: 9350.0, loss:0.19852406\n",
      "step: 9351.0, loss:0.18600627\n",
      "step: 9352.0, loss:0.30077262\n",
      "step: 9353.0, loss:0.16678439\n",
      "step: 9354.0, loss:0.21576141\n",
      "step: 9355.0, loss:0.22176804\n",
      "step: 9356.0, loss:0.30357883\n",
      "step: 9357.0, loss:0.42179601\n",
      "step: 9358.0, loss:0.26144097\n",
      "step: 9359.0, loss:0.25081723\n",
      "step: 9360.0, loss:0.32698349\n",
      "step: 9361.0, loss:0.22758524\n",
      "step: 9362.0, loss:0.30791675\n",
      "step: 9363.0, loss:0.17575171\n",
      "step: 9364.0, loss:0.26913356\n",
      "step: 9365.0, loss:0.19211853\n",
      "step: 9366.0, loss:0.13796162\n",
      "step: 9367.0, loss:0.20771042\n",
      "step: 9368.0, loss:0.27627601\n",
      "step: 9369.0, loss:0.25899856\n",
      "step: 9370.0, loss:0.16127303\n",
      "step: 9371.0, loss:0.28854165\n",
      "step: 9372.0, loss:0.45114430\n",
      "step: 9373.0, loss:0.25457468\n",
      "step: 9374.0, loss:0.18562099\n",
      "step: 9375.0, loss:0.28277498\n",
      "step: 9376.0, loss:0.17663038\n",
      "step: 9377.0, loss:0.17858670\n",
      "step: 9378.0, loss:0.19311166\n",
      "step: 9379.0, loss:0.16725292\n",
      "step: 9380.0, loss:0.18024355\n",
      "step: 9381.0, loss:0.18625684\n",
      "step: 9382.0, loss:0.19721820\n",
      "step: 9383.0, loss:0.31706188\n",
      "step: 9384.0, loss:0.17658493\n",
      "step: 9385.0, loss:0.28293003\n",
      "step: 9386.0, loss:0.18077543\n",
      "step: 9387.0, loss:0.23149347\n",
      "step: 9388.0, loss:0.17222928\n",
      "step: 9389.0, loss:0.26315855\n",
      "step: 9390.0, loss:0.21218897\n",
      "step: 9391.0, loss:0.12346921\n",
      "step: 9392.0, loss:0.24188804\n",
      "step: 9393.0, loss:0.25269782\n",
      "step: 9394.0, loss:0.11413848\n",
      "step: 9395.0, loss:0.18251738\n",
      "step: 9396.0, loss:0.13662183\n",
      "step: 9397.0, loss:0.29345804\n",
      "step: 9398.0, loss:0.19423355\n",
      "step: 9399.0, loss:0.31990117\n",
      "step: 9400.0, loss:0.24080954\n",
      "step: 9401.0, loss:0.21803165\n",
      "step: 9402.0, loss:0.22795496\n",
      "step: 9403.0, loss:0.27142766\n",
      "step: 9404.0, loss:0.25837477\n",
      "step: 9405.0, loss:0.24901289\n",
      "step: 9406.0, loss:0.21768732\n",
      "step: 9407.0, loss:0.25849512\n",
      "step: 9408.0, loss:0.10040941\n",
      "step: 9409.0, loss:0.17724184\n",
      "step: 9410.0, loss:0.23393811\n",
      "step: 9411.0, loss:0.18062208\n",
      "step: 9412.0, loss:0.16976789\n",
      "step: 9413.0, loss:0.17530511\n",
      "step: 9414.0, loss:0.10930443\n",
      "step: 9415.0, loss:0.21346889\n",
      "step: 9416.0, loss:0.24590980\n",
      "step: 9417.0, loss:0.12482329\n",
      "step: 9418.0, loss:0.25904927\n",
      "step: 9419.0, loss:0.20489874\n",
      "step: 9420.0, loss:0.32453395\n",
      "step: 9421.0, loss:0.21403611\n",
      "step: 9422.0, loss:0.19492133\n",
      "step: 9423.0, loss:0.13167317\n",
      "step: 9424.0, loss:0.26554115\n",
      "step: 9425.0, loss:0.10486053\n",
      "step: 9426.0, loss:0.27214807\n",
      "step: 9427.0, loss:0.13211395\n",
      "step: 9428.0, loss:0.28466994\n",
      "step: 9429.0, loss:0.30124777\n",
      "step: 9430.0, loss:0.22600270\n",
      "step: 9431.0, loss:0.15500419\n",
      "step: 9432.0, loss:0.21631362\n",
      "step: 9433.0, loss:0.28415490\n",
      "step: 9434.0, loss:0.27176873\n",
      "step: 9435.0, loss:0.13031219\n",
      "step: 9436.0, loss:0.18097421\n",
      "step: 9437.0, loss:0.14866973\n",
      "step: 9438.0, loss:0.21510582\n",
      "step: 9439.0, loss:0.27603888\n",
      "step: 9440.0, loss:0.18106949\n",
      "step: 9441.0, loss:0.23865690\n",
      "step: 9442.0, loss:0.21491854\n",
      "step: 9443.0, loss:0.24238039\n",
      "step: 9444.0, loss:0.20033905\n",
      "step: 9445.0, loss:0.13303149\n",
      "step: 9446.0, loss:0.21366628\n",
      "step: 9447.0, loss:0.22166267\n",
      "step: 9448.0, loss:0.23367524\n",
      "step: 9449.0, loss:0.26443967\n",
      "step: 9450.0, loss:0.24582857\n",
      "step: 9451.0, loss:0.16121049\n",
      "step: 9452.0, loss:0.24439409\n",
      "step: 9453.0, loss:0.20027405\n",
      "step: 9454.0, loss:0.22876240\n",
      "step: 9455.0, loss:0.16703905\n",
      "step: 9456.0, loss:0.22429254\n",
      "step: 9457.0, loss:0.39678723\n",
      "step: 9458.0, loss:0.26308113\n",
      "step: 9459.0, loss:0.23614539\n",
      "step: 9460.0, loss:0.29607283\n",
      "step: 9461.0, loss:0.23258900\n",
      "step: 9462.0, loss:0.20280692\n",
      "step: 9463.0, loss:0.18034456\n",
      "step: 9464.0, loss:0.16427414\n",
      "step: 9465.0, loss:0.34984096\n",
      "step: 9466.0, loss:0.13872958\n",
      "step: 9467.0, loss:0.19625648\n",
      "step: 9468.0, loss:0.21958422\n",
      "step: 9469.0, loss:0.19234878\n",
      "step: 9470.0, loss:0.29888256\n",
      "step: 9471.0, loss:0.21676364\n",
      "step: 9472.0, loss:0.16206607\n",
      "step: 9473.0, loss:0.15130305\n",
      "step: 9474.0, loss:0.16204504\n",
      "step: 9475.0, loss:0.33728335\n",
      "step: 9476.0, loss:0.22141679\n",
      "step: 9477.0, loss:0.19144006\n",
      "step: 9478.0, loss:0.14163377\n",
      "step: 9479.0, loss:0.24355634\n",
      "step: 9480.0, loss:0.12129814\n",
      "step: 9481.0, loss:0.30244193\n",
      "step: 9482.0, loss:0.11369107\n",
      "step: 9483.0, loss:0.30630194\n",
      "step: 9484.0, loss:0.12095325\n",
      "step: 9485.0, loss:0.40256090\n",
      "step: 9486.0, loss:0.20672027\n",
      "step: 9487.0, loss:0.21912382\n",
      "step: 9488.0, loss:0.16663848\n",
      "step: 9489.0, loss:0.15351002\n",
      "step: 9490.0, loss:0.24696583\n",
      "step: 9491.0, loss:0.18978920\n",
      "step: 9492.0, loss:0.14040864\n",
      "step: 9493.0, loss:0.25354104\n",
      "step: 9494.0, loss:0.19503180\n",
      "step: 9495.0, loss:0.25908075\n",
      "step: 9496.0, loss:0.16318102\n",
      "step: 9497.0, loss:0.22446716\n",
      "step: 9498.0, loss:0.16690477\n",
      "step: 9499.0, loss:0.33066954\n",
      "step: 9500.0, loss:0.16782003\n",
      "step: 9501.0, loss:0.14434763\n",
      "step: 9502.0, loss:0.26902842\n",
      "step: 9503.0, loss:0.32717468\n",
      "step: 9504.0, loss:0.22119851\n",
      "step: 9505.0, loss:0.17431736\n",
      "step: 9506.0, loss:0.34976334\n",
      "step: 9507.0, loss:0.16906324\n",
      "step: 9508.0, loss:0.15061125\n",
      "step: 9509.0, loss:0.25200339\n",
      "step: 9510.0, loss:0.21581653\n",
      "step: 9511.0, loss:0.23892262\n",
      "step: 9512.0, loss:0.16202739\n",
      "step: 9513.0, loss:0.27085325\n",
      "step: 9514.0, loss:0.19017481\n",
      "step: 9515.0, loss:0.19984144\n",
      "step: 9516.0, loss:0.16233752\n",
      "step: 9517.0, loss:0.18584880\n",
      "step: 9518.0, loss:0.12932563\n",
      "step: 9519.0, loss:0.28818105\n",
      "step: 9520.0, loss:0.26610759\n",
      "step: 9521.0, loss:0.10500687\n",
      "step: 9522.0, loss:0.17863416\n",
      "step: 9523.0, loss:0.20344849\n",
      "step: 9524.0, loss:0.21675339\n",
      "step: 9525.0, loss:0.22303385\n",
      "step: 9526.0, loss:0.21707234\n",
      "step: 9527.0, loss:0.17712538\n",
      "step: 9528.0, loss:0.18986690\n",
      "step: 9529.0, loss:0.18060075\n",
      "step: 9530.0, loss:0.15433644\n",
      "step: 9531.0, loss:0.23640157\n",
      "step: 9532.0, loss:0.29679377\n",
      "step: 9533.0, loss:0.13805249\n",
      "step: 9534.0, loss:0.30304023\n",
      "step: 9535.0, loss:0.15229861\n",
      "step: 9536.0, loss:0.24983535\n",
      "step: 9537.0, loss:0.15033865\n",
      "step: 9538.0, loss:0.32190315\n",
      "step: 9539.0, loss:0.14569151\n",
      "step: 9540.0, loss:0.27628789\n",
      "step: 9541.0, loss:0.18046357\n",
      "step: 9542.0, loss:0.29588542\n",
      "step: 9543.0, loss:0.30344682\n",
      "step: 9544.0, loss:0.17726950\n",
      "step: 9545.0, loss:0.15177232\n",
      "step: 9546.0, loss:0.13850254\n",
      "step: 9547.0, loss:0.19858189\n",
      "step: 9548.0, loss:0.22150534\n",
      "step: 9549.0, loss:0.24127180\n",
      "step: 9550.0, loss:0.17036766\n",
      "step: 9551.0, loss:0.19281783\n",
      "step: 9552.0, loss:0.13643517\n",
      "step: 9553.0, loss:0.13853309\n",
      "step: 9554.0, loss:0.20784079\n",
      "step: 9555.0, loss:0.18914635\n",
      "step: 9556.0, loss:0.25089563\n",
      "step: 9557.0, loss:0.16725546\n",
      "step: 9558.0, loss:0.17817952\n",
      "step: 9559.0, loss:0.25228100\n",
      "step: 9560.0, loss:0.14278738\n",
      "step: 9561.0, loss:0.20170170\n",
      "step: 9562.0, loss:0.23821508\n",
      "step: 9563.0, loss:0.08228375\n",
      "step: 9564.0, loss:0.19024254\n",
      "step: 9565.0, loss:0.19965804\n",
      "step: 9566.0, loss:0.31921656\n",
      "step: 9567.0, loss:0.30884801\n",
      "step: 9568.0, loss:0.25210943\n",
      "step: 9569.0, loss:0.17119315\n",
      "step: 9570.0, loss:0.22753991\n",
      "step: 9571.0, loss:0.20689228\n",
      "step: 9572.0, loss:0.26650659\n",
      "step: 9573.0, loss:0.17657624\n",
      "step: 9574.0, loss:0.18600086\n",
      "step: 9575.0, loss:0.28152122\n",
      "step: 9576.0, loss:0.28511869\n",
      "step: 9577.0, loss:0.22000208\n",
      "step: 9578.0, loss:0.21683708\n",
      "step: 9579.0, loss:0.17613508\n",
      "step: 9580.0, loss:0.19387102\n",
      "step: 9581.0, loss:0.23497845\n",
      "step: 9582.0, loss:0.16010180\n",
      "step: 9583.0, loss:0.17459583\n",
      "step: 9584.0, loss:0.16297116\n",
      "step: 9585.0, loss:0.09998843\n",
      "step: 9586.0, loss:0.26621654\n",
      "step: 9587.0, loss:0.10889953\n",
      "step: 9588.0, loss:0.15150247\n",
      "step: 9589.0, loss:0.25193810\n",
      "step: 9590.0, loss:0.17437129\n",
      "step: 9591.0, loss:0.27209276\n",
      "step: 9592.0, loss:0.21466641\n",
      "step: 9593.0, loss:0.23649856\n",
      "step: 9594.0, loss:0.23411301\n",
      "step: 9595.0, loss:0.21452373\n",
      "step: 9596.0, loss:0.18567099\n",
      "step: 9597.0, loss:0.23988485\n",
      "step: 9598.0, loss:0.31237645\n",
      "step: 9599.0, loss:0.40892323\n",
      "step: 9600.0, loss:0.36019418\n",
      "step: 9601.0, loss:0.25188848\n",
      "step: 9602.0, loss:0.21673504\n",
      "step: 9603.0, loss:0.24362745\n",
      "step: 9604.0, loss:0.13691767\n",
      "step: 9605.0, loss:0.23140719\n",
      "step: 9606.0, loss:0.27266847\n",
      "step: 9607.0, loss:0.20321919\n",
      "step: 9608.0, loss:0.22189783\n",
      "step: 9609.0, loss:0.41669271\n",
      "step: 9610.0, loss:0.25589383\n",
      "step: 9611.0, loss:0.21992985\n",
      "step: 9612.0, loss:0.25072416\n",
      "step: 9613.0, loss:0.15229351\n",
      "step: 9614.0, loss:0.22295551\n",
      "step: 9615.0, loss:0.18822261\n",
      "step: 9616.0, loss:0.24940886\n",
      "step: 9617.0, loss:0.23172829\n",
      "step: 9618.0, loss:0.20173310\n",
      "step: 9619.0, loss:0.24732635\n",
      "step: 9620.0, loss:0.24687690\n",
      "step: 9621.0, loss:0.21896803\n",
      "step: 9622.0, loss:0.27068561\n",
      "step: 9623.0, loss:0.27197719\n",
      "step: 9624.0, loss:0.18788910\n",
      "step: 9625.0, loss:0.26136323\n",
      "step: 9626.0, loss:0.20510391\n",
      "step: 9627.0, loss:0.23095996\n",
      "step: 9628.0, loss:0.33041294\n",
      "step: 9629.0, loss:0.22444470\n",
      "step: 9630.0, loss:0.32923671\n",
      "step: 9631.0, loss:0.25633938\n",
      "step: 9632.0, loss:0.15265262\n",
      "step: 9633.0, loss:0.10959405\n",
      "step: 9634.0, loss:0.30202965\n",
      "step: 9635.0, loss:0.17932271\n",
      "step: 9636.0, loss:0.19502547\n",
      "step: 9637.0, loss:0.24981195\n",
      "step: 9638.0, loss:0.37435345\n",
      "step: 9639.0, loss:0.23156152\n",
      "step: 9640.0, loss:0.22201813\n",
      "step: 9641.0, loss:0.17613677\n",
      "step: 9642.0, loss:0.16221179\n",
      "step: 9643.0, loss:0.19936850\n",
      "step: 9644.0, loss:0.19065352\n",
      "step: 9645.0, loss:0.19077383\n",
      "step: 9646.0, loss:0.22720671\n",
      "step: 9647.0, loss:0.15576867\n",
      "step: 9648.0, loss:0.21617873\n",
      "step: 9649.0, loss:0.29542124\n",
      "step: 9650.0, loss:0.24677047\n",
      "step: 9651.0, loss:0.23143831\n",
      "step: 9652.0, loss:0.12444548\n",
      "step: 9653.0, loss:0.27412834\n",
      "step: 9654.0, loss:0.25283137\n",
      "step: 9655.0, loss:0.14724855\n",
      "step: 9656.0, loss:0.19880448\n",
      "step: 9657.0, loss:0.39380099\n",
      "step: 9658.0, loss:0.21293545\n",
      "step: 9659.0, loss:0.28254092\n",
      "step: 9660.0, loss:0.17285087\n",
      "step: 9661.0, loss:0.23786454\n",
      "step: 9662.0, loss:0.27861325\n",
      "step: 9663.0, loss:0.20209630\n",
      "step: 9664.0, loss:0.10744966\n",
      "step: 9665.0, loss:0.18773035\n",
      "step: 9666.0, loss:0.11976928\n",
      "step: 9667.0, loss:0.32972142\n",
      "step: 9668.0, loss:0.23759203\n",
      "step: 9669.0, loss:0.22121845\n",
      "step: 9670.0, loss:0.27969188\n",
      "step: 9671.0, loss:0.26517279\n",
      "step: 9672.0, loss:0.18873079\n",
      "step: 9673.0, loss:0.29357222\n",
      "step: 9674.0, loss:0.19360165\n",
      "step: 9675.0, loss:0.17017403\n",
      "step: 9676.0, loss:0.22073081\n",
      "step: 9677.0, loss:0.26138636\n",
      "step: 9678.0, loss:0.21771955\n",
      "step: 9679.0, loss:0.21792810\n",
      "step: 9680.0, loss:0.14768639\n",
      "step: 9681.0, loss:0.11486281\n",
      "step: 9682.0, loss:0.35515658\n",
      "step: 9683.0, loss:0.22555824\n",
      "step: 9684.0, loss:0.19402412\n",
      "step: 9685.0, loss:0.20455505\n",
      "step: 9686.0, loss:0.29596011\n",
      "step: 9687.0, loss:0.23584971\n",
      "step: 9688.0, loss:0.21127998\n",
      "step: 9689.0, loss:0.28642131\n",
      "step: 9690.0, loss:0.17829566\n",
      "step: 9691.0, loss:0.24994100\n",
      "step: 9692.0, loss:0.28737424\n",
      "step: 9693.0, loss:0.21477511\n",
      "step: 9694.0, loss:0.21122021\n",
      "step: 9695.0, loss:0.21736887\n",
      "step: 9696.0, loss:0.27110158\n",
      "step: 9697.0, loss:0.28950971\n",
      "step: 9698.0, loss:0.21751886\n",
      "step: 9699.0, loss:0.19177465\n",
      "step: 9700.0, loss:0.18312349\n",
      "step: 9701.0, loss:0.16939428\n",
      "step: 9702.0, loss:0.28006743\n",
      "step: 9703.0, loss:0.19549127\n",
      "step: 9704.0, loss:0.22704612\n",
      "step: 9705.0, loss:0.29607726\n",
      "step: 9706.0, loss:0.22261362\n",
      "step: 9707.0, loss:0.26535798\n",
      "step: 9708.0, loss:0.29252985\n",
      "step: 9709.0, loss:0.31498779\n",
      "step: 9710.0, loss:0.26281259\n",
      "step: 9711.0, loss:0.12297265\n",
      "step: 9712.0, loss:0.24910070\n",
      "step: 9713.0, loss:0.31381026\n",
      "step: 9714.0, loss:0.25066082\n",
      "step: 9715.0, loss:0.23424301\n",
      "step: 9716.0, loss:0.11733317\n",
      "step: 9717.0, loss:0.17386021\n",
      "step: 9718.0, loss:0.19624242\n",
      "step: 9719.0, loss:0.19303751\n",
      "step: 9720.0, loss:0.10656623\n",
      "step: 9721.0, loss:0.15380850\n",
      "step: 9722.0, loss:0.20880553\n",
      "step: 9723.0, loss:0.24292484\n",
      "step: 9724.0, loss:0.23388257\n",
      "step: 9725.0, loss:0.29849244\n",
      "step: 9726.0, loss:0.19455797\n",
      "step: 9727.0, loss:0.17136353\n",
      "step: 9728.0, loss:0.26001148\n",
      "step: 9729.0, loss:0.15379959\n",
      "step: 9730.0, loss:0.23763114\n",
      "step: 9731.0, loss:0.14998925\n",
      "step: 9732.0, loss:0.23822422\n",
      "step: 9733.0, loss:0.21534398\n",
      "step: 9734.0, loss:0.15726578\n",
      "step: 9735.0, loss:0.24926474\n",
      "step: 9736.0, loss:0.17566159\n",
      "step: 9737.0, loss:0.27280161\n",
      "step: 9738.0, loss:0.29891514\n",
      "step: 9739.0, loss:0.24402988\n",
      "step: 9740.0, loss:0.28711391\n",
      "step: 9741.0, loss:0.18619742\n",
      "step: 9742.0, loss:0.19383831\n",
      "step: 9743.0, loss:0.21163172\n",
      "step: 9744.0, loss:0.25968242\n",
      "step: 9745.0, loss:0.14705595\n",
      "step: 9746.0, loss:0.20279373\n",
      "step: 9747.0, loss:0.24011403\n",
      "step: 9748.0, loss:0.14310136\n",
      "step: 9749.0, loss:0.30162016\n",
      "step: 9750.0, loss:0.30183640\n",
      "step: 9751.0, loss:0.25282844\n",
      "step: 9752.0, loss:0.24936360\n",
      "step: 9753.0, loss:0.45082477\n",
      "step: 9754.0, loss:0.18091371\n",
      "step: 9755.0, loss:0.35510345\n",
      "step: 9756.0, loss:0.13569233\n",
      "step: 9757.0, loss:0.17240429\n",
      "step: 9758.0, loss:0.17770328\n",
      "step: 9759.0, loss:0.26268580\n",
      "step: 9760.0, loss:0.18105946\n",
      "step: 9761.0, loss:0.14557030\n",
      "step: 9762.0, loss:0.28796041\n",
      "step: 9763.0, loss:0.22931080\n",
      "step: 9764.0, loss:0.26481038\n",
      "step: 9765.0, loss:0.14553637\n",
      "step: 9766.0, loss:0.16886545\n",
      "step: 9767.0, loss:0.22171411\n",
      "step: 9768.0, loss:0.25904639\n",
      "step: 9769.0, loss:0.17779925\n",
      "step: 9770.0, loss:0.21294696\n",
      "step: 9771.0, loss:0.35386195\n",
      "step: 9772.0, loss:0.27562573\n",
      "step: 9773.0, loss:0.19458671\n",
      "step: 9774.0, loss:0.17089700\n",
      "step: 9775.0, loss:0.12461406\n",
      "step: 9776.0, loss:0.23771208\n",
      "step: 9777.0, loss:0.29091071\n",
      "step: 9778.0, loss:0.14762588\n",
      "step: 9779.0, loss:0.16676986\n",
      "step: 9780.0, loss:0.28591038\n",
      "step: 9781.0, loss:0.20855227\n",
      "step: 9782.0, loss:0.16096952\n",
      "step: 9783.0, loss:0.27752945\n",
      "step: 9784.0, loss:0.20758934\n",
      "step: 9785.0, loss:0.24245171\n",
      "step: 9786.0, loss:0.30098751\n",
      "step: 9787.0, loss:0.30575202\n",
      "step: 9788.0, loss:0.24334664\n",
      "step: 9789.0, loss:0.22551983\n",
      "step: 9790.0, loss:0.09987679\n",
      "step: 9791.0, loss:0.31383046\n",
      "step: 9792.0, loss:0.28963072\n",
      "step: 9793.0, loss:0.19402941\n",
      "step: 9794.0, loss:0.29167166\n",
      "step: 9795.0, loss:0.16282424\n",
      "step: 9796.0, loss:0.25698914\n",
      "step: 9797.0, loss:0.15040595\n",
      "step: 9798.0, loss:0.21459775\n",
      "step: 9799.0, loss:0.12872290\n",
      "step: 9800.0, loss:0.18140087\n",
      "step: 9801.0, loss:0.14977510\n",
      "step: 9802.0, loss:0.18452571\n",
      "step: 9803.0, loss:0.19952833\n",
      "step: 9804.0, loss:0.20272710\n",
      "step: 9805.0, loss:0.30876414\n",
      "step: 9806.0, loss:0.25609685\n",
      "step: 9807.0, loss:0.16801089\n",
      "step: 9808.0, loss:0.17174592\n",
      "step: 9809.0, loss:0.16558670\n",
      "step: 9810.0, loss:0.15526485\n",
      "step: 9811.0, loss:0.22392560\n",
      "step: 9812.0, loss:0.24250806\n",
      "step: 9813.0, loss:0.14172282\n",
      "step: 9814.0, loss:0.17258514\n",
      "step: 9815.0, loss:0.39492487\n",
      "step: 9816.0, loss:0.27698338\n",
      "step: 9817.0, loss:0.22165270\n",
      "step: 9818.0, loss:0.12756857\n",
      "step: 9819.0, loss:0.14056044\n",
      "step: 9820.0, loss:0.18731367\n",
      "step: 9821.0, loss:0.34780300\n",
      "step: 9822.0, loss:0.27805707\n",
      "step: 9823.0, loss:0.24968967\n",
      "step: 9824.0, loss:0.17974995\n",
      "step: 9825.0, loss:0.31486641\n",
      "step: 9826.0, loss:0.19206660\n",
      "step: 9827.0, loss:0.35038157\n",
      "step: 9828.0, loss:0.14557546\n",
      "step: 9829.0, loss:0.16078284\n",
      "step: 9830.0, loss:0.19021529\n",
      "step: 9831.0, loss:0.31692290\n",
      "step: 9832.0, loss:0.23786388\n",
      "step: 9833.0, loss:0.20616233\n",
      "step: 9834.0, loss:0.15094339\n",
      "step: 9835.0, loss:0.20326705\n",
      "step: 9836.0, loss:0.35563872\n",
      "step: 9837.0, loss:0.25168863\n",
      "step: 9838.0, loss:0.21659817\n",
      "step: 9839.0, loss:0.16751331\n",
      "step: 9840.0, loss:0.25569852\n",
      "step: 9841.0, loss:0.19682819\n",
      "step: 9842.0, loss:0.21342957\n",
      "step: 9843.0, loss:0.36833588\n",
      "step: 9844.0, loss:0.22779803\n",
      "step: 9845.0, loss:0.21157759\n",
      "step: 9846.0, loss:0.31027267\n",
      "step: 9847.0, loss:0.16641453\n",
      "step: 9848.0, loss:0.28961814\n",
      "step: 9849.0, loss:0.27642761\n",
      "step: 9850.0, loss:0.28505984\n",
      "step: 9851.0, loss:0.17463664\n",
      "step: 9852.0, loss:0.28030089\n",
      "step: 9853.0, loss:0.26583487\n",
      "step: 9854.0, loss:0.24812737\n",
      "step: 9855.0, loss:0.20275089\n",
      "step: 9856.0, loss:0.30987388\n",
      "step: 9857.0, loss:0.30274487\n",
      "step: 9858.0, loss:0.33222148\n",
      "step: 9859.0, loss:0.23542485\n",
      "step: 9860.0, loss:0.29984862\n",
      "step: 9861.0, loss:0.28672927\n",
      "step: 9862.0, loss:0.30324190\n",
      "step: 9863.0, loss:0.26519634\n",
      "step: 9864.0, loss:0.25553077\n",
      "step: 9865.0, loss:0.18196783\n",
      "step: 9866.0, loss:0.22036655\n",
      "step: 9867.0, loss:0.13292761\n",
      "step: 9868.0, loss:0.19612973\n",
      "step: 9869.0, loss:0.32189164\n",
      "step: 9870.0, loss:0.38975817\n",
      "step: 9871.0, loss:0.26900637\n",
      "step: 9872.0, loss:0.22993081\n",
      "step: 9873.0, loss:0.26786325\n",
      "step: 9874.0, loss:0.21212646\n",
      "step: 9875.0, loss:0.19905726\n",
      "step: 9876.0, loss:0.19691606\n",
      "step: 9877.0, loss:0.17361600\n",
      "step: 9878.0, loss:0.28026670\n",
      "step: 9879.0, loss:0.19163737\n",
      "step: 9880.0, loss:0.21931480\n",
      "step: 9881.0, loss:0.23129452\n",
      "step: 9882.0, loss:0.20465328\n",
      "step: 9883.0, loss:0.15093189\n",
      "step: 9884.0, loss:0.22450552\n",
      "step: 9885.0, loss:0.23915799\n",
      "step: 9886.0, loss:0.18895398\n",
      "step: 9887.0, loss:0.27912722\n",
      "step: 9888.0, loss:0.18505748\n",
      "step: 9889.0, loss:0.17833943\n",
      "step: 9890.0, loss:0.22763646\n",
      "step: 9891.0, loss:0.12183359\n",
      "step: 9892.0, loss:0.17333538\n",
      "step: 9893.0, loss:0.24577874\n",
      "step: 9894.0, loss:0.28530175\n",
      "step: 9895.0, loss:0.34984669\n",
      "step: 9896.0, loss:0.30433921\n",
      "step: 9897.0, loss:0.30648991\n",
      "step: 9898.0, loss:0.28684673\n",
      "step: 9899.0, loss:0.23378386\n",
      "step: 9900.0, loss:0.26066254\n",
      "step: 9901.0, loss:0.16648371\n",
      "step: 9902.0, loss:0.15243850\n",
      "step: 9903.0, loss:0.14378748\n",
      "step: 9904.0, loss:0.21571318\n",
      "step: 9905.0, loss:0.21753319\n",
      "step: 9906.0, loss:0.19037972\n",
      "step: 9907.0, loss:0.21975882\n",
      "step: 9908.0, loss:0.20419901\n",
      "step: 9909.0, loss:0.30223779\n",
      "step: 9910.0, loss:0.29317896\n",
      "step: 9911.0, loss:0.24758284\n",
      "step: 9912.0, loss:0.22660652\n",
      "step: 9913.0, loss:0.26770354\n",
      "step: 9914.0, loss:0.17355115\n",
      "step: 9915.0, loss:0.36136915\n",
      "step: 9916.0, loss:0.16243183\n",
      "step: 9917.0, loss:0.19055695\n",
      "step: 9918.0, loss:0.28466367\n",
      "step: 9919.0, loss:0.26477883\n",
      "step: 9920.0, loss:0.31703954\n",
      "step: 9921.0, loss:0.18416964\n",
      "step: 9922.0, loss:0.16807509\n",
      "step: 9923.0, loss:0.24288260\n",
      "step: 9924.0, loss:0.21786148\n",
      "step: 9925.0, loss:0.16528259\n",
      "step: 9926.0, loss:0.16934883\n",
      "step: 9927.0, loss:0.25133896\n",
      "step: 9928.0, loss:0.20330985\n",
      "step: 9929.0, loss:0.18910849\n",
      "step: 9930.0, loss:0.21723456\n",
      "step: 9931.0, loss:0.13814039\n",
      "step: 9932.0, loss:0.24057094\n",
      "step: 9933.0, loss:0.30639469\n",
      "step: 9934.0, loss:0.13481274\n",
      "step: 9935.0, loss:0.24894900\n",
      "step: 9936.0, loss:0.19872856\n",
      "step: 9937.0, loss:0.26512554\n",
      "step: 9938.0, loss:0.18671421\n",
      "step: 9939.0, loss:0.18061411\n",
      "step: 9940.0, loss:0.20811532\n",
      "step: 9941.0, loss:0.13641269\n",
      "step: 9942.0, loss:0.32749094\n",
      "step: 9943.0, loss:0.24500227\n",
      "step: 9944.0, loss:0.27309766\n",
      "step: 9945.0, loss:0.21552709\n",
      "step: 9946.0, loss:0.15171050\n",
      "step: 9947.0, loss:0.31275248\n",
      "step: 9948.0, loss:0.29386156\n",
      "step: 9949.0, loss:0.25711161\n",
      "step: 9950.0, loss:0.25529197\n",
      "step: 9951.0, loss:0.19068838\n",
      "step: 9952.0, loss:0.19913884\n",
      "step: 9953.0, loss:0.10678706\n",
      "step: 9954.0, loss:0.14640418\n",
      "step: 9955.0, loss:0.17218501\n",
      "step: 9956.0, loss:0.21058127\n",
      "step: 9957.0, loss:0.18632025\n",
      "step: 9958.0, loss:0.22127046\n",
      "step: 9959.0, loss:0.28325047\n",
      "step: 9960.0, loss:0.16307605\n",
      "step: 9961.0, loss:0.24304532\n",
      "step: 9962.0, loss:0.17149931\n",
      "step: 9963.0, loss:0.19294736\n",
      "step: 9964.0, loss:0.25967323\n",
      "step: 9965.0, loss:0.16914542\n",
      "step: 9966.0, loss:0.21942203\n",
      "step: 9967.0, loss:0.25857971\n",
      "step: 9968.0, loss:0.20118538\n",
      "step: 9969.0, loss:0.17614206\n",
      "step: 9970.0, loss:0.21600968\n",
      "step: 9971.0, loss:0.22235494\n",
      "step: 9972.0, loss:0.15052169\n",
      "step: 9973.0, loss:0.18327167\n",
      "step: 9974.0, loss:0.23689553\n",
      "step: 9975.0, loss:0.25391992\n",
      "step: 9976.0, loss:0.41077402\n",
      "step: 9977.0, loss:0.20378668\n",
      "step: 9978.0, loss:0.16948140\n",
      "step: 9979.0, loss:0.15608596\n",
      "step: 9980.0, loss:0.15140368\n",
      "step: 9981.0, loss:0.20341146\n",
      "step: 9982.0, loss:0.24150376\n",
      "step: 9983.0, loss:0.16446032\n",
      "step: 9984.0, loss:0.18379950\n",
      "step: 9985.0, loss:0.21055029\n",
      "step: 9986.0, loss:0.27594089\n",
      "step: 9987.0, loss:0.08580132\n",
      "step: 9988.0, loss:0.21380281\n",
      "step: 9989.0, loss:0.15922827\n",
      "step: 9990.0, loss:0.24049091\n",
      "step: 9991.0, loss:0.29583324\n",
      "step: 9992.0, loss:0.14769919\n",
      "step: 9993.0, loss:0.34246768\n",
      "step: 9994.0, loss:0.27950656\n",
      "step: 9995.0, loss:0.20548146\n",
      "step: 9996.0, loss:0.13981942\n",
      "step: 9997.0, loss:0.22954943\n",
      "step: 9998.0, loss:0.19030289\n",
      "step: 9999.0, loss:0.31153560\n",
      "step: 10000.0, loss:0.38605011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1264/1264 [07:53<00:00,  2.67it/s]\n",
      "2023-04-03 00:23:48,260 - INFO - step:10000.0, matthews_corr:0.766281, Acc:89.003215%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 10001.0, loss:0.29792002\n",
      "step: 10002.0, loss:0.18389192\n",
      "step: 10003.0, loss:0.26960394\n",
      "step: 10004.0, loss:0.18823035\n",
      "step: 10005.0, loss:0.17945004\n",
      "step: 10006.0, loss:0.29821506\n",
      "step: 10007.0, loss:0.18531665\n",
      "step: 10008.0, loss:0.15584662\n",
      "step: 10009.0, loss:0.21394513\n",
      "step: 10010.0, loss:0.22071159\n",
      "step: 10011.0, loss:0.30857571\n",
      "step: 10012.0, loss:0.34559350\n",
      "step: 10013.0, loss:0.22967837\n",
      "step: 10014.0, loss:0.32059157\n",
      "step: 10015.0, loss:0.18757344\n",
      "step: 10016.0, loss:0.15794789\n",
      "step: 10017.0, loss:0.10036059\n",
      "step: 10018.0, loss:0.35036081\n",
      "step: 10019.0, loss:0.16067325\n",
      "step: 10020.0, loss:0.13166800\n",
      "step: 10021.0, loss:0.17593199\n",
      "step: 10022.0, loss:0.33110973\n",
      "step: 10023.0, loss:0.20327942\n",
      "step: 10024.0, loss:0.25715085\n",
      "step: 10025.0, loss:0.27315171\n",
      "step: 10026.0, loss:0.22489163\n",
      "step: 10027.0, loss:0.14806418\n",
      "step: 10028.0, loss:0.36036226\n",
      "step: 10029.0, loss:0.23038759\n",
      "step: 10030.0, loss:0.15575345\n",
      "step: 10031.0, loss:0.16945246\n",
      "step: 10032.0, loss:0.21977723\n",
      "step: 10033.0, loss:0.26321030\n",
      "step: 10034.0, loss:0.20687350\n",
      "step: 10035.0, loss:0.17719679\n",
      "step: 10036.0, loss:0.16356845\n",
      "step: 10037.0, loss:0.22415957\n",
      "step: 10038.0, loss:0.14520681\n",
      "step: 10039.0, loss:0.22354936\n",
      "step: 10040.0, loss:0.16793326\n",
      "step: 10041.0, loss:0.23405214\n",
      "step: 10042.0, loss:0.13325998\n",
      "step: 10043.0, loss:0.27793017\n",
      "step: 10044.0, loss:0.20368182\n",
      "step: 10045.0, loss:0.25796296\n",
      "step: 10046.0, loss:0.32783497\n",
      "step: 10047.0, loss:0.19443891\n",
      "step: 10048.0, loss:0.30006706\n",
      "step: 10049.0, loss:0.18669162\n",
      "step: 10050.0, loss:0.20933006\n",
      "step: 10051.0, loss:0.18746837\n",
      "step: 10052.0, loss:0.18364316\n",
      "step: 10053.0, loss:0.21711343\n",
      "step: 10054.0, loss:0.25590989\n",
      "step: 10055.0, loss:0.19987603\n",
      "step: 10056.0, loss:0.16451217\n",
      "step: 10057.0, loss:0.19008267\n",
      "step: 10058.0, loss:0.21323641\n",
      "step: 10059.0, loss:0.23714766\n",
      "step: 10060.0, loss:0.18436091\n",
      "step: 10061.0, loss:0.21711514\n",
      "step: 10062.0, loss:0.18733415\n",
      "step: 10063.0, loss:0.10497351\n",
      "step: 10064.0, loss:0.15968174\n",
      "step: 10065.0, loss:0.29565086\n",
      "step: 10066.0, loss:0.22277329\n",
      "step: 10067.0, loss:0.30759784\n",
      "step: 10068.0, loss:0.23600313\n",
      "step: 10069.0, loss:0.23317217\n",
      "step: 10070.0, loss:0.21858255\n",
      "step: 10071.0, loss:0.28384729\n",
      "step: 10072.0, loss:0.32655855\n",
      "step: 10073.0, loss:0.26055338\n",
      "step: 10074.0, loss:0.18196932\n",
      "step: 10075.0, loss:0.13360645\n",
      "step: 10076.0, loss:0.15870800\n",
      "step: 10077.0, loss:0.24107359\n",
      "step: 10078.0, loss:0.22140917\n",
      "step: 10079.0, loss:0.16294456\n",
      "step: 10080.0, loss:0.24281144\n",
      "step: 10081.0, loss:0.10794506\n",
      "step: 10082.0, loss:0.13857559\n",
      "step: 10083.0, loss:0.26509502\n",
      "step: 10084.0, loss:0.19187424\n",
      "step: 10085.0, loss:0.30791307\n",
      "step: 10086.0, loss:0.15754900\n",
      "step: 10087.0, loss:0.30483830\n",
      "step: 10088.0, loss:0.17282627\n",
      "step: 10089.0, loss:0.25509142\n",
      "step: 10090.0, loss:0.24530236\n",
      "step: 10091.0, loss:0.13410561\n",
      "step: 10092.0, loss:0.19694844\n",
      "step: 10093.0, loss:0.27831234\n",
      "step: 10094.0, loss:0.21218261\n",
      "step: 10095.0, loss:0.14624334\n",
      "step: 10096.0, loss:0.23680619\n",
      "step: 10097.0, loss:0.09995861\n",
      "step: 10098.0, loss:0.24473378\n",
      "step: 10099.0, loss:0.21594638\n",
      "step: 10100.0, loss:0.20640628\n",
      "step: 10101.0, loss:0.22269698\n",
      "step: 10102.0, loss:0.24104894\n",
      "step: 10103.0, loss:0.17572074\n",
      "step: 10104.0, loss:0.16937728\n",
      "step: 10105.0, loss:0.19055945\n",
      "step: 10106.0, loss:0.31547315\n",
      "step: 10107.0, loss:0.34750326\n",
      "step: 10108.0, loss:0.17132189\n",
      "step: 10109.0, loss:0.20856344\n",
      "step: 10110.0, loss:0.25184908\n",
      "step: 10111.0, loss:0.17776446\n",
      "step: 10112.0, loss:0.25657719\n",
      "step: 10113.0, loss:0.22927682\n",
      "step: 10114.0, loss:0.38471917\n",
      "step: 10115.0, loss:0.30688939\n",
      "step: 10116.0, loss:0.23941806\n",
      "step: 10117.0, loss:0.15549874\n",
      "step: 10118.0, loss:0.17118170\n",
      "step: 10119.0, loss:0.15724106\n",
      "step: 10120.0, loss:0.11663635\n",
      "step: 10121.0, loss:0.19778880\n",
      "step: 10122.0, loss:0.24382040\n",
      "step: 10123.0, loss:0.29849919\n",
      "step: 10124.0, loss:0.17882136\n",
      "step: 10125.0, loss:0.20373662\n",
      "step: 10126.0, loss:0.18720325\n",
      "step: 10127.0, loss:0.13366243\n",
      "step: 10128.0, loss:0.21134147\n",
      "step: 10129.0, loss:0.27701951\n",
      "step: 10130.0, loss:0.17685246\n",
      "step: 10131.0, loss:0.13374459\n",
      "step: 10132.0, loss:0.20156711\n",
      "step: 10133.0, loss:0.32708057\n",
      "step: 10134.0, loss:0.16008109\n",
      "step: 10135.0, loss:0.24791334\n",
      "step: 10136.0, loss:0.09965627\n",
      "step: 10137.0, loss:0.12935410\n",
      "step: 10138.0, loss:0.21109730\n",
      "step: 10139.0, loss:0.23880159\n",
      "step: 10140.0, loss:0.27582497\n",
      "step: 10141.0, loss:0.22690237\n",
      "step: 10142.0, loss:0.31816252\n",
      "step: 10143.0, loss:0.24830182\n",
      "step: 10144.0, loss:0.22482933\n",
      "step: 10145.0, loss:0.21640806\n",
      "step: 10146.0, loss:0.23119962\n",
      "step: 10147.0, loss:0.23641847\n",
      "step: 10148.0, loss:0.20497140\n",
      "step: 10149.0, loss:0.33203048\n",
      "step: 10150.0, loss:0.14388174\n",
      "step: 10151.0, loss:0.25388785\n",
      "step: 10152.0, loss:0.19924378\n",
      "step: 10153.0, loss:0.30729519\n",
      "step: 10154.0, loss:0.13377585\n",
      "step: 10155.0, loss:0.22857151\n",
      "step: 10156.0, loss:0.10640604\n",
      "step: 10157.0, loss:0.39037913\n",
      "step: 10158.0, loss:0.23179488\n",
      "step: 10159.0, loss:0.22065704\n",
      "step: 10160.0, loss:0.26638046\n",
      "step: 10161.0, loss:0.25621608\n",
      "step: 10162.0, loss:0.17399148\n",
      "step: 10163.0, loss:0.21321301\n",
      "step: 10164.0, loss:0.21199492\n",
      "step: 10165.0, loss:0.23429963\n",
      "step: 10166.0, loss:0.19774339\n",
      "step: 10167.0, loss:0.22197128\n",
      "step: 10168.0, loss:0.18510655\n",
      "step: 10169.0, loss:0.26726522\n",
      "step: 10170.0, loss:0.30070414\n",
      "step: 10171.0, loss:0.20812594\n",
      "step: 10172.0, loss:0.14133830\n",
      "step: 10173.0, loss:0.26304734\n",
      "step: 10174.0, loss:0.16275841\n",
      "step: 10175.0, loss:0.20587017\n",
      "step: 10176.0, loss:0.27974370\n",
      "step: 10177.0, loss:0.23915691\n",
      "step: 10178.0, loss:0.23607091\n",
      "step: 10179.0, loss:0.20709887\n",
      "step: 10180.0, loss:0.20778291\n",
      "step: 10181.0, loss:0.15733842\n",
      "step: 10182.0, loss:0.17430096\n",
      "step: 10183.0, loss:0.31790965\n",
      "step: 10184.0, loss:0.09148026\n",
      "step: 10185.0, loss:0.16218779\n",
      "step: 10186.0, loss:0.20193569\n",
      "step: 10187.0, loss:0.13901556\n",
      "step: 10188.0, loss:0.14103771\n",
      "step: 10189.0, loss:0.21062739\n",
      "step: 10190.0, loss:0.17571629\n",
      "step: 10191.0, loss:0.20966404\n",
      "step: 10192.0, loss:0.18913883\n",
      "step: 10193.0, loss:0.21338240\n",
      "step: 10194.0, loss:0.21768255\n",
      "step: 10195.0, loss:0.20285580\n",
      "step: 10196.0, loss:0.31214286\n",
      "step: 10197.0, loss:0.20361885\n",
      "step: 10198.0, loss:0.34388708\n",
      "step: 10199.0, loss:0.27736088\n",
      "step: 10200.0, loss:0.23455066\n",
      "step: 10201.0, loss:0.17053346\n",
      "step: 10202.0, loss:0.24102112\n",
      "step: 10203.0, loss:0.31040738\n",
      "step: 10204.0, loss:0.28924356\n",
      "step: 10205.0, loss:0.18017430\n",
      "step: 10206.0, loss:0.11801249\n",
      "step: 10207.0, loss:0.28201747\n",
      "step: 10208.0, loss:0.18591351\n",
      "step: 10209.0, loss:0.14348300\n",
      "step: 10210.0, loss:0.19059766\n",
      "step: 10211.0, loss:0.22447518\n",
      "step: 10212.0, loss:0.18310669\n",
      "step: 10213.0, loss:0.22180047\n",
      "step: 10214.0, loss:0.16202064\n",
      "step: 10215.0, loss:0.16874063\n",
      "step: 10216.0, loss:0.18697523\n",
      "step: 10217.0, loss:0.16085153\n",
      "step: 10218.0, loss:0.19331635\n",
      "step: 10219.0, loss:0.20627723\n",
      "step: 10220.0, loss:0.24532174\n",
      "step: 10221.0, loss:0.22984901\n",
      "step: 10222.0, loss:0.20767477\n",
      "step: 10223.0, loss:0.37564228\n",
      "step: 10224.0, loss:0.26690724\n",
      "step: 10225.0, loss:0.20442780\n",
      "step: 10226.0, loss:0.12974820\n",
      "step: 10227.0, loss:0.28896828\n",
      "step: 10228.0, loss:0.24721526\n",
      "step: 10229.0, loss:0.18567712\n",
      "step: 10230.0, loss:0.20174436\n",
      "step: 10231.0, loss:0.20347638\n",
      "step: 10232.0, loss:0.25522650\n",
      "step: 10233.0, loss:0.19099434\n",
      "step: 10234.0, loss:0.19046660\n",
      "step: 10235.0, loss:0.30363832\n",
      "step: 10236.0, loss:0.32191390\n",
      "step: 10237.0, loss:0.24404661\n",
      "step: 10238.0, loss:0.15070368\n",
      "step: 10239.0, loss:0.28771833\n",
      "step: 10240.0, loss:0.27020945\n",
      "step: 10241.0, loss:0.21652802\n",
      "step: 10242.0, loss:0.39300866\n",
      "step: 10243.0, loss:0.24842757\n",
      "step: 10244.0, loss:0.30397595\n",
      "step: 10245.0, loss:0.19625103\n",
      "step: 10246.0, loss:0.11907793\n",
      "step: 10247.0, loss:0.28464090\n",
      "step: 10248.0, loss:0.23777336\n",
      "step: 10249.0, loss:0.20330068\n",
      "step: 10250.0, loss:0.29293346\n",
      "step: 10251.0, loss:0.13155945\n",
      "step: 10252.0, loss:0.16008562\n",
      "step: 10253.0, loss:0.24983338\n",
      "step: 10254.0, loss:0.17003970\n",
      "step: 10255.0, loss:0.30324819\n",
      "step: 10256.0, loss:0.18261475\n",
      "step: 10257.0, loss:0.08111379\n",
      "step: 10258.0, loss:0.16077203\n",
      "step: 10259.0, loss:0.25800114\n",
      "step: 10260.0, loss:0.20808155\n",
      "step: 10261.0, loss:0.29081712\n",
      "step: 10262.0, loss:0.29827582\n",
      "step: 10263.0, loss:0.12351859\n",
      "step: 10264.0, loss:0.23149295\n",
      "step: 10265.0, loss:0.19989155\n",
      "step: 10266.0, loss:0.32871987\n",
      "step: 10267.0, loss:0.38941879\n",
      "step: 10268.0, loss:0.32747979\n",
      "step: 10269.0, loss:0.17692619\n",
      "step: 10270.0, loss:0.31044036\n",
      "step: 10271.0, loss:0.16212426\n",
      "step: 10272.0, loss:0.30646670\n",
      "step: 10273.0, loss:0.28406619\n",
      "step: 10274.0, loss:0.20365317\n",
      "step: 10275.0, loss:0.16541590\n",
      "step: 10276.0, loss:0.24021865\n",
      "step: 10277.0, loss:0.12491582\n",
      "step: 10278.0, loss:0.16367428\n",
      "step: 10279.0, loss:0.21354931\n",
      "step: 10280.0, loss:0.20244555\n",
      "step: 10281.0, loss:0.16979918\n",
      "step: 10282.0, loss:0.22449893\n",
      "step: 10283.0, loss:0.14599793\n",
      "step: 10284.0, loss:0.28175873\n",
      "step: 10285.0, loss:0.22786252\n",
      "step: 10286.0, loss:0.28093831\n",
      "step: 10287.0, loss:0.19445664\n",
      "step: 10288.0, loss:0.27051144\n",
      "step: 10289.0, loss:0.18179948\n",
      "step: 10290.0, loss:0.16196000\n",
      "step: 10291.0, loss:0.21415499\n",
      "step: 10292.0, loss:0.20327581\n",
      "step: 10293.0, loss:0.28146688\n",
      "step: 10294.0, loss:0.25037629\n",
      "step: 10295.0, loss:0.17810802\n",
      "step: 10296.0, loss:0.28921978\n",
      "step: 10297.0, loss:0.20641468\n",
      "step: 10298.0, loss:0.17187873\n",
      "step: 10299.0, loss:0.15675117\n",
      "step: 10300.0, loss:0.17952834\n",
      "step: 10301.0, loss:0.18941131\n",
      "step: 10302.0, loss:0.24571915\n",
      "step: 10303.0, loss:0.24891207\n",
      "step: 10304.0, loss:0.28835036\n",
      "step: 10305.0, loss:0.24231170\n",
      "step: 10306.0, loss:0.19041501\n",
      "step: 10307.0, loss:0.21937040\n",
      "step: 10308.0, loss:0.26717624\n",
      "step: 10309.0, loss:0.31384646\n",
      "step: 10310.0, loss:0.20185613\n",
      "step: 10311.0, loss:0.26700686\n",
      "step: 10312.0, loss:0.22453861\n",
      "step: 10313.0, loss:0.21161886\n",
      "step: 10314.0, loss:0.23585226\n",
      "step: 10315.0, loss:0.22699770\n",
      "step: 10316.0, loss:0.17424270\n",
      "step: 10317.0, loss:0.28652006\n",
      "step: 10318.0, loss:0.26866840\n",
      "step: 10319.0, loss:0.25608293\n",
      "step: 10320.0, loss:0.15834676\n",
      "step: 10321.0, loss:0.27660297\n",
      "step: 10322.0, loss:0.20346875\n",
      "step: 10323.0, loss:0.15411477\n",
      "step: 10324.0, loss:0.17086970\n",
      "step: 10325.0, loss:0.16643383\n",
      "step: 10326.0, loss:0.36813185\n",
      "step: 10327.0, loss:0.13961993\n",
      "step: 10328.0, loss:0.21627225\n",
      "step: 10329.0, loss:0.23418654\n",
      "step: 10330.0, loss:0.19442764\n",
      "step: 10331.0, loss:0.23336078\n",
      "step: 10332.0, loss:0.31008589\n",
      "step: 10333.0, loss:0.23410277\n",
      "step: 10334.0, loss:0.21706959\n",
      "step: 10335.0, loss:0.19871478\n",
      "step: 10336.0, loss:0.14103328\n",
      "step: 10337.0, loss:0.23886525\n",
      "step: 10338.0, loss:0.16962303\n",
      "step: 10339.0, loss:0.28260647\n",
      "step: 10340.0, loss:0.29954909\n",
      "step: 10341.0, loss:0.39565498\n",
      "step: 10342.0, loss:0.23312252\n",
      "step: 10343.0, loss:0.26752511\n",
      "step: 10344.0, loss:0.16861912\n",
      "step: 10345.0, loss:0.23802141\n",
      "step: 10346.0, loss:0.28779597\n",
      "step: 10347.0, loss:0.18866530\n",
      "step: 10348.0, loss:0.10683577\n",
      "step: 10349.0, loss:0.27612157\n",
      "step: 10350.0, loss:0.20270942\n",
      "step: 10351.0, loss:0.20382398\n",
      "step: 10352.0, loss:0.21394853\n",
      "step: 10353.0, loss:0.13630111\n",
      "step: 10354.0, loss:0.25304545\n",
      "step: 10355.0, loss:0.25690314\n",
      "step: 10356.0, loss:0.28741701\n",
      "step: 10357.0, loss:0.14085032\n",
      "step: 10358.0, loss:0.23080900\n",
      "step: 10359.0, loss:0.37970031\n",
      "step: 10360.0, loss:0.23025350\n",
      "step: 10361.0, loss:0.19188009\n",
      "step: 10362.0, loss:0.18888709\n",
      "step: 10363.0, loss:0.18924602\n",
      "step: 10364.0, loss:0.18469072\n",
      "step: 10365.0, loss:0.31098157\n",
      "step: 10366.0, loss:0.28112749\n",
      "step: 10367.0, loss:0.20316734\n",
      "step: 10368.0, loss:0.14376448\n",
      "step: 10369.0, loss:0.21375970\n",
      "step: 10370.0, loss:0.17919255\n",
      "step: 10371.0, loss:0.23241960\n",
      "step: 10372.0, loss:0.28495788\n",
      "step: 10373.0, loss:0.16118204\n",
      "step: 10374.0, loss:0.24702222\n",
      "step: 10375.0, loss:0.23620352\n",
      "step: 10376.0, loss:0.26268534\n",
      "step: 10377.0, loss:0.27520814\n",
      "step: 10378.0, loss:0.22130660\n",
      "step: 10379.0, loss:0.24384128\n",
      "step: 10380.0, loss:0.27117197\n",
      "step: 10381.0, loss:0.26831634\n",
      "step: 10382.0, loss:0.17767051\n",
      "step: 10383.0, loss:0.20077595\n",
      "step: 10384.0, loss:0.25915100\n",
      "step: 10385.0, loss:0.32171736\n",
      "step: 10386.0, loss:0.28410440\n",
      "step: 10387.0, loss:0.20281022\n",
      "step: 10388.0, loss:0.27548268\n",
      "step: 10389.0, loss:0.12159511\n",
      "step: 10390.0, loss:0.26201633\n",
      "step: 10391.0, loss:0.16347590\n",
      "step: 10392.0, loss:0.29308072\n",
      "step: 10393.0, loss:0.17890941\n",
      "step: 10394.0, loss:0.19482914\n",
      "step: 10395.0, loss:0.23662035\n",
      "step: 10396.0, loss:0.26622889\n",
      "step: 10397.0, loss:0.18496939\n",
      "step: 10398.0, loss:0.28560351\n",
      "step: 10399.0, loss:0.22786270\n",
      "step: 10400.0, loss:0.32646997\n",
      "step: 10401.0, loss:0.15760171\n",
      "step: 10402.0, loss:0.19922346\n",
      "step: 10403.0, loss:0.28081962\n",
      "step: 10404.0, loss:0.39352786\n",
      "step: 10405.0, loss:0.28134887\n",
      "step: 10406.0, loss:0.32891332\n",
      "step: 10407.0, loss:0.28795442\n",
      "step: 10408.0, loss:0.34646993\n",
      "step: 10409.0, loss:0.17579982\n",
      "step: 10410.0, loss:0.16040130\n",
      "step: 10411.0, loss:0.24453917\n",
      "step: 10412.0, loss:0.20662143\n",
      "step: 10413.0, loss:0.23664968\n",
      "step: 10414.0, loss:0.28701082\n",
      "step: 10415.0, loss:0.23958832\n",
      "step: 10416.0, loss:0.22315913\n",
      "step: 10417.0, loss:0.25238867\n",
      "step: 10418.0, loss:0.29642702\n",
      "step: 10419.0, loss:0.22566443\n",
      "step: 10420.0, loss:0.16192800\n",
      "step: 10421.0, loss:0.17673456\n",
      "step: 10422.0, loss:0.24776724\n",
      "step: 10423.0, loss:0.24184243\n",
      "step: 10424.0, loss:0.17590561\n",
      "step: 10425.0, loss:0.22292598\n",
      "step: 10426.0, loss:0.21253692\n",
      "step: 10427.0, loss:0.18635139\n",
      "step: 10428.0, loss:0.18481925\n",
      "step: 10429.0, loss:0.27011894\n",
      "step: 10430.0, loss:0.22512233\n",
      "step: 10431.0, loss:0.18200579\n",
      "step: 10432.0, loss:0.12709118\n",
      "step: 10433.0, loss:0.19980321\n",
      "step: 10434.0, loss:0.17384011\n",
      "step: 10435.0, loss:0.08834746\n",
      "step: 10436.0, loss:0.15285755\n",
      "step: 10437.0, loss:0.23852189\n",
      "step: 10438.0, loss:0.33260224\n",
      "step: 10439.0, loss:0.16813910\n",
      "step: 10440.0, loss:0.18495514\n",
      "step: 10441.0, loss:0.28832521\n",
      "step: 10442.0, loss:0.24024956\n",
      "step: 10443.0, loss:0.18247135\n",
      "step: 10444.0, loss:0.24601635\n",
      "step: 10445.0, loss:0.16084121\n",
      "step: 10446.0, loss:0.22378307\n",
      "step: 10447.0, loss:0.21922223\n",
      "step: 10448.0, loss:0.18501089\n",
      "step: 10449.0, loss:0.30564150\n",
      "step: 10450.0, loss:0.16984422\n",
      "step: 10451.0, loss:0.23889619\n",
      "step: 10452.0, loss:0.33534901\n",
      "step: 10453.0, loss:0.37000870\n",
      "step: 10454.0, loss:0.19643174\n",
      "step: 10455.0, loss:0.20794227\n",
      "step: 10456.0, loss:0.24618196\n",
      "step: 10457.0, loss:0.26421592\n",
      "step: 10458.0, loss:0.27192371\n",
      "step: 10459.0, loss:0.31095053\n",
      "step: 10460.0, loss:0.18844655\n",
      "step: 10461.0, loss:0.21534154\n",
      "step: 10462.0, loss:0.28981891\n",
      "step: 10463.0, loss:0.37583594\n",
      "step: 10464.0, loss:0.20337052\n",
      "step: 10465.0, loss:0.20157382\n",
      "step: 10466.0, loss:0.21044966\n",
      "step: 10467.0, loss:0.19669798\n",
      "step: 10468.0, loss:0.16853742\n",
      "step: 10469.0, loss:0.15104745\n",
      "step: 10470.0, loss:0.10497104\n",
      "step: 10471.0, loss:0.17766783\n",
      "step: 10472.0, loss:0.12552010\n",
      "step: 10473.0, loss:0.19885328\n",
      "step: 10474.0, loss:0.36317681\n",
      "step: 10475.0, loss:0.27226341\n",
      "step: 10476.0, loss:0.26114279\n",
      "step: 10477.0, loss:0.20666824\n",
      "step: 10478.0, loss:0.23068279\n",
      "step: 10479.0, loss:0.23299313\n",
      "step: 10480.0, loss:0.16864738\n",
      "step: 10481.0, loss:0.06803734\n",
      "step: 10482.0, loss:0.14236839\n",
      "step: 10483.0, loss:0.30637685\n",
      "step: 10484.0, loss:0.24908444\n",
      "step: 10485.0, loss:0.23517367\n",
      "step: 10486.0, loss:0.38167610\n",
      "step: 10487.0, loss:0.12945233\n",
      "step: 10488.0, loss:0.14456883\n",
      "step: 10489.0, loss:0.20101148\n",
      "step: 10490.0, loss:0.12932845\n",
      "step: 10491.0, loss:0.35512098\n",
      "step: 10492.0, loss:0.24120831\n",
      "step: 10493.0, loss:0.26295467\n",
      "step: 10494.0, loss:0.36703574\n",
      "step: 10495.0, loss:0.12854578\n",
      "step: 10496.0, loss:0.15154979\n",
      "step: 10497.0, loss:0.11295988\n",
      "step: 10498.0, loss:0.15567135\n",
      "step: 10499.0, loss:0.23298169\n",
      "step: 10500.0, loss:0.22723895\n",
      "step: 10501.0, loss:0.21379839\n",
      "step: 10502.0, loss:0.13474302\n",
      "step: 10503.0, loss:0.21995255\n",
      "step: 10504.0, loss:0.15030931\n",
      "step: 10505.0, loss:0.38430482\n",
      "step: 10506.0, loss:0.20027475\n",
      "step: 10507.0, loss:0.24411961\n",
      "step: 10508.0, loss:0.38500535\n",
      "step: 10509.0, loss:0.26197454\n",
      "step: 10510.0, loss:0.18270924\n",
      "step: 10511.0, loss:0.16278314\n",
      "step: 10512.0, loss:0.31152533\n",
      "step: 10513.0, loss:0.20167466\n",
      "step: 10514.0, loss:0.29515423\n",
      "step: 10515.0, loss:0.22652740\n",
      "step: 10516.0, loss:0.11617962\n",
      "step: 10517.0, loss:0.23000803\n",
      "step: 10518.0, loss:0.23703459\n",
      "step: 10519.0, loss:0.24005466\n",
      "step: 10520.0, loss:0.16471897\n",
      "step: 10521.0, loss:0.22465990\n",
      "step: 10522.0, loss:0.26507084\n",
      "step: 10523.0, loss:0.38990941\n",
      "step: 10524.0, loss:0.26262881\n",
      "step: 10525.0, loss:0.21953801\n",
      "step: 10526.0, loss:0.17549514\n",
      "step: 10527.0, loss:0.40254169\n",
      "step: 10528.0, loss:0.18687190\n",
      "step: 10529.0, loss:0.21035248\n",
      "step: 10530.0, loss:0.21290247\n",
      "step: 10531.0, loss:0.23010579\n",
      "step: 10532.0, loss:0.18154393\n",
      "step: 10533.0, loss:0.27650301\n",
      "step: 10534.0, loss:0.16190205\n",
      "step: 10535.0, loss:0.18807777\n",
      "step: 10536.0, loss:0.42220185\n",
      "step: 10537.0, loss:0.32064038\n",
      "step: 10538.0, loss:0.19214616\n",
      "step: 10539.0, loss:0.19128261\n",
      "step: 10540.0, loss:0.20602535\n",
      "step: 10541.0, loss:0.22803690\n",
      "step: 10542.0, loss:0.27153822\n",
      "step: 10543.0, loss:0.20330574\n",
      "step: 10544.0, loss:0.17655348\n",
      "step: 10545.0, loss:0.23643903\n",
      "step: 10546.0, loss:0.17481391\n",
      "step: 10547.0, loss:0.22148730\n",
      "step: 10548.0, loss:0.15780866\n",
      "step: 10549.0, loss:0.23599377\n",
      "step: 10550.0, loss:0.22874449\n",
      "step: 10551.0, loss:0.30856847\n",
      "step: 10552.0, loss:0.15017610\n",
      "step: 10553.0, loss:0.22315209\n",
      "step: 10554.0, loss:0.11265517\n",
      "step: 10555.0, loss:0.21872282\n",
      "step: 10556.0, loss:0.19619729\n",
      "step: 10557.0, loss:0.20381914\n",
      "step: 10558.0, loss:0.25343109\n",
      "step: 10559.0, loss:0.12116192\n",
      "step: 10560.0, loss:0.11557505\n",
      "step: 10561.0, loss:0.17903078\n",
      "step: 10562.0, loss:0.21962146\n",
      "step: 10563.0, loss:0.22559406\n",
      "step: 10564.0, loss:0.15232669\n",
      "step: 10565.0, loss:0.26899073\n",
      "step: 10566.0, loss:0.20857658\n",
      "step: 10567.0, loss:0.20511598\n",
      "step: 10568.0, loss:0.24218097\n",
      "step: 10569.0, loss:0.24146539\n",
      "step: 10570.0, loss:0.39277806\n",
      "step: 10571.0, loss:0.28628048\n",
      "step: 10572.0, loss:0.23813052\n",
      "step: 10573.0, loss:0.34698973\n",
      "step: 10574.0, loss:0.14028759\n",
      "step: 10575.0, loss:0.22938727\n",
      "step: 10576.0, loss:0.21636996\n",
      "step: 10577.0, loss:0.27955996\n",
      "step: 10578.0, loss:0.19299311\n",
      "step: 10579.0, loss:0.27776522\n",
      "step: 10580.0, loss:0.31998112\n",
      "step: 10581.0, loss:0.16055333\n",
      "step: 10582.0, loss:0.25987581\n",
      "step: 10583.0, loss:0.24803700\n",
      "step: 10584.0, loss:0.21996757\n",
      "step: 10585.0, loss:0.28026065\n",
      "step: 10586.0, loss:0.18669681\n",
      "step: 10587.0, loss:0.20889910\n",
      "step: 10588.0, loss:0.22884112\n",
      "step: 10589.0, loss:0.18801048\n",
      "step: 10590.0, loss:0.17128047\n",
      "step: 10591.0, loss:0.12889027\n",
      "step: 10592.0, loss:0.21870274\n",
      "step: 10593.0, loss:0.27711229\n",
      "step: 10594.0, loss:0.22654315\n",
      "step: 10595.0, loss:0.17567509\n",
      "step: 10596.0, loss:0.17958174\n",
      "step: 10597.0, loss:0.35606600\n",
      "step: 10598.0, loss:0.26149659\n",
      "step: 10599.0, loss:0.23451986\n",
      "step: 10600.0, loss:0.17631150\n",
      "step: 10601.0, loss:0.20063069\n",
      "step: 10602.0, loss:0.23029378\n",
      "step: 10603.0, loss:0.13766718\n",
      "step: 10604.0, loss:0.17466607\n",
      "step: 10605.0, loss:0.29650697\n",
      "step: 10606.0, loss:0.19544821\n",
      "step: 10607.0, loss:0.17197601\n",
      "step: 10608.0, loss:0.22155256\n",
      "step: 10609.0, loss:0.26715248\n",
      "step: 10610.0, loss:0.26512318\n",
      "step: 10611.0, loss:0.14544611\n",
      "step: 10612.0, loss:0.21768654\n",
      "step: 10613.0, loss:0.26456999\n",
      "step: 10614.0, loss:0.26106975\n",
      "step: 10615.0, loss:0.25521715\n",
      "step: 10616.0, loss:0.28444765\n",
      "step: 10617.0, loss:0.36388627\n",
      "step: 10618.0, loss:0.35625630\n",
      "step: 10619.0, loss:0.22925519\n",
      "step: 10620.0, loss:0.26947320\n",
      "step: 10621.0, loss:0.16777929\n",
      "step: 10622.0, loss:0.23896224\n",
      "step: 10623.0, loss:0.24230200\n",
      "step: 10624.0, loss:0.22420453\n",
      "step: 10625.0, loss:0.19641510\n",
      "step: 10626.0, loss:0.24510279\n",
      "step: 10627.0, loss:0.15498897\n",
      "step: 10628.0, loss:0.16186791\n",
      "step: 10629.0, loss:0.14498278\n",
      "step: 10630.0, loss:0.25218853\n",
      "step: 10631.0, loss:0.23746265\n",
      "step: 10632.0, loss:0.26004804\n",
      "step: 10633.0, loss:0.14699473\n",
      "step: 10634.0, loss:0.25417582\n",
      "step: 10635.0, loss:0.21620360\n",
      "step: 10636.0, loss:0.28395712\n",
      "step: 10637.0, loss:0.29186608\n",
      "step: 10638.0, loss:0.29948118\n",
      "step: 10639.0, loss:0.20877229\n",
      "step: 10640.0, loss:0.21602645\n",
      "step: 10641.0, loss:0.23115361\n",
      "step: 10642.0, loss:0.28519846\n",
      "step: 10643.0, loss:0.31707319\n",
      "step: 10644.0, loss:0.09804957\n",
      "step: 10645.0, loss:0.17841119\n",
      "step: 10646.0, loss:0.21144838\n",
      "step: 10647.0, loss:0.21421725\n",
      "step: 10648.0, loss:0.18742653\n",
      "step: 10649.0, loss:0.31792407\n",
      "step: 10650.0, loss:0.32092553\n",
      "step: 10651.0, loss:0.15973234\n",
      "step: 10652.0, loss:0.20629395\n",
      "step: 10653.0, loss:0.28849589\n",
      "step: 10654.0, loss:0.22075020\n",
      "step: 10655.0, loss:0.21372281\n",
      "step: 10656.0, loss:0.42177346\n",
      "step: 10657.0, loss:0.21370968\n",
      "step: 10658.0, loss:0.18417251\n",
      "step: 10659.0, loss:0.21912654\n",
      "step: 10660.0, loss:0.12267144\n",
      "step: 10661.0, loss:0.28831775\n",
      "step: 10662.0, loss:0.18950107\n",
      "step: 10663.0, loss:0.20340740\n",
      "step: 10664.0, loss:0.17653711\n",
      "step: 10665.0, loss:0.32986704\n",
      "step: 10666.0, loss:0.17284795\n",
      "step: 10667.0, loss:0.16020530\n",
      "step: 10668.0, loss:0.19199153\n",
      "step: 10669.0, loss:0.23725265\n",
      "step: 10670.0, loss:0.22190516\n",
      "step: 10671.0, loss:0.20422965\n",
      "step: 10672.0, loss:0.14071345\n",
      "step: 10673.0, loss:0.24563724\n",
      "step: 10674.0, loss:0.23951896\n",
      "step: 10675.0, loss:0.20734788\n",
      "step: 10676.0, loss:0.18999859\n",
      "step: 10677.0, loss:0.19895082\n",
      "step: 10678.0, loss:0.19018579\n",
      "step: 10679.0, loss:0.14984529\n",
      "step: 10680.0, loss:0.21441335\n",
      "step: 10681.0, loss:0.16440455\n",
      "step: 10682.0, loss:0.42657920\n",
      "step: 10683.0, loss:0.15791130\n",
      "step: 10684.0, loss:0.30556708\n",
      "step: 10685.0, loss:0.18347328\n",
      "step: 10686.0, loss:0.33921285\n",
      "step: 10687.0, loss:0.15926980\n",
      "step: 10688.0, loss:0.29599748\n",
      "step: 10689.0, loss:0.22434423\n",
      "step: 10690.0, loss:0.27152943\n",
      "step: 10691.0, loss:0.15821361\n",
      "step: 10692.0, loss:0.24524332\n",
      "step: 10693.0, loss:0.27060051\n",
      "step: 10694.0, loss:0.22065230\n",
      "step: 10695.0, loss:0.17656169\n",
      "step: 10696.0, loss:0.14522017\n",
      "step: 10697.0, loss:0.30105835\n",
      "step: 10698.0, loss:0.22135444\n",
      "step: 10699.0, loss:0.25584755\n",
      "step: 10700.0, loss:0.24622776\n",
      "step: 10701.0, loss:0.37832981\n",
      "step: 10702.0, loss:0.21095766\n",
      "step: 10703.0, loss:0.25223471\n",
      "step: 10704.0, loss:0.20439402\n",
      "step: 10705.0, loss:0.21475264\n",
      "step: 10706.0, loss:0.24943713\n",
      "step: 10707.0, loss:0.14237226\n",
      "step: 10708.0, loss:0.23825138\n",
      "step: 10709.0, loss:0.19459160\n",
      "step: 10710.0, loss:0.19440800\n",
      "step: 10711.0, loss:0.18062439\n",
      "step: 10712.0, loss:0.21069942\n",
      "step: 10713.0, loss:0.24440776\n",
      "step: 10714.0, loss:0.19127570\n",
      "step: 10715.0, loss:0.35918928\n",
      "step: 10716.0, loss:0.26078009\n",
      "step: 10717.0, loss:0.13848392\n",
      "step: 10718.0, loss:0.33910117\n",
      "step: 10719.0, loss:0.26863437\n",
      "step: 10720.0, loss:0.20550781\n",
      "step: 10721.0, loss:0.24728879\n",
      "step: 10722.0, loss:0.31569295\n",
      "step: 10723.0, loss:0.26925243\n",
      "step: 10724.0, loss:0.16585835\n",
      "step: 10725.0, loss:0.18877790\n",
      "step: 10726.0, loss:0.23057924\n",
      "step: 10727.0, loss:0.20932240\n",
      "step: 10728.0, loss:0.28351308\n",
      "step: 10729.0, loss:0.22648557\n",
      "step: 10730.0, loss:0.25063177\n",
      "step: 10731.0, loss:0.20905451\n",
      "step: 10732.0, loss:0.21518067\n",
      "step: 10733.0, loss:0.20145453\n",
      "step: 10734.0, loss:0.24166110\n",
      "step: 10735.0, loss:0.15577730\n",
      "step: 10736.0, loss:0.35449242\n",
      "step: 10737.0, loss:0.20409460\n",
      "step: 10738.0, loss:0.14598943\n",
      "step: 10739.0, loss:0.25761763\n",
      "step: 10740.0, loss:0.21253685\n",
      "step: 10741.0, loss:0.13655314\n",
      "step: 10742.0, loss:0.15296103\n",
      "step: 10743.0, loss:0.25043042\n",
      "step: 10744.0, loss:0.23058278\n",
      "step: 10745.0, loss:0.19195430\n",
      "step: 10746.0, loss:0.22017980\n",
      "step: 10747.0, loss:0.18466683\n",
      "step: 10748.0, loss:0.28092792\n",
      "step: 10749.0, loss:0.30658898\n",
      "step: 10750.0, loss:0.21470097\n",
      "step: 10751.0, loss:0.25016506\n",
      "step: 10752.0, loss:0.19306353\n",
      "step: 10753.0, loss:0.14261528\n",
      "step: 10754.0, loss:0.28900130\n",
      "step: 10755.0, loss:0.18454207\n",
      "step: 10756.0, loss:0.24189718\n",
      "step: 10757.0, loss:0.20888504\n",
      "step: 10758.0, loss:0.34054228\n",
      "step: 10759.0, loss:0.22570663\n",
      "step: 10760.0, loss:0.29449640\n",
      "step: 10761.0, loss:0.29735263\n",
      "step: 10762.0, loss:0.29697490\n",
      "step: 10763.0, loss:0.25780199\n",
      "step: 10764.0, loss:0.23303512\n",
      "step: 10765.0, loss:0.13554713\n",
      "step: 10766.0, loss:0.19574152\n",
      "step: 10767.0, loss:0.16420588\n",
      "step: 10768.0, loss:0.18854261\n",
      "step: 10769.0, loss:0.20075122\n",
      "step: 10770.0, loss:0.26758144\n",
      "step: 10771.0, loss:0.18121899\n",
      "step: 10772.0, loss:0.20683745\n",
      "step: 10773.0, loss:0.26195283\n",
      "step: 10774.0, loss:0.25599057\n",
      "step: 10775.0, loss:0.17185000\n",
      "step: 10776.0, loss:0.24213807\n",
      "step: 10777.0, loss:0.17706898\n",
      "step: 10778.0, loss:0.27197569\n",
      "step: 10779.0, loss:0.13991733\n",
      "step: 10780.0, loss:0.16599804\n",
      "step: 10781.0, loss:0.21616178\n",
      "step: 10782.0, loss:0.18131960\n",
      "step: 10783.0, loss:0.16897738\n",
      "step: 10784.0, loss:0.13166306\n",
      "step: 10785.0, loss:0.21452587\n",
      "step: 10786.0, loss:0.18989971\n",
      "step: 10787.0, loss:0.17992804\n",
      "step: 10788.0, loss:0.20881354\n",
      "step: 10789.0, loss:0.35472591\n",
      "step: 10790.0, loss:0.37746847\n",
      "step: 10791.0, loss:0.27236793\n",
      "step: 10792.0, loss:0.27886885\n",
      "step: 10793.0, loss:0.20541971\n",
      "step: 10794.0, loss:0.26882058\n",
      "step: 10795.0, loss:0.19518310\n",
      "step: 10796.0, loss:0.29413727\n",
      "step: 10797.0, loss:0.20850743\n",
      "step: 10798.0, loss:0.22335268\n",
      "step: 10799.0, loss:0.23472024\n",
      "step: 10800.0, loss:0.11767966\n",
      "step: 10801.0, loss:0.21499218\n",
      "step: 10802.0, loss:0.39976657\n",
      "step: 10803.0, loss:0.26599142\n",
      "step: 10804.0, loss:0.21514529\n",
      "step: 10805.0, loss:0.11530833\n",
      "step: 10806.0, loss:0.18556971\n",
      "step: 10807.0, loss:0.22410126\n",
      "step: 10808.0, loss:0.25717109\n",
      "step: 10809.0, loss:0.20549295\n",
      "step: 10810.0, loss:0.10730601\n",
      "step: 10811.0, loss:0.29816451\n",
      "step: 10812.0, loss:0.16959462\n",
      "step: 10813.0, loss:0.20658783\n",
      "step: 10814.0, loss:0.18320996\n",
      "step: 10815.0, loss:0.18067606\n",
      "step: 10816.0, loss:0.24839675\n",
      "step: 10817.0, loss:0.24021462\n",
      "step: 10818.0, loss:0.31148178\n",
      "step: 10819.0, loss:0.22392582\n",
      "step: 10820.0, loss:0.20035650\n",
      "step: 10821.0, loss:0.26020774\n",
      "step: 10822.0, loss:0.37610567\n",
      "step: 10823.0, loss:0.24685249\n",
      "step: 10824.0, loss:0.25720759\n",
      "step: 10825.0, loss:0.15358537\n",
      "step: 10826.0, loss:0.14199687\n",
      "step: 10827.0, loss:0.18098178\n",
      "step: 10828.0, loss:0.17508336\n",
      "step: 10829.0, loss:0.15823114\n",
      "step: 10830.0, loss:0.23592626\n",
      "step: 10831.0, loss:0.19949405\n",
      "step: 10832.0, loss:0.37946234\n",
      "step: 10833.0, loss:0.16422421\n",
      "step: 10834.0, loss:0.33404066\n",
      "step: 10835.0, loss:0.23424885\n",
      "step: 10836.0, loss:0.19647960\n",
      "step: 10837.0, loss:0.16626715\n",
      "step: 10838.0, loss:0.16743136\n",
      "step: 10839.0, loss:0.22067960\n",
      "step: 10840.0, loss:0.29549067\n",
      "step: 10841.0, loss:0.15560175\n",
      "step: 10842.0, loss:0.24131167\n",
      "step: 10843.0, loss:0.25784361\n",
      "step: 10844.0, loss:0.25103539\n",
      "step: 10845.0, loss:0.24004971\n",
      "step: 10846.0, loss:0.11699261\n",
      "step: 10847.0, loss:0.32016854\n",
      "step: 10848.0, loss:0.31505260\n",
      "step: 10849.0, loss:0.13052743\n",
      "step: 10850.0, loss:0.17114643\n",
      "step: 10851.0, loss:0.22318732\n",
      "step: 10852.0, loss:0.23914256\n",
      "step: 10853.0, loss:0.18161002\n",
      "step: 10854.0, loss:0.28593786\n",
      "step: 10855.0, loss:0.28713546\n",
      "step: 10856.0, loss:0.17060834\n",
      "step: 10857.0, loss:0.24977949\n",
      "step: 10858.0, loss:0.25451387\n",
      "step: 10859.0, loss:0.08103725\n",
      "step: 10860.0, loss:0.23338596\n",
      "step: 10861.0, loss:0.28852444\n",
      "step: 10862.0, loss:0.16447341\n",
      "step: 10863.0, loss:0.26687148\n",
      "step: 10864.0, loss:0.18024629\n",
      "step: 10865.0, loss:0.21744535\n",
      "step: 10866.0, loss:0.16915475\n",
      "step: 10867.0, loss:0.24827406\n",
      "step: 10868.0, loss:0.24418463\n",
      "step: 10869.0, loss:0.25611192\n",
      "step: 10870.0, loss:0.33091675\n",
      "step: 10871.0, loss:0.24463755\n",
      "step: 10872.0, loss:0.18028923\n",
      "step: 10873.0, loss:0.25498768\n",
      "step: 10874.0, loss:0.10558299\n",
      "step: 10875.0, loss:0.23018393\n",
      "step: 10876.0, loss:0.25063474\n",
      "step: 10877.0, loss:0.24432780\n",
      "step: 10878.0, loss:0.27115232\n",
      "step: 10879.0, loss:0.20010839\n",
      "step: 10880.0, loss:0.34138772\n",
      "step: 10881.0, loss:0.16509870\n",
      "step: 10882.0, loss:0.21199778\n",
      "step: 10883.0, loss:0.23364437\n",
      "step: 10884.0, loss:0.24796497\n",
      "step: 10885.0, loss:0.21364228\n",
      "step: 10886.0, loss:0.14823011\n",
      "step: 10887.0, loss:0.31003659\n",
      "step: 10888.0, loss:0.20169303\n",
      "step: 10889.0, loss:0.23720796\n",
      "step: 10890.0, loss:0.26965953\n",
      "step: 10891.0, loss:0.25307873\n",
      "step: 10892.0, loss:0.17451373\n",
      "step: 10893.0, loss:0.16671447\n",
      "step: 10894.0, loss:0.27365273\n",
      "step: 10895.0, loss:0.26496816\n",
      "step: 10896.0, loss:0.12185164\n",
      "step: 10897.0, loss:0.13665337\n",
      "step: 10898.0, loss:0.20491930\n",
      "step: 10899.0, loss:0.20517878\n",
      "step: 10900.0, loss:0.28666429\n",
      "step: 10901.0, loss:0.23331946\n",
      "step: 10902.0, loss:0.18427899\n",
      "step: 10903.0, loss:0.11586531\n",
      "step: 10904.0, loss:0.31481629\n",
      "step: 10905.0, loss:0.16000085\n",
      "step: 10906.0, loss:0.23033700\n",
      "step: 10907.0, loss:0.24861521\n",
      "step: 10908.0, loss:0.10622180\n",
      "step: 10909.0, loss:0.18495050\n",
      "step: 10910.0, loss:0.25797911\n",
      "step: 10911.0, loss:0.24583605\n",
      "step: 10912.0, loss:0.28960470\n",
      "step: 10913.0, loss:0.16152997\n",
      "step: 10914.0, loss:0.18022385\n",
      "step: 10915.0, loss:0.31553801\n",
      "step: 10916.0, loss:0.24527293\n",
      "step: 10917.0, loss:0.26892011\n",
      "step: 10918.0, loss:0.22395758\n",
      "step: 10919.0, loss:0.17778041\n",
      "step: 10920.0, loss:0.28131865\n",
      "step: 10921.0, loss:0.19912052\n",
      "step: 10922.0, loss:0.13008129\n",
      "step: 10923.0, loss:0.21628797\n",
      "step: 10924.0, loss:0.15763785\n",
      "step: 10925.0, loss:0.14201068\n",
      "step: 10926.0, loss:0.21522394\n",
      "step: 10927.0, loss:0.19102554\n",
      "step: 10928.0, loss:0.24691899\n",
      "step: 10929.0, loss:0.20934887\n",
      "step: 10930.0, loss:0.43088116\n",
      "step: 10931.0, loss:0.22389945\n",
      "step: 10932.0, loss:0.14002683\n",
      "step: 10933.0, loss:0.13662081\n",
      "step: 10934.0, loss:0.19553248\n",
      "step: 10935.0, loss:0.23069895\n",
      "step: 10936.0, loss:0.22051568\n",
      "step: 10937.0, loss:0.30407089\n",
      "step: 10938.0, loss:0.31529938\n",
      "step: 10939.0, loss:0.30016167\n",
      "step: 10940.0, loss:0.19084064\n",
      "step: 10941.0, loss:0.24138130\n",
      "step: 10942.0, loss:0.21656007\n",
      "step: 10943.0, loss:0.25098853\n",
      "step: 10944.0, loss:0.15448426\n",
      "step: 10945.0, loss:0.22083213\n",
      "step: 10946.0, loss:0.21633250\n",
      "step: 10947.0, loss:0.11122113\n",
      "step: 10948.0, loss:0.14290455\n",
      "step: 10949.0, loss:0.32747266\n",
      "step: 10950.0, loss:0.28550759\n",
      "step: 10951.0, loss:0.15232557\n",
      "step: 10952.0, loss:0.17984803\n",
      "step: 10953.0, loss:0.19441053\n",
      "step: 10954.0, loss:0.27402944\n",
      "step: 10955.0, loss:0.22549604\n",
      "step: 10956.0, loss:0.33304527\n",
      "step: 10957.0, loss:0.25961167\n",
      "step: 10958.0, loss:0.09977960\n",
      "step: 10959.0, loss:0.15778356\n",
      "step: 10960.0, loss:0.32197527\n",
      "step: 10961.0, loss:0.26722743\n",
      "step: 10962.0, loss:0.17387039\n",
      "step: 10963.0, loss:0.28570815\n",
      "step: 10964.0, loss:0.11335387\n",
      "step: 10965.0, loss:0.18598581\n",
      "step: 10966.0, loss:0.18218885\n",
      "step: 10967.0, loss:0.19870572\n",
      "step: 10968.0, loss:0.19254226\n",
      "step: 10969.0, loss:0.19727896\n",
      "step: 10970.0, loss:0.18891493\n",
      "step: 10971.0, loss:0.16781058\n",
      "step: 10972.0, loss:0.37637311\n",
      "step: 10973.0, loss:0.17453370\n",
      "step: 10974.0, loss:0.16283024\n",
      "step: 10975.0, loss:0.24170824\n",
      "step: 10976.0, loss:0.16835670\n",
      "step: 10977.0, loss:0.25218093\n",
      "step: 10978.0, loss:0.14644899\n",
      "step: 10979.0, loss:0.19248375\n",
      "step: 10980.0, loss:0.27912519\n",
      "step: 10981.0, loss:0.39177957\n",
      "step: 10982.0, loss:0.17719623\n",
      "step: 10983.0, loss:0.16988441\n",
      "step: 10984.0, loss:0.14206106\n",
      "step: 10985.0, loss:0.16607608\n",
      "step: 10986.0, loss:0.24545967\n",
      "step: 10987.0, loss:0.16763167\n",
      "step: 10988.0, loss:0.29561360\n",
      "step: 10989.0, loss:0.28336495\n",
      "step: 10990.0, loss:0.20568201\n",
      "step: 10991.0, loss:0.15019382\n",
      "step: 10992.0, loss:0.19854486\n",
      "step: 10993.0, loss:0.20057343\n",
      "step: 10994.0, loss:0.24045370\n",
      "step: 10995.0, loss:0.30505311\n",
      "step: 10996.0, loss:0.19869762\n",
      "step: 10997.0, loss:0.37151242\n",
      "step: 10998.0, loss:0.25202294\n",
      "step: 10999.0, loss:0.21060130\n",
      "step: 11000.0, loss:0.21219674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1264/1264 [07:52<00:00,  2.67it/s]\n",
      "2023-04-03 01:06:13,656 - INFO - step:11000.0, matthews_corr:0.768946, Acc:89.188721%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 11001.0, loss:0.18395868\n",
      "step: 11002.0, loss:0.13453139\n",
      "step: 11003.0, loss:0.23339785\n",
      "step: 11004.0, loss:0.37282157\n",
      "step: 11005.0, loss:0.34012479\n",
      "step: 11006.0, loss:0.18059949\n",
      "step: 11007.0, loss:0.27637004\n",
      "step: 11008.0, loss:0.26579076\n",
      "step: 11009.0, loss:0.33433951\n",
      "step: 11010.0, loss:0.17930858\n",
      "step: 11011.0, loss:0.19004980\n",
      "step: 11012.0, loss:0.24254277\n",
      "step: 11013.0, loss:0.20250165\n",
      "step: 11014.0, loss:0.21294960\n",
      "step: 11015.0, loss:0.23034060\n",
      "step: 11016.0, loss:0.15341114\n",
      "step: 11017.0, loss:0.24215398\n",
      "step: 11018.0, loss:0.24031810\n",
      "step: 11019.0, loss:0.22769073\n",
      "step: 11020.0, loss:0.27507707\n",
      "step: 11021.0, loss:0.23658326\n",
      "step: 11022.0, loss:0.29713496\n",
      "step: 11023.0, loss:0.15116226\n",
      "step: 11024.0, loss:0.19457429\n",
      "step: 11025.0, loss:0.25979233\n",
      "step: 11026.0, loss:0.17431847\n",
      "step: 11027.0, loss:0.22319185\n",
      "step: 11028.0, loss:0.20727568\n",
      "step: 11029.0, loss:0.23406934\n",
      "step: 11030.0, loss:0.19607811\n",
      "step: 11031.0, loss:0.17340822\n",
      "step: 11032.0, loss:0.15035666\n",
      "step: 11033.0, loss:0.17667604\n",
      "step: 11034.0, loss:0.14140306\n",
      "step: 11035.0, loss:0.25258300\n",
      "step: 11036.0, loss:0.19001056\n",
      "step: 11037.0, loss:0.09937238\n",
      "step: 11038.0, loss:0.20256925\n",
      "step: 11039.0, loss:0.31298080\n",
      "step: 11040.0, loss:0.26623185\n",
      "step: 11041.0, loss:0.15124914\n",
      "step: 11042.0, loss:0.21624961\n",
      "step: 11043.0, loss:0.19507381\n",
      "step: 11044.0, loss:0.20704120\n",
      "step: 11045.0, loss:0.19280682\n",
      "step: 11046.0, loss:0.17949041\n",
      "step: 11047.0, loss:0.26023200\n",
      "step: 11048.0, loss:0.10455506\n",
      "step: 11049.0, loss:0.20618118\n",
      "step: 11050.0, loss:0.18308472\n",
      "step: 11051.0, loss:0.12029239\n",
      "step: 11052.0, loss:0.22587173\n",
      "step: 11053.0, loss:0.24606717\n",
      "step: 11054.0, loss:0.13916631\n",
      "step: 11055.0, loss:0.23601546\n",
      "step: 11056.0, loss:0.14729266\n",
      "step: 11057.0, loss:0.16012588\n",
      "step: 11058.0, loss:0.15693124\n",
      "step: 11059.0, loss:0.19579884\n",
      "step: 11060.0, loss:0.25306164\n",
      "step: 11061.0, loss:0.30575553\n",
      "step: 11062.0, loss:0.25996872\n",
      "step: 11063.0, loss:0.12340913\n",
      "step: 11064.0, loss:0.37577418\n",
      "step: 11065.0, loss:0.26141588\n",
      "step: 11066.0, loss:0.21637383\n",
      "step: 11067.0, loss:0.18566601\n",
      "step: 11068.0, loss:0.18069803\n",
      "step: 11069.0, loss:0.19242136\n",
      "step: 11070.0, loss:0.25411914\n",
      "step: 11071.0, loss:0.10622691\n",
      "step: 11072.0, loss:0.25936029\n",
      "step: 11073.0, loss:0.15800014\n",
      "step: 11074.0, loss:0.17287716\n",
      "step: 11075.0, loss:0.18633890\n",
      "step: 11076.0, loss:0.32652098\n",
      "step: 11077.0, loss:0.24772047\n",
      "step: 11078.0, loss:0.26013141\n",
      "step: 11079.0, loss:0.31755532\n",
      "step: 11080.0, loss:0.18143184\n",
      "step: 11081.0, loss:0.18476335\n",
      "step: 11082.0, loss:0.28257353\n",
      "step: 11083.0, loss:0.15240745\n",
      "step: 11084.0, loss:0.18915139\n",
      "step: 11085.0, loss:0.21100951\n",
      "step: 11086.0, loss:0.18244129\n",
      "step: 11087.0, loss:0.19886938\n",
      "step: 11088.0, loss:0.18226028\n",
      "step: 11089.0, loss:0.27753631\n",
      "step: 11090.0, loss:0.34219656\n",
      "step: 11091.0, loss:0.20837526\n",
      "step: 11092.0, loss:0.14756628\n",
      "step: 11093.0, loss:0.37818069\n",
      "step: 11094.0, loss:0.34918587\n",
      "step: 11095.0, loss:0.22825582\n",
      "step: 11096.0, loss:0.32131310\n",
      "step: 11097.0, loss:0.18974362\n",
      "step: 11098.0, loss:0.18690611\n",
      "step: 11099.0, loss:0.20482682\n",
      "step: 11100.0, loss:0.25185133\n",
      "step: 11101.0, loss:0.12771021\n",
      "step: 11102.0, loss:0.17259053\n",
      "step: 11103.0, loss:0.17532994\n",
      "step: 11104.0, loss:0.17525522\n",
      "step: 11105.0, loss:0.25990850\n",
      "step: 11106.0, loss:0.17210751\n",
      "step: 11107.0, loss:0.19547402\n",
      "step: 11108.0, loss:0.18154942\n",
      "step: 11109.0, loss:0.23847787\n",
      "step: 11110.0, loss:0.22020372\n",
      "step: 11111.0, loss:0.37806299\n",
      "step: 11112.0, loss:0.20688033\n",
      "step: 11113.0, loss:0.25907148\n",
      "step: 11114.0, loss:0.33577491\n",
      "step: 11115.0, loss:0.14575140\n",
      "step: 11116.0, loss:0.23840763\n",
      "step: 11117.0, loss:0.33638522\n",
      "step: 11118.0, loss:0.22153631\n",
      "step: 11119.0, loss:0.23526765\n",
      "step: 11120.0, loss:0.20227781\n",
      "step: 11121.0, loss:0.16289611\n",
      "step: 11122.0, loss:0.19163275\n",
      "step: 11123.0, loss:0.19200965\n",
      "step: 11124.0, loss:0.19850246\n",
      "step: 11125.0, loss:0.21385492\n",
      "step: 11126.0, loss:0.24398288\n",
      "step: 11127.0, loss:0.24342098\n",
      "step: 11128.0, loss:0.21110298\n",
      "step: 11129.0, loss:0.18003536\n",
      "step: 11130.0, loss:0.17164162\n",
      "step: 11131.0, loss:0.14943574\n",
      "step: 11132.0, loss:0.17161845\n",
      "step: 11133.0, loss:0.25084027\n",
      "step: 11134.0, loss:0.18192138\n",
      "step: 11135.0, loss:0.16981586\n",
      "step: 11136.0, loss:0.15940461\n",
      "step: 11137.0, loss:0.21348931\n",
      "step: 11138.0, loss:0.10878491\n",
      "step: 11139.0, loss:0.40391456\n",
      "step: 11140.0, loss:0.27658487\n",
      "step: 11141.0, loss:0.19154638\n",
      "step: 11142.0, loss:0.25593294\n",
      "step: 11143.0, loss:0.24968842\n",
      "step: 11144.0, loss:0.21119294\n",
      "step: 11145.0, loss:0.18630515\n",
      "step: 11146.0, loss:0.16918732\n",
      "step: 11147.0, loss:0.14055573\n",
      "step: 11148.0, loss:0.14167102\n",
      "step: 11149.0, loss:0.17292047\n",
      "step: 11150.0, loss:0.16277338\n",
      "step: 11151.0, loss:0.14558755\n",
      "step: 11152.0, loss:0.26955009\n",
      "step: 11153.0, loss:0.15852636\n",
      "step: 11154.0, loss:0.17189354\n",
      "step: 11155.0, loss:0.18161347\n",
      "step: 11156.0, loss:0.27954108\n",
      "step: 11157.0, loss:0.32625138\n",
      "step: 11158.0, loss:0.17289269\n",
      "step: 11159.0, loss:0.25926301\n",
      "step: 11160.0, loss:0.25039800\n",
      "step: 11161.0, loss:0.30663715\n",
      "step: 11162.0, loss:0.12379715\n",
      "step: 11163.0, loss:0.26909533\n",
      "step: 11164.0, loss:0.24544352\n",
      "step: 11165.0, loss:0.16486757\n",
      "step: 11166.0, loss:0.19837428\n",
      "step: 11167.0, loss:0.27792160\n",
      "step: 11168.0, loss:0.16392116\n",
      "step: 11169.0, loss:0.23715089\n",
      "step: 11170.0, loss:0.36086153\n",
      "step: 11171.0, loss:0.29618550\n",
      "step: 11172.0, loss:0.15929008\n",
      "step: 11173.0, loss:0.13025528\n",
      "step: 11174.0, loss:0.15606012\n",
      "step: 11175.0, loss:0.34272725\n",
      "step: 11176.0, loss:0.16728137\n",
      "step: 11177.0, loss:0.08775446\n",
      "step: 11178.0, loss:0.16457175\n",
      "step: 11179.0, loss:0.13500493\n",
      "step: 11180.0, loss:0.16085395\n",
      "step: 11181.0, loss:0.34767182\n",
      "step: 11182.0, loss:0.28909412\n",
      "step: 11183.0, loss:0.19912237\n",
      "step: 11184.0, loss:0.28774979\n",
      "step: 11185.0, loss:0.22194983\n",
      "step: 11186.0, loss:0.17831211\n",
      "step: 11187.0, loss:0.17280704\n",
      "step: 11188.0, loss:0.11908225\n",
      "step: 11189.0, loss:0.27433698\n",
      "step: 11190.0, loss:0.22775922\n",
      "step: 11191.0, loss:0.29442961\n",
      "step: 11192.0, loss:0.17909179\n",
      "step: 11193.0, loss:0.13303674\n",
      "step: 11194.0, loss:0.27497257\n",
      "step: 11195.0, loss:0.10882725\n",
      "step: 11196.0, loss:0.32544052\n",
      "step: 11197.0, loss:0.10969077\n",
      "step: 11198.0, loss:0.18176069\n",
      "step: 11199.0, loss:0.12613009\n",
      "step: 11200.0, loss:0.14264445\n",
      "step: 11201.0, loss:0.25641534\n",
      "step: 11202.0, loss:0.09010294\n",
      "step: 11203.0, loss:0.19052653\n",
      "step: 11204.0, loss:0.12885821\n",
      "step: 11205.0, loss:0.25882001\n",
      "step: 11206.0, loss:0.21635531\n",
      "step: 11207.0, loss:0.39786980\n",
      "step: 11208.0, loss:0.21738029\n",
      "step: 11209.0, loss:0.21520335\n",
      "step: 11210.0, loss:0.24218980\n",
      "step: 11211.0, loss:0.18140597\n",
      "step: 11212.0, loss:0.17640079\n",
      "step: 11213.0, loss:0.26190474\n",
      "step: 11214.0, loss:0.11271745\n",
      "step: 11215.0, loss:0.14551757\n",
      "step: 11216.0, loss:0.24946531\n",
      "step: 11217.0, loss:0.15297488\n",
      "step: 11218.0, loss:0.18588040\n",
      "step: 11219.0, loss:0.22438417\n",
      "step: 11220.0, loss:0.14791660\n",
      "step: 11221.0, loss:0.23296738\n",
      "step: 11222.0, loss:0.26204518\n",
      "step: 11223.0, loss:0.14838312\n",
      "step: 11224.0, loss:0.10876848\n",
      "step: 11225.0, loss:0.15856186\n",
      "step: 11226.0, loss:0.14888560\n",
      "step: 11227.0, loss:0.26233404\n",
      "step: 11228.0, loss:0.20074414\n",
      "step: 11229.0, loss:0.15774668\n",
      "step: 11230.0, loss:0.16558870\n",
      "step: 11231.0, loss:0.21414213\n",
      "step: 11232.0, loss:0.20618470\n",
      "step: 11233.0, loss:0.13922146\n",
      "step: 11234.0, loss:0.25474834\n",
      "step: 11235.0, loss:0.18625374\n",
      "step: 11236.0, loss:0.30841176\n",
      "step: 11237.0, loss:0.15025438\n",
      "step: 11238.0, loss:0.38302009\n",
      "step: 11239.0, loss:0.13475383\n",
      "step: 11240.0, loss:0.15459352\n",
      "step: 11241.0, loss:0.28625148\n",
      "step: 11242.0, loss:0.24033967\n",
      "step: 11243.0, loss:0.17114498\n",
      "step: 11244.0, loss:0.17112883\n",
      "step: 11245.0, loss:0.17689218\n",
      "step: 11246.0, loss:0.20161444\n",
      "step: 11247.0, loss:0.30245401\n",
      "step: 11248.0, loss:0.12813811\n",
      "step: 11249.0, loss:0.15158778\n",
      "step: 11250.0, loss:0.22065922\n",
      "step: 11251.0, loss:0.11580280\n",
      "step: 11252.0, loss:0.20598228\n",
      "step: 11253.0, loss:0.18737004\n",
      "step: 11254.0, loss:0.26651513\n",
      "step: 11255.0, loss:0.21953544\n",
      "step: 11256.0, loss:0.26980135\n",
      "step: 11257.0, loss:0.19739142\n",
      "step: 11258.0, loss:0.11553604\n",
      "step: 11259.0, loss:0.18488010\n",
      "step: 11260.0, loss:0.18185263\n",
      "step: 11261.0, loss:0.11252374\n",
      "step: 11262.0, loss:0.31342942\n",
      "step: 11263.0, loss:0.17671261\n",
      "step: 11264.0, loss:0.22836405\n",
      "step: 11265.0, loss:0.22670841\n",
      "step: 11266.0, loss:0.17344454\n",
      "step: 11267.0, loss:0.21972203\n",
      "step: 11268.0, loss:0.17965810\n",
      "step: 11269.0, loss:0.34083360\n",
      "step: 11270.0, loss:0.13780688\n",
      "step: 11271.0, loss:0.24903699\n",
      "step: 11272.0, loss:0.29520113\n",
      "step: 11273.0, loss:0.17903467\n",
      "step: 11274.0, loss:0.12948373\n",
      "step: 11275.0, loss:0.27939121\n",
      "step: 11276.0, loss:0.25945924\n",
      "step: 11277.0, loss:0.11394630\n",
      "step: 11278.0, loss:0.21513937\n",
      "step: 11279.0, loss:0.25886623\n",
      "step: 11280.0, loss:0.29881303\n",
      "step: 11281.0, loss:0.24634327\n",
      "step: 11282.0, loss:0.22888311\n",
      "step: 11283.0, loss:0.23397457\n",
      "step: 11284.0, loss:0.15914702\n",
      "step: 11285.0, loss:0.14187584\n",
      "step: 11286.0, loss:0.10077805\n",
      "step: 11287.0, loss:0.28121718\n",
      "step: 11288.0, loss:0.18141993\n",
      "step: 11289.0, loss:0.27099380\n",
      "step: 11290.0, loss:0.15642730\n",
      "step: 11291.0, loss:0.25982963\n",
      "step: 11292.0, loss:0.27840807\n",
      "step: 11293.0, loss:0.12204501\n",
      "step: 11294.0, loss:0.27074808\n",
      "step: 11295.0, loss:0.25212488\n",
      "step: 11296.0, loss:0.25201732\n",
      "step: 11297.0, loss:0.19699447\n",
      "step: 11298.0, loss:0.28635070\n",
      "step: 11299.0, loss:0.17103622\n",
      "step: 11300.0, loss:0.33526559\n",
      "step: 11301.0, loss:0.19425813\n",
      "step: 11302.0, loss:0.17455341\n",
      "step: 11303.0, loss:0.18243044\n",
      "step: 11304.0, loss:0.23053140\n",
      "step: 11305.0, loss:0.15166175\n",
      "step: 11306.0, loss:0.16838980\n",
      "step: 11307.0, loss:0.28932159\n",
      "step: 11308.0, loss:0.19460675\n",
      "step: 11309.0, loss:0.17819614\n",
      "step: 11310.0, loss:0.26504264\n",
      "step: 11311.0, loss:0.17136773\n",
      "step: 11312.0, loss:0.22472776\n",
      "step: 11313.0, loss:0.15352214\n",
      "step: 11314.0, loss:0.24572740\n",
      "step: 11315.0, loss:0.22748870\n",
      "step: 11316.0, loss:0.15134005\n",
      "step: 11317.0, loss:0.07114001\n",
      "step: 11318.0, loss:0.22706066\n",
      "step: 11319.0, loss:0.30295419\n",
      "step: 11320.0, loss:0.17542170\n",
      "step: 11321.0, loss:0.27991406\n",
      "step: 11322.0, loss:0.32169660\n",
      "step: 11323.0, loss:0.17019466\n",
      "step: 11324.0, loss:0.22994471\n",
      "step: 11325.0, loss:0.32110542\n",
      "step: 11326.0, loss:0.12231181\n",
      "step: 11327.0, loss:0.33650620\n",
      "step: 11328.0, loss:0.13364707\n",
      "step: 11329.0, loss:0.09331746\n",
      "step: 11330.0, loss:0.28856079\n",
      "step: 11331.0, loss:0.30976737\n",
      "step: 11332.0, loss:0.15651242\n",
      "step: 11333.0, loss:0.26686935\n",
      "step: 11334.0, loss:0.24048497\n",
      "step: 11335.0, loss:0.28216646\n",
      "step: 11336.0, loss:0.34985461\n",
      "step: 11337.0, loss:0.26973056\n",
      "step: 11338.0, loss:0.27762283\n",
      "step: 11339.0, loss:0.19076035\n",
      "step: 11340.0, loss:0.32821862\n",
      "step: 11341.0, loss:0.22087461\n",
      "step: 11342.0, loss:0.21626449\n",
      "step: 11343.0, loss:0.19632499\n",
      "step: 11344.0, loss:0.25445533\n",
      "step: 11345.0, loss:0.31513593\n",
      "step: 11346.0, loss:0.31464938\n",
      "step: 11347.0, loss:0.20354021\n",
      "step: 11348.0, loss:0.28749772\n",
      "step: 11349.0, loss:0.14523876\n",
      "step: 11350.0, loss:0.17698185\n",
      "step: 11351.0, loss:0.25498635\n",
      "step: 11352.0, loss:0.15447582\n",
      "step: 11353.0, loss:0.27338323\n",
      "step: 11354.0, loss:0.20123543\n",
      "step: 11355.0, loss:0.27728343\n",
      "step: 11356.0, loss:0.21078088\n",
      "step: 11357.0, loss:0.22895155\n",
      "step: 11358.0, loss:0.20293150\n",
      "step: 11359.0, loss:0.33543501\n",
      "step: 11360.0, loss:0.33059145\n",
      "step: 11361.0, loss:0.17845041\n",
      "step: 11362.0, loss:0.15812695\n",
      "step: 11363.0, loss:0.18370244\n",
      "step: 11364.0, loss:0.16056358\n",
      "step: 11365.0, loss:0.20675504\n",
      "step: 11366.0, loss:0.29906320\n",
      "step: 11367.0, loss:0.26040124\n",
      "step: 11368.0, loss:0.17955128\n",
      "step: 11369.0, loss:0.13796970\n",
      "step: 11370.0, loss:0.30390036\n",
      "step: 11371.0, loss:0.22082330\n",
      "step: 11372.0, loss:0.31922453\n",
      "step: 11373.0, loss:0.21244729\n",
      "step: 11374.0, loss:0.29358821\n",
      "step: 11375.0, loss:0.27866403\n",
      "step: 11376.0, loss:0.26291753\n",
      "step: 11377.0, loss:0.24464986\n",
      "step: 11378.0, loss:0.27860477\n",
      "step: 11379.0, loss:0.26527195\n",
      "step: 11380.0, loss:0.23114396\n",
      "step: 11381.0, loss:0.31235318\n",
      "step: 11382.0, loss:0.21371881\n",
      "step: 11383.0, loss:0.25590619\n",
      "step: 11384.0, loss:0.10220539\n",
      "step: 11385.0, loss:0.34702005\n",
      "step: 11386.0, loss:0.19093399\n",
      "step: 11387.0, loss:0.18232054\n",
      "step: 11388.0, loss:0.26823771\n",
      "step: 11389.0, loss:0.17318494\n",
      "step: 11390.0, loss:0.25262189\n",
      "step: 11391.0, loss:0.17846540\n",
      "step: 11392.0, loss:0.21004725\n",
      "step: 11393.0, loss:0.20544371\n",
      "step: 11394.0, loss:0.16976241\n",
      "step: 11395.0, loss:0.25816016\n",
      "step: 11396.0, loss:0.16627573\n",
      "step: 11397.0, loss:0.22157216\n",
      "step: 11398.0, loss:0.16784883\n",
      "step: 11399.0, loss:0.12286947\n",
      "step: 11400.0, loss:0.18405276\n",
      "step: 11401.0, loss:0.29623024\n",
      "step: 11402.0, loss:0.29991416\n",
      "step: 11403.0, loss:0.21890137\n",
      "step: 11404.0, loss:0.28308807\n",
      "step: 11405.0, loss:0.14053876\n",
      "step: 11406.0, loss:0.23415905\n",
      "step: 11407.0, loss:0.24261807\n",
      "step: 11408.0, loss:0.15375785\n",
      "step: 11409.0, loss:0.26979936\n",
      "step: 11410.0, loss:0.20516169\n",
      "step: 11411.0, loss:0.32051231\n",
      "step: 11412.0, loss:0.30293289\n",
      "step: 11413.0, loss:0.25600597\n",
      "step: 11414.0, loss:0.29593800\n",
      "step: 11415.0, loss:0.17683106\n",
      "step: 11416.0, loss:0.21093341\n",
      "step: 11417.0, loss:0.21278431\n",
      "step: 11418.0, loss:0.24410144\n",
      "step: 11419.0, loss:0.25299919\n",
      "step: 11420.0, loss:0.28684225\n",
      "step: 11421.0, loss:0.31744064\n",
      "step: 11422.0, loss:0.26028694\n",
      "step: 11423.0, loss:0.18469504\n",
      "step: 11424.0, loss:0.18427950\n",
      "step: 11425.0, loss:0.19676949\n",
      "step: 11426.0, loss:0.16195547\n",
      "step: 11427.0, loss:0.26415715\n",
      "step: 11428.0, loss:0.27067399\n",
      "step: 11429.0, loss:0.27605698\n",
      "step: 11430.0, loss:0.26195378\n",
      "step: 11431.0, loss:0.18291975\n",
      "step: 11432.0, loss:0.23631591\n",
      "step: 11433.0, loss:0.30113475\n",
      "step: 11434.0, loss:0.23635459\n",
      "step: 11435.0, loss:0.31157985\n",
      "step: 11436.0, loss:0.26208235\n",
      "step: 11437.0, loss:0.11465081\n",
      "step: 11438.0, loss:0.23398603\n",
      "step: 11439.0, loss:0.23212103\n",
      "step: 11440.0, loss:0.16178113\n",
      "step: 11441.0, loss:0.29244189\n",
      "step: 11442.0, loss:0.33834219\n",
      "step: 11443.0, loss:0.29524808\n",
      "step: 11444.0, loss:0.08448881\n",
      "step: 11445.0, loss:0.32045239\n",
      "step: 11446.0, loss:0.19551384\n",
      "step: 11447.0, loss:0.30282318\n",
      "step: 11448.0, loss:0.19932133\n",
      "step: 11449.0, loss:0.17906144\n",
      "step: 11450.0, loss:0.23881747\n",
      "step: 11451.0, loss:0.25156902\n",
      "step: 11452.0, loss:0.20255706\n",
      "step: 11453.0, loss:0.31815750\n",
      "step: 11454.0, loss:0.27179621\n",
      "step: 11455.0, loss:0.19327847\n",
      "step: 11456.0, loss:0.16500442\n",
      "step: 11457.0, loss:0.15523612\n",
      "step: 11458.0, loss:0.34369836\n",
      "step: 11459.0, loss:0.20034767\n",
      "step: 11460.0, loss:0.25692179\n",
      "step: 11461.0, loss:0.29444667\n",
      "step: 11462.0, loss:0.21802082\n",
      "step: 11463.0, loss:0.18324133\n",
      "step: 11464.0, loss:0.19058038\n",
      "step: 11465.0, loss:0.22177592\n",
      "step: 11466.0, loss:0.17040495\n",
      "step: 11467.0, loss:0.18546156\n",
      "step: 11468.0, loss:0.21300285\n",
      "step: 11469.0, loss:0.23813951\n",
      "step: 11470.0, loss:0.29647658\n",
      "step: 11471.0, loss:0.18723431\n",
      "step: 11472.0, loss:0.22641535\n",
      "step: 11473.0, loss:0.16840863\n",
      "step: 11474.0, loss:0.23801690\n",
      "step: 11475.0, loss:0.14668855\n",
      "step: 11476.0, loss:0.19906794\n",
      "step: 11477.0, loss:0.13729255\n",
      "step: 11478.0, loss:0.20436005\n",
      "step: 11479.0, loss:0.27670069\n",
      "step: 11480.0, loss:0.17864178\n",
      "step: 11481.0, loss:0.20460982\n",
      "step: 11482.0, loss:0.24953968\n",
      "step: 11483.0, loss:0.14032008\n",
      "step: 11484.0, loss:0.24355391\n",
      "step: 11485.0, loss:0.38254010\n",
      "step: 11486.0, loss:0.14983174\n",
      "step: 11487.0, loss:0.21676726\n",
      "step: 11488.0, loss:0.27517610\n",
      "step: 11489.0, loss:0.16532995\n",
      "step: 11490.0, loss:0.15733700\n",
      "step: 11491.0, loss:0.16107796\n",
      "step: 11492.0, loss:0.26812470\n",
      "step: 11493.0, loss:0.24508393\n",
      "step: 11494.0, loss:0.27321891\n",
      "step: 11495.0, loss:0.28230482\n",
      "step: 11496.0, loss:0.19789790\n",
      "step: 11497.0, loss:0.23503861\n",
      "step: 11498.0, loss:0.39166976\n",
      "step: 11499.0, loss:0.16966439\n",
      "step: 11500.0, loss:0.16608662\n",
      "step: 11501.0, loss:0.18472216\n",
      "step: 11502.0, loss:0.33546406\n",
      "step: 11503.0, loss:0.18314212\n",
      "step: 11504.0, loss:0.16991590\n",
      "step: 11505.0, loss:0.30543842\n",
      "step: 11506.0, loss:0.36734734\n",
      "step: 11507.0, loss:0.24126789\n",
      "step: 11508.0, loss:0.23545472\n",
      "step: 11509.0, loss:0.15633379\n",
      "step: 11510.0, loss:0.30475583\n",
      "step: 11511.0, loss:0.24577023\n",
      "step: 11512.0, loss:0.25655426\n",
      "step: 11513.0, loss:0.29429319\n",
      "step: 11514.0, loss:0.32265406\n",
      "step: 11515.0, loss:0.27730783\n",
      "step: 11516.0, loss:0.24553934\n",
      "step: 11517.0, loss:0.30465053\n",
      "step: 11518.0, loss:0.37579139\n",
      "step: 11519.0, loss:0.13658313\n",
      "step: 11520.0, loss:0.13489129\n",
      "step: 11521.0, loss:0.18631437\n",
      "step: 11522.0, loss:0.26700192\n",
      "step: 11523.0, loss:0.22965149\n",
      "step: 11524.0, loss:0.09380571\n",
      "step: 11525.0, loss:0.37735726\n",
      "step: 11526.0, loss:0.16553590\n",
      "step: 11527.0, loss:0.27078415\n",
      "step: 11528.0, loss:0.24757559\n",
      "step: 11529.0, loss:0.15785221\n",
      "step: 11530.0, loss:0.12996101\n",
      "step: 11531.0, loss:0.28603401\n",
      "step: 11532.0, loss:0.21100228\n",
      "step: 11533.0, loss:0.21655334\n",
      "step: 11534.0, loss:0.27662240\n",
      "step: 11535.0, loss:0.17932719\n",
      "step: 11536.0, loss:0.31476795\n",
      "step: 11537.0, loss:0.21637347\n",
      "step: 11538.0, loss:0.18600556\n",
      "step: 11539.0, loss:0.25966514\n",
      "step: 11540.0, loss:0.17352506\n",
      "step: 11541.0, loss:0.10830716\n",
      "step: 11542.0, loss:0.13652567\n",
      "step: 11543.0, loss:0.12772129\n",
      "step: 11544.0, loss:0.31360308\n",
      "step: 11545.0, loss:0.27119577\n",
      "step: 11546.0, loss:0.23756824\n",
      "step: 11547.0, loss:0.22131201\n",
      "step: 11548.0, loss:0.18597970\n",
      "step: 11549.0, loss:0.30889545\n",
      "step: 11550.0, loss:0.23703723\n",
      "step: 11551.0, loss:0.21626485\n",
      "step: 11552.0, loss:0.16354956\n",
      "step: 11553.0, loss:0.29331793\n",
      "step: 11554.0, loss:0.22797620\n",
      "step: 11555.0, loss:0.24984699\n",
      "step: 11556.0, loss:0.17619413\n",
      "step: 11557.0, loss:0.18963817\n",
      "step: 11558.0, loss:0.18345481\n",
      "step: 11559.0, loss:0.25758571\n",
      "step: 11560.0, loss:0.20575115\n",
      "step: 11561.0, loss:0.20311237\n",
      "step: 11562.0, loss:0.15605790\n",
      "step: 11563.0, loss:0.17906923\n",
      "step: 11564.0, loss:0.25532213\n",
      "step: 11565.0, loss:0.23532142\n",
      "step: 11566.0, loss:0.13903522\n",
      "step: 11567.0, loss:0.24770974\n",
      "step: 11568.0, loss:0.22564409\n",
      "step: 11569.0, loss:0.24307404\n",
      "step: 11570.0, loss:0.22238094\n",
      "step: 11571.0, loss:0.32893694\n",
      "step: 11572.0, loss:0.20134819\n",
      "step: 11573.0, loss:0.22793060\n",
      "step: 11574.0, loss:0.21031499\n",
      "step: 11575.0, loss:0.29114443\n",
      "step: 11576.0, loss:0.21642991\n",
      "step: 11577.0, loss:0.17299106\n",
      "step: 11578.0, loss:0.23811122\n",
      "step: 11579.0, loss:0.32931205\n",
      "step: 11580.0, loss:0.20172355\n",
      "step: 11581.0, loss:0.22466807\n",
      "step: 11582.0, loss:0.22023220\n",
      "step: 11583.0, loss:0.17116729\n",
      "step: 11584.0, loss:0.22471479\n",
      "step: 11585.0, loss:0.16406868\n",
      "step: 11586.0, loss:0.29859332\n",
      "step: 11587.0, loss:0.13653161\n",
      "step: 11588.0, loss:0.26706014\n",
      "step: 11589.0, loss:0.16860175\n",
      "step: 11590.0, loss:0.29692163\n",
      "step: 11591.0, loss:0.19775568\n",
      "step: 11592.0, loss:0.26271191\n",
      "step: 11593.0, loss:0.37251362\n",
      "step: 11594.0, loss:0.18531488\n",
      "step: 11595.0, loss:0.19466408\n",
      "step: 11596.0, loss:0.43869594\n",
      "step: 11597.0, loss:0.13853549\n",
      "step: 11598.0, loss:0.28109367\n",
      "step: 11599.0, loss:0.20122087\n",
      "step: 11600.0, loss:0.17469890\n",
      "step: 11601.0, loss:0.21159443\n",
      "step: 11602.0, loss:0.30204738\n",
      "step: 11603.0, loss:0.19406766\n",
      "step: 11604.0, loss:0.21216535\n",
      "step: 11605.0, loss:0.21797536\n",
      "step: 11606.0, loss:0.37429235\n",
      "step: 11607.0, loss:0.16170851\n",
      "step: 11608.0, loss:0.19455658\n",
      "step: 11609.0, loss:0.24853951\n",
      "step: 11610.0, loss:0.25322158\n",
      "step: 11611.0, loss:0.25144032\n",
      "step: 11612.0, loss:0.20675554\n",
      "step: 11613.0, loss:0.24958861\n",
      "step: 11614.0, loss:0.17983041\n",
      "step: 11615.0, loss:0.19929503\n",
      "step: 11616.0, loss:0.15967876\n",
      "step: 11617.0, loss:0.22935972\n",
      "step: 11618.0, loss:0.12998733\n",
      "step: 11619.0, loss:0.15771859\n",
      "step: 11620.0, loss:0.18059604\n",
      "step: 11621.0, loss:0.16964903\n",
      "step: 11622.0, loss:0.20259628\n",
      "step: 11623.0, loss:0.19907162\n",
      "step: 11624.0, loss:0.13357446\n",
      "step: 11625.0, loss:0.20018237\n",
      "step: 11626.0, loss:0.30517139\n",
      "step: 11627.0, loss:0.30166644\n",
      "step: 11628.0, loss:0.14654675\n",
      "step: 11629.0, loss:0.17636215\n",
      "step: 11630.0, loss:0.23457926\n",
      "step: 11631.0, loss:0.22162568\n",
      "step: 11632.0, loss:0.22707558\n",
      "step: 11633.0, loss:0.22592359\n",
      "step: 11634.0, loss:0.28113118\n",
      "step: 11635.0, loss:0.20515515\n",
      "step: 11636.0, loss:0.23985170\n",
      "step: 11637.0, loss:0.21577666\n",
      "step: 11638.0, loss:0.14906328\n",
      "step: 11639.0, loss:0.20515214\n",
      "step: 11640.0, loss:0.23349324\n",
      "step: 11641.0, loss:0.27612748\n",
      "step: 11642.0, loss:0.11094283\n",
      "step: 11643.0, loss:0.19694441\n",
      "step: 11644.0, loss:0.10661659\n",
      "step: 11645.0, loss:0.23116662\n",
      "step: 11646.0, loss:0.17103072\n",
      "step: 11647.0, loss:0.24492550\n",
      "step: 11648.0, loss:0.22879309\n",
      "step: 11649.0, loss:0.19581113\n",
      "step: 11650.0, loss:0.25663319\n",
      "step: 11651.0, loss:0.23895095\n",
      "step: 11652.0, loss:0.27533226\n",
      "step: 11653.0, loss:0.24210956\n",
      "step: 11654.0, loss:0.13591199\n",
      "step: 11655.0, loss:0.24314825\n",
      "step: 11656.0, loss:0.22462967\n",
      "step: 11657.0, loss:0.29683766\n",
      "step: 11658.0, loss:0.34259115\n",
      "step: 11659.0, loss:0.29148844\n",
      "step: 11660.0, loss:0.18695889\n",
      "step: 11661.0, loss:0.24463316\n",
      "step: 11662.0, loss:0.28994238\n",
      "step: 11663.0, loss:0.21041969\n",
      "step: 11664.0, loss:0.19084315\n",
      "step: 11665.0, loss:0.21378632\n",
      "step: 11666.0, loss:0.31304884\n",
      "step: 11667.0, loss:0.17410003\n",
      "step: 11668.0, loss:0.20649950\n",
      "step: 11669.0, loss:0.21700645\n",
      "step: 11670.0, loss:0.32996482\n",
      "step: 11671.0, loss:0.14961796\n",
      "step: 11672.0, loss:0.17161980\n",
      "step: 11673.0, loss:0.23589766\n",
      "step: 11674.0, loss:0.22094657\n",
      "step: 11675.0, loss:0.16502122\n",
      "step: 11676.0, loss:0.25040432\n",
      "step: 11677.0, loss:0.28408721\n",
      "step: 11678.0, loss:0.19935141\n",
      "step: 11679.0, loss:0.17563650\n",
      "step: 11680.0, loss:0.15527065\n",
      "step: 11681.0, loss:0.18821005\n",
      "step: 11682.0, loss:0.28068576\n",
      "step: 11683.0, loss:0.16496671\n",
      "step: 11684.0, loss:0.22288532\n",
      "step: 11685.0, loss:0.15457333\n",
      "step: 11686.0, loss:0.26146431\n",
      "step: 11687.0, loss:0.20637317\n",
      "step: 11688.0, loss:0.12008821\n",
      "step: 11689.0, loss:0.24038155\n",
      "step: 11690.0, loss:0.25816741\n",
      "step: 11691.0, loss:0.16270065\n",
      "step: 11692.0, loss:0.25912499\n",
      "step: 11693.0, loss:0.23755563\n",
      "step: 11694.0, loss:0.25771331\n",
      "step: 11695.0, loss:0.36941502\n",
      "step: 11696.0, loss:0.16296359\n",
      "step: 11697.0, loss:0.26394302\n",
      "step: 11698.0, loss:0.20309087\n",
      "step: 11699.0, loss:0.19033067\n",
      "step: 11700.0, loss:0.16869524\n",
      "step: 11701.0, loss:0.13462733\n",
      "step: 11702.0, loss:0.16148448\n",
      "step: 11703.0, loss:0.23302467\n",
      "step: 11704.0, loss:0.25639733\n",
      "step: 11705.0, loss:0.21848323\n",
      "step: 11706.0, loss:0.25899875\n",
      "step: 11707.0, loss:0.12186587\n",
      "step: 11708.0, loss:0.25825632\n",
      "step: 11709.0, loss:0.11889822\n",
      "step: 11710.0, loss:0.19538450\n",
      "step: 11711.0, loss:0.23076919\n",
      "step: 11712.0, loss:0.24884322\n",
      "step: 11713.0, loss:0.10162694\n",
      "step: 11714.0, loss:0.18935876\n",
      "step: 11715.0, loss:0.20600678\n",
      "step: 11716.0, loss:0.16400415\n",
      "step: 11717.0, loss:0.26223659\n",
      "step: 11718.0, loss:0.21375971\n",
      "step: 11719.0, loss:0.13697804\n",
      "step: 11720.0, loss:0.17915564\n",
      "step: 11721.0, loss:0.29905224\n",
      "step: 11722.0, loss:0.28463289\n",
      "step: 11723.0, loss:0.22722062\n",
      "step: 11724.0, loss:0.18067484\n",
      "step: 11725.0, loss:0.22792705\n",
      "step: 11726.0, loss:0.25147435\n",
      "step: 11727.0, loss:0.14448139\n",
      "step: 11728.0, loss:0.20465129\n",
      "step: 11729.0, loss:0.09628306\n",
      "step: 11730.0, loss:0.15033271\n",
      "step: 11731.0, loss:0.21207437\n",
      "step: 11732.0, loss:0.20588600\n",
      "step: 11733.0, loss:0.16641667\n",
      "step: 11734.0, loss:0.40792004\n",
      "step: 11735.0, loss:0.14984493\n",
      "step: 11736.0, loss:0.28693553\n",
      "step: 11737.0, loss:0.16089014\n",
      "step: 11738.0, loss:0.23813299\n",
      "step: 11739.0, loss:0.13728385\n",
      "step: 11740.0, loss:0.19852147\n",
      "step: 11741.0, loss:0.26224639\n",
      "step: 11742.0, loss:0.22101128\n",
      "step: 11743.0, loss:0.24011237\n",
      "step: 11744.0, loss:0.20559554\n",
      "step: 11745.0, loss:0.27037026\n",
      "step: 11746.0, loss:0.22215738\n",
      "step: 11747.0, loss:0.17386838\n",
      "step: 11748.0, loss:0.29811864\n",
      "step: 11749.0, loss:0.34285982\n",
      "step: 11750.0, loss:0.22786798\n",
      "step: 11751.0, loss:0.20796939\n",
      "step: 11752.0, loss:0.23966756\n",
      "step: 11753.0, loss:0.13810758\n",
      "step: 11754.0, loss:0.32708570\n",
      "step: 11755.0, loss:0.17612291\n",
      "step: 11756.0, loss:0.29043229\n",
      "step: 11757.0, loss:0.24536766\n",
      "step: 11758.0, loss:0.18975736\n",
      "step: 11759.0, loss:0.21294573\n",
      "step: 11760.0, loss:0.13432080\n",
      "step: 11761.0, loss:0.14943723\n",
      "step: 11762.0, loss:0.15784984\n",
      "step: 11763.0, loss:0.32680560\n",
      "step: 11764.0, loss:0.14483074\n",
      "step: 11765.0, loss:0.30334581\n",
      "step: 11766.0, loss:0.13831034\n",
      "step: 11767.0, loss:0.10664536\n",
      "step: 11768.0, loss:0.27398056\n",
      "step: 11769.0, loss:0.16558731\n",
      "step: 11770.0, loss:0.18199113\n",
      "step: 11771.0, loss:0.27577852\n",
      "step: 11772.0, loss:0.19417097\n",
      "step: 11773.0, loss:0.16535253\n",
      "step: 11774.0, loss:0.22577632\n",
      "step: 11775.0, loss:0.29874695\n",
      "step: 11776.0, loss:0.29277357\n",
      "step: 11777.0, loss:0.13775275\n",
      "step: 11778.0, loss:0.29694851\n",
      "step: 11779.0, loss:0.25884535\n",
      "step: 11780.0, loss:0.32070025\n",
      "step: 11781.0, loss:0.24374967\n",
      "step: 11782.0, loss:0.19919276\n",
      "step: 11783.0, loss:0.15908396\n",
      "step: 11784.0, loss:0.15033123\n",
      "step: 11785.0, loss:0.18560685\n",
      "step: 11786.0, loss:0.29670504\n",
      "step: 11787.0, loss:0.15156501\n",
      "step: 11788.0, loss:0.19445385\n",
      "step: 11789.0, loss:0.16248179\n",
      "step: 11790.0, loss:0.32385076\n",
      "step: 11791.0, loss:0.16728522\n",
      "step: 11792.0, loss:0.17041200\n",
      "step: 11793.0, loss:0.17921686\n",
      "step: 11794.0, loss:0.22960672\n",
      "step: 11795.0, loss:0.23837468\n",
      "step: 11796.0, loss:0.09464733\n",
      "step: 11797.0, loss:0.21075121\n",
      "step: 11798.0, loss:0.34355177\n",
      "step: 11799.0, loss:0.23228094\n",
      "step: 11800.0, loss:0.21169170\n",
      "step: 11801.0, loss:0.32351534\n",
      "step: 11802.0, loss:0.19056455\n",
      "step: 11803.0, loss:0.13223936\n",
      "step: 11804.0, loss:0.36372120\n",
      "step: 11805.0, loss:0.26469802\n",
      "step: 11806.0, loss:0.24249889\n",
      "step: 11807.0, loss:0.24498306\n",
      "step: 11808.0, loss:0.18883487\n",
      "step: 11809.0, loss:0.21559656\n",
      "step: 11810.0, loss:0.23600100\n",
      "step: 11811.0, loss:0.19957732\n",
      "step: 11812.0, loss:0.17255281\n",
      "step: 11813.0, loss:0.12911968\n",
      "step: 11814.0, loss:0.30452345\n",
      "step: 11815.0, loss:0.15685763\n",
      "step: 11816.0, loss:0.14147646\n",
      "step: 11817.0, loss:0.19639520\n",
      "step: 11818.0, loss:0.18309396\n",
      "step: 11819.0, loss:0.18518275\n",
      "step: 11820.0, loss:0.23268425\n",
      "step: 11821.0, loss:0.29284957\n",
      "step: 11822.0, loss:0.20183571\n",
      "step: 11823.0, loss:0.17691735\n",
      "step: 11824.0, loss:0.35679086\n",
      "step: 11825.0, loss:0.30315204\n",
      "step: 11826.0, loss:0.13972279\n",
      "step: 11827.0, loss:0.17330683\n",
      "step: 11828.0, loss:0.20731084\n",
      "step: 11829.0, loss:0.20918052\n",
      "step: 11830.0, loss:0.26425663\n",
      "step: 11831.0, loss:0.15032965\n",
      "step: 11832.0, loss:0.20044916\n",
      "step: 11833.0, loss:0.32186606\n",
      "step: 11834.0, loss:0.22685897\n",
      "step: 11835.0, loss:0.15536589\n",
      "step: 11836.0, loss:0.27639204\n",
      "step: 11837.0, loss:0.22372274\n",
      "step: 11838.0, loss:0.18548627\n",
      "step: 11839.0, loss:0.16338760\n",
      "step: 11840.0, loss:0.22373020\n",
      "step: 11841.0, loss:0.26183740\n",
      "step: 11842.0, loss:0.26263039\n",
      "step: 11843.0, loss:0.24450634\n",
      "step: 11844.0, loss:0.21026591\n",
      "step: 11845.0, loss:0.16092321\n",
      "step: 11846.0, loss:0.31556664\n",
      "step: 11847.0, loss:0.13940751\n",
      "step: 11848.0, loss:0.12114506\n",
      "step: 11849.0, loss:0.27666271\n",
      "step: 11850.0, loss:0.19320854\n",
      "step: 11851.0, loss:0.12201530\n",
      "step: 11852.0, loss:0.19469903\n",
      "step: 11853.0, loss:0.18964342\n",
      "step: 11854.0, loss:0.22963935\n",
      "step: 11855.0, loss:0.19883318\n",
      "step: 11856.0, loss:0.26709705\n",
      "step: 11857.0, loss:0.13376185\n",
      "step: 11858.0, loss:0.19227398\n",
      "step: 11859.0, loss:0.19138879\n",
      "step: 11860.0, loss:0.22366915\n",
      "step: 11861.0, loss:0.29453751\n",
      "step: 11862.0, loss:0.21548221\n",
      "step: 11863.0, loss:0.32873327\n",
      "step: 11864.0, loss:0.17027363\n",
      "step: 11865.0, loss:0.26518268\n",
      "step: 11866.0, loss:0.25984214\n",
      "step: 11867.0, loss:0.24452973\n",
      "step: 11868.0, loss:0.09575370\n",
      "step: 11869.0, loss:0.33953072\n",
      "step: 11870.0, loss:0.11490740\n",
      "step: 11871.0, loss:0.18747790\n",
      "step: 11872.0, loss:0.19272064\n",
      "step: 11873.0, loss:0.16576312\n",
      "step: 11874.0, loss:0.24096637\n",
      "step: 11875.0, loss:0.25545198\n",
      "step: 11876.0, loss:0.12171164\n",
      "step: 11877.0, loss:0.13567483\n",
      "step: 11878.0, loss:0.21265278\n",
      "step: 11879.0, loss:0.24865817\n",
      "step: 11880.0, loss:0.23019822\n",
      "step: 11881.0, loss:0.24110842\n",
      "step: 11882.0, loss:0.21610597\n",
      "step: 11883.0, loss:0.29098779\n",
      "step: 11884.0, loss:0.24112138\n",
      "step: 11885.0, loss:0.21226643\n",
      "step: 11886.0, loss:0.25439148\n",
      "step: 11887.0, loss:0.33972420\n",
      "step: 11888.0, loss:0.37573529\n",
      "step: 11889.0, loss:0.20354161\n",
      "step: 11890.0, loss:0.17741624\n",
      "step: 11891.0, loss:0.30743300\n",
      "step: 11892.0, loss:0.15047645\n",
      "step: 11893.0, loss:0.17763723\n",
      "step: 11894.0, loss:0.09934926\n",
      "step: 11895.0, loss:0.23661570\n",
      "step: 11896.0, loss:0.20007135\n",
      "step: 11897.0, loss:0.34570022\n",
      "step: 11898.0, loss:0.25949747\n",
      "step: 11899.0, loss:0.15713410\n",
      "step: 11900.0, loss:0.21631558\n",
      "step: 11901.0, loss:0.15322864\n",
      "step: 11902.0, loss:0.19447479\n",
      "step: 11903.0, loss:0.12408250\n",
      "step: 11904.0, loss:0.25087755\n",
      "step: 11905.0, loss:0.22659196\n",
      "step: 11906.0, loss:0.11923583\n",
      "step: 11907.0, loss:0.15990203\n",
      "step: 11908.0, loss:0.17994292\n",
      "step: 11909.0, loss:0.11913072\n",
      "step: 11910.0, loss:0.19731075\n",
      "step: 11911.0, loss:0.20800779\n",
      "step: 11912.0, loss:0.27300580\n",
      "step: 11913.0, loss:0.16889404\n",
      "step: 11914.0, loss:0.15970486\n",
      "step: 11915.0, loss:0.34351698\n",
      "step: 11916.0, loss:0.24138734\n",
      "step: 11917.0, loss:0.21778266\n",
      "step: 11918.0, loss:0.24939719\n",
      "step: 11919.0, loss:0.23290802\n",
      "step: 11920.0, loss:0.30053094\n",
      "step: 11921.0, loss:0.41890977\n",
      "step: 11922.0, loss:0.12721319\n",
      "step: 11923.0, loss:0.17228874\n",
      "step: 11924.0, loss:0.27086251\n",
      "step: 11925.0, loss:0.22732096\n",
      "step: 11926.0, loss:0.27066949\n",
      "step: 11927.0, loss:0.17128999\n",
      "step: 11928.0, loss:0.25276427\n",
      "step: 11929.0, loss:0.21015390\n",
      "step: 11930.0, loss:0.32378425\n",
      "step: 11931.0, loss:0.20286005\n",
      "step: 11932.0, loss:0.17091327\n",
      "step: 11933.0, loss:0.21821429\n",
      "step: 11934.0, loss:0.28986782\n",
      "step: 11935.0, loss:0.12103604\n",
      "step: 11936.0, loss:0.18628920\n",
      "step: 11937.0, loss:0.31199948\n",
      "step: 11938.0, loss:0.25960070\n",
      "step: 11939.0, loss:0.25154403\n",
      "step: 11940.0, loss:0.30656577\n",
      "step: 11941.0, loss:0.23173952\n",
      "step: 11942.0, loss:0.14361746\n",
      "step: 11943.0, loss:0.16160715\n",
      "step: 11944.0, loss:0.31747213\n",
      "step: 11945.0, loss:0.27850351\n",
      "step: 11946.0, loss:0.18366793\n",
      "step: 11947.0, loss:0.14006545\n",
      "step: 11948.0, loss:0.17193147\n",
      "step: 11949.0, loss:0.19506249\n",
      "step: 11950.0, loss:0.20791744\n",
      "step: 11951.0, loss:0.26890912\n",
      "step: 11952.0, loss:0.29434501\n",
      "step: 11953.0, loss:0.25597633\n",
      "step: 11954.0, loss:0.24590806\n",
      "step: 11955.0, loss:0.30345746\n",
      "step: 11956.0, loss:0.19582088\n",
      "step: 11957.0, loss:0.31834824\n",
      "step: 11958.0, loss:0.20568379\n",
      "step: 11959.0, loss:0.21665920\n",
      "step: 11960.0, loss:0.18349644\n",
      "step: 11961.0, loss:0.21676377\n",
      "step: 11962.0, loss:0.17541727\n",
      "step: 11963.0, loss:0.20768178\n",
      "step: 11964.0, loss:0.19066938\n",
      "step: 11965.0, loss:0.32395753\n",
      "step: 11966.0, loss:0.25146578\n",
      "step: 11967.0, loss:0.21376271\n",
      "step: 11968.0, loss:0.18098463\n",
      "step: 11969.0, loss:0.22145610\n",
      "step: 11970.0, loss:0.19639394\n",
      "step: 11971.0, loss:0.21977901\n",
      "step: 11972.0, loss:0.22264212\n",
      "step: 11973.0, loss:0.14560201\n",
      "step: 11974.0, loss:0.29119075\n",
      "step: 11975.0, loss:0.24464365\n",
      "step: 11976.0, loss:0.19752161\n",
      "step: 11977.0, loss:0.19286455\n",
      "step: 11978.0, loss:0.33568572\n",
      "step: 11979.0, loss:0.19980174\n",
      "step: 11980.0, loss:0.29018604\n",
      "step: 11981.0, loss:0.17017706\n",
      "step: 11982.0, loss:0.16922990\n",
      "step: 11983.0, loss:0.23053184\n",
      "step: 11984.0, loss:0.20486319\n",
      "step: 11985.0, loss:0.17897337\n",
      "step: 11986.0, loss:0.19524052\n",
      "step: 11987.0, loss:0.18487182\n",
      "step: 11988.0, loss:0.23275328\n",
      "step: 11989.0, loss:0.20755398\n",
      "step: 11990.0, loss:0.30793574\n",
      "step: 11991.0, loss:0.33586226\n",
      "step: 11992.0, loss:0.21561104\n",
      "step: 11993.0, loss:0.17746646\n",
      "step: 11994.0, loss:0.41044377\n",
      "step: 11995.0, loss:0.31706140\n",
      "step: 11996.0, loss:0.18210985\n",
      "step: 11997.0, loss:0.24771838\n",
      "step: 11998.0, loss:0.25886263\n",
      "step: 11999.0, loss:0.24262105\n",
      "step: 12000.0, loss:0.22768514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1264/1264 [09:26<00:00,  2.23it/s] \n",
      "2023-04-03 01:50:22,470 - INFO - step:12000.0, matthews_corr:0.773976, Acc:89.119466%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 12001.0, loss:0.22975279\n",
      "step: 12002.0, loss:0.15397328\n",
      "step: 12003.0, loss:0.32940986\n",
      "step: 12004.0, loss:0.33910067\n",
      "step: 12005.0, loss:0.30118101\n",
      "step: 12006.0, loss:0.33116725\n",
      "step: 12007.0, loss:0.25224368\n",
      "step: 12008.0, loss:0.18392829\n",
      "step: 12009.0, loss:0.14081231\n",
      "step: 12010.0, loss:0.27141323\n",
      "step: 12011.0, loss:0.21568022\n",
      "step: 12012.0, loss:0.19764407\n",
      "step: 12013.0, loss:0.15766938\n",
      "step: 12014.0, loss:0.24385040\n",
      "step: 12015.0, loss:0.20817600\n",
      "step: 12016.0, loss:0.17744465\n",
      "step: 12017.0, loss:0.20847663\n",
      "step: 12018.0, loss:0.25529781\n",
      "step: 12019.0, loss:0.28788659\n",
      "step: 12020.0, loss:0.16366905\n",
      "step: 12021.0, loss:0.24233575\n",
      "step: 12022.0, loss:0.16444914\n",
      "step: 12023.0, loss:0.22288005\n",
      "step: 12024.0, loss:0.32855510\n",
      "step: 12025.0, loss:0.19454949\n",
      "step: 12026.0, loss:0.15382124\n",
      "step: 12027.0, loss:0.21941097\n",
      "step: 12028.0, loss:0.32302486\n",
      "step: 12029.0, loss:0.29650952\n",
      "step: 12030.0, loss:0.24087091\n",
      "step: 12031.0, loss:0.34472664\n",
      "step: 12032.0, loss:0.23840178\n",
      "step: 12033.0, loss:0.29657338\n",
      "step: 12034.0, loss:0.24428182\n",
      "step: 12035.0, loss:0.26886533\n",
      "step: 12036.0, loss:0.27701861\n",
      "step: 12037.0, loss:0.18377981\n",
      "step: 12038.0, loss:0.23679432\n",
      "step: 12039.0, loss:0.23896651\n",
      "step: 12040.0, loss:0.20321075\n",
      "step: 12041.0, loss:0.29019620\n",
      "step: 12042.0, loss:0.21774420\n",
      "step: 12043.0, loss:0.23541187\n",
      "step: 12044.0, loss:0.25244338\n",
      "step: 12045.0, loss:0.18225955\n",
      "step: 12046.0, loss:0.23531866\n",
      "step: 12047.0, loss:0.19051844\n",
      "step: 12048.0, loss:0.34764711\n",
      "step: 12049.0, loss:0.23339317\n",
      "step: 12050.0, loss:0.28709127\n",
      "step: 12051.0, loss:0.21925569\n",
      "step: 12052.0, loss:0.25622970\n",
      "step: 12053.0, loss:0.20731282\n",
      "step: 12054.0, loss:0.20615027\n",
      "step: 12055.0, loss:0.23666531\n",
      "step: 12056.0, loss:0.18088012\n",
      "step: 12057.0, loss:0.29563120\n",
      "step: 12058.0, loss:0.28275750\n",
      "step: 12059.0, loss:0.15092967\n",
      "step: 12060.0, loss:0.28628775\n",
      "step: 12061.0, loss:0.20985276\n",
      "step: 12062.0, loss:0.22818223\n",
      "step: 12063.0, loss:0.21399682\n",
      "step: 12064.0, loss:0.15825595\n",
      "step: 12065.0, loss:0.21234449\n",
      "step: 12066.0, loss:0.22883871\n",
      "step: 12067.0, loss:0.12490898\n",
      "step: 12068.0, loss:0.32623227\n",
      "step: 12069.0, loss:0.35045618\n",
      "step: 12070.0, loss:0.26147336\n",
      "step: 12071.0, loss:0.24124258\n",
      "step: 12072.0, loss:0.23895951\n",
      "step: 12073.0, loss:0.15025038\n",
      "step: 12074.0, loss:0.18799553\n",
      "step: 12075.0, loss:0.27951252\n",
      "step: 12076.0, loss:0.10961671\n",
      "step: 12077.0, loss:0.28865902\n",
      "step: 12078.0, loss:0.17017906\n",
      "step: 12079.0, loss:0.11150727\n",
      "step: 12080.0, loss:0.21018056\n",
      "step: 12081.0, loss:0.14633785\n",
      "step: 12082.0, loss:0.18037828\n",
      "step: 12083.0, loss:0.17020014\n",
      "step: 12084.0, loss:0.20901124\n",
      "step: 12085.0, loss:0.22533182\n",
      "step: 12086.0, loss:0.17181948\n",
      "step: 12087.0, loss:0.28097754\n",
      "step: 12088.0, loss:0.27288881\n",
      "step: 12089.0, loss:0.22438851\n",
      "step: 12090.0, loss:0.14063093\n",
      "step: 12091.0, loss:0.23298006\n",
      "step: 12092.0, loss:0.20852777\n",
      "step: 12093.0, loss:0.17262242\n",
      "step: 12094.0, loss:0.17475931\n",
      "step: 12095.0, loss:0.25846503\n",
      "step: 12096.0, loss:0.21302435\n",
      "step: 12097.0, loss:0.18905797\n",
      "step: 12098.0, loss:0.23038414\n",
      "step: 12099.0, loss:0.20501693\n",
      "step: 12100.0, loss:0.26638957\n",
      "step: 12101.0, loss:0.19004105\n",
      "step: 12102.0, loss:0.22941839\n",
      "step: 12103.0, loss:0.19367756\n",
      "step: 12104.0, loss:0.14679089\n",
      "step: 12105.0, loss:0.24623544\n",
      "step: 12106.0, loss:0.18649534\n",
      "step: 12107.0, loss:0.36615183\n",
      "step: 12108.0, loss:0.24766322\n",
      "step: 12109.0, loss:0.23843918\n",
      "step: 12110.0, loss:0.21382531\n",
      "step: 12111.0, loss:0.28398209\n",
      "step: 12112.0, loss:0.35963656\n",
      "step: 12113.0, loss:0.15257771\n",
      "step: 12114.0, loss:0.15312013\n",
      "step: 12115.0, loss:0.14708679\n",
      "step: 12116.0, loss:0.15326085\n",
      "step: 12117.0, loss:0.21157772\n",
      "step: 12118.0, loss:0.28721911\n",
      "step: 12119.0, loss:0.23775103\n",
      "step: 12120.0, loss:0.15999542\n",
      "step: 12121.0, loss:0.28101154\n",
      "step: 12122.0, loss:0.18164597\n",
      "step: 12123.0, loss:0.16507979\n",
      "step: 12124.0, loss:0.08069440\n",
      "step: 12125.0, loss:0.15464313\n",
      "step: 12126.0, loss:0.18972620\n",
      "step: 12127.0, loss:0.26203661\n",
      "step: 12128.0, loss:0.24261037\n",
      "step: 12129.0, loss:0.27434591\n",
      "step: 12130.0, loss:0.16089650\n",
      "step: 12131.0, loss:0.24277966\n",
      "step: 12132.0, loss:0.20309646\n",
      "step: 12133.0, loss:0.19435631\n",
      "step: 12134.0, loss:0.17934561\n",
      "step: 12135.0, loss:0.06008123\n",
      "step: 12136.0, loss:0.25208065\n",
      "step: 12137.0, loss:0.14761703\n",
      "step: 12138.0, loss:0.29571741\n",
      "step: 12139.0, loss:0.21331520\n",
      "step: 12140.0, loss:0.10575387\n",
      "step: 12141.0, loss:0.11541870\n",
      "step: 12142.0, loss:0.26663335\n",
      "step: 12143.0, loss:0.16050169\n",
      "step: 12144.0, loss:0.25249906\n",
      "step: 12145.0, loss:0.22110394\n",
      "step: 12146.0, loss:0.29274725\n",
      "step: 12147.0, loss:0.33645247\n",
      "step: 12148.0, loss:0.20695060\n",
      "step: 12149.0, loss:0.12111851\n",
      "step: 12150.0, loss:0.14181351\n",
      "step: 12151.0, loss:0.24989402\n",
      "step: 12152.0, loss:0.27180767\n",
      "step: 12153.0, loss:0.15709985\n",
      "step: 12154.0, loss:0.24335969\n",
      "step: 12155.0, loss:0.26401972\n",
      "step: 12156.0, loss:0.20723851\n",
      "step: 12157.0, loss:0.25705617\n",
      "step: 12158.0, loss:0.33540063\n",
      "step: 12159.0, loss:0.28538775\n",
      "step: 12160.0, loss:0.21025118\n",
      "step: 12161.0, loss:0.16615244\n",
      "step: 12162.0, loss:0.18664028\n",
      "step: 12163.0, loss:0.24740405\n",
      "step: 12164.0, loss:0.13944830\n",
      "step: 12165.0, loss:0.23625449\n",
      "step: 12166.0, loss:0.19939821\n",
      "step: 12167.0, loss:0.20753562\n",
      "step: 12168.0, loss:0.17128274\n",
      "step: 12169.0, loss:0.36146740\n",
      "step: 12170.0, loss:0.22144934\n",
      "step: 12171.0, loss:0.33240851\n",
      "step: 12172.0, loss:0.20068750\n",
      "step: 12173.0, loss:0.31815695\n",
      "step: 12174.0, loss:0.15105574\n",
      "step: 12175.0, loss:0.28036886\n",
      "step: 12176.0, loss:0.32630460\n",
      "step: 12177.0, loss:0.18205801\n",
      "step: 12178.0, loss:0.20531864\n",
      "step: 12179.0, loss:0.18524117\n",
      "step: 12180.0, loss:0.20060547\n",
      "step: 12181.0, loss:0.19750040\n",
      "step: 12182.0, loss:0.17621263\n",
      "step: 12183.0, loss:0.25284799\n",
      "step: 12184.0, loss:0.18837915\n",
      "step: 12185.0, loss:0.26713150\n",
      "step: 12186.0, loss:0.29489975\n",
      "step: 12187.0, loss:0.11605411\n",
      "step: 12188.0, loss:0.14225391\n",
      "step: 12189.0, loss:0.38025459\n",
      "step: 12190.0, loss:0.26602936\n",
      "step: 12191.0, loss:0.20179841\n",
      "step: 12192.0, loss:0.19387471\n",
      "step: 12193.0, loss:0.19597824\n",
      "step: 12194.0, loss:0.12595933\n",
      "step: 12195.0, loss:0.21527760\n",
      "step: 12196.0, loss:0.17509311\n",
      "step: 12197.0, loss:0.28763969\n",
      "step: 12198.0, loss:0.13172084\n",
      "step: 12199.0, loss:0.13828941\n",
      "step: 12200.0, loss:0.19876073\n",
      "step: 12201.0, loss:0.19343929\n",
      "step: 12202.0, loss:0.28916551\n",
      "step: 12203.0, loss:0.19502912\n",
      "step: 12204.0, loss:0.17330165\n",
      "step: 12205.0, loss:0.20386378\n",
      "step: 12206.0, loss:0.20626334\n",
      "step: 12207.0, loss:0.17740909\n",
      "step: 12208.0, loss:0.21403815\n",
      "step: 12209.0, loss:0.17302596\n",
      "step: 12210.0, loss:0.34331514\n",
      "step: 12211.0, loss:0.21790284\n",
      "step: 12212.0, loss:0.31358813\n",
      "step: 12213.0, loss:0.20026316\n",
      "step: 12214.0, loss:0.23444235\n",
      "step: 12215.0, loss:0.16637175\n",
      "step: 12216.0, loss:0.19394780\n",
      "step: 12217.0, loss:0.15314583\n",
      "step: 12218.0, loss:0.19900853\n",
      "step: 12219.0, loss:0.23111813\n",
      "step: 12220.0, loss:0.12655431\n",
      "step: 12221.0, loss:0.12193564\n",
      "step: 12222.0, loss:0.20071916\n",
      "step: 12223.0, loss:0.27496461\n",
      "step: 12224.0, loss:0.22054808\n",
      "step: 12225.0, loss:0.22513246\n",
      "step: 12226.0, loss:0.26745418\n",
      "step: 12227.0, loss:0.20512999\n",
      "step: 12228.0, loss:0.25947933\n",
      "step: 12229.0, loss:0.11617683\n",
      "step: 12230.0, loss:0.29499369\n",
      "step: 12231.0, loss:0.25329950\n",
      "step: 12232.0, loss:0.19611721\n",
      "step: 12233.0, loss:0.13747886\n",
      "step: 12234.0, loss:0.17853134\n",
      "step: 12235.0, loss:0.15677667\n",
      "step: 12236.0, loss:0.17715558\n",
      "step: 12237.0, loss:0.13862045\n",
      "step: 12238.0, loss:0.41804060\n",
      "step: 12239.0, loss:0.23885299\n",
      "step: 12240.0, loss:0.15888476\n",
      "step: 12241.0, loss:0.19396202\n",
      "step: 12242.0, loss:0.21622187\n",
      "step: 12243.0, loss:0.14119783\n",
      "step: 12244.0, loss:0.12538880\n",
      "step: 12245.0, loss:0.26442633\n",
      "step: 12246.0, loss:0.28761173\n",
      "step: 12247.0, loss:0.18354334\n",
      "step: 12248.0, loss:0.20110760\n",
      "step: 12249.0, loss:0.23890920\n",
      "step: 12250.0, loss:0.23711307\n",
      "step: 12251.0, loss:0.20388971\n",
      "step: 12252.0, loss:0.28449261\n",
      "step: 12253.0, loss:0.16475555\n",
      "step: 12254.0, loss:0.18227475\n",
      "step: 12255.0, loss:0.21485167\n",
      "step: 12256.0, loss:0.20472865\n",
      "step: 12257.0, loss:0.18008928\n",
      "step: 12258.0, loss:0.14290217\n",
      "step: 12259.0, loss:0.30310703\n",
      "step: 12260.0, loss:0.18761523\n",
      "step: 12261.0, loss:0.41127966\n",
      "step: 12262.0, loss:0.20813041\n",
      "step: 12263.0, loss:0.20048693\n",
      "step: 12264.0, loss:0.32816085\n",
      "step: 12265.0, loss:0.15986830\n",
      "step: 12266.0, loss:0.19062843\n",
      "step: 12267.0, loss:0.21870401\n",
      "step: 12268.0, loss:0.25255027\n",
      "step: 12269.0, loss:0.19064532\n",
      "step: 12270.0, loss:0.15653091\n",
      "step: 12271.0, loss:0.18900083\n",
      "step: 12272.0, loss:0.19797679\n",
      "step: 12273.0, loss:0.20696607\n",
      "step: 12274.0, loss:0.21361118\n",
      "step: 12275.0, loss:0.42374352\n",
      "step: 12276.0, loss:0.20609491\n",
      "step: 12277.0, loss:0.12793567\n",
      "step: 12278.0, loss:0.23141579\n",
      "step: 12279.0, loss:0.24044873\n",
      "step: 12280.0, loss:0.17530749\n",
      "step: 12281.0, loss:0.11123015\n",
      "step: 12282.0, loss:0.18610543\n",
      "step: 12283.0, loss:0.32602777\n",
      "step: 12284.0, loss:0.18006272\n",
      "step: 12285.0, loss:0.17521560\n",
      "step: 12286.0, loss:0.16825712\n",
      "step: 12287.0, loss:0.08410376\n",
      "step: 12288.0, loss:0.15222222\n",
      "step: 12289.0, loss:0.37697535\n",
      "step: 12290.0, loss:0.23504972\n",
      "step: 12291.0, loss:0.21231395\n",
      "step: 12292.0, loss:0.14553545\n",
      "step: 12293.0, loss:0.21172532\n",
      "step: 12294.0, loss:0.13903354\n",
      "step: 12295.0, loss:0.18662117\n",
      "step: 12296.0, loss:0.21998330\n",
      "step: 12297.0, loss:0.24929344\n",
      "step: 12298.0, loss:0.13685345\n",
      "step: 12299.0, loss:0.22171712\n",
      "step: 12300.0, loss:0.09291641\n",
      "step: 12301.0, loss:0.17715876\n",
      "step: 12302.0, loss:0.13495525\n",
      "step: 12303.0, loss:0.23230227\n",
      "step: 12304.0, loss:0.13352590\n",
      "step: 12305.0, loss:0.19610354\n",
      "step: 12306.0, loss:0.16651103\n",
      "step: 12307.0, loss:0.19079983\n",
      "step: 12308.0, loss:0.16290573\n",
      "step: 12309.0, loss:0.18844565\n",
      "step: 12310.0, loss:0.13220136\n",
      "step: 12311.0, loss:0.24150274\n",
      "step: 12312.0, loss:0.20124327\n",
      "step: 12313.0, loss:0.15740978\n",
      "step: 12314.0, loss:0.21778146\n",
      "step: 12315.0, loss:0.22044695\n",
      "step: 12316.0, loss:0.18737575\n",
      "step: 12317.0, loss:0.22773686\n",
      "step: 12318.0, loss:0.29001032\n",
      "step: 12319.0, loss:0.33748590\n",
      "step: 12320.0, loss:0.17927933\n",
      "step: 12321.0, loss:0.18493547\n",
      "step: 12322.0, loss:0.18405897\n",
      "step: 12323.0, loss:0.11030257\n",
      "step: 12324.0, loss:0.12984552\n",
      "step: 12325.0, loss:0.11543264\n",
      "step: 12326.0, loss:0.28216054\n",
      "step: 12327.0, loss:0.31793300\n",
      "step: 12328.0, loss:0.23061259\n",
      "step: 12329.0, loss:0.20463336\n",
      "step: 12330.0, loss:0.27421432\n",
      "step: 12331.0, loss:0.18721178\n",
      "step: 12332.0, loss:0.17468292\n",
      "step: 12333.0, loss:0.28360715\n",
      "step: 12334.0, loss:0.25438558\n",
      "step: 12335.0, loss:0.22180750\n",
      "step: 12336.0, loss:0.17158195\n",
      "step: 12337.0, loss:0.27033420\n",
      "step: 12338.0, loss:0.20900065\n",
      "step: 12339.0, loss:0.14608021\n",
      "step: 12340.0, loss:0.21896716\n",
      "step: 12341.0, loss:0.18869595\n",
      "step: 12342.0, loss:0.22317016\n",
      "step: 12343.0, loss:0.19375954\n",
      "step: 12344.0, loss:0.31745695\n",
      "step: 12345.0, loss:0.24740009\n",
      "step: 12346.0, loss:0.14250195\n",
      "step: 12347.0, loss:0.11855512\n",
      "step: 12348.0, loss:0.19407580\n",
      "step: 12349.0, loss:0.24134248\n",
      "step: 12350.0, loss:0.15356018\n",
      "step: 12351.0, loss:0.14827681\n",
      "step: 12352.0, loss:0.19339708\n",
      "step: 12353.0, loss:0.15772994\n",
      "step: 12354.0, loss:0.16010071\n",
      "step: 12355.0, loss:0.17520083\n",
      "step: 12356.0, loss:0.18025444\n",
      "step: 12357.0, loss:0.22542837\n",
      "step: 12358.0, loss:0.20656470\n",
      "step: 12359.0, loss:0.22281093\n",
      "step: 12360.0, loss:0.28983557\n",
      "step: 12361.0, loss:0.10177106\n",
      "step: 12362.0, loss:0.20670474\n",
      "step: 12363.0, loss:0.24604845\n",
      "step: 12364.0, loss:0.11493564\n",
      "step: 12365.0, loss:0.17209108\n",
      "step: 12366.0, loss:0.28722020\n",
      "step: 12367.0, loss:0.26675892\n",
      "step: 12368.0, loss:0.24849414\n",
      "step: 12369.0, loss:0.25894543\n",
      "step: 12370.0, loss:0.11097861\n",
      "step: 12371.0, loss:0.23653102\n",
      "step: 12372.0, loss:0.20182316\n",
      "step: 12373.0, loss:0.14462802\n",
      "step: 12374.0, loss:0.15993704\n",
      "step: 12375.0, loss:0.29383945\n",
      "step: 12376.0, loss:0.13286355\n",
      "step: 12377.0, loss:0.11298995\n",
      "step: 12378.0, loss:0.09610349\n",
      "step: 12379.0, loss:0.14746910\n",
      "step: 12380.0, loss:0.23651927\n",
      "step: 12381.0, loss:0.38594138\n",
      "step: 12382.0, loss:0.36428909\n",
      "step: 12383.0, loss:0.19653627\n",
      "step: 12384.0, loss:0.22750712\n",
      "step: 12385.0, loss:0.21680368\n",
      "step: 12386.0, loss:0.25556996\n",
      "step: 12387.0, loss:0.25349500\n",
      "step: 12388.0, loss:0.30980447\n",
      "step: 12389.0, loss:0.17356252\n",
      "step: 12390.0, loss:0.15347957\n",
      "step: 12391.0, loss:0.21922642\n",
      "step: 12392.0, loss:0.14426442\n",
      "step: 12393.0, loss:0.21864040\n",
      "step: 12394.0, loss:0.20315235\n",
      "step: 12395.0, loss:0.15877289\n",
      "step: 12396.0, loss:0.18525439\n",
      "step: 12397.0, loss:0.18320474\n",
      "step: 12398.0, loss:0.19242815\n",
      "step: 12399.0, loss:0.19703943\n",
      "step: 12400.0, loss:0.24651816\n",
      "step: 12401.0, loss:0.12892310\n",
      "step: 12402.0, loss:0.15386066\n",
      "step: 12403.0, loss:0.17890447\n",
      "step: 12404.0, loss:0.21899024\n",
      "step: 12405.0, loss:0.15417328\n",
      "step: 12406.0, loss:0.16093204\n",
      "step: 12407.0, loss:0.22923967\n",
      "step: 12408.0, loss:0.22716018\n",
      "step: 12409.0, loss:0.16313934\n",
      "step: 12410.0, loss:0.24203687\n",
      "step: 12411.0, loss:0.18139041\n",
      "step: 12412.0, loss:0.23188531\n",
      "step: 12413.0, loss:0.19261832\n",
      "step: 12414.0, loss:0.20799609\n",
      "step: 12415.0, loss:0.14337029\n",
      "step: 12416.0, loss:0.17224800\n",
      "step: 12417.0, loss:0.20872304\n",
      "step: 12418.0, loss:0.15192367\n",
      "step: 12419.0, loss:0.31357194\n",
      "step: 12420.0, loss:0.16704764\n",
      "step: 12421.0, loss:0.08791505\n",
      "step: 12422.0, loss:0.21513377\n",
      "step: 12423.0, loss:0.23462954\n",
      "step: 12424.0, loss:0.31030169\n",
      "step: 12425.0, loss:0.22506951\n",
      "step: 12426.0, loss:0.15300839\n",
      "step: 12427.0, loss:0.30266304\n",
      "step: 12428.0, loss:0.22643284\n",
      "step: 12429.0, loss:0.13486744\n",
      "step: 12430.0, loss:0.23881339\n",
      "step: 12431.0, loss:0.11668313\n",
      "step: 12432.0, loss:0.14943261\n",
      "step: 12433.0, loss:0.13696744\n",
      "step: 12434.0, loss:0.16139930\n",
      "step: 12435.0, loss:0.23983352\n",
      "step: 12436.0, loss:0.12135846\n",
      "step: 12437.0, loss:0.20630838\n",
      "step: 12438.0, loss:0.21580433\n",
      "step: 12439.0, loss:0.23864955\n",
      "step: 12440.0, loss:0.18814724\n",
      "step: 12441.0, loss:0.22552442\n",
      "step: 12442.0, loss:0.29611137\n",
      "step: 12443.0, loss:0.13086816\n",
      "step: 12444.0, loss:0.18563500\n",
      "step: 12445.0, loss:0.16712559\n",
      "step: 12446.0, loss:0.17409591\n",
      "step: 12447.0, loss:0.16799909\n",
      "step: 12448.0, loss:0.44254256\n",
      "step: 12449.0, loss:0.19206492\n",
      "step: 12450.0, loss:0.19605700\n",
      "step: 12451.0, loss:0.23573603\n",
      "step: 12452.0, loss:0.18801197\n",
      "step: 12453.0, loss:0.24960046\n",
      "step: 12454.0, loss:0.24221732\n",
      "step: 12455.0, loss:0.16426028\n",
      "step: 12456.0, loss:0.35910816\n",
      "step: 12457.0, loss:0.17695119\n",
      "step: 12458.0, loss:0.09874539\n",
      "step: 12459.0, loss:0.17477867\n",
      "step: 12460.0, loss:0.16980120\n",
      "step: 12461.0, loss:0.22154344\n",
      "step: 12462.0, loss:0.16090634\n",
      "step: 12463.0, loss:0.19131477\n",
      "step: 12464.0, loss:0.17737288\n",
      "step: 12465.0, loss:0.36178102\n",
      "step: 12466.0, loss:0.40767909\n",
      "step: 12467.0, loss:0.13715314\n",
      "step: 12468.0, loss:0.21728322\n",
      "step: 12469.0, loss:0.18297693\n",
      "step: 12470.0, loss:0.13822323\n",
      "step: 12471.0, loss:0.14095316\n",
      "step: 12472.0, loss:0.17130082\n",
      "step: 12473.0, loss:0.24124911\n",
      "step: 12474.0, loss:0.09220731\n",
      "step: 12475.0, loss:0.16106906\n",
      "step: 12476.0, loss:0.22092981\n",
      "step: 12477.0, loss:0.27892509\n",
      "step: 12478.0, loss:0.22456084\n",
      "step: 12479.0, loss:0.17214895\n",
      "step: 12480.0, loss:0.23980369\n",
      "step: 12481.0, loss:0.26173421\n",
      "step: 12482.0, loss:0.11401017\n",
      "step: 12483.0, loss:0.17441840\n",
      "step: 12484.0, loss:0.21919551\n",
      "step: 12485.0, loss:0.36244353\n",
      "step: 12486.0, loss:0.25156868\n",
      "step: 12487.0, loss:0.17304271\n",
      "step: 12488.0, loss:0.32554798\n",
      "step: 12489.0, loss:0.15145326\n",
      "step: 12490.0, loss:0.20629914\n",
      "step: 12491.0, loss:0.30562960\n",
      "step: 12492.0, loss:0.22258555\n",
      "step: 12493.0, loss:0.17322036\n",
      "step: 12494.0, loss:0.27809909\n",
      "step: 12495.0, loss:0.22988866\n",
      "step: 12496.0, loss:0.28032061\n",
      "step: 12497.0, loss:0.19744233\n",
      "step: 12498.0, loss:0.18186595\n",
      "step: 12499.0, loss:0.20853045\n",
      "step: 12500.0, loss:0.26995100\n",
      "step: 12501.0, loss:0.39363771\n",
      "step: 12502.0, loss:0.13843035\n",
      "step: 12503.0, loss:0.17198012\n",
      "step: 12504.0, loss:0.11801880\n",
      "step: 12505.0, loss:0.06575409\n",
      "step: 12506.0, loss:0.21873651\n",
      "step: 12507.0, loss:0.24818069\n",
      "step: 12508.0, loss:0.20263159\n",
      "step: 12509.0, loss:0.25720117\n",
      "step: 12510.0, loss:0.21442279\n",
      "step: 12511.0, loss:0.15022529\n",
      "step: 12512.0, loss:0.21634515\n",
      "step: 12513.0, loss:0.20293175\n",
      "step: 12514.0, loss:0.18625721\n",
      "step: 12515.0, loss:0.26428561\n",
      "step: 12516.0, loss:0.25377368\n",
      "step: 12517.0, loss:0.22452284\n",
      "step: 12518.0, loss:0.15972502\n",
      "step: 12519.0, loss:0.18455273\n",
      "step: 12520.0, loss:0.25005865\n",
      "step: 12521.0, loss:0.18878999\n",
      "step: 12522.0, loss:0.16180293\n",
      "step: 12523.0, loss:0.20967389\n",
      "step: 12524.0, loss:0.17368297\n",
      "step: 12525.0, loss:0.42368861\n",
      "step: 12526.0, loss:0.15432269\n",
      "step: 12527.0, loss:0.16460444\n",
      "step: 12528.0, loss:0.17994671\n",
      "step: 12529.0, loss:0.36146293\n",
      "step: 12530.0, loss:0.10869281\n",
      "step: 12531.0, loss:0.23075644\n",
      "step: 12532.0, loss:0.21986792\n",
      "step: 12533.0, loss:0.32849096\n",
      "step: 12534.0, loss:0.16825573\n",
      "step: 12535.0, loss:0.17040116\n",
      "step: 12536.0, loss:0.28180578\n",
      "step: 12537.0, loss:0.12302449\n",
      "step: 12538.0, loss:0.30138209\n",
      "step: 12539.0, loss:0.08127822\n",
      "step: 12540.0, loss:0.29767930\n",
      "step: 12541.0, loss:0.26887456\n",
      "step: 12542.0, loss:0.17711319\n",
      "step: 12543.0, loss:0.20471648\n",
      "step: 12544.0, loss:0.16811060\n",
      "step: 12545.0, loss:0.12510995\n",
      "step: 12546.0, loss:0.40910954\n",
      "step: 12547.0, loss:0.28910068\n",
      "step: 12548.0, loss:0.27255608\n",
      "step: 12549.0, loss:0.19311005\n",
      "step: 12550.0, loss:0.28345475\n",
      "step: 12551.0, loss:0.14455850\n",
      "step: 12552.0, loss:0.24067910\n",
      "step: 12553.0, loss:0.16132081\n",
      "step: 12554.0, loss:0.23154278\n",
      "step: 12555.0, loss:0.17764862\n",
      "step: 12556.0, loss:0.22311403\n",
      "step: 12557.0, loss:0.27992774\n",
      "step: 12558.0, loss:0.15918784\n",
      "step: 12559.0, loss:0.14770509\n",
      "step: 12560.0, loss:0.15577596\n",
      "step: 12561.0, loss:0.21144509\n",
      "step: 12562.0, loss:0.14418184\n",
      "step: 12563.0, loss:0.23189389\n",
      "step: 12564.0, loss:0.15022046\n",
      "step: 12565.0, loss:0.16424457\n",
      "step: 12566.0, loss:0.16565773\n",
      "step: 12567.0, loss:0.09228271\n",
      "step: 12568.0, loss:0.24028567\n",
      "step: 12569.0, loss:0.24903893\n",
      "step: 12570.0, loss:0.16610189\n",
      "step: 12571.0, loss:0.16575880\n",
      "step: 12572.0, loss:0.21233351\n",
      "step: 12573.0, loss:0.24543612\n",
      "step: 12574.0, loss:0.22428403\n",
      "step: 12575.0, loss:0.18110328\n",
      "step: 12576.0, loss:0.21376884\n",
      "step: 12577.0, loss:0.21413742\n",
      "step: 12578.0, loss:0.23894973\n",
      "step: 12579.0, loss:0.17489147\n",
      "step: 12580.0, loss:0.19798293\n",
      "step: 12581.0, loss:0.31211178\n",
      "step: 12582.0, loss:0.21390276\n",
      "step: 12583.0, loss:0.23827185\n",
      "step: 12584.0, loss:0.16921167\n",
      "step: 12585.0, loss:0.26721821\n",
      "step: 12586.0, loss:0.22266963\n",
      "step: 12587.0, loss:0.23860186\n",
      "step: 12588.0, loss:0.40138065\n",
      "step: 12589.0, loss:0.20229618\n",
      "step: 12590.0, loss:0.17403029\n",
      "step: 12591.0, loss:0.21136435\n",
      "step: 12592.0, loss:0.25955683\n",
      "step: 12593.0, loss:0.14955011\n",
      "step: 12594.0, loss:0.17650114\n",
      "step: 12595.0, loss:0.15027924\n",
      "step: 12596.0, loss:0.17379688\n",
      "step: 12597.0, loss:0.13799603\n",
      "step: 12598.0, loss:0.18360521\n",
      "step: 12599.0, loss:0.15485744\n",
      "step: 12600.0, loss:0.16940763\n",
      "step: 12601.0, loss:0.18305192\n",
      "step: 12602.0, loss:0.13898620\n",
      "step: 12603.0, loss:0.19472308\n",
      "step: 12604.0, loss:0.17416957\n",
      "step: 12605.0, loss:0.23993563\n",
      "step: 12606.0, loss:0.13503345\n",
      "step: 12607.0, loss:0.21320180\n",
      "step: 12608.0, loss:0.16336543\n",
      "step: 12609.0, loss:0.10057436\n",
      "step: 12610.0, loss:0.17291987\n",
      "step: 12611.0, loss:0.13493095\n",
      "step: 12612.0, loss:0.21438200\n",
      "step: 12613.0, loss:0.16542360\n",
      "step: 12614.0, loss:0.14448556\n",
      "step: 12615.0, loss:0.26939249\n",
      "step: 12616.0, loss:0.22820181\n",
      "step: 12617.0, loss:0.23340977\n",
      "step: 12618.0, loss:0.25149169\n",
      "step: 12619.0, loss:0.23214077\n",
      "step: 12620.0, loss:0.18465093\n",
      "step: 12621.0, loss:0.13965903\n",
      "step: 12622.0, loss:0.14841808\n",
      "step: 12623.0, loss:0.20246137\n",
      "step: 12624.0, loss:0.18122418\n",
      "step: 12625.0, loss:0.24657127\n",
      "step: 12626.0, loss:0.10166309\n",
      "step: 12627.0, loss:0.11250648\n",
      "step: 12628.0, loss:0.16292110\n",
      "step: 12629.0, loss:0.15680922\n",
      "step: 12630.0, loss:0.09339632\n",
      "step: 12631.0, loss:0.11066115\n",
      "step: 12632.0, loss:0.15898503\n",
      "step: 12633.0, loss:0.19349479\n",
      "step: 12634.0, loss:0.13965775\n",
      "step: 12635.0, loss:0.21610876\n",
      "step: 12636.0, loss:0.15650496\n",
      "step: 12637.0, loss:0.21351288\n",
      "step: 12638.0, loss:0.19102931\n",
      "step: 12639.0, loss:0.25378978\n",
      "step: 12640.0, loss:0.29293092\n",
      "step: 12641.0, loss:0.25663693\n",
      "step: 12642.0, loss:0.11708736\n",
      "step: 12643.0, loss:0.29549995\n",
      "step: 12644.0, loss:0.19648210\n",
      "step: 12645.0, loss:0.10024645\n",
      "step: 12646.0, loss:0.29793487\n",
      "step: 12647.0, loss:0.17602567\n",
      "step: 12648.0, loss:0.30256174\n",
      "step: 12649.0, loss:0.29348215\n",
      "step: 12650.0, loss:0.37239266\n",
      "step: 12651.0, loss:0.27382918\n",
      "step: 12652.0, loss:0.13464449\n",
      "step: 12653.0, loss:0.13070847\n",
      "step: 12654.0, loss:0.10899636\n",
      "step: 12655.0, loss:0.22770393\n",
      "step: 12656.0, loss:0.22824387\n",
      "step: 12657.0, loss:0.28621324\n",
      "step: 12658.0, loss:0.30259473\n",
      "step: 12659.0, loss:0.16984320\n",
      "step: 12660.0, loss:0.21140401\n",
      "step: 12661.0, loss:0.23247940\n",
      "step: 12662.0, loss:0.32170780\n",
      "step: 12663.0, loss:0.13652550\n",
      "step: 12664.0, loss:0.34110639\n",
      "step: 12665.0, loss:0.23550784\n",
      "step: 12666.0, loss:0.14425659\n",
      "step: 12667.0, loss:0.20380359\n",
      "step: 12668.0, loss:0.16737663\n",
      "step: 12669.0, loss:0.28093196\n",
      "step: 12670.0, loss:0.19074982\n",
      "step: 12671.0, loss:0.14925220\n",
      "step: 12672.0, loss:0.15107928\n",
      "step: 12673.0, loss:0.23273157\n",
      "step: 12674.0, loss:0.23758190\n",
      "step: 12675.0, loss:0.26244186\n",
      "step: 12676.0, loss:0.15791388\n",
      "step: 12677.0, loss:0.24624924\n",
      "step: 12678.0, loss:0.21673074\n",
      "step: 12679.0, loss:0.17942137\n",
      "step: 12680.0, loss:0.22408322\n",
      "step: 12681.0, loss:0.19848569\n",
      "step: 12682.0, loss:0.16911652\n",
      "step: 12683.0, loss:0.09804759\n",
      "step: 12684.0, loss:0.14243992\n",
      "step: 12685.0, loss:0.24733961\n",
      "step: 12686.0, loss:0.35591238\n",
      "step: 12687.0, loss:0.16496975\n",
      "step: 12688.0, loss:0.25370409\n",
      "step: 12689.0, loss:0.24937653\n",
      "step: 12690.0, loss:0.30713322\n",
      "step: 12691.0, loss:0.30172521\n",
      "step: 12692.0, loss:0.23735091\n",
      "step: 12693.0, loss:0.36635762\n",
      "step: 12694.0, loss:0.21765497\n",
      "step: 12695.0, loss:0.31858251\n",
      "step: 12696.0, loss:0.27698376\n",
      "step: 12697.0, loss:0.21607275\n",
      "step: 12698.0, loss:0.17917710\n",
      "step: 12699.0, loss:0.37018131\n",
      "step: 12700.0, loss:0.18100838\n",
      "step: 12701.0, loss:0.22371217\n",
      "step: 12702.0, loss:0.25956558\n",
      "step: 12703.0, loss:0.20001996\n",
      "step: 12704.0, loss:0.19764501\n",
      "step: 12705.0, loss:0.19857820\n",
      "step: 12706.0, loss:0.25861155\n",
      "step: 12707.0, loss:0.14147488\n",
      "step: 12708.0, loss:0.27773679\n",
      "step: 12709.0, loss:0.26038520\n",
      "step: 12710.0, loss:0.32212287\n",
      "step: 12711.0, loss:0.13895966\n",
      "step: 12712.0, loss:0.11347546\n",
      "step: 12713.0, loss:0.34180902\n",
      "step: 12714.0, loss:0.22413341\n",
      "step: 12715.0, loss:0.28043272\n",
      "step: 12716.0, loss:0.15989293\n",
      "step: 12717.0, loss:0.24999276\n",
      "step: 12718.0, loss:0.22584764\n",
      "step: 12719.0, loss:0.21067313\n",
      "step: 12720.0, loss:0.21585774\n",
      "step: 12721.0, loss:0.16150418\n",
      "step: 12722.0, loss:0.14114283\n",
      "step: 12723.0, loss:0.19339921\n",
      "step: 12724.0, loss:0.22735597\n",
      "step: 12725.0, loss:0.10591587\n",
      "step: 12726.0, loss:0.16769088\n",
      "step: 12727.0, loss:0.27891064\n",
      "step: 12728.0, loss:0.19871386\n",
      "step: 12729.0, loss:0.19802441\n",
      "step: 12730.0, loss:0.17748800\n",
      "step: 12731.0, loss:0.07739670\n",
      "step: 12732.0, loss:0.16713514\n",
      "step: 12733.0, loss:0.20393313\n",
      "step: 12734.0, loss:0.14867194\n",
      "step: 12735.0, loss:0.20512906\n",
      "step: 12736.0, loss:0.21563600\n",
      "step: 12737.0, loss:0.20200522\n",
      "step: 12738.0, loss:0.15600137\n",
      "step: 12739.0, loss:0.21185858\n",
      "step: 12740.0, loss:0.21208028\n",
      "step: 12741.0, loss:0.24887914\n",
      "step: 12742.0, loss:0.18465586\n",
      "step: 12743.0, loss:0.17881075\n",
      "step: 12744.0, loss:0.20787312\n",
      "step: 12745.0, loss:0.52825354\n",
      "step: 12746.0, loss:0.26098315\n",
      "step: 12747.0, loss:0.15001583\n",
      "step: 12748.0, loss:0.33369513\n",
      "step: 12749.0, loss:0.13925341\n",
      "step: 12750.0, loss:0.21740643\n",
      "step: 12751.0, loss:0.32313262\n",
      "step: 12752.0, loss:0.23503617\n",
      "step: 12753.0, loss:0.18104507\n",
      "step: 12754.0, loss:0.22556881\n",
      "step: 12755.0, loss:0.13252759\n",
      "step: 12756.0, loss:0.17026242\n",
      "step: 12757.0, loss:0.18032344\n",
      "step: 12758.0, loss:0.23319555\n",
      "step: 12759.0, loss:0.24237113\n",
      "step: 12760.0, loss:0.19335184\n",
      "step: 12761.0, loss:0.30649455\n",
      "step: 12762.0, loss:0.23029018\n",
      "step: 12763.0, loss:0.34582886\n",
      "step: 12764.0, loss:0.23538421\n",
      "step: 12765.0, loss:0.21761449\n",
      "step: 12766.0, loss:0.19377335\n",
      "step: 12767.0, loss:0.21078077\n",
      "step: 12768.0, loss:0.11327155\n",
      "step: 12769.0, loss:0.31370769\n",
      "step: 12770.0, loss:0.21890014\n",
      "step: 12771.0, loss:0.42764250\n",
      "step: 12772.0, loss:0.18299391\n",
      "step: 12773.0, loss:0.18089400\n",
      "step: 12774.0, loss:0.25845964\n",
      "step: 12775.0, loss:0.16917845\n",
      "step: 12776.0, loss:0.17675206\n",
      "step: 12777.0, loss:0.19359775\n",
      "step: 12778.0, loss:0.12708557\n",
      "step: 12779.0, loss:0.25893702\n",
      "step: 12780.0, loss:0.40944542\n",
      "step: 12781.0, loss:0.21822614\n",
      "step: 12782.0, loss:0.23600443\n",
      "step: 12783.0, loss:0.21377954\n",
      "step: 12784.0, loss:0.18325832\n",
      "step: 12785.0, loss:0.20271894\n",
      "step: 12786.0, loss:0.24945734\n",
      "step: 12787.0, loss:0.30014309\n",
      "step: 12788.0, loss:0.21884987\n",
      "step: 12789.0, loss:0.18680036\n",
      "step: 12790.0, loss:0.20983788\n",
      "step: 12791.0, loss:0.21010762\n",
      "step: 12792.0, loss:0.20709760\n",
      "step: 12793.0, loss:0.27104822\n",
      "step: 12794.0, loss:0.26186880\n",
      "step: 12795.0, loss:0.17304268\n",
      "step: 12796.0, loss:0.21632354\n",
      "step: 12797.0, loss:0.18607070\n",
      "step: 12798.0, loss:0.32251137\n",
      "step: 12799.0, loss:0.28041217\n",
      "step: 12800.0, loss:0.15561604\n",
      "step: 12801.0, loss:0.22311971\n",
      "step: 12802.0, loss:0.14452383\n",
      "step: 12803.0, loss:0.18757458\n",
      "step: 12804.0, loss:0.28739979\n",
      "step: 12805.0, loss:0.19438441\n",
      "step: 12806.0, loss:0.15461922\n",
      "step: 12807.0, loss:0.14792670\n",
      "step: 12808.0, loss:0.12285772\n",
      "step: 12809.0, loss:0.22894071\n",
      "step: 12810.0, loss:0.27025903\n",
      "step: 12811.0, loss:0.14956590\n",
      "step: 12812.0, loss:0.12080975\n",
      "step: 12813.0, loss:0.17148485\n",
      "step: 12814.0, loss:0.18374150\n",
      "step: 12815.0, loss:0.18459896\n",
      "step: 12816.0, loss:0.26827589\n",
      "step: 12817.0, loss:0.13924576\n",
      "step: 12818.0, loss:0.21069197\n",
      "step: 12819.0, loss:0.18421020\n",
      "step: 12820.0, loss:0.20805188\n",
      "step: 12821.0, loss:0.17337773\n",
      "step: 12822.0, loss:0.26541490\n",
      "step: 12823.0, loss:0.30348158\n",
      "step: 12824.0, loss:0.19491446\n",
      "step: 12825.0, loss:0.18024407\n",
      "step: 12826.0, loss:0.21219298\n",
      "step: 12827.0, loss:0.36600877\n",
      "step: 12828.0, loss:0.20187671\n",
      "step: 12829.0, loss:0.20413859\n",
      "step: 12830.0, loss:0.29176571\n",
      "step: 12831.0, loss:0.30415296\n",
      "step: 12832.0, loss:0.13828291\n",
      "step: 12833.0, loss:0.16018544\n",
      "step: 12834.0, loss:0.19278744\n",
      "step: 12835.0, loss:0.32915702\n",
      "step: 12836.0, loss:0.26639567\n",
      "step: 12837.0, loss:0.14052738\n",
      "step: 12838.0, loss:0.14222694\n",
      "step: 12839.0, loss:0.23725839\n",
      "step: 12840.0, loss:0.14163142\n",
      "step: 12841.0, loss:0.20637123\n",
      "step: 12842.0, loss:0.23284676\n",
      "step: 12843.0, loss:0.16316224\n",
      "step: 12844.0, loss:0.18125934\n",
      "step: 12845.0, loss:0.20245128\n",
      "step: 12846.0, loss:0.16474282\n",
      "step: 12847.0, loss:0.28388638\n",
      "step: 12848.0, loss:0.15309584\n",
      "step: 12849.0, loss:0.20081026\n",
      "step: 12850.0, loss:0.14588593\n",
      "step: 12851.0, loss:0.23128423\n",
      "step: 12852.0, loss:0.15228785\n",
      "step: 12853.0, loss:0.23991057\n",
      "step: 12854.0, loss:0.22785595\n",
      "step: 12855.0, loss:0.08098430\n",
      "step: 12856.0, loss:0.23210688\n",
      "step: 12857.0, loss:0.08371950\n",
      "step: 12858.0, loss:0.13290149\n",
      "step: 12859.0, loss:0.13153135\n",
      "step: 12860.0, loss:0.23822740\n",
      "step: 12861.0, loss:0.13998113\n",
      "step: 12862.0, loss:0.21933348\n",
      "step: 12863.0, loss:0.29924886\n",
      "step: 12864.0, loss:0.10726048\n",
      "step: 12865.0, loss:0.23721544\n",
      "step: 12866.0, loss:0.24082037\n",
      "step: 12867.0, loss:0.21250722\n",
      "step: 12868.0, loss:0.32016290\n",
      "step: 12869.0, loss:0.19381615\n",
      "step: 12870.0, loss:0.23208965\n",
      "step: 12871.0, loss:0.26990519\n",
      "step: 12872.0, loss:0.10956392\n",
      "step: 12873.0, loss:0.21907409\n",
      "step: 12874.0, loss:0.21667300\n",
      "step: 12875.0, loss:0.24012346\n",
      "step: 12876.0, loss:0.30822366\n",
      "step: 12877.0, loss:0.20977659\n",
      "step: 12878.0, loss:0.33305287\n",
      "step: 12879.0, loss:0.28627004\n",
      "step: 12880.0, loss:0.22050519\n",
      "step: 12881.0, loss:0.22738251\n",
      "step: 12882.0, loss:0.32531393\n",
      "step: 12883.0, loss:0.20950696\n",
      "step: 12884.0, loss:0.11373782\n",
      "step: 12885.0, loss:0.38762964\n",
      "step: 12886.0, loss:0.14031630\n",
      "step: 12887.0, loss:0.34703724\n",
      "step: 12888.0, loss:0.23536750\n",
      "step: 12889.0, loss:0.18585170\n",
      "step: 12890.0, loss:0.22531849\n",
      "step: 12891.0, loss:0.18215596\n",
      "step: 12892.0, loss:0.29347670\n",
      "step: 12893.0, loss:0.15743918\n",
      "step: 12894.0, loss:0.33429327\n",
      "step: 12895.0, loss:0.22701781\n",
      "step: 12896.0, loss:0.21768266\n",
      "step: 12897.0, loss:0.26139104\n",
      "step: 12898.0, loss:0.24030376\n",
      "step: 12899.0, loss:0.33724986\n",
      "step: 12900.0, loss:0.31854869\n",
      "step: 12901.0, loss:0.28628742\n",
      "step: 12902.0, loss:0.30948322\n",
      "step: 12903.0, loss:0.27707104\n",
      "step: 12904.0, loss:0.19014459\n",
      "step: 12905.0, loss:0.12178693\n",
      "step: 12906.0, loss:0.29132685\n",
      "step: 12907.0, loss:0.14595409\n",
      "step: 12908.0, loss:0.16322837\n",
      "step: 12909.0, loss:0.32083861\n",
      "step: 12910.0, loss:0.20197527\n",
      "step: 12911.0, loss:0.20398022\n",
      "step: 12912.0, loss:0.19412029\n",
      "step: 12913.0, loss:0.27988961\n",
      "step: 12914.0, loss:0.19962542\n",
      "step: 12915.0, loss:0.11981367\n",
      "step: 12916.0, loss:0.21710589\n",
      "step: 12917.0, loss:0.17308249\n",
      "step: 12918.0, loss:0.29387499\n",
      "step: 12919.0, loss:0.21625483\n",
      "step: 12920.0, loss:0.24261801\n",
      "step: 12921.0, loss:0.27711118\n",
      "step: 12922.0, loss:0.24743379\n",
      "step: 12923.0, loss:0.11470728\n",
      "step: 12924.0, loss:0.18306855\n",
      "step: 12925.0, loss:0.24614774\n",
      "step: 12926.0, loss:0.25574931\n",
      "step: 12927.0, loss:0.23918825\n",
      "step: 12928.0, loss:0.24726174\n",
      "step: 12929.0, loss:0.12315520\n",
      "step: 12930.0, loss:0.22941405\n",
      "step: 12931.0, loss:0.19280777\n",
      "step: 12932.0, loss:0.21818556\n",
      "step: 12933.0, loss:0.21968702\n",
      "step: 12934.0, loss:0.22755144\n",
      "step: 12935.0, loss:0.12348098\n",
      "step: 12936.0, loss:0.20549971\n",
      "step: 12937.0, loss:0.30871221\n",
      "step: 12938.0, loss:0.25196807\n",
      "step: 12939.0, loss:0.22794643\n",
      "step: 12940.0, loss:0.15969752\n",
      "step: 12941.0, loss:0.20827978\n",
      "step: 12942.0, loss:0.19650625\n",
      "step: 12943.0, loss:0.23045333\n",
      "step: 12944.0, loss:0.27316335\n",
      "step: 12945.0, loss:0.19069038\n",
      "step: 12946.0, loss:0.21533414\n",
      "step: 12947.0, loss:0.19656793\n",
      "step: 12948.0, loss:0.19720094\n",
      "step: 12949.0, loss:0.28540253\n",
      "step: 12950.0, loss:0.16145616\n",
      "step: 12951.0, loss:0.33870970\n",
      "step: 12952.0, loss:0.12088285\n",
      "step: 12953.0, loss:0.14058905\n",
      "step: 12954.0, loss:0.26939866\n",
      "step: 12955.0, loss:0.15953753\n",
      "step: 12956.0, loss:0.26738317\n",
      "step: 12957.0, loss:0.17477564\n",
      "step: 12958.0, loss:0.15797135\n",
      "step: 12959.0, loss:0.19148394\n",
      "step: 12960.0, loss:0.17149665\n",
      "step: 12961.0, loss:0.21746325\n",
      "step: 12962.0, loss:0.32940033\n",
      "step: 12963.0, loss:0.20176787\n",
      "step: 12964.0, loss:0.26932634\n",
      "step: 12965.0, loss:0.15849584\n",
      "step: 12966.0, loss:0.23025424\n",
      "step: 12967.0, loss:0.17769666\n",
      "step: 12968.0, loss:0.22967006\n",
      "step: 12969.0, loss:0.23745187\n",
      "step: 12970.0, loss:0.16107705\n",
      "step: 12971.0, loss:0.21945588\n",
      "step: 12972.0, loss:0.14158823\n",
      "step: 12973.0, loss:0.19452434\n",
      "step: 12974.0, loss:0.16637140\n",
      "step: 12975.0, loss:0.16040540\n",
      "step: 12976.0, loss:0.14995520\n",
      "step: 12977.0, loss:0.23941142\n",
      "step: 12978.0, loss:0.23209840\n",
      "step: 12979.0, loss:0.32699055\n",
      "step: 12980.0, loss:0.25816097\n",
      "step: 12981.0, loss:0.25883769\n",
      "step: 12982.0, loss:0.20758964\n",
      "step: 12983.0, loss:0.27250215\n",
      "step: 12984.0, loss:0.16301096\n",
      "step: 12985.0, loss:0.13765283\n",
      "step: 12986.0, loss:0.24308469\n",
      "step: 12987.0, loss:0.25211248\n",
      "step: 12988.0, loss:0.21423655\n",
      "step: 12989.0, loss:0.23972109\n",
      "step: 12990.0, loss:0.23252223\n",
      "step: 12991.0, loss:0.30698650\n",
      "step: 12992.0, loss:0.22181295\n",
      "step: 12993.0, loss:0.14290626\n",
      "step: 12994.0, loss:0.23076935\n",
      "step: 12995.0, loss:0.14985263\n",
      "step: 12996.0, loss:0.25117347\n",
      "step: 12997.0, loss:0.22434416\n",
      "step: 12998.0, loss:0.21930373\n",
      "step: 12999.0, loss:0.25493595\n",
      "step: 13000.0, loss:0.23481380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1264/1264 [07:50<00:00,  2.68it/s]\n",
      "2023-04-03 02:35:40,597 - INFO - step:13000.0, matthews_corr:0.777183, Acc:89.525105%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 13001.0, loss:0.16169505\n",
      "step: 13002.0, loss:0.12539617\n",
      "step: 13003.0, loss:0.16364896\n",
      "step: 13004.0, loss:0.19034958\n",
      "step: 13005.0, loss:0.19620986\n",
      "step: 13006.0, loss:0.11564812\n",
      "step: 13007.0, loss:0.16981858\n",
      "step: 13008.0, loss:0.27605497\n",
      "step: 13009.0, loss:0.18594688\n",
      "step: 13010.0, loss:0.23126135\n",
      "step: 13011.0, loss:0.15530014\n",
      "step: 13012.0, loss:0.17735460\n",
      "step: 13013.0, loss:0.33468994\n",
      "step: 13014.0, loss:0.35219949\n",
      "step: 13015.0, loss:0.27995707\n",
      "step: 13016.0, loss:0.12622717\n",
      "step: 13017.0, loss:0.18346526\n",
      "step: 13018.0, loss:0.23770918\n",
      "step: 13019.0, loss:0.22009923\n",
      "step: 13020.0, loss:0.20149221\n",
      "step: 13021.0, loss:0.21244842\n",
      "step: 13022.0, loss:0.32009149\n",
      "step: 13023.0, loss:0.19644861\n",
      "step: 13024.0, loss:0.17233863\n",
      "step: 13025.0, loss:0.24013698\n",
      "step: 13026.0, loss:0.15233127\n",
      "step: 13027.0, loss:0.20462770\n",
      "step: 13028.0, loss:0.16791258\n",
      "step: 13029.0, loss:0.13857465\n",
      "step: 13030.0, loss:0.12155975\n",
      "step: 13031.0, loss:0.32644358\n",
      "step: 13032.0, loss:0.27301496\n",
      "step: 13033.0, loss:0.24462862\n",
      "step: 13034.0, loss:0.17395720\n",
      "step: 13035.0, loss:0.20496206\n",
      "step: 13036.0, loss:0.20919214\n",
      "step: 13037.0, loss:0.19610278\n",
      "step: 13038.0, loss:0.16293837\n",
      "step: 13039.0, loss:0.23492697\n",
      "step: 13040.0, loss:0.20363358\n",
      "step: 13041.0, loss:0.29191237\n",
      "step: 13042.0, loss:0.19667666\n",
      "step: 13043.0, loss:0.18039132\n",
      "step: 13044.0, loss:0.11490666\n",
      "step: 13045.0, loss:0.16074049\n",
      "step: 13046.0, loss:0.09944169\n",
      "step: 13047.0, loss:0.13039439\n",
      "step: 13048.0, loss:0.18872274\n",
      "step: 13049.0, loss:0.10259814\n",
      "step: 13050.0, loss:0.14585464\n",
      "step: 13051.0, loss:0.18714830\n",
      "step: 13052.0, loss:0.30949081\n",
      "step: 13053.0, loss:0.24009361\n",
      "step: 13054.0, loss:0.22440573\n",
      "step: 13055.0, loss:0.17189978\n",
      "step: 13056.0, loss:0.23801195\n",
      "step: 13057.0, loss:0.25243505\n",
      "step: 13058.0, loss:0.23847144\n",
      "step: 13059.0, loss:0.11716481\n",
      "step: 13060.0, loss:0.22980151\n",
      "step: 13061.0, loss:0.16926696\n",
      "step: 13062.0, loss:0.20504837\n",
      "step: 13063.0, loss:0.18550638\n",
      "step: 13064.0, loss:0.17418987\n",
      "step: 13065.0, loss:0.23031055\n",
      "step: 13066.0, loss:0.16359923\n",
      "step: 13067.0, loss:0.37255971\n",
      "step: 13068.0, loss:0.13429346\n",
      "step: 13069.0, loss:0.20781192\n",
      "step: 13070.0, loss:0.20770663\n",
      "step: 13071.0, loss:0.15747533\n",
      "step: 13072.0, loss:0.19407290\n",
      "step: 13073.0, loss:0.18591269\n",
      "step: 13074.0, loss:0.16992737\n",
      "step: 13075.0, loss:0.15117715\n",
      "step: 13076.0, loss:0.29379539\n",
      "step: 13077.0, loss:0.15804202\n",
      "step: 13078.0, loss:0.15608437\n",
      "step: 13079.0, loss:0.27150068\n",
      "step: 13080.0, loss:0.21801646\n",
      "step: 13081.0, loss:0.14217370\n",
      "step: 13082.0, loss:0.17511546\n",
      "step: 13083.0, loss:0.13843506\n",
      "step: 13084.0, loss:0.15796690\n",
      "step: 13085.0, loss:0.21109875\n",
      "step: 13086.0, loss:0.14303764\n",
      "step: 13087.0, loss:0.21438471\n",
      "step: 13088.0, loss:0.16847762\n",
      "step: 13089.0, loss:0.13264068\n",
      "step: 13090.0, loss:0.18183622\n",
      "step: 13091.0, loss:0.12609466\n",
      "step: 13092.0, loss:0.10105447\n",
      "step: 13093.0, loss:0.22528123\n",
      "step: 13094.0, loss:0.19505947\n",
      "step: 13095.0, loss:0.14197227\n",
      "step: 13096.0, loss:0.27058743\n",
      "step: 13097.0, loss:0.17110509\n",
      "step: 13098.0, loss:0.21064256\n",
      "step: 13099.0, loss:0.11007805\n",
      "step: 13100.0, loss:0.21793229\n",
      "step: 13101.0, loss:0.10294015\n",
      "step: 13102.0, loss:0.15561516\n",
      "step: 13103.0, loss:0.10520561\n",
      "step: 13104.0, loss:0.23883349\n",
      "step: 13105.0, loss:0.18068553\n",
      "step: 13106.0, loss:0.24950486\n",
      "step: 13107.0, loss:0.18633680\n",
      "step: 13108.0, loss:0.14074334\n",
      "step: 13109.0, loss:0.18332783\n",
      "step: 13110.0, loss:0.13614301\n",
      "step: 13111.0, loss:0.19658902\n",
      "step: 13112.0, loss:0.26087883\n",
      "step: 13113.0, loss:0.19126246\n",
      "step: 13114.0, loss:0.30075140\n",
      "step: 13115.0, loss:0.08342285\n",
      "step: 13116.0, loss:0.30285594\n",
      "step: 13117.0, loss:0.12952974\n",
      "step: 13118.0, loss:0.25448913\n",
      "step: 13119.0, loss:0.29653663\n",
      "step: 13120.0, loss:0.25876098\n",
      "step: 13121.0, loss:0.26244544\n",
      "step: 13122.0, loss:0.20830897\n",
      "step: 13123.0, loss:0.20455430\n",
      "step: 13124.0, loss:0.32919026\n",
      "step: 13125.0, loss:0.06692092\n",
      "step: 13126.0, loss:0.10356922\n",
      "step: 13127.0, loss:0.20601040\n",
      "step: 13128.0, loss:0.21537495\n",
      "step: 13129.0, loss:0.21938346\n",
      "step: 13130.0, loss:0.28378834\n",
      "step: 13131.0, loss:0.17320423\n",
      "step: 13132.0, loss:0.21391923\n",
      "step: 13133.0, loss:0.13358810\n",
      "step: 13134.0, loss:0.17208626\n",
      "step: 13135.0, loss:0.29727514\n",
      "step: 13136.0, loss:0.21453054\n",
      "step: 13137.0, loss:0.08850241\n",
      "step: 13138.0, loss:0.24826258\n",
      "step: 13139.0, loss:0.14622875\n",
      "step: 13140.0, loss:0.12986179\n",
      "step: 13141.0, loss:0.27425579\n",
      "step: 13142.0, loss:0.20148162\n",
      "step: 13143.0, loss:0.20598388\n",
      "step: 13144.0, loss:0.13067574\n",
      "step: 13145.0, loss:0.26066543\n",
      "step: 13146.0, loss:0.13225547\n",
      "step: 13147.0, loss:0.17421116\n",
      "step: 13148.0, loss:0.20579144\n",
      "step: 13149.0, loss:0.26201894\n",
      "step: 13150.0, loss:0.18355425\n",
      "step: 13151.0, loss:0.24738828\n",
      "step: 13152.0, loss:0.11621792\n",
      "step: 13153.0, loss:0.19535453\n",
      "step: 13154.0, loss:0.27886772\n",
      "step: 13155.0, loss:0.34303392\n",
      "step: 13156.0, loss:0.14072196\n",
      "step: 13157.0, loss:0.14143988\n",
      "step: 13158.0, loss:0.37624635\n",
      "step: 13159.0, loss:0.37741942\n",
      "step: 13160.0, loss:0.26015724\n",
      "step: 13161.0, loss:0.18824857\n",
      "step: 13162.0, loss:0.20472614\n",
      "step: 13163.0, loss:0.16200799\n",
      "step: 13164.0, loss:0.18064742\n",
      "step: 13165.0, loss:0.24468428\n",
      "step: 13166.0, loss:0.20903986\n",
      "step: 13167.0, loss:0.20863064\n",
      "step: 13168.0, loss:0.19425400\n",
      "step: 13169.0, loss:0.23371241\n",
      "step: 13170.0, loss:0.25134432\n",
      "step: 13171.0, loss:0.29757773\n",
      "step: 13172.0, loss:0.25201269\n",
      "step: 13173.0, loss:0.13386216\n",
      "step: 13174.0, loss:0.28126390\n",
      "step: 13175.0, loss:0.24124009\n",
      "step: 13176.0, loss:0.09435872\n",
      "step: 13177.0, loss:0.16044779\n",
      "step: 13178.0, loss:0.11968221\n",
      "step: 13179.0, loss:0.15356543\n",
      "step: 13180.0, loss:0.23576346\n",
      "step: 13181.0, loss:0.16752726\n",
      "step: 13182.0, loss:0.27558950\n",
      "step: 13183.0, loss:0.19699894\n",
      "step: 13184.0, loss:0.30178198\n",
      "step: 13185.0, loss:0.25607679\n",
      "step: 13186.0, loss:0.30355583\n",
      "step: 13187.0, loss:0.15034597\n",
      "step: 13188.0, loss:0.14586843\n",
      "step: 13189.0, loss:0.14947650\n",
      "step: 13190.0, loss:0.24092234\n",
      "step: 13191.0, loss:0.20549034\n",
      "step: 13192.0, loss:0.19526492\n",
      "step: 13193.0, loss:0.12794022\n",
      "step: 13194.0, loss:0.17869483\n",
      "step: 13195.0, loss:0.13702073\n",
      "step: 13196.0, loss:0.23740670\n",
      "step: 13197.0, loss:0.13878950\n",
      "step: 13198.0, loss:0.22315677\n",
      "step: 13199.0, loss:0.13873586\n",
      "step: 13200.0, loss:0.24420270\n",
      "step: 13201.0, loss:0.15369339\n",
      "step: 13202.0, loss:0.18010394\n",
      "step: 13203.0, loss:0.22407234\n",
      "step: 13204.0, loss:0.21159585\n",
      "step: 13205.0, loss:0.12658235\n",
      "step: 13206.0, loss:0.29485281\n",
      "step: 13207.0, loss:0.15382365\n",
      "step: 13208.0, loss:0.28661619\n",
      "step: 13209.0, loss:0.08497733\n",
      "step: 13210.0, loss:0.29402080\n",
      "step: 13211.0, loss:0.23185786\n",
      "step: 13212.0, loss:0.11826878\n",
      "step: 13213.0, loss:0.11241867\n",
      "step: 13214.0, loss:0.29203763\n",
      "step: 13215.0, loss:0.15639805\n",
      "step: 13216.0, loss:0.12759507\n",
      "step: 13217.0, loss:0.25832059\n",
      "step: 13218.0, loss:0.21990550\n",
      "step: 13219.0, loss:0.22282079\n",
      "step: 13220.0, loss:0.21935441\n",
      "step: 13221.0, loss:0.23201656\n",
      "step: 13222.0, loss:0.24954551\n",
      "step: 13223.0, loss:0.20948925\n",
      "step: 13224.0, loss:0.21471481\n",
      "step: 13225.0, loss:0.18505701\n",
      "step: 13226.0, loss:0.15727760\n",
      "step: 13227.0, loss:0.24425028\n",
      "step: 13228.0, loss:0.28891509\n",
      "step: 13229.0, loss:0.16577737\n",
      "step: 13230.0, loss:0.14964934\n",
      "step: 13231.0, loss:0.32702439\n",
      "step: 13232.0, loss:0.21129031\n",
      "step: 13233.0, loss:0.25895679\n",
      "step: 13234.0, loss:0.15244229\n",
      "step: 13235.0, loss:0.24619716\n",
      "step: 13236.0, loss:0.29377493\n",
      "step: 13237.0, loss:0.19812961\n",
      "step: 13238.0, loss:0.23198339\n",
      "step: 13239.0, loss:0.12473900\n",
      "step: 13240.0, loss:0.21207248\n",
      "step: 13241.0, loss:0.19070247\n",
      "step: 13242.0, loss:0.26831368\n",
      "step: 13243.0, loss:0.18119622\n",
      "step: 13244.0, loss:0.20023213\n",
      "step: 13245.0, loss:0.27417314\n",
      "step: 13246.0, loss:0.23040211\n",
      "step: 13247.0, loss:0.30333299\n",
      "step: 13248.0, loss:0.22827799\n",
      "step: 13249.0, loss:0.18662934\n",
      "step: 13250.0, loss:0.13010081\n",
      "step: 13251.0, loss:0.20050203\n",
      "step: 13252.0, loss:0.25428751\n",
      "step: 13253.0, loss:0.21884617\n",
      "step: 13254.0, loss:0.26561050\n",
      "step: 13255.0, loss:0.16323756\n",
      "step: 13256.0, loss:0.14358689\n",
      "step: 13257.0, loss:0.15205760\n",
      "step: 13258.0, loss:0.22803678\n",
      "step: 13259.0, loss:0.20239624\n",
      "step: 13260.0, loss:0.17174738\n",
      "step: 13261.0, loss:0.16423677\n",
      "step: 13262.0, loss:0.21401402\n",
      "step: 13263.0, loss:0.20196682\n",
      "step: 13264.0, loss:0.14590597\n",
      "step: 13265.0, loss:0.30063663\n",
      "step: 13266.0, loss:0.20325533\n",
      "step: 13267.0, loss:0.17700620\n",
      "step: 13268.0, loss:0.15959583\n",
      "step: 13269.0, loss:0.12754552\n",
      "step: 13270.0, loss:0.26026715\n",
      "step: 13271.0, loss:0.24314052\n",
      "step: 13272.0, loss:0.21484910\n",
      "step: 13273.0, loss:0.17022535\n",
      "step: 13274.0, loss:0.17542603\n",
      "step: 13275.0, loss:0.14038626\n",
      "step: 13276.0, loss:0.34463423\n",
      "step: 13277.0, loss:0.19587122\n",
      "step: 13278.0, loss:0.15843336\n",
      "step: 13279.0, loss:0.24636366\n",
      "step: 13280.0, loss:0.15659238\n",
      "step: 13281.0, loss:0.20723233\n",
      "step: 13282.0, loss:0.18792407\n",
      "step: 13283.0, loss:0.15698171\n",
      "step: 13284.0, loss:0.18857419\n",
      "step: 13285.0, loss:0.14564505\n",
      "step: 13286.0, loss:0.26121198\n",
      "step: 13287.0, loss:0.29504787\n",
      "step: 13288.0, loss:0.25279578\n",
      "step: 13289.0, loss:0.20569059\n",
      "step: 13290.0, loss:0.32919136\n",
      "step: 13291.0, loss:0.17294099\n",
      "step: 13292.0, loss:0.11625343\n",
      "step: 13293.0, loss:0.16250261\n",
      "step: 13294.0, loss:0.25360045\n",
      "step: 13295.0, loss:0.19295070\n",
      "step: 13296.0, loss:0.20967832\n",
      "step: 13297.0, loss:0.19777870\n",
      "step: 13298.0, loss:0.22114933\n",
      "step: 13299.0, loss:0.17592294\n",
      "step: 13300.0, loss:0.13214024\n",
      "step: 13301.0, loss:0.17380840\n",
      "step: 13302.0, loss:0.26786808\n",
      "step: 13303.0, loss:0.26341849\n",
      "step: 13304.0, loss:0.10636396\n",
      "step: 13305.0, loss:0.25952110\n",
      "step: 13306.0, loss:0.12765948\n",
      "step: 13307.0, loss:0.30273316\n",
      "step: 13308.0, loss:0.12623097\n",
      "step: 13309.0, loss:0.18207029\n",
      "step: 13310.0, loss:0.15124488\n",
      "step: 13311.0, loss:0.17553098\n",
      "step: 13312.0, loss:0.12929435\n",
      "step: 13313.0, loss:0.17143265\n",
      "step: 13314.0, loss:0.16740777\n",
      "step: 13315.0, loss:0.20570425\n",
      "step: 13316.0, loss:0.19674683\n",
      "step: 13317.0, loss:0.21415459\n",
      "step: 13318.0, loss:0.21871868\n",
      "step: 13319.0, loss:0.28846595\n",
      "step: 13320.0, loss:0.16405449\n",
      "step: 13321.0, loss:0.24751503\n",
      "step: 13322.0, loss:0.19549021\n",
      "step: 13323.0, loss:0.35535099\n",
      "step: 13324.0, loss:0.20498022\n",
      "step: 13325.0, loss:0.15784954\n",
      "step: 13326.0, loss:0.28694041\n",
      "step: 13327.0, loss:0.16322549\n",
      "step: 13328.0, loss:0.13658990\n",
      "step: 13329.0, loss:0.26226716\n",
      "step: 13330.0, loss:0.17381351\n",
      "step: 13331.0, loss:0.17211504\n",
      "step: 13332.0, loss:0.20415785\n",
      "step: 13333.0, loss:0.16239839\n",
      "step: 13334.0, loss:0.17751244\n",
      "step: 13335.0, loss:0.22973948\n",
      "step: 13336.0, loss:0.19072274\n",
      "step: 13337.0, loss:0.34828917\n",
      "step: 13338.0, loss:0.13421507\n",
      "step: 13339.0, loss:0.19648383\n",
      "step: 13340.0, loss:0.17276069\n",
      "step: 13341.0, loss:0.21894217\n",
      "step: 13342.0, loss:0.18884519\n",
      "step: 13343.0, loss:0.21128568\n",
      "step: 13344.0, loss:0.20999665\n",
      "step: 13345.0, loss:0.27686545\n",
      "step: 13346.0, loss:0.15002474\n",
      "step: 13347.0, loss:0.12067558\n",
      "step: 13348.0, loss:0.12165526\n",
      "step: 13349.0, loss:0.16447972\n",
      "step: 13350.0, loss:0.13489256\n",
      "step: 13351.0, loss:0.28782968\n",
      "step: 13352.0, loss:0.26412955\n",
      "step: 13353.0, loss:0.26256779\n",
      "step: 13354.0, loss:0.13065590\n",
      "step: 13355.0, loss:0.19730642\n",
      "step: 13356.0, loss:0.17503065\n",
      "step: 13357.0, loss:0.17523819\n",
      "step: 13358.0, loss:0.21008184\n",
      "step: 13359.0, loss:0.19175639\n",
      "step: 13360.0, loss:0.12080550\n",
      "step: 13361.0, loss:0.20393641\n",
      "step: 13362.0, loss:0.23526084\n",
      "step: 13363.0, loss:0.19032456\n",
      "step: 13364.0, loss:0.24083029\n",
      "step: 13365.0, loss:0.16952249\n",
      "step: 13366.0, loss:0.20181224\n",
      "step: 13367.0, loss:0.07353470\n",
      "step: 13368.0, loss:0.18787883\n",
      "step: 13369.0, loss:0.15942485\n",
      "step: 13370.0, loss:0.23541484\n",
      "step: 13371.0, loss:0.20044727\n",
      "step: 13372.0, loss:0.14392198\n",
      "step: 13373.0, loss:0.18082976\n",
      "step: 13374.0, loss:0.22478075\n",
      "step: 13375.0, loss:0.18690055\n",
      "step: 13376.0, loss:0.12743232\n",
      "step: 13377.0, loss:0.19270177\n",
      "step: 13378.0, loss:0.14889022\n",
      "step: 13379.0, loss:0.21818162\n",
      "step: 13380.0, loss:0.13602386\n",
      "step: 13381.0, loss:0.16895619\n",
      "step: 13382.0, loss:0.19054819\n",
      "step: 13383.0, loss:0.18443758\n",
      "step: 13384.0, loss:0.19246253\n",
      "step: 13385.0, loss:0.24068383\n",
      "step: 13386.0, loss:0.22138463\n",
      "step: 13387.0, loss:0.30765056\n",
      "step: 13388.0, loss:0.13414782\n",
      "step: 13389.0, loss:0.10960808\n",
      "step: 13390.0, loss:0.14344323\n",
      "step: 13391.0, loss:0.24752482\n",
      "step: 13392.0, loss:0.13405873\n",
      "step: 13393.0, loss:0.17699752\n",
      "step: 13394.0, loss:0.21374005\n",
      "step: 13395.0, loss:0.16327279\n",
      "step: 13396.0, loss:0.13195634\n",
      "step: 13397.0, loss:0.13055822\n",
      "step: 13398.0, loss:0.15643875\n",
      "step: 13399.0, loss:0.13829745\n",
      "step: 13400.0, loss:0.19240941\n",
      "step: 13401.0, loss:0.18506178\n",
      "step: 13402.0, loss:0.14154872\n",
      "step: 13403.0, loss:0.28008044\n",
      "step: 13404.0, loss:0.17908270\n",
      "step: 13405.0, loss:0.17675213\n",
      "step: 13406.0, loss:0.14408855\n",
      "step: 13407.0, loss:0.36382695\n",
      "step: 13408.0, loss:0.19382734\n",
      "step: 13409.0, loss:0.30303314\n",
      "step: 13410.0, loss:0.16584939\n",
      "step: 13411.0, loss:0.25779803\n",
      "step: 13412.0, loss:0.09317751\n",
      "step: 13413.0, loss:0.15279763\n",
      "step: 13414.0, loss:0.17926097\n",
      "step: 13415.0, loss:0.20317158\n",
      "step: 13416.0, loss:0.13414485\n",
      "step: 13417.0, loss:0.15902668\n",
      "step: 13418.0, loss:0.21247041\n",
      "step: 13419.0, loss:0.12069402\n",
      "step: 13420.0, loss:0.14464717\n",
      "step: 13421.0, loss:0.22016943\n",
      "step: 13422.0, loss:0.09386860\n",
      "step: 13423.0, loss:0.19888762\n",
      "step: 13424.0, loss:0.06344146\n",
      "step: 13425.0, loss:0.13493701\n",
      "step: 13426.0, loss:0.14590082\n",
      "step: 13427.0, loss:0.19813306\n",
      "step: 13428.0, loss:0.17048116\n",
      "step: 13429.0, loss:0.23250612\n",
      "step: 13430.0, loss:0.28638340\n",
      "step: 13431.0, loss:0.18926745\n",
      "step: 13432.0, loss:0.10369239\n",
      "step: 13433.0, loss:0.18980825\n",
      "step: 13434.0, loss:0.25494828\n",
      "step: 13435.0, loss:0.13097159\n",
      "step: 13436.0, loss:0.28572647\n",
      "step: 13437.0, loss:0.20436913\n",
      "step: 13438.0, loss:0.15011652\n",
      "step: 13439.0, loss:0.15483450\n",
      "step: 13440.0, loss:0.13871190\n",
      "step: 13441.0, loss:0.11653364\n",
      "step: 13442.0, loss:0.20236049\n",
      "step: 13443.0, loss:0.16717839\n",
      "step: 13444.0, loss:0.33938796\n",
      "step: 13445.0, loss:0.26571964\n",
      "step: 13446.0, loss:0.35574911\n",
      "step: 13447.0, loss:0.39428022\n",
      "step: 13448.0, loss:0.22170406\n",
      "step: 13449.0, loss:0.22722429\n",
      "step: 13450.0, loss:0.19356096\n",
      "step: 13451.0, loss:0.15910423\n",
      "step: 13452.0, loss:0.17879701\n",
      "step: 13453.0, loss:0.21642428\n",
      "step: 13454.0, loss:0.27933926\n",
      "step: 13455.0, loss:0.12844214\n",
      "step: 13456.0, loss:0.24056180\n",
      "step: 13457.0, loss:0.17373811\n",
      "step: 13458.0, loss:0.24064007\n",
      "step: 13459.0, loss:0.16559726\n",
      "step: 13460.0, loss:0.20203636\n",
      "step: 13461.0, loss:0.19040139\n",
      "step: 13462.0, loss:0.33347553\n",
      "step: 13463.0, loss:0.28651609\n",
      "step: 13464.0, loss:0.24134916\n",
      "step: 13465.0, loss:0.14620670\n",
      "step: 13466.0, loss:0.13393841\n",
      "step: 13467.0, loss:0.11839875\n",
      "step: 13468.0, loss:0.11552221\n",
      "step: 13469.0, loss:0.19564467\n",
      "step: 13470.0, loss:0.19919039\n",
      "step: 13471.0, loss:0.18495925\n",
      "step: 13472.0, loss:0.15274412\n",
      "step: 13473.0, loss:0.12053488\n",
      "step: 13474.0, loss:0.15336291\n",
      "step: 13475.0, loss:0.18425694\n",
      "step: 13476.0, loss:0.14827732\n",
      "step: 13477.0, loss:0.14486917\n",
      "step: 13478.0, loss:0.31705769\n",
      "step: 13479.0, loss:0.18736652\n",
      "step: 13480.0, loss:0.18321925\n",
      "step: 13481.0, loss:0.21028298\n",
      "step: 13482.0, loss:0.22830535\n",
      "step: 13483.0, loss:0.22816458\n",
      "step: 13484.0, loss:0.17860999\n",
      "step: 13485.0, loss:0.23049636\n",
      "step: 13486.0, loss:0.13096385\n",
      "step: 13487.0, loss:0.23996904\n",
      "step: 13488.0, loss:0.16085340\n",
      "step: 13489.0, loss:0.20666211\n",
      "step: 13490.0, loss:0.21722690\n",
      "step: 13491.0, loss:0.26265719\n",
      "step: 13492.0, loss:0.27180171\n",
      "step: 13493.0, loss:0.18207256\n",
      "step: 13494.0, loss:0.17806703\n",
      "step: 13495.0, loss:0.19106255\n",
      "step: 13496.0, loss:0.23629959\n",
      "step: 13497.0, loss:0.17151031\n",
      "step: 13498.0, loss:0.27042587\n",
      "step: 13499.0, loss:0.17313479\n",
      "step: 13500.0, loss:0.27709115\n",
      "step: 13501.0, loss:0.23305019\n",
      "step: 13502.0, loss:0.27616721\n",
      "step: 13503.0, loss:0.22821586\n",
      "step: 13504.0, loss:0.17755942\n",
      "step: 13505.0, loss:0.22593670\n",
      "step: 13506.0, loss:0.35032978\n",
      "step: 13507.0, loss:0.13105870\n",
      "step: 13508.0, loss:0.14066093\n",
      "step: 13509.0, loss:0.16299956\n",
      "step: 13510.0, loss:0.14032751\n",
      "step: 13511.0, loss:0.27644451\n",
      "step: 13512.0, loss:0.19215959\n",
      "step: 13513.0, loss:0.22655941\n",
      "step: 13514.0, loss:0.34199427\n",
      "step: 13515.0, loss:0.26107975\n",
      "step: 13516.0, loss:0.15169197\n",
      "step: 13517.0, loss:0.14272798\n",
      "step: 13518.0, loss:0.22526367\n",
      "step: 13519.0, loss:0.20635647\n",
      "step: 13520.0, loss:0.23483410\n",
      "step: 13521.0, loss:0.22839378\n",
      "step: 13522.0, loss:0.16495064\n",
      "step: 13523.0, loss:0.29500330\n",
      "step: 13524.0, loss:0.18326294\n",
      "step: 13525.0, loss:0.41960644\n",
      "step: 13526.0, loss:0.23996940\n",
      "step: 13527.0, loss:0.16506072\n",
      "step: 13528.0, loss:0.29205929\n",
      "step: 13529.0, loss:0.20143509\n",
      "step: 13530.0, loss:0.13405344\n",
      "step: 13531.0, loss:0.28067773\n",
      "step: 13532.0, loss:0.19571451\n",
      "step: 13533.0, loss:0.18021262\n",
      "step: 13534.0, loss:0.16905280\n",
      "step: 13535.0, loss:0.15864682\n",
      "step: 13536.0, loss:0.17354214\n",
      "step: 13537.0, loss:0.20647432\n",
      "step: 13538.0, loss:0.18321795\n",
      "step: 13539.0, loss:0.17731467\n",
      "step: 13540.0, loss:0.32057233\n",
      "step: 13541.0, loss:0.14317773\n",
      "step: 13542.0, loss:0.19428109\n",
      "step: 13543.0, loss:0.12184525\n",
      "step: 13544.0, loss:0.17098818\n",
      "step: 13545.0, loss:0.17619503\n",
      "step: 13546.0, loss:0.17753399\n",
      "step: 13547.0, loss:0.15605578\n",
      "step: 13548.0, loss:0.13335274\n",
      "step: 13549.0, loss:0.18605576\n",
      "step: 13550.0, loss:0.14623795\n",
      "step: 13551.0, loss:0.19195463\n",
      "step: 13552.0, loss:0.17450281\n",
      "step: 13553.0, loss:0.15387658\n",
      "step: 13554.0, loss:0.13535772\n",
      "step: 13555.0, loss:0.27500192\n",
      "step: 13556.0, loss:0.28469928\n",
      "step: 13557.0, loss:0.23505346\n",
      "step: 13558.0, loss:0.26224154\n",
      "step: 13559.0, loss:0.12736414\n",
      "step: 13560.0, loss:0.16254632\n",
      "step: 13561.0, loss:0.13077763\n",
      "step: 13562.0, loss:0.24597340\n",
      "step: 13563.0, loss:0.15882048\n",
      "step: 13564.0, loss:0.27027532\n",
      "step: 13565.0, loss:0.30002684\n",
      "step: 13566.0, loss:0.19284493\n",
      "step: 13567.0, loss:0.18531791\n",
      "step: 13568.0, loss:0.18079352\n",
      "step: 13569.0, loss:0.17898400\n",
      "step: 13570.0, loss:0.20012326\n",
      "step: 13571.0, loss:0.14051024\n",
      "step: 13572.0, loss:0.17826737\n",
      "step: 13573.0, loss:0.15193108\n",
      "step: 13574.0, loss:0.16565417\n",
      "step: 13575.0, loss:0.16500792\n",
      "step: 13576.0, loss:0.26126434\n",
      "step: 13577.0, loss:0.13359603\n",
      "step: 13578.0, loss:0.16061688\n",
      "step: 13579.0, loss:0.17299425\n",
      "step: 13580.0, loss:0.23046738\n",
      "step: 13581.0, loss:0.17898300\n",
      "step: 13582.0, loss:0.15047973\n",
      "step: 13583.0, loss:0.32923487\n",
      "step: 13584.0, loss:0.22946948\n",
      "step: 13585.0, loss:0.22545199\n",
      "step: 13586.0, loss:0.09197919\n",
      "step: 13587.0, loss:0.28716097\n",
      "step: 13588.0, loss:0.17672932\n",
      "step: 13589.0, loss:0.15871629\n",
      "step: 13590.0, loss:0.13435187\n",
      "step: 13591.0, loss:0.16191606\n",
      "step: 13592.0, loss:0.15412251\n",
      "step: 13593.0, loss:0.29413667\n",
      "step: 13594.0, loss:0.17504062\n",
      "step: 13595.0, loss:0.16839032\n",
      "step: 13596.0, loss:0.22654434\n",
      "step: 13597.0, loss:0.14321945\n",
      "step: 13598.0, loss:0.15550486\n",
      "step: 13599.0, loss:0.18936805\n",
      "step: 13600.0, loss:0.18646528\n",
      "step: 13601.0, loss:0.17848995\n",
      "step: 13602.0, loss:0.09520088\n",
      "step: 13603.0, loss:0.19742075\n",
      "step: 13604.0, loss:0.20947079\n",
      "step: 13605.0, loss:0.12545619\n",
      "step: 13606.0, loss:0.17604497\n",
      "step: 13607.0, loss:0.19971893\n",
      "step: 13608.0, loss:0.12539927\n",
      "step: 13609.0, loss:0.14885981\n",
      "step: 13610.0, loss:0.22837930\n",
      "step: 13611.0, loss:0.17349357\n",
      "step: 13612.0, loss:0.32172848\n",
      "step: 13613.0, loss:0.24570680\n",
      "step: 13614.0, loss:0.19662307\n",
      "step: 13615.0, loss:0.23944227\n",
      "step: 13616.0, loss:0.15825838\n",
      "step: 13617.0, loss:0.22726108\n",
      "step: 13618.0, loss:0.26119566\n",
      "step: 13619.0, loss:0.14490182\n",
      "step: 13620.0, loss:0.22956410\n",
      "step: 13621.0, loss:0.17863516\n",
      "step: 13622.0, loss:0.12891505\n",
      "step: 13623.0, loss:0.15010707\n",
      "step: 13624.0, loss:0.08682088\n",
      "step: 13625.0, loss:0.21524119\n",
      "step: 13626.0, loss:0.21007076\n",
      "step: 13627.0, loss:0.17121458\n",
      "step: 13628.0, loss:0.22038816\n",
      "step: 13629.0, loss:0.10666183\n",
      "step: 13630.0, loss:0.16573488\n",
      "step: 13631.0, loss:0.13856371\n",
      "step: 13632.0, loss:0.19356004\n",
      "step: 13633.0, loss:0.23180433\n",
      "step: 13634.0, loss:0.26865867\n",
      "step: 13635.0, loss:0.13824418\n",
      "step: 13636.0, loss:0.17807505\n",
      "step: 13637.0, loss:0.13311490\n",
      "step: 13638.0, loss:0.18025092\n",
      "step: 13639.0, loss:0.17323118\n",
      "step: 13640.0, loss:0.24036210\n",
      "step: 13641.0, loss:0.28404752\n",
      "step: 13642.0, loss:0.27055551\n",
      "step: 13643.0, loss:0.18750690\n",
      "step: 13644.0, loss:0.19773948\n",
      "step: 13645.0, loss:0.18876415\n",
      "step: 13646.0, loss:0.32073713\n",
      "step: 13647.0, loss:0.17722893\n",
      "step: 13648.0, loss:0.24028581\n",
      "step: 13649.0, loss:0.16001377\n",
      "step: 13650.0, loss:0.21687242\n",
      "step: 13651.0, loss:0.14237031\n",
      "step: 13652.0, loss:0.14375630\n",
      "step: 13653.0, loss:0.18973957\n",
      "step: 13654.0, loss:0.19930841\n",
      "step: 13655.0, loss:0.14569467\n",
      "step: 13656.0, loss:0.22946646\n",
      "step: 13657.0, loss:0.17491777\n",
      "step: 13658.0, loss:0.14831748\n",
      "step: 13659.0, loss:0.13609544\n",
      "step: 13660.0, loss:0.38138356\n",
      "step: 13661.0, loss:0.22752471\n",
      "step: 13662.0, loss:0.22625280\n",
      "step: 13663.0, loss:0.16971030\n",
      "step: 13664.0, loss:0.17198314\n",
      "step: 13665.0, loss:0.31524214\n",
      "step: 13666.0, loss:0.28892777\n",
      "step: 13667.0, loss:0.26061946\n",
      "step: 13668.0, loss:0.13206649\n",
      "step: 13669.0, loss:0.25344388\n",
      "step: 13670.0, loss:0.21974190\n",
      "step: 13671.0, loss:0.24838124\n",
      "step: 13672.0, loss:0.16964218\n",
      "step: 13673.0, loss:0.27607577\n",
      "step: 13674.0, loss:0.20370178\n",
      "step: 13675.0, loss:0.21132352\n",
      "step: 13676.0, loss:0.32114956\n",
      "step: 13677.0, loss:0.20062085\n",
      "step: 13678.0, loss:0.17297701\n",
      "step: 13679.0, loss:0.10171013\n",
      "step: 13680.0, loss:0.10826389\n",
      "step: 13681.0, loss:0.23644507\n",
      "step: 13682.0, loss:0.21848334\n",
      "step: 13683.0, loss:0.17723083\n",
      "step: 13684.0, loss:0.10860415\n",
      "step: 13685.0, loss:0.10063446\n",
      "step: 13686.0, loss:0.19457574\n",
      "step: 13687.0, loss:0.29703059\n",
      "step: 13688.0, loss:0.15920668\n",
      "step: 13689.0, loss:0.24300905\n",
      "step: 13690.0, loss:0.24850188\n",
      "step: 13691.0, loss:0.21523481\n",
      "step: 13692.0, loss:0.26649525\n",
      "step: 13693.0, loss:0.27059191\n",
      "step: 13694.0, loss:0.17261630\n",
      "step: 13695.0, loss:0.11646520\n",
      "step: 13696.0, loss:0.15652108\n",
      "step: 13697.0, loss:0.16845994\n",
      "step: 13698.0, loss:0.27865302\n",
      "step: 13699.0, loss:0.08463555\n",
      "step: 13700.0, loss:0.12110412\n",
      "step: 13701.0, loss:0.19121019\n",
      "step: 13702.0, loss:0.15672530\n",
      "step: 13703.0, loss:0.28608088\n",
      "step: 13704.0, loss:0.16319382\n",
      "step: 13705.0, loss:0.15532441\n",
      "step: 13706.0, loss:0.25134778\n",
      "step: 13707.0, loss:0.16308661\n",
      "step: 13708.0, loss:0.15614797\n",
      "step: 13709.0, loss:0.12740641\n",
      "step: 13710.0, loss:0.15190390\n",
      "step: 13711.0, loss:0.27879823\n",
      "step: 13712.0, loss:0.22148444\n",
      "step: 13713.0, loss:0.25042542\n",
      "step: 13714.0, loss:0.17105043\n",
      "step: 13715.0, loss:0.27411909\n",
      "step: 13716.0, loss:0.14092988\n",
      "step: 13717.0, loss:0.26532877\n",
      "step: 13718.0, loss:0.32168033\n",
      "step: 13719.0, loss:0.19225688\n",
      "step: 13720.0, loss:0.19478203\n",
      "step: 13721.0, loss:0.15551423\n",
      "step: 13722.0, loss:0.17969148\n",
      "step: 13723.0, loss:0.31002628\n",
      "step: 13724.0, loss:0.10546059\n",
      "step: 13725.0, loss:0.17198004\n",
      "step: 13726.0, loss:0.25368862\n",
      "step: 13727.0, loss:0.09472247\n",
      "step: 13728.0, loss:0.23260759\n",
      "step: 13729.0, loss:0.13969989\n",
      "step: 13730.0, loss:0.21973945\n",
      "step: 13731.0, loss:0.12035750\n",
      "step: 13732.0, loss:0.10250043\n",
      "step: 13733.0, loss:0.13240266\n",
      "step: 13734.0, loss:0.20017686\n",
      "step: 13735.0, loss:0.12741098\n",
      "step: 13736.0, loss:0.39394392\n",
      "step: 13737.0, loss:0.17153824\n",
      "step: 13738.0, loss:0.08671530\n",
      "step: 13739.0, loss:0.07503880\n",
      "step: 13740.0, loss:0.14516988\n",
      "step: 13741.0, loss:0.18251511\n",
      "step: 13742.0, loss:0.09074396\n",
      "step: 13743.0, loss:0.21765259\n",
      "step: 13744.0, loss:0.28469176\n",
      "step: 13745.0, loss:0.08044559\n",
      "step: 13746.0, loss:0.15538171\n",
      "step: 13747.0, loss:0.23371188\n",
      "step: 13748.0, loss:0.18778817\n",
      "step: 13749.0, loss:0.17436794\n",
      "step: 13750.0, loss:0.17687173\n",
      "step: 13751.0, loss:0.18851961\n",
      "step: 13752.0, loss:0.22712113\n",
      "step: 13753.0, loss:0.22498913\n",
      "step: 13754.0, loss:0.27007808\n",
      "step: 13755.0, loss:0.18414375\n",
      "step: 13756.0, loss:0.18558086\n",
      "step: 13757.0, loss:0.18596894\n",
      "step: 13758.0, loss:0.28697996\n",
      "step: 13759.0, loss:0.25682832\n",
      "step: 13760.0, loss:0.23490522\n",
      "step: 13761.0, loss:0.16451168\n",
      "step: 13762.0, loss:0.19454699\n",
      "step: 13763.0, loss:0.25641641\n",
      "step: 13764.0, loss:0.16498452\n",
      "step: 13765.0, loss:0.22138009\n",
      "step: 13766.0, loss:0.33506078\n",
      "step: 13767.0, loss:0.16575226\n",
      "step: 13768.0, loss:0.20230046\n",
      "step: 13769.0, loss:0.15694439\n",
      "step: 13770.0, loss:0.19155608\n",
      "step: 13771.0, loss:0.19563583\n",
      "step: 13772.0, loss:0.23463343\n",
      "step: 13773.0, loss:0.20967314\n",
      "step: 13774.0, loss:0.20708813\n",
      "step: 13775.0, loss:0.10861941\n",
      "step: 13776.0, loss:0.09759035\n",
      "step: 13777.0, loss:0.14882954\n",
      "step: 13778.0, loss:0.08968762\n",
      "step: 13779.0, loss:0.18159468\n",
      "step: 13780.0, loss:0.13473343\n",
      "step: 13781.0, loss:0.19090093\n",
      "step: 13782.0, loss:0.24187556\n",
      "step: 13783.0, loss:0.21032042\n",
      "step: 13784.0, loss:0.30807249\n",
      "step: 13785.0, loss:0.26840020\n",
      "step: 13786.0, loss:0.30411276\n",
      "step: 13787.0, loss:0.17560385\n",
      "step: 13788.0, loss:0.17427398\n",
      "step: 13789.0, loss:0.20938497\n",
      "step: 13790.0, loss:0.19431432\n",
      "step: 13791.0, loss:0.24374854\n",
      "step: 13792.0, loss:0.26449739\n",
      "step: 13793.0, loss:0.20281758\n",
      "step: 13794.0, loss:0.18787195\n",
      "step: 13795.0, loss:0.12909630\n",
      "step: 13796.0, loss:0.14004385\n",
      "step: 13797.0, loss:0.29694121\n",
      "step: 13798.0, loss:0.32075426\n",
      "step: 13799.0, loss:0.11090866\n",
      "step: 13800.0, loss:0.21266613\n",
      "step: 13801.0, loss:0.21617307\n",
      "step: 13802.0, loss:0.21743415\n",
      "step: 13803.0, loss:0.25065782\n",
      "step: 13804.0, loss:0.23738209\n",
      "step: 13805.0, loss:0.21497376\n",
      "step: 13806.0, loss:0.16634953\n",
      "step: 13807.0, loss:0.25512340\n",
      "step: 13808.0, loss:0.25103415\n",
      "step: 13809.0, loss:0.17691361\n",
      "step: 13810.0, loss:0.18693958\n",
      "step: 13811.0, loss:0.09680846\n",
      "step: 13812.0, loss:0.12766791\n",
      "step: 13813.0, loss:0.12514714\n",
      "step: 13814.0, loss:0.21224995\n",
      "step: 13815.0, loss:0.21643347\n",
      "step: 13816.0, loss:0.24711635\n",
      "step: 13817.0, loss:0.17078821\n",
      "step: 13818.0, loss:0.15544605\n",
      "step: 13819.0, loss:0.20740073\n",
      "step: 13820.0, loss:0.16915853\n",
      "step: 13821.0, loss:0.15073922\n",
      "step: 13822.0, loss:0.14662310\n",
      "step: 13823.0, loss:0.15621979\n",
      "step: 13824.0, loss:0.16415773\n",
      "step: 13825.0, loss:0.17971137\n",
      "step: 13826.0, loss:0.13597640\n",
      "step: 13827.0, loss:0.22099536\n",
      "step: 13828.0, loss:0.11909387\n",
      "step: 13829.0, loss:0.21560743\n",
      "step: 13830.0, loss:0.24380974\n",
      "step: 13831.0, loss:0.21393320\n",
      "step: 13832.0, loss:0.17986017\n",
      "step: 13833.0, loss:0.25019145\n",
      "step: 13834.0, loss:0.23791321\n",
      "step: 13835.0, loss:0.28185233\n",
      "step: 13836.0, loss:0.19851584\n",
      "step: 13837.0, loss:0.16598350\n",
      "step: 13838.0, loss:0.11699043\n",
      "step: 13839.0, loss:0.18026764\n",
      "step: 13840.0, loss:0.25226668\n",
      "step: 13841.0, loss:0.22106865\n",
      "step: 13842.0, loss:0.17370599\n",
      "step: 13843.0, loss:0.30637625\n",
      "step: 13844.0, loss:0.18834716\n",
      "step: 13845.0, loss:0.17577984\n",
      "step: 13846.0, loss:0.11018074\n",
      "step: 13847.0, loss:0.19952715\n",
      "step: 13848.0, loss:0.13763917\n",
      "step: 13849.0, loss:0.27304609\n",
      "step: 13850.0, loss:0.22544828\n",
      "step: 13851.0, loss:0.11055687\n",
      "step: 13852.0, loss:0.31778348\n",
      "step: 13853.0, loss:0.21602574\n",
      "step: 13854.0, loss:0.14223672\n",
      "step: 13855.0, loss:0.24521759\n",
      "step: 13856.0, loss:0.13331634\n",
      "step: 13857.0, loss:0.19021132\n",
      "step: 13858.0, loss:0.08735843\n",
      "step: 13859.0, loss:0.25068598\n",
      "step: 13860.0, loss:0.13719043\n",
      "step: 13861.0, loss:0.14398990\n",
      "step: 13862.0, loss:0.14859670\n",
      "step: 13863.0, loss:0.18679467\n",
      "step: 13864.0, loss:0.17616041\n",
      "step: 13865.0, loss:0.14445060\n",
      "step: 13866.0, loss:0.27058268\n",
      "step: 13867.0, loss:0.25712941\n",
      "step: 13868.0, loss:0.15029128\n",
      "step: 13869.0, loss:0.23064635\n",
      "step: 13870.0, loss:0.28974448\n",
      "step: 13871.0, loss:0.16071634\n",
      "step: 13872.0, loss:0.15292576\n",
      "step: 13873.0, loss:0.19423501\n",
      "step: 13874.0, loss:0.13552242\n",
      "step: 13875.0, loss:0.15007115\n",
      "step: 13876.0, loss:0.19417291\n",
      "step: 13877.0, loss:0.26857436\n",
      "step: 13878.0, loss:0.18788283\n",
      "step: 13879.0, loss:0.29197997\n",
      "step: 13880.0, loss:0.24016243\n",
      "step: 13881.0, loss:0.30551068\n",
      "step: 13882.0, loss:0.22329379\n",
      "step: 13883.0, loss:0.13628679\n",
      "step: 13884.0, loss:0.09508847\n",
      "step: 13885.0, loss:0.29438555\n",
      "step: 13886.0, loss:0.12933740\n",
      "step: 13887.0, loss:0.23747530\n",
      "step: 13888.0, loss:0.27141421\n",
      "step: 13889.0, loss:0.25996370\n",
      "step: 13890.0, loss:0.13025855\n",
      "step: 13891.0, loss:0.23131041\n",
      "step: 13892.0, loss:0.14974515\n",
      "step: 13893.0, loss:0.19382317\n",
      "step: 13894.0, loss:0.20541367\n",
      "step: 13895.0, loss:0.29966529\n",
      "step: 13896.0, loss:0.24195901\n",
      "step: 13897.0, loss:0.13935002\n",
      "step: 13898.0, loss:0.20878514\n",
      "step: 13899.0, loss:0.09223537\n",
      "step: 13900.0, loss:0.28517487\n",
      "step: 13901.0, loss:0.16596878\n",
      "step: 13902.0, loss:0.13696375\n",
      "step: 13903.0, loss:0.24151224\n",
      "step: 13904.0, loss:0.30087954\n",
      "step: 13905.0, loss:0.17439620\n",
      "step: 13906.0, loss:0.21942328\n",
      "step: 13907.0, loss:0.11373923\n",
      "step: 13908.0, loss:0.14959101\n",
      "step: 13909.0, loss:0.13018873\n",
      "step: 13910.0, loss:0.20209328\n",
      "step: 13911.0, loss:0.13224422\n",
      "step: 13912.0, loss:0.20680887\n",
      "step: 13913.0, loss:0.20168334\n",
      "step: 13914.0, loss:0.24392267\n",
      "step: 13915.0, loss:0.08328999\n",
      "step: 13916.0, loss:0.13920226\n",
      "step: 13917.0, loss:0.20716811\n",
      "step: 13918.0, loss:0.24185184\n",
      "step: 13919.0, loss:0.09113457\n",
      "step: 13920.0, loss:0.09185250\n",
      "step: 13921.0, loss:0.22615090\n",
      "step: 13922.0, loss:0.23094595\n",
      "step: 13923.0, loss:0.13879771\n",
      "step: 13924.0, loss:0.27656548\n",
      "step: 13925.0, loss:0.15885331\n",
      "step: 13926.0, loss:0.14078664\n",
      "step: 13927.0, loss:0.12019568\n",
      "step: 13928.0, loss:0.26625565\n",
      "step: 13929.0, loss:0.19744374\n",
      "step: 13930.0, loss:0.12865463\n",
      "step: 13931.0, loss:0.23883055\n",
      "step: 13932.0, loss:0.14194121\n",
      "step: 13933.0, loss:0.15811866\n",
      "step: 13934.0, loss:0.23115816\n",
      "step: 13935.0, loss:0.22324682\n",
      "step: 13936.0, loss:0.17839508\n",
      "step: 13937.0, loss:0.29253957\n",
      "step: 13938.0, loss:0.23132763\n",
      "step: 13939.0, loss:0.25120950\n",
      "step: 13940.0, loss:0.17561155\n",
      "step: 13941.0, loss:0.18512273\n",
      "step: 13942.0, loss:0.15601203\n",
      "step: 13943.0, loss:0.16048914\n",
      "step: 13944.0, loss:0.25862800\n",
      "step: 13945.0, loss:0.14680065\n",
      "step: 13946.0, loss:0.15079641\n",
      "step: 13947.0, loss:0.18532293\n",
      "step: 13948.0, loss:0.19084297\n",
      "step: 13949.0, loss:0.18231910\n",
      "step: 13950.0, loss:0.07991850\n",
      "step: 13951.0, loss:0.20684342\n",
      "step: 13952.0, loss:0.11220563\n",
      "step: 13953.0, loss:0.25196142\n",
      "step: 13954.0, loss:0.14211463\n",
      "step: 13955.0, loss:0.18548133\n",
      "step: 13956.0, loss:0.09790865\n",
      "step: 13957.0, loss:0.08970793\n",
      "step: 13958.0, loss:0.17363901\n",
      "step: 13959.0, loss:0.16934573\n",
      "step: 13960.0, loss:0.18568701\n",
      "step: 13961.0, loss:0.07741580\n",
      "step: 13962.0, loss:0.21228559\n",
      "step: 13963.0, loss:0.17292614\n",
      "step: 13964.0, loss:0.26314211\n",
      "step: 13965.0, loss:0.14207045\n",
      "step: 13966.0, loss:0.21059241\n",
      "step: 13967.0, loss:0.18434826\n",
      "step: 13968.0, loss:0.14788312\n",
      "step: 13969.0, loss:0.27446012\n",
      "step: 13970.0, loss:0.18672173\n",
      "step: 13971.0, loss:0.19055106\n",
      "step: 13972.0, loss:0.25809741\n",
      "step: 13973.0, loss:0.18197116\n",
      "step: 13974.0, loss:0.21179470\n",
      "step: 13975.0, loss:0.29117347\n",
      "step: 13976.0, loss:0.15893042\n",
      "step: 13977.0, loss:0.25330472\n",
      "step: 13978.0, loss:0.14834175\n",
      "step: 13979.0, loss:0.17219825\n",
      "step: 13980.0, loss:0.22416166\n",
      "step: 13981.0, loss:0.27424525\n",
      "step: 13982.0, loss:0.13993530\n",
      "step: 13983.0, loss:0.30329593\n",
      "step: 13984.0, loss:0.32099670\n",
      "step: 13985.0, loss:0.29984238\n",
      "step: 13986.0, loss:0.11153647\n",
      "step: 13987.0, loss:0.21747872\n",
      "step: 13988.0, loss:0.18058969\n",
      "step: 13989.0, loss:0.23052256\n",
      "step: 13990.0, loss:0.21700914\n",
      "step: 13991.0, loss:0.18564915\n",
      "step: 13992.0, loss:0.21911801\n",
      "step: 13993.0, loss:0.23946396\n",
      "step: 13994.0, loss:0.14567466\n",
      "step: 13995.0, loss:0.17567442\n",
      "step: 13996.0, loss:0.27340544\n",
      "step: 13997.0, loss:0.27334643\n",
      "step: 13998.0, loss:0.20546198\n",
      "step: 13999.0, loss:0.18729574\n",
      "step: 14000.0, loss:0.18530374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1264/1264 [09:06<00:00,  2.31it/s]\n",
      "2023-04-03 03:23:00,467 - INFO - step:14000.0, matthews_corr:0.778959, Acc:89.512738%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 14001.0, loss:0.12325616\n",
      "step: 14002.0, loss:0.19198118\n",
      "step: 14003.0, loss:0.32682823\n",
      "step: 14004.0, loss:0.14477158\n",
      "step: 14005.0, loss:0.16198685\n",
      "step: 14006.0, loss:0.26180433\n",
      "step: 14007.0, loss:0.33058739\n",
      "step: 14008.0, loss:0.25387558\n",
      "step: 14009.0, loss:0.15938497\n",
      "step: 14010.0, loss:0.16494913\n",
      "step: 14011.0, loss:0.22183565\n",
      "step: 14012.0, loss:0.25148794\n",
      "step: 14013.0, loss:0.31907088\n",
      "step: 14014.0, loss:0.36923942\n",
      "step: 14015.0, loss:0.25052303\n",
      "step: 14016.0, loss:0.20422445\n",
      "step: 14017.0, loss:0.12453820\n",
      "step: 14018.0, loss:0.20774323\n",
      "step: 14019.0, loss:0.08412029\n",
      "step: 14020.0, loss:0.14920118\n",
      "step: 14021.0, loss:0.27068132\n",
      "step: 14022.0, loss:0.34460859\n",
      "step: 14023.0, loss:0.24431861\n",
      "step: 14024.0, loss:0.10451075\n",
      "step: 14025.0, loss:0.13992085\n",
      "step: 14026.0, loss:0.27945478\n",
      "step: 14027.0, loss:0.16301965\n",
      "step: 14028.0, loss:0.16076177\n",
      "step: 14029.0, loss:0.12800465\n",
      "step: 14030.0, loss:0.22692055\n",
      "step: 14031.0, loss:0.20969428\n",
      "step: 14032.0, loss:0.19543210\n",
      "step: 14033.0, loss:0.33359381\n",
      "step: 14034.0, loss:0.07416522\n",
      "step: 14035.0, loss:0.17143353\n",
      "step: 14036.0, loss:0.12070254\n",
      "step: 14037.0, loss:0.09496480\n",
      "step: 14038.0, loss:0.23936874\n",
      "step: 14039.0, loss:0.15442451\n",
      "step: 14040.0, loss:0.33325104\n",
      "step: 14041.0, loss:0.35298269\n",
      "step: 14042.0, loss:0.19120177\n",
      "step: 14043.0, loss:0.18432167\n",
      "step: 14044.0, loss:0.16777235\n",
      "step: 14045.0, loss:0.17292690\n",
      "step: 14046.0, loss:0.14243185\n",
      "step: 14047.0, loss:0.16528794\n",
      "step: 14048.0, loss:0.14285803\n",
      "step: 14049.0, loss:0.20280342\n",
      "step: 14050.0, loss:0.27926951\n",
      "step: 14051.0, loss:0.30321643\n",
      "step: 14052.0, loss:0.19880398\n",
      "step: 14053.0, loss:0.07978266\n",
      "step: 14054.0, loss:0.22882647\n",
      "step: 14055.0, loss:0.23811249\n",
      "step: 14056.0, loss:0.20719992\n",
      "step: 14057.0, loss:0.11661072\n",
      "step: 14058.0, loss:0.16846261\n",
      "step: 14059.0, loss:0.34774726\n",
      "step: 14060.0, loss:0.16941346\n",
      "step: 14061.0, loss:0.23675282\n",
      "step: 14062.0, loss:0.27935840\n",
      "step: 14063.0, loss:0.22222647\n",
      "step: 14064.0, loss:0.22186192\n",
      "step: 14065.0, loss:0.19364711\n",
      "step: 14066.0, loss:0.13231812\n",
      "step: 14067.0, loss:0.20819988\n",
      "step: 14068.0, loss:0.27950795\n",
      "step: 14069.0, loss:0.28729524\n",
      "step: 14070.0, loss:0.22236367\n",
      "step: 14071.0, loss:0.21383690\n",
      "step: 14072.0, loss:0.12874172\n",
      "step: 14073.0, loss:0.19200072\n",
      "step: 14074.0, loss:0.26381305\n",
      "step: 14075.0, loss:0.25447127\n",
      "step: 14076.0, loss:0.29220327\n",
      "step: 14077.0, loss:0.11706967\n",
      "step: 14078.0, loss:0.16288044\n",
      "step: 14079.0, loss:0.23540025\n",
      "step: 14080.0, loss:0.11222422\n",
      "step: 14081.0, loss:0.19900252\n",
      "step: 14082.0, loss:0.17619719\n",
      "step: 14083.0, loss:0.18621034\n",
      "step: 14084.0, loss:0.21893803\n",
      "step: 14085.0, loss:0.24375076\n",
      "step: 14086.0, loss:0.15723879\n",
      "step: 14087.0, loss:0.25065287\n",
      "step: 14088.0, loss:0.27726952\n",
      "step: 14089.0, loss:0.17485520\n",
      "step: 14090.0, loss:0.26729822\n",
      "step: 14091.0, loss:0.16298763\n",
      "step: 14092.0, loss:0.17110658\n",
      "step: 14093.0, loss:0.13869468\n",
      "step: 14094.0, loss:0.09792991\n",
      "step: 14095.0, loss:0.21571727\n",
      "step: 14096.0, loss:0.23670344\n",
      "step: 14097.0, loss:0.16333512\n",
      "step: 14098.0, loss:0.18853460\n",
      "step: 14099.0, loss:0.24229555\n",
      "step: 14100.0, loss:0.19592468\n",
      "step: 14101.0, loss:0.18770411\n",
      "step: 14102.0, loss:0.24753770\n",
      "step: 14103.0, loss:0.16849664\n",
      "step: 14104.0, loss:0.15473215\n",
      "step: 14105.0, loss:0.22355560\n",
      "step: 14106.0, loss:0.17969971\n",
      "step: 14107.0, loss:0.24013212\n",
      "step: 14108.0, loss:0.23916666\n",
      "step: 14109.0, loss:0.21982611\n",
      "step: 14110.0, loss:0.20840068\n",
      "step: 14111.0, loss:0.19927021\n",
      "step: 14112.0, loss:0.13273949\n",
      "step: 14113.0, loss:0.09311673\n",
      "step: 14114.0, loss:0.15368714\n",
      "step: 14115.0, loss:0.26592250\n",
      "step: 14116.0, loss:0.33873958\n",
      "step: 14117.0, loss:0.21807104\n",
      "step: 14118.0, loss:0.21231597\n",
      "step: 14119.0, loss:0.13837581\n",
      "step: 14120.0, loss:0.18359900\n",
      "step: 14121.0, loss:0.21030302\n",
      "step: 14122.0, loss:0.24582265\n",
      "step: 14123.0, loss:0.19014768\n",
      "step: 14124.0, loss:0.24601956\n",
      "step: 14125.0, loss:0.13289497\n",
      "step: 14126.0, loss:0.18828130\n",
      "step: 14127.0, loss:0.16706284\n",
      "step: 14128.0, loss:0.12296530\n",
      "step: 14129.0, loss:0.15858250\n",
      "step: 14130.0, loss:0.23026439\n",
      "step: 14131.0, loss:0.19919738\n",
      "step: 14132.0, loss:0.24620629\n",
      "step: 14133.0, loss:0.16631323\n",
      "step: 14134.0, loss:0.13458664\n",
      "step: 14135.0, loss:0.19979409\n",
      "step: 14136.0, loss:0.30996276\n",
      "step: 14137.0, loss:0.22019802\n",
      "step: 14138.0, loss:0.20015613\n",
      "step: 14139.0, loss:0.29871953\n",
      "step: 14140.0, loss:0.19882654\n",
      "step: 14141.0, loss:0.24335237\n",
      "step: 14142.0, loss:0.12341972\n",
      "step: 14143.0, loss:0.16646824\n",
      "step: 14144.0, loss:0.13553248\n",
      "step: 14145.0, loss:0.18023212\n",
      "step: 14146.0, loss:0.27373194\n",
      "step: 14147.0, loss:0.13589693\n",
      "step: 14148.0, loss:0.18046043\n",
      "step: 14149.0, loss:0.16478706\n",
      "step: 14150.0, loss:0.16716889\n",
      "step: 14151.0, loss:0.12156097\n",
      "step: 14152.0, loss:0.23211750\n",
      "step: 14153.0, loss:0.15642264\n",
      "step: 14154.0, loss:0.16979395\n",
      "step: 14155.0, loss:0.15374125\n",
      "step: 14156.0, loss:0.14060079\n",
      "step: 14157.0, loss:0.07511991\n",
      "step: 14158.0, loss:0.19548456\n",
      "step: 14159.0, loss:0.17068792\n",
      "step: 14160.0, loss:0.17650953\n",
      "step: 14161.0, loss:0.20495917\n",
      "step: 14162.0, loss:0.31086481\n",
      "step: 14163.0, loss:0.20410078\n",
      "step: 14164.0, loss:0.23446544\n",
      "step: 14165.0, loss:0.18838361\n",
      "step: 14166.0, loss:0.19161953\n",
      "step: 14167.0, loss:0.14668409\n",
      "step: 14168.0, loss:0.11724717\n",
      "step: 14169.0, loss:0.09251055\n",
      "step: 14170.0, loss:0.19718623\n",
      "step: 14171.0, loss:0.14357959\n",
      "step: 14172.0, loss:0.16204386\n",
      "step: 14173.0, loss:0.19858642\n",
      "step: 14174.0, loss:0.13492142\n",
      "step: 14175.0, loss:0.25847279\n",
      "step: 14176.0, loss:0.23475137\n",
      "step: 14177.0, loss:0.14035693\n",
      "step: 14178.0, loss:0.08254337\n",
      "step: 14179.0, loss:0.15694929\n",
      "step: 14180.0, loss:0.18035364\n",
      "step: 14181.0, loss:0.32178613\n",
      "step: 14182.0, loss:0.16670526\n",
      "step: 14183.0, loss:0.13661033\n",
      "step: 14184.0, loss:0.10356970\n",
      "step: 14185.0, loss:0.27525057\n",
      "step: 14186.0, loss:0.16143174\n",
      "step: 14187.0, loss:0.15989106\n",
      "step: 14188.0, loss:0.19417708\n",
      "step: 14189.0, loss:0.10817440\n",
      "step: 14190.0, loss:0.31867694\n",
      "step: 14191.0, loss:0.22483822\n",
      "step: 14192.0, loss:0.15555494\n",
      "step: 14193.0, loss:0.12532941\n",
      "step: 14194.0, loss:0.11298009\n",
      "step: 14195.0, loss:0.11404282\n",
      "step: 14196.0, loss:0.13159515\n",
      "step: 14197.0, loss:0.21826675\n",
      "step: 14198.0, loss:0.22404164\n",
      "step: 14199.0, loss:0.13361908\n",
      "step: 14200.0, loss:0.19850307\n",
      "step: 14201.0, loss:0.12484406\n",
      "step: 14202.0, loss:0.08952917\n",
      "step: 14203.0, loss:0.20315670\n",
      "step: 14204.0, loss:0.17009517\n",
      "step: 14205.0, loss:0.08977203\n",
      "step: 14206.0, loss:0.11941557\n",
      "step: 14207.0, loss:0.16524457\n",
      "step: 14208.0, loss:0.26880157\n",
      "step: 14209.0, loss:0.20545880\n",
      "step: 14210.0, loss:0.18772942\n",
      "step: 14211.0, loss:0.14943695\n",
      "step: 14212.0, loss:0.15405118\n",
      "step: 14213.0, loss:0.30746277\n",
      "step: 14214.0, loss:0.33161848\n",
      "step: 14215.0, loss:0.31369852\n",
      "step: 14216.0, loss:0.19362075\n",
      "step: 14217.0, loss:0.19556511\n",
      "step: 14218.0, loss:0.15310465\n",
      "step: 14219.0, loss:0.11487660\n",
      "step: 14220.0, loss:0.21809005\n",
      "step: 14221.0, loss:0.18246100\n",
      "step: 14222.0, loss:0.27236158\n",
      "step: 14223.0, loss:0.12654271\n",
      "step: 14224.0, loss:0.18124362\n",
      "step: 14225.0, loss:0.31808012\n",
      "step: 14226.0, loss:0.08077207\n",
      "step: 14227.0, loss:0.25257378\n",
      "step: 14228.0, loss:0.13277512\n",
      "step: 14229.0, loss:0.24240709\n",
      "step: 14230.0, loss:0.30638488\n",
      "step: 14231.0, loss:0.17660921\n",
      "step: 14232.0, loss:0.13618179\n",
      "step: 14233.0, loss:0.09204895\n",
      "step: 14234.0, loss:0.29285221\n",
      "step: 14235.0, loss:0.17707832\n",
      "step: 14236.0, loss:0.20288077\n",
      "step: 14237.0, loss:0.25856031\n",
      "step: 14238.0, loss:0.13298420\n",
      "step: 14239.0, loss:0.13553733\n",
      "step: 14240.0, loss:0.13852066\n",
      "step: 14241.0, loss:0.27247152\n",
      "step: 14242.0, loss:0.17677689\n",
      "step: 14243.0, loss:0.19506699\n",
      "step: 14244.0, loss:0.09293473\n",
      "step: 14245.0, loss:0.21201907\n",
      "step: 14246.0, loss:0.17503425\n",
      "step: 14247.0, loss:0.17932187\n",
      "step: 14248.0, loss:0.11176727\n",
      "step: 14249.0, loss:0.24226708\n",
      "step: 14250.0, loss:0.21079202\n",
      "step: 14251.0, loss:0.12697529\n",
      "step: 14252.0, loss:0.21224224\n",
      "step: 14253.0, loss:0.16502254\n",
      "step: 14254.0, loss:0.19793072\n",
      "step: 14255.0, loss:0.10654660\n",
      "step: 14256.0, loss:0.26041854\n",
      "step: 14257.0, loss:0.10851808\n",
      "step: 14258.0, loss:0.12486006\n",
      "step: 14259.0, loss:0.16861508\n",
      "step: 14260.0, loss:0.17918517\n",
      "step: 14261.0, loss:0.20389051\n",
      "step: 14262.0, loss:0.17668299\n",
      "step: 14263.0, loss:0.11726269\n",
      "step: 14264.0, loss:0.26120019\n",
      "step: 14265.0, loss:0.40787086\n",
      "step: 14266.0, loss:0.25900629\n",
      "step: 14267.0, loss:0.19963871\n",
      "step: 14268.0, loss:0.13445681\n",
      "step: 14269.0, loss:0.15817394\n",
      "step: 14270.0, loss:0.12112291\n",
      "step: 14271.0, loss:0.20585888\n",
      "step: 14272.0, loss:0.13354936\n",
      "step: 14273.0, loss:0.09094403\n",
      "step: 14274.0, loss:0.09821913\n",
      "step: 14275.0, loss:0.15289671\n",
      "step: 14276.0, loss:0.14384805\n",
      "step: 14277.0, loss:0.14393660\n",
      "step: 14278.0, loss:0.13975735\n",
      "step: 14279.0, loss:0.24882431\n",
      "step: 14280.0, loss:0.17627747\n",
      "step: 14281.0, loss:0.20859189\n",
      "step: 14282.0, loss:0.11822832\n",
      "step: 14283.0, loss:0.16559782\n",
      "step: 14284.0, loss:0.13473388\n",
      "step: 14285.0, loss:0.13996667\n",
      "step: 14286.0, loss:0.17515180\n",
      "step: 14287.0, loss:0.22449799\n",
      "step: 14288.0, loss:0.28475017\n",
      "step: 14289.0, loss:0.29877733\n",
      "step: 14290.0, loss:0.18463932\n",
      "step: 14291.0, loss:0.17459267\n",
      "step: 14292.0, loss:0.34547268\n",
      "step: 14293.0, loss:0.17927504\n",
      "step: 14294.0, loss:0.19346366\n",
      "step: 14295.0, loss:0.11847101\n",
      "step: 14296.0, loss:0.12159554\n",
      "step: 14297.0, loss:0.16185793\n",
      "step: 14298.0, loss:0.31745912\n",
      "step: 14299.0, loss:0.25066639\n",
      "step: 14300.0, loss:0.17462960\n",
      "step: 14301.0, loss:0.15742854\n",
      "step: 14302.0, loss:0.11025705\n",
      "step: 14303.0, loss:0.21869376\n",
      "step: 14304.0, loss:0.18942534\n",
      "step: 14305.0, loss:0.23194286\n",
      "step: 14306.0, loss:0.19534137\n",
      "step: 14307.0, loss:0.25730941\n",
      "step: 14308.0, loss:0.13254429\n",
      "step: 14309.0, loss:0.20171063\n",
      "step: 14310.0, loss:0.22014189\n",
      "step: 14311.0, loss:0.16000754\n",
      "step: 14312.0, loss:0.23337195\n",
      "step: 14313.0, loss:0.15052126\n",
      "step: 14314.0, loss:0.25828202\n",
      "step: 14315.0, loss:0.19531165\n",
      "step: 14316.0, loss:0.22572014\n",
      "step: 14317.0, loss:0.21238562\n",
      "step: 14318.0, loss:0.15636985\n",
      "step: 14319.0, loss:0.18598797\n",
      "step: 14320.0, loss:0.20544173\n",
      "step: 14321.0, loss:0.10205346\n",
      "step: 14322.0, loss:0.18686563\n",
      "step: 14323.0, loss:0.14235275\n",
      "step: 14324.0, loss:0.22224366\n",
      "step: 14325.0, loss:0.10768926\n",
      "step: 14326.0, loss:0.14598317\n",
      "step: 14327.0, loss:0.17062026\n",
      "step: 14328.0, loss:0.26152859\n",
      "step: 14329.0, loss:0.35090967\n",
      "step: 14330.0, loss:0.18626962\n",
      "step: 14331.0, loss:0.14400875\n",
      "step: 14332.0, loss:0.15230752\n",
      "step: 14333.0, loss:0.13952723\n",
      "step: 14334.0, loss:0.19365645\n",
      "step: 14335.0, loss:0.13640305\n",
      "step: 14336.0, loss:0.15611383\n",
      "step: 14337.0, loss:0.38322629\n",
      "step: 14338.0, loss:0.17994202\n",
      "step: 14339.0, loss:0.19158424\n",
      "step: 14340.0, loss:0.13981893\n",
      "step: 14341.0, loss:0.10152993\n",
      "step: 14342.0, loss:0.18323586\n",
      "step: 14343.0, loss:0.12329552\n",
      "step: 14344.0, loss:0.23347863\n",
      "step: 14345.0, loss:0.18250785\n",
      "step: 14346.0, loss:0.16750929\n",
      "step: 14347.0, loss:0.22798051\n",
      "step: 14348.0, loss:0.22428914\n",
      "step: 14349.0, loss:0.16493934\n",
      "step: 14350.0, loss:0.26689833\n",
      "step: 14351.0, loss:0.30910047\n",
      "step: 14352.0, loss:0.25401653\n",
      "step: 14353.0, loss:0.17484024\n",
      "step: 14354.0, loss:0.14719508\n",
      "step: 14355.0, loss:0.16938822\n",
      "step: 14356.0, loss:0.07555205\n",
      "step: 14357.0, loss:0.08754019\n",
      "step: 14358.0, loss:0.20159046\n",
      "step: 14359.0, loss:0.21069977\n",
      "step: 14360.0, loss:0.11691837\n",
      "step: 14361.0, loss:0.17557384\n",
      "step: 14362.0, loss:0.09889049\n",
      "step: 14363.0, loss:0.20627173\n",
      "step: 14364.0, loss:0.16197999\n",
      "step: 14365.0, loss:0.20319575\n",
      "step: 14366.0, loss:0.25322358\n",
      "step: 14367.0, loss:0.26045009\n",
      "step: 14368.0, loss:0.19787736\n",
      "step: 14369.0, loss:0.20503730\n",
      "step: 14370.0, loss:0.22834294\n",
      "step: 14371.0, loss:0.13400818\n",
      "step: 14372.0, loss:0.20851952\n",
      "step: 14373.0, loss:0.07134171\n",
      "step: 14374.0, loss:0.14045223\n",
      "step: 14375.0, loss:0.34633483\n",
      "step: 14376.0, loss:0.11468900\n",
      "step: 14377.0, loss:0.21073164\n",
      "step: 14378.0, loss:0.21097707\n",
      "step: 14379.0, loss:0.12220554\n",
      "step: 14380.0, loss:0.18062152\n",
      "step: 14381.0, loss:0.14348399\n",
      "step: 14382.0, loss:0.12192214\n",
      "step: 14383.0, loss:0.18340472\n",
      "step: 14384.0, loss:0.25953563\n",
      "step: 14385.0, loss:0.15567999\n",
      "step: 14386.0, loss:0.15342009\n",
      "step: 14387.0, loss:0.12825784\n",
      "step: 14388.0, loss:0.14147014\n",
      "step: 14389.0, loss:0.13661376\n",
      "step: 14390.0, loss:0.23437400\n",
      "step: 14391.0, loss:0.18871772\n",
      "step: 14392.0, loss:0.16127485\n",
      "step: 14393.0, loss:0.22080204\n",
      "step: 14394.0, loss:0.16240176\n",
      "step: 14395.0, loss:0.15293339\n",
      "step: 14396.0, loss:0.07696707\n",
      "step: 14397.0, loss:0.18672754\n",
      "step: 14398.0, loss:0.11332058\n",
      "step: 14399.0, loss:0.18426226\n",
      "step: 14400.0, loss:0.18884092\n",
      "step: 14401.0, loss:0.18194130\n",
      "step: 14402.0, loss:0.33366178\n",
      "step: 14403.0, loss:0.14624858\n",
      "step: 14404.0, loss:0.18463968\n",
      "step: 14405.0, loss:0.21549191\n",
      "step: 14406.0, loss:0.24103392\n",
      "step: 14407.0, loss:0.20840920\n",
      "step: 14408.0, loss:0.22269754\n",
      "step: 14409.0, loss:0.23524630\n",
      "step: 14410.0, loss:0.12212851\n",
      "step: 14411.0, loss:0.09367593\n",
      "step: 14412.0, loss:0.26498618\n",
      "step: 14413.0, loss:0.10108510\n",
      "step: 14414.0, loss:0.24680465\n",
      "step: 14415.0, loss:0.23023268\n",
      "step: 14416.0, loss:0.17227269\n",
      "step: 14417.0, loss:0.18374183\n",
      "step: 14418.0, loss:0.21271924\n",
      "step: 14419.0, loss:0.18888502\n",
      "step: 14420.0, loss:0.20318029\n",
      "step: 14421.0, loss:0.25520146\n",
      "step: 14422.0, loss:0.13215083\n",
      "step: 14423.0, loss:0.10402994\n",
      "step: 14424.0, loss:0.11372768\n",
      "step: 14425.0, loss:0.15303220\n",
      "step: 14426.0, loss:0.17479235\n",
      "step: 14427.0, loss:0.14493183\n",
      "step: 14428.0, loss:0.11771064\n",
      "step: 14429.0, loss:0.07575500\n",
      "step: 14430.0, loss:0.17518110\n",
      "step: 14431.0, loss:0.16755340\n",
      "step: 14432.0, loss:0.17110423\n",
      "step: 14433.0, loss:0.11401772\n",
      "step: 14434.0, loss:0.12981929\n",
      "step: 14435.0, loss:0.27745144\n",
      "step: 14436.0, loss:0.18204282\n",
      "step: 14437.0, loss:0.12163170\n",
      "step: 14438.0, loss:0.16821004\n",
      "step: 14439.0, loss:0.28451430\n",
      "step: 14440.0, loss:0.13436016\n",
      "step: 14441.0, loss:0.13390133\n",
      "step: 14442.0, loss:0.14680481\n",
      "step: 14443.0, loss:0.24675395\n",
      "step: 14444.0, loss:0.24448322\n",
      "step: 14445.0, loss:0.19797740\n",
      "step: 14446.0, loss:0.23042759\n",
      "step: 14447.0, loss:0.16295964\n",
      "step: 14448.0, loss:0.08631854\n",
      "step: 14449.0, loss:0.22589905\n",
      "step: 14450.0, loss:0.22485187\n",
      "step: 14451.0, loss:0.16971639\n",
      "step: 14452.0, loss:0.15720180\n",
      "step: 14453.0, loss:0.15014684\n",
      "step: 14454.0, loss:0.26129480\n",
      "step: 14455.0, loss:0.20987760\n",
      "step: 14456.0, loss:0.16804980\n",
      "step: 14457.0, loss:0.14798017\n",
      "step: 14458.0, loss:0.22012813\n",
      "step: 14459.0, loss:0.13649667\n",
      "step: 14460.0, loss:0.16019568\n",
      "step: 14461.0, loss:0.17465653\n",
      "step: 14462.0, loss:0.17830269\n",
      "step: 14463.0, loss:0.12341185\n",
      "step: 14464.0, loss:0.14377072\n",
      "step: 14465.0, loss:0.15950129\n",
      "step: 14466.0, loss:0.14131680\n",
      "step: 14467.0, loss:0.17639195\n",
      "step: 14468.0, loss:0.11480896\n",
      "step: 14469.0, loss:0.10023452\n",
      "step: 14470.0, loss:0.18572408\n",
      "step: 14471.0, loss:0.31279277\n",
      "step: 14472.0, loss:0.19429169\n",
      "step: 14473.0, loss:0.15205071\n",
      "step: 14474.0, loss:0.17378442\n",
      "step: 14475.0, loss:0.19514492\n",
      "step: 14476.0, loss:0.18068737\n",
      "step: 14477.0, loss:0.12142761\n",
      "step: 14478.0, loss:0.09443204\n",
      "step: 14479.0, loss:0.27251857\n",
      "step: 14480.0, loss:0.08769934\n",
      "step: 14481.0, loss:0.21598974\n",
      "step: 14482.0, loss:0.16646093\n",
      "step: 14483.0, loss:0.21902357\n",
      "step: 14484.0, loss:0.13132128\n",
      "step: 14485.0, loss:0.17350927\n",
      "step: 14486.0, loss:0.25703331\n",
      "step: 14487.0, loss:0.17364109\n",
      "step: 14488.0, loss:0.09118063\n",
      "step: 14489.0, loss:0.17063938\n",
      "step: 14490.0, loss:0.19206007\n",
      "step: 14491.0, loss:0.15029305\n",
      "step: 14492.0, loss:0.12875915\n",
      "step: 14493.0, loss:0.06607271\n",
      "step: 14494.0, loss:0.19149938\n",
      "step: 14495.0, loss:0.10735163\n",
      "step: 14496.0, loss:0.09051755\n",
      "step: 14497.0, loss:0.17195644\n",
      "step: 14498.0, loss:0.17485549\n",
      "step: 14499.0, loss:0.26781698\n",
      "step: 14500.0, loss:0.26950105\n",
      "step: 14501.0, loss:0.13988330\n",
      "step: 14502.0, loss:0.06165768\n",
      "step: 14503.0, loss:0.23806392\n",
      "step: 14504.0, loss:0.13826859\n",
      "step: 14505.0, loss:0.27897730\n",
      "step: 14506.0, loss:0.17312485\n",
      "step: 14507.0, loss:0.11273349\n",
      "step: 14508.0, loss:0.10590556\n",
      "step: 14509.0, loss:0.10276527\n",
      "step: 14510.0, loss:0.16050402\n",
      "step: 14511.0, loss:0.22625756\n",
      "step: 14512.0, loss:0.24819999\n",
      "step: 14513.0, loss:0.08967900\n",
      "step: 14514.0, loss:0.16544179\n",
      "step: 14515.0, loss:0.14478356\n",
      "step: 14516.0, loss:0.14161577\n",
      "step: 14517.0, loss:0.18797562\n",
      "step: 14518.0, loss:0.35550077\n",
      "step: 14519.0, loss:0.22999889\n",
      "step: 14520.0, loss:0.11596226\n",
      "step: 14521.0, loss:0.24026915\n",
      "step: 14522.0, loss:0.27482395\n",
      "step: 14523.0, loss:0.19743974\n",
      "step: 14524.0, loss:0.18682899\n",
      "step: 14525.0, loss:0.17120554\n",
      "step: 14526.0, loss:0.25280594\n",
      "step: 14527.0, loss:0.12646270\n",
      "step: 14528.0, loss:0.10239820\n",
      "step: 14529.0, loss:0.14914121\n",
      "step: 14530.0, loss:0.27764413\n",
      "step: 14531.0, loss:0.20124341\n",
      "step: 14532.0, loss:0.17370183\n",
      "step: 14533.0, loss:0.16243127\n",
      "step: 14534.0, loss:0.21943190\n",
      "step: 14535.0, loss:0.24427682\n",
      "step: 14536.0, loss:0.19200056\n",
      "step: 14537.0, loss:0.19060209\n",
      "step: 14538.0, loss:0.14491469\n",
      "step: 14539.0, loss:0.16548064\n",
      "step: 14540.0, loss:0.14337029\n",
      "step: 14541.0, loss:0.18494360\n",
      "step: 14542.0, loss:0.22859885\n",
      "step: 14543.0, loss:0.12540486\n",
      "step: 14544.0, loss:0.21195691\n",
      "step: 14545.0, loss:0.11561480\n",
      "step: 14546.0, loss:0.14554876\n",
      "step: 14547.0, loss:0.21578026\n",
      "step: 14548.0, loss:0.17264020\n",
      "step: 14549.0, loss:0.20845903\n",
      "step: 14550.0, loss:0.13025006\n",
      "step: 14551.0, loss:0.06515926\n",
      "step: 14552.0, loss:0.19280813\n",
      "step: 14553.0, loss:0.21314510\n",
      "step: 14554.0, loss:0.10581970\n",
      "step: 14555.0, loss:0.33938658\n",
      "step: 14556.0, loss:0.22022119\n",
      "step: 14557.0, loss:0.14884548\n",
      "step: 14558.0, loss:0.20060705\n",
      "step: 14559.0, loss:0.21104683\n",
      "step: 14560.0, loss:0.19522749\n",
      "step: 14561.0, loss:0.12449893\n",
      "step: 14562.0, loss:0.25568717\n",
      "step: 14563.0, loss:0.15266422\n",
      "step: 14564.0, loss:0.09599011\n",
      "step: 14565.0, loss:0.10352671\n",
      "step: 14566.0, loss:0.25647034\n",
      "step: 14567.0, loss:0.18415340\n",
      "step: 14568.0, loss:0.11483606\n",
      "step: 14569.0, loss:0.16290461\n",
      "step: 14570.0, loss:0.14254945\n",
      "step: 14571.0, loss:0.13769208\n",
      "step: 14572.0, loss:0.12708831\n",
      "step: 14573.0, loss:0.41533227\n",
      "step: 14574.0, loss:0.19564659\n",
      "step: 14575.0, loss:0.21839724\n",
      "step: 14576.0, loss:0.29655922\n",
      "step: 14577.0, loss:0.20601548\n",
      "step: 14578.0, loss:0.16132565\n",
      "step: 14579.0, loss:0.24136626\n",
      "step: 14580.0, loss:0.11753670\n",
      "step: 14581.0, loss:0.20817294\n",
      "step: 14582.0, loss:0.14032736\n",
      "step: 14583.0, loss:0.06969967\n",
      "step: 14584.0, loss:0.19804435\n",
      "step: 14585.0, loss:0.30948688\n",
      "step: 14586.0, loss:0.18788472\n",
      "step: 14587.0, loss:0.17695160\n",
      "step: 14588.0, loss:0.14094663\n",
      "step: 14589.0, loss:0.21039108\n",
      "step: 14590.0, loss:0.14601263\n",
      "step: 14591.0, loss:0.16168645\n",
      "step: 14592.0, loss:0.12903200\n",
      "step: 14593.0, loss:0.20325645\n",
      "step: 14594.0, loss:0.23504881\n",
      "step: 14595.0, loss:0.18109014\n",
      "step: 14596.0, loss:0.20318146\n",
      "step: 14597.0, loss:0.13167037\n",
      "step: 14598.0, loss:0.16284965\n",
      "step: 14599.0, loss:0.15331614\n",
      "step: 14600.0, loss:0.19115639\n",
      "step: 14601.0, loss:0.17476268\n",
      "step: 14602.0, loss:0.20833831\n",
      "step: 14603.0, loss:0.16412803\n",
      "step: 14604.0, loss:0.18764399\n",
      "step: 14605.0, loss:0.24605731\n",
      "step: 14606.0, loss:0.19986539\n",
      "step: 14607.0, loss:0.14896189\n",
      "step: 14608.0, loss:0.14129646\n",
      "step: 14609.0, loss:0.16404386\n",
      "step: 14610.0, loss:0.26248365\n",
      "step: 14611.0, loss:0.20266749\n",
      "step: 14612.0, loss:0.16872637\n",
      "step: 14613.0, loss:0.15495807\n",
      "step: 14614.0, loss:0.28365097\n",
      "step: 14615.0, loss:0.11295396\n",
      "step: 14616.0, loss:0.19010973\n",
      "step: 14617.0, loss:0.13038574\n",
      "step: 14618.0, loss:0.27000927\n",
      "step: 14619.0, loss:0.14587556\n",
      "step: 14620.0, loss:0.27204666\n",
      "step: 14621.0, loss:0.17787571\n",
      "step: 14622.0, loss:0.12114107\n",
      "step: 14623.0, loss:0.09729480\n",
      "step: 14624.0, loss:0.14264822\n",
      "step: 14625.0, loss:0.20522691\n",
      "step: 14626.0, loss:0.14183757\n",
      "step: 14627.0, loss:0.16254597\n",
      "step: 14628.0, loss:0.15157660\n",
      "step: 14629.0, loss:0.19825817\n",
      "step: 14630.0, loss:0.22335591\n",
      "step: 14631.0, loss:0.21737818\n",
      "step: 14632.0, loss:0.23384445\n",
      "step: 14633.0, loss:0.34797288\n",
      "step: 14634.0, loss:0.19510231\n",
      "step: 14635.0, loss:0.18841161\n",
      "step: 14636.0, loss:0.22534620\n",
      "step: 14637.0, loss:0.16840267\n",
      "step: 14638.0, loss:0.13194571\n",
      "step: 14639.0, loss:0.17423143\n",
      "step: 14640.0, loss:0.26622346\n",
      "step: 14641.0, loss:0.11214784\n",
      "step: 14642.0, loss:0.10809295\n",
      "step: 14643.0, loss:0.16687389\n",
      "step: 14644.0, loss:0.22500163\n",
      "step: 14645.0, loss:0.13952833\n",
      "step: 14646.0, loss:0.27414943\n",
      "step: 14647.0, loss:0.22938338\n",
      "step: 14648.0, loss:0.25091784\n",
      "step: 14649.0, loss:0.28379968\n",
      "step: 14650.0, loss:0.11569476\n",
      "step: 14651.0, loss:0.14014647\n",
      "step: 14652.0, loss:0.18400050\n",
      "step: 14653.0, loss:0.18604925\n",
      "step: 14654.0, loss:0.19052033\n",
      "step: 14655.0, loss:0.19982745\n",
      "step: 14656.0, loss:0.16936827\n",
      "step: 14657.0, loss:0.08601696\n",
      "step: 14658.0, loss:0.21057924\n",
      "step: 14659.0, loss:0.14090601\n",
      "step: 14660.0, loss:0.18061855\n",
      "step: 14661.0, loss:0.11260842\n",
      "step: 14662.0, loss:0.18650959\n",
      "step: 14663.0, loss:0.21153156\n",
      "step: 14664.0, loss:0.25438496\n",
      "step: 14665.0, loss:0.29680374\n",
      "step: 14666.0, loss:0.24433215\n",
      "step: 14667.0, loss:0.20483389\n",
      "step: 14668.0, loss:0.19235214\n",
      "step: 14669.0, loss:0.15376296\n",
      "step: 14670.0, loss:0.17225958\n",
      "step: 14671.0, loss:0.15364439\n",
      "step: 14672.0, loss:0.21659747\n",
      "step: 14673.0, loss:0.17623289\n",
      "step: 14674.0, loss:0.15237554\n",
      "step: 14675.0, loss:0.16564778\n",
      "step: 14676.0, loss:0.26643594\n",
      "step: 14677.0, loss:0.23579554\n",
      "step: 14678.0, loss:0.20202306\n",
      "step: 14679.0, loss:0.15443810\n",
      "step: 14680.0, loss:0.15105986\n",
      "step: 14681.0, loss:0.19963562\n",
      "step: 14682.0, loss:0.31352528\n",
      "step: 14683.0, loss:0.19155790\n",
      "step: 14684.0, loss:0.12548005\n",
      "step: 14685.0, loss:0.18486427\n",
      "step: 14686.0, loss:0.33760278\n",
      "step: 14687.0, loss:0.18344087\n",
      "step: 14688.0, loss:0.18227153\n",
      "step: 14689.0, loss:0.10649773\n",
      "step: 14690.0, loss:0.17672412\n",
      "step: 14691.0, loss:0.17717276\n",
      "step: 14692.0, loss:0.22593396\n",
      "step: 14693.0, loss:0.15230094\n",
      "step: 14694.0, loss:0.21855938\n",
      "step: 14695.0, loss:0.22506955\n",
      "step: 14696.0, loss:0.18045250\n",
      "step: 14697.0, loss:0.23996917\n",
      "step: 14698.0, loss:0.13894281\n",
      "step: 14699.0, loss:0.24237263\n",
      "step: 14700.0, loss:0.19137705\n",
      "step: 14701.0, loss:0.26776655\n",
      "step: 14702.0, loss:0.22064383\n",
      "step: 14703.0, loss:0.14849690\n",
      "step: 14704.0, loss:0.13931212\n",
      "step: 14705.0, loss:0.21067034\n",
      "step: 14706.0, loss:0.17343420\n",
      "step: 14707.0, loss:0.18318579\n",
      "step: 14708.0, loss:0.15080424\n",
      "step: 14709.0, loss:0.19210455\n",
      "step: 14710.0, loss:0.16522973\n",
      "step: 14711.0, loss:0.17153580\n",
      "step: 14712.0, loss:0.19370616\n",
      "step: 14713.0, loss:0.16863514\n",
      "step: 14714.0, loss:0.20600857\n",
      "step: 14715.0, loss:0.09091812\n",
      "step: 14716.0, loss:0.27021083\n",
      "step: 14717.0, loss:0.22134963\n",
      "step: 14718.0, loss:0.15449851\n",
      "step: 14719.0, loss:0.19920092\n",
      "step: 14720.0, loss:0.21001463\n",
      "step: 14721.0, loss:0.06228085\n",
      "step: 14722.0, loss:0.27650145\n",
      "step: 14723.0, loss:0.21350879\n",
      "step: 14724.0, loss:0.17617497\n",
      "step: 14725.0, loss:0.27278738\n",
      "step: 14726.0, loss:0.15435869\n",
      "step: 14727.0, loss:0.14877145\n",
      "step: 14728.0, loss:0.16355338\n",
      "step: 14729.0, loss:0.22398690\n",
      "step: 14730.0, loss:0.18155955\n",
      "step: 14731.0, loss:0.13227164\n",
      "step: 14732.0, loss:0.18189689\n",
      "step: 14733.0, loss:0.13284056\n",
      "step: 14734.0, loss:0.15838727\n",
      "step: 14735.0, loss:0.08641960\n",
      "step: 14736.0, loss:0.12561343\n",
      "step: 14737.0, loss:0.15879735\n",
      "step: 14738.0, loss:0.18436785\n",
      "step: 14739.0, loss:0.15381759\n",
      "step: 14740.0, loss:0.21294202\n",
      "step: 14741.0, loss:0.14921494\n",
      "step: 14742.0, loss:0.25903041\n",
      "step: 14743.0, loss:0.28853106\n",
      "step: 14744.0, loss:0.08303158\n",
      "step: 14745.0, loss:0.09017334\n",
      "step: 14746.0, loss:0.12539115\n",
      "step: 14747.0, loss:0.23687319\n",
      "step: 14748.0, loss:0.14218629\n",
      "step: 14749.0, loss:0.10945186\n",
      "step: 14750.0, loss:0.18518434\n",
      "step: 14751.0, loss:0.13416995\n",
      "step: 14752.0, loss:0.09338408\n",
      "step: 14753.0, loss:0.10834302\n",
      "step: 14754.0, loss:0.28498048\n",
      "step: 14755.0, loss:0.15720839\n",
      "step: 14756.0, loss:0.20741298\n",
      "step: 14757.0, loss:0.16102244\n",
      "step: 14758.0, loss:0.21697582\n",
      "step: 14759.0, loss:0.28983353\n",
      "step: 14760.0, loss:0.21610734\n",
      "step: 14761.0, loss:0.26625735\n",
      "step: 14762.0, loss:0.17590475\n",
      "step: 14763.0, loss:0.28673450\n",
      "step: 14764.0, loss:0.20130345\n",
      "step: 14765.0, loss:0.22176204\n",
      "step: 14766.0, loss:0.15700326\n",
      "step: 14767.0, loss:0.26782264\n",
      "step: 14768.0, loss:0.09856736\n",
      "step: 14769.0, loss:0.19018484\n",
      "step: 14770.0, loss:0.20460450\n",
      "step: 14771.0, loss:0.14410729\n",
      "step: 14772.0, loss:0.10680283\n",
      "step: 14773.0, loss:0.18166067\n",
      "step: 14774.0, loss:0.19443813\n",
      "step: 14775.0, loss:0.17406979\n",
      "step: 14776.0, loss:0.13635226\n",
      "step: 14777.0, loss:0.28316863\n",
      "step: 14778.0, loss:0.14199169\n",
      "step: 14779.0, loss:0.19535752\n",
      "step: 14780.0, loss:0.24175694\n",
      "step: 14781.0, loss:0.22588334\n",
      "step: 14782.0, loss:0.25124888\n",
      "step: 14783.0, loss:0.16446488\n",
      "step: 14784.0, loss:0.12442747\n",
      "step: 14785.0, loss:0.13308861\n",
      "step: 14786.0, loss:0.23177837\n",
      "step: 14787.0, loss:0.20798603\n",
      "step: 14788.0, loss:0.13019727\n",
      "step: 14789.0, loss:0.21873833\n",
      "step: 14790.0, loss:0.16273422\n",
      "step: 14791.0, loss:0.24651425\n",
      "step: 14792.0, loss:0.15958900\n",
      "step: 14793.0, loss:0.22211566\n",
      "step: 14794.0, loss:0.15625393\n",
      "step: 14795.0, loss:0.17512905\n",
      "step: 14796.0, loss:0.27009755\n",
      "step: 14797.0, loss:0.12015100\n",
      "step: 14798.0, loss:0.22119166\n",
      "step: 14799.0, loss:0.18090096\n",
      "step: 14800.0, loss:0.29775534\n",
      "step: 14801.0, loss:0.29588677\n",
      "step: 14802.0, loss:0.22681407\n",
      "step: 14803.0, loss:0.20601173\n",
      "step: 14804.0, loss:0.18626027\n",
      "step: 14805.0, loss:0.20722060\n",
      "step: 14806.0, loss:0.22281147\n",
      "step: 14807.0, loss:0.14625753\n",
      "step: 14808.0, loss:0.21142406\n",
      "step: 14809.0, loss:0.23254067\n",
      "step: 14810.0, loss:0.19277105\n",
      "step: 14811.0, loss:0.32535566\n",
      "step: 14812.0, loss:0.22676965\n",
      "step: 14813.0, loss:0.14759460\n",
      "step: 14814.0, loss:0.22010290\n",
      "step: 14815.0, loss:0.18042207\n",
      "step: 14816.0, loss:0.14148724\n",
      "step: 14817.0, loss:0.25034081\n",
      "step: 14818.0, loss:0.17539495\n",
      "step: 14819.0, loss:0.15238071\n",
      "step: 14820.0, loss:0.12126874\n",
      "step: 14821.0, loss:0.29329793\n",
      "step: 14822.0, loss:0.09650068\n",
      "step: 14823.0, loss:0.33131458\n",
      "step: 14824.0, loss:0.19016807\n",
      "step: 14825.0, loss:0.20014690\n",
      "step: 14826.0, loss:0.28474624\n",
      "step: 14827.0, loss:0.31536648\n",
      "step: 14828.0, loss:0.22796252\n",
      "step: 14829.0, loss:0.15505447\n",
      "step: 14830.0, loss:0.16283629\n",
      "step: 14831.0, loss:0.17586481\n",
      "step: 14832.0, loss:0.23123248\n",
      "step: 14833.0, loss:0.15450376\n",
      "step: 14834.0, loss:0.24347720\n",
      "step: 14835.0, loss:0.20499003\n",
      "step: 14836.0, loss:0.27941193\n",
      "step: 14837.0, loss:0.13724933\n",
      "step: 14838.0, loss:0.11409009\n",
      "step: 14839.0, loss:0.21161822\n",
      "step: 14840.0, loss:0.10325812\n",
      "step: 14841.0, loss:0.20350503\n",
      "step: 14842.0, loss:0.28086202\n",
      "step: 14843.0, loss:0.14894853\n",
      "step: 14844.0, loss:0.21253251\n",
      "step: 14845.0, loss:0.12582131\n",
      "step: 14846.0, loss:0.14939484\n",
      "step: 14847.0, loss:0.19481240\n",
      "step: 14848.0, loss:0.19092374\n",
      "step: 14849.0, loss:0.11867180\n",
      "step: 14850.0, loss:0.19968879\n",
      "step: 14851.0, loss:0.05463236\n",
      "step: 14852.0, loss:0.20164209\n",
      "step: 14853.0, loss:0.26878513\n",
      "step: 14854.0, loss:0.24823028\n",
      "step: 14855.0, loss:0.17151780\n",
      "step: 14856.0, loss:0.28169604\n",
      "step: 14857.0, loss:0.22935017\n",
      "step: 14858.0, loss:0.15057765\n",
      "step: 14859.0, loss:0.13724737\n",
      "step: 14860.0, loss:0.19886769\n",
      "step: 14861.0, loss:0.30996159\n",
      "step: 14862.0, loss:0.19457621\n",
      "step: 14863.0, loss:0.13266303\n",
      "step: 14864.0, loss:0.19943269\n",
      "step: 14865.0, loss:0.33856530\n",
      "step: 14866.0, loss:0.15157187\n",
      "step: 14867.0, loss:0.16601161\n",
      "step: 14868.0, loss:0.23541236\n",
      "step: 14869.0, loss:0.19857377\n",
      "step: 14870.0, loss:0.21559704\n",
      "step: 14871.0, loss:0.19319929\n",
      "step: 14872.0, loss:0.22467862\n",
      "step: 14873.0, loss:0.16469981\n",
      "step: 14874.0, loss:0.25595389\n",
      "step: 14875.0, loss:0.16967117\n",
      "step: 14876.0, loss:0.25376108\n",
      "step: 14877.0, loss:0.13306449\n",
      "step: 14878.0, loss:0.12420609\n",
      "step: 14879.0, loss:0.18058396\n",
      "step: 14880.0, loss:0.11472710\n",
      "step: 14881.0, loss:0.21825688\n",
      "step: 14882.0, loss:0.14291838\n",
      "step: 14883.0, loss:0.11960853\n",
      "step: 14884.0, loss:0.19412476\n",
      "step: 14885.0, loss:0.19408632\n",
      "step: 14886.0, loss:0.13945905\n",
      "step: 14887.0, loss:0.22444437\n",
      "step: 14888.0, loss:0.11980378\n",
      "step: 14889.0, loss:0.09248395\n",
      "step: 14890.0, loss:0.28157572\n",
      "step: 14891.0, loss:0.22279176\n",
      "step: 14892.0, loss:0.25476328\n",
      "step: 14893.0, loss:0.10747495\n",
      "step: 14894.0, loss:0.26992762\n",
      "step: 14895.0, loss:0.14841814\n",
      "step: 14896.0, loss:0.19370509\n",
      "step: 14897.0, loss:0.22111728\n",
      "step: 14898.0, loss:0.20009036\n",
      "step: 14899.0, loss:0.16868712\n",
      "step: 14900.0, loss:0.23149077\n",
      "step: 14901.0, loss:0.17698730\n",
      "step: 14902.0, loss:0.15439784\n",
      "step: 14903.0, loss:0.11874618\n",
      "step: 14904.0, loss:0.18956810\n",
      "step: 14905.0, loss:0.12212654\n",
      "step: 14906.0, loss:0.12117296\n",
      "step: 14907.0, loss:0.19767690\n",
      "step: 14908.0, loss:0.15939989\n",
      "step: 14909.0, loss:0.17834765\n",
      "step: 14910.0, loss:0.25703885\n",
      "step: 14911.0, loss:0.30291109\n",
      "step: 14912.0, loss:0.19436643\n",
      "step: 14913.0, loss:0.14522255\n",
      "step: 14914.0, loss:0.26788227\n",
      "step: 14915.0, loss:0.14929785\n",
      "step: 14916.0, loss:0.31163867\n",
      "step: 14917.0, loss:0.19293071\n",
      "step: 14918.0, loss:0.28525793\n",
      "step: 14919.0, loss:0.19454309\n",
      "step: 14920.0, loss:0.19674328\n",
      "step: 14921.0, loss:0.14267895\n",
      "step: 14922.0, loss:0.14946132\n",
      "step: 14923.0, loss:0.19621045\n",
      "step: 14924.0, loss:0.18355840\n",
      "step: 14925.0, loss:0.25615946\n",
      "step: 14926.0, loss:0.29152007\n",
      "step: 14927.0, loss:0.40784271\n",
      "step: 14928.0, loss:0.13582993\n",
      "step: 14929.0, loss:0.10577165\n",
      "step: 14930.0, loss:0.24835660\n",
      "step: 14931.0, loss:0.20475169\n",
      "step: 14932.0, loss:0.22900892\n",
      "step: 14933.0, loss:0.19003847\n",
      "step: 14934.0, loss:0.27954014\n",
      "step: 14935.0, loss:0.14153315\n",
      "step: 14936.0, loss:0.15926922\n",
      "step: 14937.0, loss:0.25607217\n",
      "step: 14938.0, loss:0.24667057\n",
      "step: 14939.0, loss:0.10707918\n",
      "step: 14940.0, loss:0.13170896\n",
      "step: 14941.0, loss:0.15670580\n",
      "step: 14942.0, loss:0.17348765\n",
      "step: 14943.0, loss:0.23987057\n",
      "step: 14944.0, loss:0.15115335\n",
      "step: 14945.0, loss:0.21218828\n",
      "step: 14946.0, loss:0.21944868\n",
      "step: 14947.0, loss:0.23237922\n",
      "step: 14948.0, loss:0.25798380\n",
      "step: 14949.0, loss:0.18118510\n",
      "step: 14950.0, loss:0.15544148\n",
      "step: 14951.0, loss:0.17703100\n",
      "step: 14952.0, loss:0.15392614\n",
      "step: 14953.0, loss:0.12324097\n",
      "step: 14954.0, loss:0.19346741\n",
      "step: 14955.0, loss:0.15503983\n",
      "step: 14956.0, loss:0.19819077\n",
      "step: 14957.0, loss:0.27643987\n",
      "step: 14958.0, loss:0.12176112\n",
      "step: 14959.0, loss:0.08663194\n",
      "step: 14960.0, loss:0.23054920\n",
      "step: 14961.0, loss:0.18760516\n",
      "step: 14962.0, loss:0.30746769\n",
      "step: 14963.0, loss:0.18466457\n",
      "step: 14964.0, loss:0.12245954\n",
      "step: 14965.0, loss:0.22847107\n",
      "step: 14966.0, loss:0.13542482\n",
      "step: 14967.0, loss:0.21142278\n",
      "step: 14968.0, loss:0.25447697\n",
      "step: 14969.0, loss:0.12782641\n",
      "step: 14970.0, loss:0.23750756\n",
      "step: 14971.0, loss:0.21190694\n",
      "step: 14972.0, loss:0.23441475\n",
      "step: 14973.0, loss:0.20716097\n",
      "step: 14974.0, loss:0.19448504\n",
      "step: 14975.0, loss:0.18449431\n",
      "step: 14976.0, loss:0.13290234\n",
      "step: 14977.0, loss:0.13312238\n",
      "step: 14978.0, loss:0.25657203\n",
      "step: 14979.0, loss:0.15068869\n",
      "step: 14980.0, loss:0.17481340\n",
      "step: 14981.0, loss:0.21642745\n",
      "step: 14982.0, loss:0.08855086\n",
      "step: 14983.0, loss:0.14927772\n",
      "step: 14984.0, loss:0.11374456\n",
      "step: 14985.0, loss:0.14197495\n",
      "step: 14986.0, loss:0.10250724\n",
      "step: 14987.0, loss:0.09956229\n",
      "step: 14988.0, loss:0.18084719\n",
      "step: 14989.0, loss:0.12968628\n",
      "step: 14990.0, loss:0.10360491\n",
      "step: 14991.0, loss:0.27456828\n",
      "step: 14992.0, loss:0.11610598\n",
      "step: 14993.0, loss:0.11898429\n",
      "step: 14994.0, loss:0.18040884\n",
      "step: 14995.0, loss:0.21146391\n",
      "step: 14996.0, loss:0.18534731\n",
      "step: 14997.0, loss:0.14983498\n",
      "step: 14998.0, loss:0.22363835\n",
      "step: 14999.0, loss:0.18462413\n",
      "step: 15000.0, loss:0.20250522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1264/1264 [07:03<00:00,  2.98it/s]\n",
      "2023-04-03 04:08:06,321 - INFO - step:15000.0, matthews_corr:0.778817, Acc:89.351966%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 15001.0, loss:0.11909167\n",
      "step: 15002.0, loss:0.19490119\n",
      "step: 15003.0, loss:0.25069860\n",
      "step: 15004.0, loss:0.16387094\n",
      "step: 15005.0, loss:0.15010906\n",
      "step: 15006.0, loss:0.17104198\n",
      "step: 15007.0, loss:0.18073647\n",
      "step: 15008.0, loss:0.16353778\n",
      "step: 15009.0, loss:0.18193450\n",
      "step: 15010.0, loss:0.14867556\n",
      "step: 15011.0, loss:0.25500568\n",
      "step: 15012.0, loss:0.09116602\n",
      "step: 15013.0, loss:0.09374430\n",
      "step: 15014.0, loss:0.21561908\n",
      "step: 15015.0, loss:0.16142588\n",
      "step: 15016.0, loss:0.12143107\n",
      "step: 15017.0, loss:0.12225501\n",
      "step: 15018.0, loss:0.27021883\n",
      "step: 15019.0, loss:0.22491220\n",
      "step: 15020.0, loss:0.16974873\n",
      "step: 15021.0, loss:0.15946730\n",
      "step: 15022.0, loss:0.17367357\n",
      "step: 15023.0, loss:0.41769826\n",
      "step: 15024.0, loss:0.09025283\n",
      "step: 15025.0, loss:0.13962571\n",
      "step: 15026.0, loss:0.10721672\n",
      "step: 15027.0, loss:0.12288456\n",
      "step: 15028.0, loss:0.14336579\n",
      "step: 15029.0, loss:0.19885936\n",
      "step: 15030.0, loss:0.11649552\n",
      "step: 15031.0, loss:0.15694586\n",
      "step: 15032.0, loss:0.19351980\n",
      "step: 15033.0, loss:0.25704946\n",
      "step: 15034.0, loss:0.09131132\n",
      "step: 15035.0, loss:0.12793428\n",
      "step: 15036.0, loss:0.19935017\n",
      "step: 15037.0, loss:0.21046145\n",
      "step: 15038.0, loss:0.21344732\n",
      "step: 15039.0, loss:0.18542802\n",
      "step: 15040.0, loss:0.24389811\n",
      "step: 15041.0, loss:0.12997342\n",
      "step: 15042.0, loss:0.29579106\n",
      "step: 15043.0, loss:0.21036473\n",
      "step: 15044.0, loss:0.19627580\n",
      "step: 15045.0, loss:0.27313953\n",
      "step: 15046.0, loss:0.35570851\n",
      "step: 15047.0, loss:0.16900750\n",
      "step: 15048.0, loss:0.12824682\n",
      "step: 15049.0, loss:0.22004450\n",
      "step: 15050.0, loss:0.11105510\n",
      "step: 15051.0, loss:0.21508980\n",
      "step: 15052.0, loss:0.15143194\n",
      "step: 15053.0, loss:0.23738781\n",
      "step: 15054.0, loss:0.25845212\n",
      "step: 15055.0, loss:0.13550609\n",
      "step: 15056.0, loss:0.21493246\n",
      "step: 15057.0, loss:0.27567970\n",
      "step: 15058.0, loss:0.24287587\n",
      "step: 15059.0, loss:0.20374807\n",
      "step: 15060.0, loss:0.30070447\n",
      "step: 15061.0, loss:0.22293130\n",
      "step: 15062.0, loss:0.16483804\n",
      "step: 15063.0, loss:0.12775776\n",
      "step: 15064.0, loss:0.17300789\n",
      "step: 15065.0, loss:0.12534758\n",
      "step: 15066.0, loss:0.12492823\n",
      "step: 15067.0, loss:0.19334935\n",
      "step: 15068.0, loss:0.23463251\n",
      "step: 15069.0, loss:0.17233852\n",
      "step: 15070.0, loss:0.27073698\n",
      "step: 15071.0, loss:0.12639666\n",
      "step: 15072.0, loss:0.19435871\n",
      "step: 15073.0, loss:0.14119341\n",
      "step: 15074.0, loss:0.23318323\n",
      "step: 15075.0, loss:0.16130100\n",
      "step: 15076.0, loss:0.16388564\n",
      "step: 15077.0, loss:0.16892268\n",
      "step: 15078.0, loss:0.23180305\n",
      "step: 15079.0, loss:0.20315317\n",
      "step: 15080.0, loss:0.15021753\n",
      "step: 15081.0, loss:0.09174155\n",
      "step: 15082.0, loss:0.24645569\n",
      "step: 15083.0, loss:0.07554321\n",
      "step: 15084.0, loss:0.34083241\n",
      "step: 15085.0, loss:0.23615125\n",
      "step: 15086.0, loss:0.15014314\n",
      "step: 15087.0, loss:0.22145340\n",
      "step: 15088.0, loss:0.15193394\n",
      "step: 15089.0, loss:0.17937814\n",
      "step: 15090.0, loss:0.17789540\n",
      "step: 15091.0, loss:0.14170972\n",
      "step: 15092.0, loss:0.25838649\n",
      "step: 15093.0, loss:0.09857082\n",
      "step: 15094.0, loss:0.12182174\n",
      "step: 15095.0, loss:0.19609597\n",
      "step: 15096.0, loss:0.12561639\n",
      "step: 15097.0, loss:0.09976208\n",
      "step: 15098.0, loss:0.11793178\n",
      "step: 15099.0, loss:0.10790217\n",
      "step: 15100.0, loss:0.07880742\n",
      "step: 15101.0, loss:0.11856365\n",
      "step: 15102.0, loss:0.15226685\n",
      "step: 15103.0, loss:0.14283408\n",
      "step: 15104.0, loss:0.19178937\n",
      "step: 15105.0, loss:0.11817333\n",
      "step: 15106.0, loss:0.19579946\n",
      "step: 15107.0, loss:0.14611957\n",
      "step: 15108.0, loss:0.16990080\n",
      "step: 15109.0, loss:0.24130557\n",
      "step: 15110.0, loss:0.12931983\n",
      "step: 15111.0, loss:0.16439403\n",
      "step: 15112.0, loss:0.12833867\n",
      "step: 15113.0, loss:0.15340842\n",
      "step: 15114.0, loss:0.16462679\n",
      "step: 15115.0, loss:0.25673141\n",
      "step: 15116.0, loss:0.11968402\n",
      "step: 15117.0, loss:0.33934065\n",
      "step: 15118.0, loss:0.21323839\n",
      "step: 15119.0, loss:0.18560129\n",
      "step: 15120.0, loss:0.16079498\n",
      "step: 15121.0, loss:0.12374913\n",
      "step: 15122.0, loss:0.16186518\n",
      "step: 15123.0, loss:0.15543525\n",
      "step: 15124.0, loss:0.19833110\n",
      "step: 15125.0, loss:0.19451636\n",
      "step: 15126.0, loss:0.06526272\n",
      "step: 15127.0, loss:0.22076894\n",
      "step: 15128.0, loss:0.13883771\n",
      "step: 15129.0, loss:0.14949234\n",
      "step: 15130.0, loss:0.17559659\n",
      "step: 15131.0, loss:0.12538079\n",
      "step: 15132.0, loss:0.23020639\n",
      "step: 15133.0, loss:0.22559267\n",
      "step: 15134.0, loss:0.20621328\n",
      "step: 15135.0, loss:0.21758903\n",
      "step: 15136.0, loss:0.11217909\n",
      "step: 15137.0, loss:0.18283483\n",
      "step: 15138.0, loss:0.11959601\n",
      "step: 15139.0, loss:0.14533779\n",
      "step: 15140.0, loss:0.12631102\n",
      "step: 15141.0, loss:0.13548692\n",
      "step: 15142.0, loss:0.20198748\n",
      "step: 15143.0, loss:0.28126090\n",
      "step: 15144.0, loss:0.20346151\n",
      "step: 15145.0, loss:0.29368805\n",
      "step: 15146.0, loss:0.15483146\n",
      "step: 15147.0, loss:0.14821153\n",
      "step: 15148.0, loss:0.16316473\n",
      "step: 15149.0, loss:0.09736652\n",
      "step: 15150.0, loss:0.28989975\n",
      "step: 15151.0, loss:0.12011793\n",
      "step: 15152.0, loss:0.16428011\n",
      "step: 15153.0, loss:0.13775701\n",
      "step: 15154.0, loss:0.14139738\n",
      "step: 15155.0, loss:0.15276738\n",
      "step: 15156.0, loss:0.27676219\n",
      "step: 15157.0, loss:0.11165371\n",
      "step: 15158.0, loss:0.13960744\n",
      "step: 15159.0, loss:0.12795834\n",
      "step: 15160.0, loss:0.23174698\n",
      "step: 15161.0, loss:0.12338720\n",
      "step: 15162.0, loss:0.23979584\n",
      "step: 15163.0, loss:0.13235761\n",
      "step: 15164.0, loss:0.19690967\n",
      "step: 15165.0, loss:0.11336970\n",
      "step: 15166.0, loss:0.24815341\n",
      "step: 15167.0, loss:0.05647986\n",
      "step: 15168.0, loss:0.26978403\n",
      "step: 15169.0, loss:0.10528163\n",
      "step: 15170.0, loss:0.22847620\n",
      "step: 15171.0, loss:0.31205497\n",
      "step: 15172.0, loss:0.13012850\n",
      "step: 15173.0, loss:0.17645306\n",
      "step: 15174.0, loss:0.09942867\n",
      "step: 15175.0, loss:0.26199359\n",
      "step: 15176.0, loss:0.11440719\n",
      "step: 15177.0, loss:0.14414829\n",
      "step: 15178.0, loss:0.18157122\n",
      "step: 15179.0, loss:0.16266667\n",
      "step: 15180.0, loss:0.14653703\n",
      "step: 15181.0, loss:0.12714159\n",
      "step: 15182.0, loss:0.08125397\n",
      "step: 15183.0, loss:0.21921822\n",
      "step: 15184.0, loss:0.22958928\n",
      "step: 15185.0, loss:0.23024512\n",
      "step: 15186.0, loss:0.11545376\n",
      "step: 15187.0, loss:0.11381723\n",
      "step: 15188.0, loss:0.20874420\n",
      "step: 15189.0, loss:0.21646225\n",
      "step: 15190.0, loss:0.17982117\n",
      "step: 15191.0, loss:0.22667399\n",
      "step: 15192.0, loss:0.14900442\n",
      "step: 15193.0, loss:0.14284504\n",
      "step: 15194.0, loss:0.27003833\n",
      "step: 15195.0, loss:0.23145587\n",
      "step: 15196.0, loss:0.25246105\n",
      "step: 15197.0, loss:0.08735339\n",
      "step: 15198.0, loss:0.13813263\n",
      "step: 15199.0, loss:0.15046817\n",
      "step: 15200.0, loss:0.15106149\n",
      "step: 15201.0, loss:0.11302848\n",
      "step: 15202.0, loss:0.21715131\n",
      "step: 15203.0, loss:0.16778432\n",
      "step: 15204.0, loss:0.22770542\n",
      "step: 15205.0, loss:0.25366327\n",
      "step: 15206.0, loss:0.11611565\n",
      "step: 15207.0, loss:0.14088726\n",
      "step: 15208.0, loss:0.20025418\n",
      "step: 15209.0, loss:0.20807699\n",
      "step: 15210.0, loss:0.15241627\n",
      "step: 15211.0, loss:0.14410228\n",
      "step: 15212.0, loss:0.22590608\n",
      "step: 15213.0, loss:0.10734926\n",
      "step: 15214.0, loss:0.15112459\n",
      "step: 15215.0, loss:0.12383548\n",
      "step: 15216.0, loss:0.19738398\n",
      "step: 15217.0, loss:0.16990212\n",
      "step: 15218.0, loss:0.14383205\n",
      "step: 15219.0, loss:0.18838663\n",
      "step: 15220.0, loss:0.14853595\n",
      "step: 15221.0, loss:0.12438630\n",
      "step: 15222.0, loss:0.22409897\n",
      "step: 15223.0, loss:0.24123682\n",
      "step: 15224.0, loss:0.08168932\n",
      "step: 15225.0, loss:0.15640528\n",
      "step: 15226.0, loss:0.14296122\n",
      "step: 15227.0, loss:0.33514482\n",
      "step: 15228.0, loss:0.23692336\n",
      "step: 15229.0, loss:0.13978938\n",
      "step: 15230.0, loss:0.09120416\n",
      "step: 15231.0, loss:0.10217496\n",
      "step: 15232.0, loss:0.18824990\n",
      "step: 15233.0, loss:0.23272136\n",
      "step: 15234.0, loss:0.17851012\n",
      "step: 15235.0, loss:0.17973372\n",
      "step: 15236.0, loss:0.14055049\n",
      "step: 15237.0, loss:0.09694749\n",
      "step: 15238.0, loss:0.08431839\n",
      "step: 15239.0, loss:0.16078811\n",
      "step: 15240.0, loss:0.14665323\n",
      "step: 15241.0, loss:0.18589869\n",
      "step: 15242.0, loss:0.15083838\n",
      "step: 15243.0, loss:0.19185457\n",
      "step: 15244.0, loss:0.18181925\n",
      "step: 15245.0, loss:0.14297019\n",
      "step: 15246.0, loss:0.08994794\n",
      "step: 15247.0, loss:0.19304885\n",
      "step: 15248.0, loss:0.13494542\n",
      "step: 15249.0, loss:0.08805335\n",
      "step: 15250.0, loss:0.21682195\n",
      "step: 15251.0, loss:0.19927799\n",
      "step: 15252.0, loss:0.29935019\n",
      "step: 15253.0, loss:0.24919369\n",
      "step: 15254.0, loss:0.13440099\n",
      "step: 15255.0, loss:0.13454401\n",
      "step: 15256.0, loss:0.18740085\n",
      "step: 15257.0, loss:0.10960250\n",
      "step: 15258.0, loss:0.14812655\n",
      "step: 15259.0, loss:0.11180840\n",
      "step: 15260.0, loss:0.28829288\n",
      "step: 15261.0, loss:0.20710143\n",
      "step: 15262.0, loss:0.13764882\n",
      "step: 15263.0, loss:0.20155460\n",
      "step: 15264.0, loss:0.11714720\n",
      "step: 15265.0, loss:0.20887264\n",
      "step: 15266.0, loss:0.18206139\n",
      "step: 15267.0, loss:0.12772693\n",
      "step: 15268.0, loss:0.10954994\n",
      "step: 15269.0, loss:0.15492293\n",
      "step: 15270.0, loss:0.11836122\n",
      "step: 15271.0, loss:0.16202958\n",
      "step: 15272.0, loss:0.13826537\n",
      "step: 15273.0, loss:0.12579976\n",
      "step: 15274.0, loss:0.24673434\n",
      "step: 15275.0, loss:0.22364840\n",
      "step: 15276.0, loss:0.24177341\n",
      "step: 15277.0, loss:0.20015832\n",
      "step: 15278.0, loss:0.15713741\n",
      "step: 15279.0, loss:0.18582924\n",
      "step: 15280.0, loss:0.18158776\n",
      "step: 15281.0, loss:0.10137426\n",
      "step: 15282.0, loss:0.20006207\n",
      "step: 15283.0, loss:0.18442122\n",
      "step: 15284.0, loss:0.29873807\n",
      "step: 15285.0, loss:0.29853659\n",
      "step: 15286.0, loss:0.20769232\n",
      "step: 15287.0, loss:0.26026613\n",
      "step: 15288.0, loss:0.27629205\n",
      "step: 15289.0, loss:0.12918215\n",
      "step: 15290.0, loss:0.14814842\n",
      "step: 15291.0, loss:0.14665071\n",
      "step: 15292.0, loss:0.20930357\n",
      "step: 15293.0, loss:0.15627914\n",
      "step: 15294.0, loss:0.33409773\n",
      "step: 15295.0, loss:0.22397503\n",
      "step: 15296.0, loss:0.14977802\n",
      "step: 15297.0, loss:0.16207355\n",
      "step: 15298.0, loss:0.16970195\n",
      "step: 15299.0, loss:0.23347410\n",
      "step: 15300.0, loss:0.17015013\n",
      "step: 15301.0, loss:0.16868887\n",
      "step: 15302.0, loss:0.16462849\n",
      "step: 15303.0, loss:0.19874076\n",
      "step: 15304.0, loss:0.16748875\n",
      "step: 15305.0, loss:0.17025335\n",
      "step: 15306.0, loss:0.16100423\n",
      "step: 15307.0, loss:0.17421314\n",
      "step: 15308.0, loss:0.17556080\n",
      "step: 15309.0, loss:0.12162660\n",
      "step: 15310.0, loss:0.21626828\n",
      "step: 15311.0, loss:0.14293564\n",
      "step: 15312.0, loss:0.10885695\n",
      "step: 15313.0, loss:0.37216538\n",
      "step: 15314.0, loss:0.24761310\n",
      "step: 15315.0, loss:0.29241963\n",
      "step: 15316.0, loss:0.22288037\n",
      "step: 15317.0, loss:0.09177974\n",
      "step: 15318.0, loss:0.05409472\n",
      "step: 15319.0, loss:0.26781879\n",
      "step: 15320.0, loss:0.11052722\n",
      "step: 15321.0, loss:0.21293231\n",
      "step: 15322.0, loss:0.13926552\n",
      "step: 15323.0, loss:0.30522794\n",
      "step: 15324.0, loss:0.21203741\n",
      "step: 15325.0, loss:0.21978317\n",
      "step: 15326.0, loss:0.14224367\n",
      "step: 15327.0, loss:0.10963422\n",
      "step: 15328.0, loss:0.13652114\n",
      "step: 15329.0, loss:0.09520212\n",
      "step: 15330.0, loss:0.17670875\n",
      "step: 15331.0, loss:0.17738349\n",
      "step: 15332.0, loss:0.11366060\n",
      "step: 15333.0, loss:0.13944599\n",
      "step: 15334.0, loss:0.27941249\n",
      "step: 15335.0, loss:0.26097189\n",
      "step: 15336.0, loss:0.25168938\n",
      "step: 15337.0, loss:0.14697661\n",
      "step: 15338.0, loss:0.20190860\n",
      "step: 15339.0, loss:0.24813311\n",
      "step: 15340.0, loss:0.12577326\n",
      "step: 15341.0, loss:0.13379193\n",
      "step: 15342.0, loss:0.30053775\n",
      "step: 15343.0, loss:0.11312411\n",
      "step: 15344.0, loss:0.17156459\n",
      "step: 15345.0, loss:0.22667291\n",
      "step: 15346.0, loss:0.16697476\n",
      "step: 15347.0, loss:0.19212086\n",
      "step: 15348.0, loss:0.18280150\n",
      "step: 15349.0, loss:0.19516395\n",
      "step: 15350.0, loss:0.11136550\n",
      "step: 15351.0, loss:0.12280049\n",
      "step: 15352.0, loss:0.22463908\n",
      "step: 15353.0, loss:0.28539928\n",
      "step: 15354.0, loss:0.15117749\n",
      "step: 15355.0, loss:0.26303356\n",
      "step: 15356.0, loss:0.13766458\n",
      "step: 15357.0, loss:0.20460876\n",
      "step: 15358.0, loss:0.20538719\n",
      "step: 15359.0, loss:0.12988283\n",
      "step: 15360.0, loss:0.11002132\n",
      "step: 15361.0, loss:0.24760106\n",
      "step: 15362.0, loss:0.24654788\n",
      "step: 15363.0, loss:0.15793994\n",
      "step: 15364.0, loss:0.17725292\n",
      "step: 15365.0, loss:0.11982590\n",
      "step: 15366.0, loss:0.05682190\n",
      "step: 15367.0, loss:0.24145788\n",
      "step: 15368.0, loss:0.25961854\n",
      "step: 15369.0, loss:0.11350449\n",
      "step: 15370.0, loss:0.14884856\n",
      "step: 15371.0, loss:0.32072148\n",
      "step: 15372.0, loss:0.16213738\n",
      "step: 15373.0, loss:0.24947294\n",
      "step: 15374.0, loss:0.20237828\n",
      "step: 15375.0, loss:0.14148843\n",
      "step: 15376.0, loss:0.22942152\n",
      "step: 15377.0, loss:0.17682912\n",
      "step: 15378.0, loss:0.13467649\n",
      "step: 15379.0, loss:0.12321809\n",
      "step: 15380.0, loss:0.13081725\n",
      "step: 15381.0, loss:0.12866095\n",
      "step: 15382.0, loss:0.17816482\n",
      "step: 15383.0, loss:0.33883867\n",
      "step: 15384.0, loss:0.12243404\n",
      "step: 15385.0, loss:0.16625690\n",
      "step: 15386.0, loss:0.10966941\n",
      "step: 15387.0, loss:0.18910549\n",
      "step: 15388.0, loss:0.16105442\n",
      "step: 15389.0, loss:0.21617609\n",
      "step: 15390.0, loss:0.21571836\n",
      "step: 15391.0, loss:0.19259815\n",
      "step: 15392.0, loss:0.10057715\n",
      "step: 15393.0, loss:0.27321781\n",
      "step: 15394.0, loss:0.25738737\n",
      "step: 15395.0, loss:0.23496503\n",
      "step: 15396.0, loss:0.15134715\n",
      "step: 15397.0, loss:0.12580431\n",
      "step: 15398.0, loss:0.30476612\n",
      "step: 15399.0, loss:0.12011013\n",
      "step: 15400.0, loss:0.20734097\n",
      "step: 15401.0, loss:0.15514930\n",
      "step: 15402.0, loss:0.14336765\n",
      "step: 15403.0, loss:0.08784503\n",
      "step: 15404.0, loss:0.18508724\n",
      "step: 15405.0, loss:0.12906459\n",
      "step: 15406.0, loss:0.10595953\n",
      "step: 15407.0, loss:0.13456787\n",
      "step: 15408.0, loss:0.17895745\n",
      "step: 15409.0, loss:0.21466061\n",
      "step: 15410.0, loss:0.18355215\n",
      "step: 15411.0, loss:0.17158624\n",
      "step: 15412.0, loss:0.15287873\n",
      "step: 15413.0, loss:0.12240185\n",
      "step: 15414.0, loss:0.14780492\n",
      "step: 15415.0, loss:0.15656419\n",
      "step: 15416.0, loss:0.18381771\n",
      "step: 15417.0, loss:0.13904321\n",
      "step: 15418.0, loss:0.15793618\n",
      "step: 15419.0, loss:0.16815290\n",
      "step: 15420.0, loss:0.12935843\n",
      "step: 15421.0, loss:0.15968058\n",
      "step: 15422.0, loss:0.21725516\n",
      "step: 15423.0, loss:0.30797117\n",
      "step: 15424.0, loss:0.19904126\n",
      "step: 15425.0, loss:0.23109492\n",
      "step: 15426.0, loss:0.20862995\n",
      "step: 15427.0, loss:0.14973423\n",
      "step: 15428.0, loss:0.07918415\n",
      "step: 15429.0, loss:0.20236597\n",
      "step: 15430.0, loss:0.18047900\n",
      "step: 15431.0, loss:0.27487653\n",
      "step: 15432.0, loss:0.13945258\n",
      "step: 15433.0, loss:0.17001010\n",
      "step: 15434.0, loss:0.21766061\n",
      "step: 15435.0, loss:0.16983216\n",
      "step: 15436.0, loss:0.17012211\n",
      "step: 15437.0, loss:0.16899936\n",
      "step: 15438.0, loss:0.37730682\n",
      "step: 15439.0, loss:0.14143964\n",
      "step: 15440.0, loss:0.18131254\n",
      "step: 15441.0, loss:0.20305150\n",
      "step: 15442.0, loss:0.14379453\n",
      "step: 15443.0, loss:0.22088363\n",
      "step: 15444.0, loss:0.17502671\n",
      "step: 15445.0, loss:0.10058851\n",
      "step: 15446.0, loss:0.19078188\n",
      "step: 15447.0, loss:0.16477726\n",
      "step: 15448.0, loss:0.15876623\n",
      "step: 15449.0, loss:0.20043106\n",
      "step: 15450.0, loss:0.20605240\n",
      "step: 15451.0, loss:0.11724085\n",
      "step: 15452.0, loss:0.15048382\n",
      "step: 15453.0, loss:0.23167989\n",
      "step: 15454.0, loss:0.13332777\n",
      "step: 15455.0, loss:0.24381941\n",
      "step: 15456.0, loss:0.29444562\n",
      "step: 15457.0, loss:0.15688563\n",
      "step: 15458.0, loss:0.19392545\n",
      "step: 15459.0, loss:0.11469933\n",
      "step: 15460.0, loss:0.08279669\n",
      "step: 15461.0, loss:0.28484222\n",
      "step: 15462.0, loss:0.26705555\n",
      "step: 15463.0, loss:0.12584731\n",
      "step: 15464.0, loss:0.09677981\n",
      "step: 15465.0, loss:0.17609716\n",
      "step: 15466.0, loss:0.16679654\n",
      "step: 15467.0, loss:0.15045000\n",
      "step: 15468.0, loss:0.15934894\n",
      "step: 15469.0, loss:0.16425860\n",
      "step: 15470.0, loss:0.16518741\n",
      "step: 15471.0, loss:0.29459891\n",
      "step: 15472.0, loss:0.21656938\n",
      "step: 15473.0, loss:0.24845753\n",
      "step: 15474.0, loss:0.17064312\n",
      "step: 15475.0, loss:0.12585334\n",
      "step: 15476.0, loss:0.12723686\n",
      "step: 15477.0, loss:0.31829347\n",
      "step: 15478.0, loss:0.16157324\n",
      "step: 15479.0, loss:0.29117706\n",
      "step: 15480.0, loss:0.10896053\n",
      "step: 15481.0, loss:0.09208982\n",
      "step: 15482.0, loss:0.15587958\n",
      "step: 15483.0, loss:0.22477979\n",
      "step: 15484.0, loss:0.12121322\n",
      "step: 15485.0, loss:0.08101501\n",
      "step: 15486.0, loss:0.12629128\n",
      "step: 15487.0, loss:0.16957015\n",
      "step: 15488.0, loss:0.17143359\n",
      "step: 15489.0, loss:0.12453747\n",
      "step: 15490.0, loss:0.18559352\n",
      "step: 15491.0, loss:0.26228738\n",
      "step: 15492.0, loss:0.10221771\n",
      "step: 15493.0, loss:0.19714921\n",
      "step: 15494.0, loss:0.12564649\n",
      "step: 15495.0, loss:0.21918473\n",
      "step: 15496.0, loss:0.15962143\n",
      "step: 15497.0, loss:0.18557988\n",
      "step: 15498.0, loss:0.16903184\n",
      "step: 15499.0, loss:0.13297972\n",
      "step: 15500.0, loss:0.25101994\n",
      "step: 15501.0, loss:0.28301759\n",
      "step: 15502.0, loss:0.13090849\n",
      "step: 15503.0, loss:0.19828793\n",
      "step: 15504.0, loss:0.12279817\n",
      "step: 15505.0, loss:0.18714203\n",
      "step: 15506.0, loss:0.20683318\n",
      "step: 15507.0, loss:0.19818508\n",
      "step: 15508.0, loss:0.16618910\n",
      "step: 15509.0, loss:0.27078559\n",
      "step: 15510.0, loss:0.19168598\n",
      "step: 15511.0, loss:0.18056905\n",
      "step: 15512.0, loss:0.17442761\n",
      "step: 15513.0, loss:0.13483025\n",
      "step: 15514.0, loss:0.11816933\n",
      "step: 15515.0, loss:0.12677022\n",
      "step: 15516.0, loss:0.22909432\n",
      "step: 15517.0, loss:0.21898742\n",
      "step: 15518.0, loss:0.11206872\n",
      "step: 15519.0, loss:0.09574659\n",
      "step: 15520.0, loss:0.18995890\n",
      "step: 15521.0, loss:0.27055060\n",
      "step: 15522.0, loss:0.16789625\n",
      "step: 15523.0, loss:0.15113449\n",
      "step: 15524.0, loss:0.18367535\n",
      "step: 15525.0, loss:0.16487222\n",
      "step: 15526.0, loss:0.12774777\n",
      "step: 15527.0, loss:0.14696475\n",
      "step: 15528.0, loss:0.32383912\n",
      "step: 15529.0, loss:0.17562879\n",
      "step: 15530.0, loss:0.16444990\n",
      "step: 15531.0, loss:0.21352310\n",
      "step: 15532.0, loss:0.17926545\n",
      "step: 15533.0, loss:0.14552933\n",
      "step: 15534.0, loss:0.16539004\n",
      "step: 15535.0, loss:0.28183829\n",
      "step: 15536.0, loss:0.21813703\n",
      "step: 15537.0, loss:0.25511878\n",
      "step: 15538.0, loss:0.16477192\n",
      "step: 15539.0, loss:0.20368567\n",
      "step: 15540.0, loss:0.26713778\n",
      "step: 15541.0, loss:0.21414861\n",
      "step: 15542.0, loss:0.35606403\n",
      "step: 15543.0, loss:0.25323958\n",
      "step: 15544.0, loss:0.31098579\n",
      "step: 15545.0, loss:0.28921179\n",
      "step: 15546.0, loss:0.17930038\n",
      "step: 15547.0, loss:0.21622048\n",
      "step: 15548.0, loss:0.21952487\n",
      "step: 15549.0, loss:0.15788301\n",
      "step: 15550.0, loss:0.15461942\n",
      "step: 15551.0, loss:0.24240280\n",
      "step: 15552.0, loss:0.12475077\n",
      "step: 15553.0, loss:0.18199516\n",
      "step: 15554.0, loss:0.22234955\n",
      "step: 15555.0, loss:0.29681253\n",
      "step: 15556.0, loss:0.29909900\n",
      "step: 15557.0, loss:0.13038120\n",
      "step: 15558.0, loss:0.10973006\n",
      "step: 15559.0, loss:0.21290838\n",
      "step: 15560.0, loss:0.14576439\n",
      "step: 15561.0, loss:0.13598482\n",
      "step: 15562.0, loss:0.10362474\n",
      "step: 15563.0, loss:0.16126029\n",
      "step: 15564.0, loss:0.30576020\n",
      "step: 15565.0, loss:0.22997188\n",
      "step: 15566.0, loss:0.12827381\n",
      "step: 15567.0, loss:0.14211889\n",
      "step: 15568.0, loss:0.13565646\n",
      "step: 15569.0, loss:0.16075693\n",
      "step: 15570.0, loss:0.13651020\n",
      "step: 15571.0, loss:0.12033683\n",
      "step: 15572.0, loss:0.14439778\n",
      "step: 15573.0, loss:0.16336214\n",
      "step: 15574.0, loss:0.15718064\n",
      "step: 15575.0, loss:0.14276997\n",
      "step: 15576.0, loss:0.07984511\n",
      "step: 15577.0, loss:0.14984093\n",
      "step: 15578.0, loss:0.18367572\n",
      "step: 15579.0, loss:0.26263770\n",
      "step: 15580.0, loss:0.29801491\n",
      "step: 15581.0, loss:0.24668233\n",
      "step: 15582.0, loss:0.26487372\n",
      "step: 15583.0, loss:0.21569637\n",
      "step: 15584.0, loss:0.27234079\n",
      "step: 15585.0, loss:0.22881605\n",
      "step: 15586.0, loss:0.12835299\n",
      "step: 15587.0, loss:0.10327091\n",
      "step: 15588.0, loss:0.16891553\n",
      "step: 15589.0, loss:0.19823339\n",
      "step: 15590.0, loss:0.17067514\n",
      "step: 15591.0, loss:0.14599736\n",
      "step: 15592.0, loss:0.23072047\n",
      "step: 15593.0, loss:0.15887452\n",
      "step: 15594.0, loss:0.24265578\n",
      "step: 15595.0, loss:0.41124010\n",
      "step: 15596.0, loss:0.17492734\n",
      "step: 15597.0, loss:0.11750997\n",
      "step: 15598.0, loss:0.19206734\n",
      "step: 15599.0, loss:0.26471693\n",
      "step: 15600.0, loss:0.18055639\n",
      "step: 15601.0, loss:0.16263670\n",
      "step: 15602.0, loss:0.20897437\n",
      "step: 15603.0, loss:0.14264291\n",
      "step: 15604.0, loss:0.21609166\n",
      "step: 15605.0, loss:0.23681823\n",
      "step: 15606.0, loss:0.09261441\n",
      "step: 15607.0, loss:0.12973187\n",
      "step: 15608.0, loss:0.18422250\n",
      "step: 15609.0, loss:0.19071665\n",
      "step: 15610.0, loss:0.21960779\n",
      "step: 15611.0, loss:0.11155445\n",
      "step: 15612.0, loss:0.17124679\n",
      "step: 15613.0, loss:0.12934984\n",
      "step: 15614.0, loss:0.16596216\n",
      "step: 15615.0, loss:0.18437647\n",
      "step: 15616.0, loss:0.14878721\n",
      "step: 15617.0, loss:0.12289077\n",
      "step: 15618.0, loss:0.14626648\n",
      "step: 15619.0, loss:0.17566584\n",
      "step: 15620.0, loss:0.13683852\n",
      "step: 15621.0, loss:0.19989744\n",
      "step: 15622.0, loss:0.20756544\n",
      "step: 15623.0, loss:0.18577497\n",
      "step: 15624.0, loss:0.09818375\n",
      "step: 15625.0, loss:0.14995687\n",
      "step: 15626.0, loss:0.14851784\n",
      "step: 15627.0, loss:0.20612617\n",
      "step: 15628.0, loss:0.17518273\n",
      "step: 15629.0, loss:0.22283570\n",
      "step: 15630.0, loss:0.15810903\n",
      "step: 15631.0, loss:0.10167277\n",
      "step: 15632.0, loss:0.30105881\n",
      "step: 15633.0, loss:0.22867115\n",
      "step: 15634.0, loss:0.21921099\n",
      "step: 15635.0, loss:0.19005379\n",
      "step: 15636.0, loss:0.16522356\n",
      "step: 15637.0, loss:0.13788171\n",
      "step: 15638.0, loss:0.15099768\n",
      "step: 15639.0, loss:0.08430247\n",
      "step: 15640.0, loss:0.14167136\n",
      "step: 15641.0, loss:0.13072740\n",
      "step: 15642.0, loss:0.13853387\n",
      "step: 15643.0, loss:0.09485209\n",
      "step: 15644.0, loss:0.27153558\n",
      "step: 15645.0, loss:0.15838369\n",
      "step: 15646.0, loss:0.13542980\n",
      "step: 15647.0, loss:0.19688720\n",
      "step: 15648.0, loss:0.12673030\n",
      "step: 15649.0, loss:0.18573303\n",
      "step: 15650.0, loss:0.28272142\n",
      "step: 15651.0, loss:0.11694807\n",
      "step: 15652.0, loss:0.33075288\n",
      "step: 15653.0, loss:0.16611794\n",
      "step: 15654.0, loss:0.07851443\n",
      "step: 15655.0, loss:0.27872936\n",
      "step: 15656.0, loss:0.15585591\n",
      "step: 15657.0, loss:0.17281752\n",
      "step: 15658.0, loss:0.18231552\n",
      "step: 15659.0, loss:0.22392656\n",
      "step: 15660.0, loss:0.21586904\n",
      "step: 15661.0, loss:0.28310160\n",
      "step: 15662.0, loss:0.12088455\n",
      "step: 15663.0, loss:0.19562007\n",
      "step: 15664.0, loss:0.14779944\n",
      "step: 15665.0, loss:0.23466996\n",
      "step: 15666.0, loss:0.14425638\n",
      "step: 15667.0, loss:0.24952712\n",
      "step: 15668.0, loss:0.19060101\n",
      "step: 15669.0, loss:0.14401400\n",
      "step: 15670.0, loss:0.16891272\n",
      "step: 15671.0, loss:0.17499638\n",
      "step: 15672.0, loss:0.10081421\n",
      "step: 15673.0, loss:0.22009001\n",
      "step: 15674.0, loss:0.12212023\n",
      "step: 15675.0, loss:0.23662554\n",
      "step: 15676.0, loss:0.25766891\n",
      "step: 15677.0, loss:0.13093499\n",
      "step: 15678.0, loss:0.17882752\n",
      "step: 15679.0, loss:0.29825855\n",
      "step: 15680.0, loss:0.18951901\n",
      "step: 15681.0, loss:0.17014236\n",
      "step: 15682.0, loss:0.12687047\n",
      "step: 15683.0, loss:0.18380359\n",
      "step: 15684.0, loss:0.20302611\n",
      "step: 15685.0, loss:0.23087528\n",
      "step: 15686.0, loss:0.15542164\n",
      "step: 15687.0, loss:0.26022977\n",
      "step: 15688.0, loss:0.21486397\n",
      "step: 15689.0, loss:0.10853241\n",
      "step: 15690.0, loss:0.12580850\n",
      "step: 15691.0, loss:0.16398053\n",
      "step: 15692.0, loss:0.18639411\n",
      "step: 15693.0, loss:0.11453472\n",
      "step: 15694.0, loss:0.24604191\n",
      "step: 15695.0, loss:0.21268176\n",
      "step: 15696.0, loss:0.27851035\n",
      "step: 15697.0, loss:0.30657368\n",
      "step: 15698.0, loss:0.25621913\n",
      "step: 15699.0, loss:0.23602153\n",
      "step: 15700.0, loss:0.22555881\n",
      "step: 15701.0, loss:0.07983782\n",
      "step: 15702.0, loss:0.06305772\n",
      "step: 15703.0, loss:0.15904366\n",
      "step: 15704.0, loss:0.20283497\n",
      "step: 15705.0, loss:0.15782287\n",
      "step: 15706.0, loss:0.16631375\n",
      "step: 15707.0, loss:0.24588180\n",
      "step: 15708.0, loss:0.21242889\n",
      "step: 15709.0, loss:0.13137227\n",
      "step: 15710.0, loss:0.19523678\n",
      "step: 15711.0, loss:0.10916685\n",
      "step: 15712.0, loss:0.14194032\n",
      "step: 15713.0, loss:0.27788751\n",
      "step: 15714.0, loss:0.23855613\n",
      "step: 15715.0, loss:0.09967364\n",
      "step: 15716.0, loss:0.11659277\n",
      "step: 15717.0, loss:0.17245697\n",
      "step: 15718.0, loss:0.15351799\n",
      "step: 15719.0, loss:0.14378453\n",
      "step: 15720.0, loss:0.18107219\n",
      "step: 15721.0, loss:0.16718523\n",
      "step: 15722.0, loss:0.17943349\n",
      "step: 15723.0, loss:0.09695438\n",
      "step: 15724.0, loss:0.09121556\n",
      "step: 15725.0, loss:0.16308306\n",
      "step: 15726.0, loss:0.21502004\n",
      "step: 15727.0, loss:0.15427902\n",
      "step: 15728.0, loss:0.18588894\n",
      "step: 15729.0, loss:0.18673761\n",
      "step: 15730.0, loss:0.17606325\n",
      "step: 15731.0, loss:0.23681409\n",
      "step: 15732.0, loss:0.17674613\n",
      "step: 15733.0, loss:0.15762678\n",
      "step: 15734.0, loss:0.19532074\n",
      "step: 15735.0, loss:0.16788301\n",
      "step: 15736.0, loss:0.17416256\n",
      "step: 15737.0, loss:0.10048407\n",
      "step: 15738.0, loss:0.18691884\n",
      "step: 15739.0, loss:0.19882693\n",
      "step: 15740.0, loss:0.15587213\n",
      "step: 15741.0, loss:0.12559581\n",
      "step: 15742.0, loss:0.07571358\n",
      "step: 15743.0, loss:0.25418434\n",
      "step: 15744.0, loss:0.12381832\n",
      "step: 15745.0, loss:0.16037978\n",
      "step: 15746.0, loss:0.24804797\n",
      "step: 15747.0, loss:0.15905778\n",
      "step: 15748.0, loss:0.12094513\n",
      "step: 15749.0, loss:0.11175147\n",
      "step: 15750.0, loss:0.23926524\n",
      "step: 15751.0, loss:0.19431837\n",
      "step: 15752.0, loss:0.26862225\n",
      "step: 15753.0, loss:0.17635103\n",
      "step: 15754.0, loss:0.12245420\n",
      "step: 15755.0, loss:0.11986288\n",
      "step: 15756.0, loss:0.21750782\n",
      "step: 15757.0, loss:0.24363806\n",
      "step: 15758.0, loss:0.15699053\n",
      "step: 15759.0, loss:0.21399280\n",
      "step: 15760.0, loss:0.06911109\n",
      "step: 15761.0, loss:0.09541986\n",
      "step: 15762.0, loss:0.18901401\n",
      "step: 15763.0, loss:0.10905612\n",
      "step: 15764.0, loss:0.12402185\n",
      "step: 15765.0, loss:0.21538822\n",
      "step: 15766.0, loss:0.10211842\n",
      "step: 15767.0, loss:0.10933630\n",
      "step: 15768.0, loss:0.21810336\n",
      "step: 15769.0, loss:0.13472752\n",
      "step: 15770.0, loss:0.20972453\n",
      "step: 15771.0, loss:0.18694091\n",
      "step: 15772.0, loss:0.13416078\n",
      "step: 15773.0, loss:0.21850145\n",
      "step: 15774.0, loss:0.19067328\n",
      "step: 15775.0, loss:0.24249703\n",
      "step: 15776.0, loss:0.11234279\n",
      "step: 15777.0, loss:0.20456784\n",
      "step: 15778.0, loss:0.23469874\n",
      "step: 15779.0, loss:0.14692119\n",
      "step: 15780.0, loss:0.16431047\n",
      "step: 15781.0, loss:0.14796516\n",
      "step: 15782.0, loss:0.03212627\n",
      "step: 15783.0, loss:0.14775195\n",
      "step: 15784.0, loss:0.19804264\n",
      "step: 15785.0, loss:0.18176363\n",
      "step: 15786.0, loss:0.15535633\n",
      "step: 15787.0, loss:0.17047212\n",
      "step: 15788.0, loss:0.18038848\n",
      "step: 15789.0, loss:0.14935307\n",
      "step: 15790.0, loss:0.11632608\n",
      "step: 15791.0, loss:0.27516326\n",
      "step: 15792.0, loss:0.20076106\n",
      "step: 15793.0, loss:0.17959081\n",
      "step: 15794.0, loss:0.13361830\n",
      "step: 15795.0, loss:0.15580718\n",
      "step: 15796.0, loss:0.19452818\n",
      "step: 15797.0, loss:0.16028678\n",
      "step: 15798.0, loss:0.24362756\n",
      "step: 15799.0, loss:0.26690290\n",
      "step: 15800.0, loss:0.32538008\n",
      "step: 15801.0, loss:0.27530731\n",
      "step: 15802.0, loss:0.17891452\n",
      "step: 15803.0, loss:0.09898494\n",
      "step: 15804.0, loss:0.14437996\n",
      "step: 15805.0, loss:0.09984610\n",
      "step: 15806.0, loss:0.11431771\n",
      "step: 15807.0, loss:0.23722151\n",
      "step: 15808.0, loss:0.20013520\n",
      "step: 15809.0, loss:0.16944514\n",
      "step: 15810.0, loss:0.13443278\n",
      "step: 15811.0, loss:0.19910789\n",
      "step: 15812.0, loss:0.07812221\n",
      "step: 15813.0, loss:0.13073580\n",
      "step: 15814.0, loss:0.14955688\n",
      "step: 15815.0, loss:0.21628460\n",
      "step: 15816.0, loss:0.09567478\n",
      "step: 15817.0, loss:0.17315623\n",
      "step: 15818.0, loss:0.19381236\n",
      "step: 15819.0, loss:0.20172330\n",
      "step: 15820.0, loss:0.16259130\n",
      "step: 15821.0, loss:0.14738298\n",
      "step: 15822.0, loss:0.08260087\n",
      "step: 15823.0, loss:0.16029720\n",
      "step: 15824.0, loss:0.18517498\n",
      "step: 15825.0, loss:0.23978897\n",
      "step: 15826.0, loss:0.14096062\n",
      "step: 15827.0, loss:0.19471624\n",
      "step: 15828.0, loss:0.24332678\n",
      "step: 15829.0, loss:0.16334593\n",
      "step: 15830.0, loss:0.21685942\n",
      "step: 15831.0, loss:0.23231586\n",
      "step: 15832.0, loss:0.15324684\n",
      "step: 15833.0, loss:0.20521412\n",
      "step: 15834.0, loss:0.27738082\n",
      "step: 15835.0, loss:0.10564804\n",
      "step: 15836.0, loss:0.10445304\n",
      "step: 15837.0, loss:0.23425734\n",
      "step: 15838.0, loss:0.14976822\n",
      "step: 15839.0, loss:0.10508145\n",
      "step: 15840.0, loss:0.16591780\n",
      "step: 15841.0, loss:0.13517726\n",
      "step: 15842.0, loss:0.24046386\n",
      "step: 15843.0, loss:0.24472174\n",
      "step: 15844.0, loss:0.23828195\n",
      "step: 15845.0, loss:0.15928903\n",
      "step: 15846.0, loss:0.21174222\n",
      "step: 15847.0, loss:0.13292391\n",
      "step: 15848.0, loss:0.17174649\n",
      "step: 15849.0, loss:0.18605796\n",
      "step: 15850.0, loss:0.23493958\n",
      "step: 15851.0, loss:0.19451232\n",
      "step: 15852.0, loss:0.18508126\n",
      "step: 15853.0, loss:0.18523750\n",
      "step: 15854.0, loss:0.20091660\n",
      "step: 15855.0, loss:0.29543927\n",
      "step: 15856.0, loss:0.15502738\n",
      "step: 15857.0, loss:0.12192490\n",
      "step: 15858.0, loss:0.19323879\n",
      "step: 15859.0, loss:0.09333389\n",
      "step: 15860.0, loss:0.12809475\n",
      "step: 15861.0, loss:0.21894245\n",
      "step: 15862.0, loss:0.14382007\n",
      "step: 15863.0, loss:0.28108297\n",
      "step: 15864.0, loss:0.12101321\n",
      "step: 15865.0, loss:0.11531288\n",
      "step: 15866.0, loss:0.21334867\n",
      "step: 15867.0, loss:0.13159697\n",
      "step: 15868.0, loss:0.14705897\n",
      "step: 15869.0, loss:0.12293505\n",
      "step: 15870.0, loss:0.13491120\n",
      "step: 15871.0, loss:0.09081446\n",
      "step: 15872.0, loss:0.14001069\n",
      "step: 15873.0, loss:0.09701089\n",
      "step: 15874.0, loss:0.20972677\n",
      "step: 15875.0, loss:0.12422529\n",
      "step: 15876.0, loss:0.21287523\n",
      "step: 15877.0, loss:0.16037045\n",
      "step: 15878.0, loss:0.17239490\n",
      "step: 15879.0, loss:0.14492391\n",
      "step: 15880.0, loss:0.24370306\n",
      "step: 15881.0, loss:0.25943679\n",
      "step: 15882.0, loss:0.19206738\n",
      "step: 15883.0, loss:0.23769371\n",
      "step: 15884.0, loss:0.16652823\n",
      "step: 15885.0, loss:0.13646925\n",
      "step: 15886.0, loss:0.13932985\n",
      "step: 15887.0, loss:0.12855674\n",
      "step: 15888.0, loss:0.18430274\n",
      "step: 15889.0, loss:0.23882239\n",
      "step: 15890.0, loss:0.19702374\n",
      "step: 15891.0, loss:0.13067244\n",
      "step: 15892.0, loss:0.16772548\n",
      "step: 15893.0, loss:0.18634827\n",
      "step: 15894.0, loss:0.14665984\n",
      "step: 15895.0, loss:0.12643560\n",
      "step: 15896.0, loss:0.17487596\n",
      "step: 15897.0, loss:0.16924517\n",
      "step: 15898.0, loss:0.12408079\n",
      "step: 15899.0, loss:0.13095283\n",
      "step: 15900.0, loss:0.16208357\n",
      "step: 15901.0, loss:0.17188044\n",
      "step: 15902.0, loss:0.09118440\n",
      "step: 15903.0, loss:0.16561025\n",
      "step: 15904.0, loss:0.10674269\n",
      "step: 15905.0, loss:0.19896046\n",
      "step: 15906.0, loss:0.18506423\n",
      "step: 15907.0, loss:0.16510544\n",
      "step: 15908.0, loss:0.36962060\n",
      "step: 15909.0, loss:0.19036645\n",
      "step: 15910.0, loss:0.15295732\n",
      "step: 15911.0, loss:0.16025404\n",
      "step: 15912.0, loss:0.22422691\n",
      "step: 15913.0, loss:0.23306444\n",
      "step: 15914.0, loss:0.14630663\n",
      "step: 15915.0, loss:0.23515690\n",
      "step: 15916.0, loss:0.16528582\n",
      "step: 15917.0, loss:0.26379514\n",
      "step: 15918.0, loss:0.14512566\n",
      "step: 15919.0, loss:0.07383136\n",
      "step: 15920.0, loss:0.24043034\n",
      "step: 15921.0, loss:0.32333383\n",
      "step: 15922.0, loss:0.24211075\n",
      "step: 15923.0, loss:0.13636653\n",
      "step: 15924.0, loss:0.23231696\n",
      "step: 15925.0, loss:0.19050843\n",
      "step: 15926.0, loss:0.21280979\n",
      "step: 15927.0, loss:0.23274657\n",
      "step: 15928.0, loss:0.22209255\n",
      "step: 15929.0, loss:0.38315254\n",
      "step: 15930.0, loss:0.13172488\n",
      "step: 15931.0, loss:0.10810801\n",
      "step: 15932.0, loss:0.19363071\n",
      "step: 15933.0, loss:0.19033917\n",
      "step: 15934.0, loss:0.15486366\n",
      "step: 15935.0, loss:0.18361479\n",
      "step: 15936.0, loss:0.10899866\n",
      "step: 15937.0, loss:0.10104790\n",
      "step: 15938.0, loss:0.20859948\n",
      "step: 15939.0, loss:0.13478512\n",
      "step: 15940.0, loss:0.26378303\n",
      "step: 15941.0, loss:0.08824699\n",
      "step: 15942.0, loss:0.11299596\n",
      "step: 15943.0, loss:0.08931518\n",
      "step: 15944.0, loss:0.19476560\n",
      "step: 15945.0, loss:0.23183419\n",
      "step: 15946.0, loss:0.26144179\n",
      "step: 15947.0, loss:0.18753907\n",
      "step: 15948.0, loss:0.15676374\n",
      "step: 15949.0, loss:0.18284478\n",
      "step: 15950.0, loss:0.23926187\n",
      "step: 15951.0, loss:0.25594726\n",
      "step: 15952.0, loss:0.28611645\n",
      "step: 15953.0, loss:0.39458401\n",
      "step: 15954.0, loss:0.08289035\n",
      "step: 15955.0, loss:0.15157268\n",
      "step: 15956.0, loss:0.22005505\n",
      "step: 15957.0, loss:0.17447960\n",
      "step: 15958.0, loss:0.24002907\n",
      "step: 15959.0, loss:0.15027750\n",
      "step: 15960.0, loss:0.12763924\n",
      "step: 15961.0, loss:0.19115725\n",
      "step: 15962.0, loss:0.10170439\n",
      "step: 15963.0, loss:0.15806831\n",
      "step: 15964.0, loss:0.13368864\n",
      "step: 15965.0, loss:0.08472155\n",
      "step: 15966.0, loss:0.17937279\n",
      "step: 15967.0, loss:0.18448832\n",
      "step: 15968.0, loss:0.17687415\n",
      "step: 15969.0, loss:0.20722784\n",
      "step: 15970.0, loss:0.24676214\n",
      "step: 15971.0, loss:0.17394025\n",
      "step: 15972.0, loss:0.16872117\n",
      "step: 15973.0, loss:0.20265244\n",
      "step: 15974.0, loss:0.11479933\n",
      "step: 15975.0, loss:0.12872759\n",
      "step: 15976.0, loss:0.18890598\n",
      "step: 15977.0, loss:0.15648639\n",
      "step: 15978.0, loss:0.17955044\n",
      "step: 15979.0, loss:0.18321013\n",
      "step: 15980.0, loss:0.21363861\n",
      "step: 15981.0, loss:0.14919163\n",
      "step: 15982.0, loss:0.26594965\n",
      "step: 15983.0, loss:0.17608926\n",
      "step: 15984.0, loss:0.07703324\n",
      "step: 15985.0, loss:0.10994347\n",
      "step: 15986.0, loss:0.09753167\n",
      "step: 15987.0, loss:0.20010998\n",
      "step: 15988.0, loss:0.27462512\n",
      "step: 15989.0, loss:0.21453091\n",
      "step: 15990.0, loss:0.17765048\n",
      "step: 15991.0, loss:0.09300310\n",
      "step: 15992.0, loss:0.20027988\n",
      "step: 15993.0, loss:0.15783552\n",
      "step: 15994.0, loss:0.25806688\n",
      "step: 15995.0, loss:0.12260500\n",
      "step: 15996.0, loss:0.14387588\n",
      "step: 15997.0, loss:0.30171386\n",
      "step: 15998.0, loss:0.24034272\n",
      "step: 15999.0, loss:0.24150393\n",
      "step: 16000.0, loss:0.15665497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1264/1264 [08:58<00:00,  2.35it/s]\n",
      "2023-04-03 04:57:32,591 - INFO - step:16000.0, matthews_corr:0.784502, Acc:89.883750%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 16001.0, loss:0.24710424\n",
      "step: 16002.0, loss:0.22499022\n",
      "step: 16003.0, loss:0.24762163\n",
      "step: 16004.0, loss:0.20671687\n",
      "step: 16005.0, loss:0.20290502\n",
      "step: 16006.0, loss:0.21911691\n",
      "step: 16007.0, loss:0.09550610\n",
      "step: 16008.0, loss:0.14234468\n",
      "step: 16009.0, loss:0.15698253\n",
      "step: 16010.0, loss:0.10459737\n",
      "step: 16011.0, loss:0.29473342\n",
      "step: 16012.0, loss:0.14173020\n",
      "step: 16013.0, loss:0.15172939\n",
      "step: 16014.0, loss:0.21305296\n",
      "step: 16015.0, loss:0.07310322\n",
      "step: 16016.0, loss:0.30857975\n",
      "step: 16017.0, loss:0.21696881\n",
      "step: 16018.0, loss:0.16383776\n",
      "step: 16019.0, loss:0.16948608\n",
      "step: 16020.0, loss:0.23702028\n",
      "step: 16021.0, loss:0.06737899\n",
      "step: 16022.0, loss:0.08747522\n",
      "step: 16023.0, loss:0.21938751\n",
      "step: 16024.0, loss:0.18272725\n",
      "step: 16025.0, loss:0.21006215\n",
      "step: 16026.0, loss:0.36383306\n",
      "step: 16027.0, loss:0.30940165\n",
      "step: 16028.0, loss:0.09386713\n",
      "step: 16029.0, loss:0.26112806\n",
      "step: 16030.0, loss:0.30782480\n",
      "step: 16031.0, loss:0.15548383\n",
      "step: 16032.0, loss:0.21894627\n",
      "step: 16033.0, loss:0.07035564\n",
      "step: 16034.0, loss:0.19621642\n",
      "step: 16035.0, loss:0.20761777\n",
      "step: 16036.0, loss:0.18589684\n",
      "step: 16037.0, loss:0.11513259\n",
      "step: 16038.0, loss:0.10006028\n",
      "step: 16039.0, loss:0.22039488\n",
      "step: 16040.0, loss:0.14623183\n",
      "step: 16041.0, loss:0.19343692\n",
      "step: 16042.0, loss:0.05890992\n",
      "step: 16043.0, loss:0.19625392\n",
      "step: 16044.0, loss:0.29750773\n",
      "step: 16045.0, loss:0.20488072\n",
      "step: 16046.0, loss:0.16876503\n",
      "step: 16047.0, loss:0.16281814\n",
      "step: 16048.0, loss:0.19123522\n",
      "step: 16049.0, loss:0.13393829\n",
      "step: 16050.0, loss:0.21408817\n",
      "step: 16051.0, loss:0.20059436\n",
      "step: 16052.0, loss:0.24145777\n",
      "step: 16053.0, loss:0.07575978\n",
      "step: 16054.0, loss:0.12912997\n",
      "step: 16055.0, loss:0.18338911\n",
      "step: 16056.0, loss:0.24397952\n",
      "step: 16057.0, loss:0.18344848\n",
      "step: 16058.0, loss:0.20391848\n",
      "step: 16059.0, loss:0.18266326\n",
      "step: 16060.0, loss:0.19934588\n",
      "step: 16061.0, loss:0.15678455\n",
      "step: 16062.0, loss:0.30076529\n",
      "step: 16063.0, loss:0.19887451\n",
      "step: 16064.0, loss:0.21315482\n",
      "step: 16065.0, loss:0.21445384\n",
      "step: 16066.0, loss:0.17189009\n",
      "step: 16067.0, loss:0.23212433\n",
      "step: 16068.0, loss:0.19469804\n",
      "step: 16069.0, loss:0.13354889\n",
      "step: 16070.0, loss:0.23955744\n",
      "step: 16071.0, loss:0.21957548\n",
      "step: 16072.0, loss:0.23228347\n",
      "step: 16073.0, loss:0.19495239\n",
      "step: 16074.0, loss:0.16298552\n",
      "step: 16075.0, loss:0.12965742\n",
      "step: 16076.0, loss:0.17229156\n",
      "step: 16077.0, loss:0.27032370\n",
      "step: 16078.0, loss:0.20615911\n",
      "step: 16079.0, loss:0.13360944\n",
      "step: 16080.0, loss:0.30561040\n",
      "step: 16081.0, loss:0.21456049\n",
      "step: 16082.0, loss:0.09368936\n",
      "step: 16083.0, loss:0.13455220\n",
      "step: 16084.0, loss:0.21504342\n",
      "step: 16085.0, loss:0.32856525\n",
      "step: 16086.0, loss:0.12810252\n",
      "step: 16087.0, loss:0.23466736\n",
      "step: 16088.0, loss:0.15983776\n",
      "step: 16089.0, loss:0.33725678\n",
      "step: 16090.0, loss:0.23300761\n",
      "step: 16091.0, loss:0.29634117\n",
      "step: 16092.0, loss:0.27058447\n",
      "step: 16093.0, loss:0.27772373\n",
      "step: 16094.0, loss:0.12910494\n",
      "step: 16095.0, loss:0.12020945\n",
      "step: 16096.0, loss:0.25989062\n",
      "step: 16097.0, loss:0.18706163\n",
      "step: 16098.0, loss:0.17099932\n",
      "step: 16099.0, loss:0.19555802\n",
      "step: 16100.0, loss:0.24885351\n",
      "step: 16101.0, loss:0.21540965\n",
      "step: 16102.0, loss:0.18853705\n",
      "step: 16103.0, loss:0.22630280\n",
      "step: 16104.0, loss:0.20407946\n",
      "step: 16105.0, loss:0.12304418\n",
      "step: 16106.0, loss:0.10718245\n",
      "step: 16107.0, loss:0.10318520\n",
      "step: 16108.0, loss:0.22546971\n",
      "step: 16109.0, loss:0.23341358\n",
      "step: 16110.0, loss:0.17134224\n",
      "step: 16111.0, loss:0.27041546\n",
      "step: 16112.0, loss:0.10377142\n",
      "step: 16113.0, loss:0.16932733\n",
      "step: 16114.0, loss:0.11438636\n",
      "step: 16115.0, loss:0.22048762\n",
      "step: 16116.0, loss:0.14354523\n",
      "step: 16117.0, loss:0.12773081\n",
      "step: 16118.0, loss:0.13250015\n",
      "step: 16119.0, loss:0.15883189\n",
      "step: 16120.0, loss:0.08400005\n",
      "step: 16121.0, loss:0.10602413\n",
      "step: 16122.0, loss:0.13216673\n",
      "step: 16123.0, loss:0.28675050\n",
      "step: 16124.0, loss:0.23984782\n",
      "step: 16125.0, loss:0.07472451\n",
      "step: 16126.0, loss:0.27055876\n",
      "step: 16127.0, loss:0.13592347\n",
      "step: 16128.0, loss:0.22659998\n",
      "step: 16129.0, loss:0.18469502\n",
      "step: 16130.0, loss:0.19608434\n",
      "step: 16131.0, loss:0.21472593\n",
      "step: 16132.0, loss:0.15084684\n",
      "step: 16133.0, loss:0.13230118\n",
      "step: 16134.0, loss:0.22555915\n",
      "step: 16135.0, loss:0.20650957\n",
      "step: 16136.0, loss:0.16889984\n",
      "step: 16137.0, loss:0.15879925\n",
      "step: 16138.0, loss:0.37790063\n",
      "step: 16139.0, loss:0.18602795\n",
      "step: 16140.0, loss:0.20406133\n",
      "step: 16141.0, loss:0.15555108\n",
      "step: 16142.0, loss:0.23848764\n",
      "step: 16143.0, loss:0.28025120\n",
      "step: 16144.0, loss:0.30309499\n",
      "step: 16145.0, loss:0.16819063\n",
      "step: 16146.0, loss:0.10356656\n",
      "step: 16147.0, loss:0.18460641\n",
      "step: 16148.0, loss:0.23590879\n",
      "step: 16149.0, loss:0.28306249\n",
      "step: 16150.0, loss:0.11407878\n",
      "step: 16151.0, loss:0.11374388\n",
      "step: 16152.0, loss:0.14388363\n",
      "step: 16153.0, loss:0.17039333\n",
      "step: 16154.0, loss:0.11220354\n",
      "step: 16155.0, loss:0.14069322\n",
      "step: 16156.0, loss:0.11294810\n",
      "step: 16157.0, loss:0.07631579\n",
      "step: 16158.0, loss:0.23003884\n",
      "step: 16159.0, loss:0.21967673\n",
      "step: 16160.0, loss:0.21405303\n",
      "step: 16161.0, loss:0.20904034\n",
      "step: 16162.0, loss:0.13140078\n",
      "step: 16163.0, loss:0.23992641\n",
      "step: 16164.0, loss:0.15790462\n",
      "step: 16165.0, loss:0.14730802\n",
      "step: 16166.0, loss:0.05220164\n",
      "step: 16167.0, loss:0.11429272\n",
      "step: 16168.0, loss:0.12415436\n",
      "step: 16169.0, loss:0.23985316\n",
      "step: 16170.0, loss:0.19003918\n",
      "step: 16171.0, loss:0.35426914\n",
      "step: 16172.0, loss:0.12885757\n",
      "step: 16173.0, loss:0.13326941\n",
      "step: 16174.0, loss:0.19355316\n",
      "step: 16175.0, loss:0.15462733\n",
      "step: 16176.0, loss:0.21132625\n",
      "step: 16177.0, loss:0.20490961\n",
      "step: 16178.0, loss:0.13214724\n",
      "step: 16179.0, loss:0.34580350\n",
      "step: 16180.0, loss:0.11078926\n",
      "step: 16181.0, loss:0.08714880\n",
      "step: 16182.0, loss:0.12958874\n",
      "step: 16183.0, loss:0.16969961\n",
      "step: 16184.0, loss:0.13733050\n",
      "step: 16185.0, loss:0.11109278\n",
      "step: 16186.0, loss:0.18675902\n",
      "step: 16187.0, loss:0.10717610\n",
      "step: 16188.0, loss:0.16311860\n",
      "step: 16189.0, loss:0.16162741\n",
      "step: 16190.0, loss:0.24246279\n",
      "step: 16191.0, loss:0.38159461\n",
      "step: 16192.0, loss:0.23925427\n",
      "step: 16193.0, loss:0.27875648\n",
      "step: 16194.0, loss:0.33384209\n",
      "step: 16195.0, loss:0.20769949\n",
      "step: 16196.0, loss:0.11272174\n",
      "step: 16197.0, loss:0.16721785\n",
      "step: 16198.0, loss:0.20842080\n",
      "step: 16199.0, loss:0.25161358\n",
      "step: 16200.0, loss:0.19055184\n",
      "step: 16201.0, loss:0.15296741\n",
      "step: 16202.0, loss:0.15640244\n",
      "step: 16203.0, loss:0.14938769\n",
      "step: 16204.0, loss:0.26487919\n",
      "step: 16205.0, loss:0.16561133\n",
      "step: 16206.0, loss:0.17287091\n",
      "step: 16207.0, loss:0.21956765\n",
      "step: 16208.0, loss:0.24291759\n",
      "step: 16209.0, loss:0.39473429\n",
      "step: 16210.0, loss:0.22980559\n",
      "step: 16211.0, loss:0.13034412\n",
      "step: 16212.0, loss:0.28033300\n",
      "step: 16213.0, loss:0.16502816\n",
      "step: 16214.0, loss:0.18598332\n",
      "step: 16215.0, loss:0.17615750\n",
      "step: 16216.0, loss:0.19142261\n",
      "step: 16217.0, loss:0.19437392\n",
      "step: 16218.0, loss:0.28213908\n",
      "step: 16219.0, loss:0.05674501\n",
      "step: 16220.0, loss:0.11206236\n",
      "step: 16221.0, loss:0.26708778\n",
      "step: 16222.0, loss:0.09163045\n",
      "step: 16223.0, loss:0.18494202\n",
      "step: 16224.0, loss:0.16543114\n",
      "step: 16225.0, loss:0.15192966\n",
      "step: 16226.0, loss:0.18911970\n",
      "step: 16227.0, loss:0.20304419\n",
      "step: 16228.0, loss:0.11867415\n",
      "step: 16229.0, loss:0.20319131\n",
      "step: 16230.0, loss:0.18394545\n",
      "step: 16231.0, loss:0.11261807\n",
      "step: 16232.0, loss:0.15897425\n",
      "step: 16233.0, loss:0.13566000\n",
      "step: 16234.0, loss:0.24665600\n",
      "step: 16235.0, loss:0.15459341\n",
      "step: 16236.0, loss:0.19927140\n",
      "step: 16237.0, loss:0.14138568\n",
      "step: 16238.0, loss:0.20673307\n",
      "step: 16239.0, loss:0.13219883\n",
      "step: 16240.0, loss:0.08397412\n",
      "step: 16241.0, loss:0.26325621\n",
      "step: 16242.0, loss:0.07131724\n",
      "step: 16243.0, loss:0.25683766\n",
      "step: 16244.0, loss:0.09461363\n",
      "step: 16245.0, loss:0.13481574\n",
      "step: 16246.0, loss:0.06270575\n",
      "step: 16247.0, loss:0.20312447\n",
      "step: 16248.0, loss:0.13752722\n",
      "step: 16249.0, loss:0.11549438\n",
      "step: 16250.0, loss:0.17554019\n",
      "step: 16251.0, loss:0.18788268\n",
      "step: 16252.0, loss:0.21394558\n",
      "step: 16253.0, loss:0.10361223\n",
      "step: 16254.0, loss:0.25794199\n",
      "step: 16255.0, loss:0.25035434\n",
      "step: 16256.0, loss:0.21617220\n",
      "step: 16257.0, loss:0.21308167\n",
      "step: 16258.0, loss:0.26130949\n",
      "step: 16259.0, loss:0.14498741\n",
      "step: 16260.0, loss:0.18303504\n",
      "step: 16261.0, loss:0.16587421\n",
      "step: 16262.0, loss:0.32521163\n",
      "step: 16263.0, loss:0.12709981\n",
      "step: 16264.0, loss:0.18633674\n",
      "step: 16265.0, loss:0.27064367\n",
      "step: 16266.0, loss:0.17039378\n",
      "step: 16267.0, loss:0.13240533\n",
      "step: 16268.0, loss:0.18873253\n",
      "step: 16269.0, loss:0.17909118\n",
      "step: 16270.0, loss:0.18804224\n",
      "step: 16271.0, loss:0.19224346\n",
      "step: 16272.0, loss:0.18920426\n",
      "step: 16273.0, loss:0.16535184\n",
      "step: 16274.0, loss:0.09807914\n",
      "step: 16275.0, loss:0.22223700\n",
      "step: 16276.0, loss:0.10643575\n",
      "step: 16277.0, loss:0.11052837\n",
      "step: 16278.0, loss:0.18112936\n",
      "step: 16279.0, loss:0.23640156\n",
      "step: 16280.0, loss:0.17248339\n",
      "step: 16281.0, loss:0.16144429\n",
      "step: 16282.0, loss:0.32661321\n",
      "step: 16283.0, loss:0.16157247\n",
      "step: 16284.0, loss:0.24702087\n",
      "step: 16285.0, loss:0.12815953\n",
      "step: 16286.0, loss:0.11002657\n",
      "step: 16287.0, loss:0.17089418\n",
      "step: 16288.0, loss:0.11303200\n",
      "step: 16289.0, loss:0.07243547\n",
      "step: 16290.0, loss:0.23434108\n",
      "step: 16291.0, loss:0.23016270\n",
      "step: 16292.0, loss:0.10912222\n",
      "step: 16293.0, loss:0.30714531\n",
      "step: 16294.0, loss:0.20067005\n",
      "step: 16295.0, loss:0.17554172\n",
      "step: 16296.0, loss:0.13792412\n",
      "step: 16297.0, loss:0.11535359\n",
      "step: 16298.0, loss:0.14664611\n",
      "step: 16299.0, loss:0.12661875\n",
      "step: 16300.0, loss:0.27662506\n",
      "step: 16301.0, loss:0.25950427\n",
      "step: 16302.0, loss:0.29086494\n",
      "step: 16303.0, loss:0.28045737\n",
      "step: 16304.0, loss:0.25431544\n",
      "step: 16305.0, loss:0.22793611\n",
      "step: 16306.0, loss:0.14006432\n",
      "step: 16307.0, loss:0.20520786\n",
      "step: 16308.0, loss:0.11270257\n",
      "step: 16309.0, loss:0.21886342\n",
      "step: 16310.0, loss:0.19894927\n",
      "step: 16311.0, loss:0.25074157\n",
      "step: 16312.0, loss:0.17456553\n",
      "step: 16313.0, loss:0.13346117\n",
      "step: 16314.0, loss:0.15388330\n",
      "step: 16315.0, loss:0.20592771\n",
      "step: 16316.0, loss:0.14703850\n",
      "step: 16317.0, loss:0.26185916\n",
      "step: 16318.0, loss:0.11273583\n",
      "step: 16319.0, loss:0.18711464\n",
      "step: 16320.0, loss:0.22229094\n",
      "step: 16321.0, loss:0.24895232\n",
      "step: 16322.0, loss:0.21785142\n",
      "step: 16323.0, loss:0.32057779\n",
      "step: 16324.0, loss:0.09396869\n",
      "step: 16325.0, loss:0.10166986\n",
      "step: 16326.0, loss:0.23790060\n",
      "step: 16327.0, loss:0.20424948\n",
      "step: 16328.0, loss:0.17409360\n",
      "step: 16329.0, loss:0.10767279\n",
      "step: 16330.0, loss:0.09609544\n",
      "step: 16331.0, loss:0.13562478\n",
      "step: 16332.0, loss:0.12025282\n",
      "step: 16333.0, loss:0.14498567\n",
      "step: 16334.0, loss:0.25763457\n",
      "step: 16335.0, loss:0.22952515\n",
      "step: 16336.0, loss:0.21166989\n",
      "step: 16337.0, loss:0.14378448\n",
      "step: 16338.0, loss:0.18122162\n",
      "step: 16339.0, loss:0.14604102\n",
      "step: 16340.0, loss:0.14680102\n",
      "step: 16341.0, loss:0.25188358\n",
      "step: 16342.0, loss:0.30021144\n",
      "step: 16343.0, loss:0.13151652\n",
      "step: 16344.0, loss:0.29697989\n",
      "step: 16345.0, loss:0.10183013\n",
      "step: 16346.0, loss:0.13746108\n",
      "step: 16347.0, loss:0.15602524\n",
      "step: 16348.0, loss:0.15124181\n",
      "step: 16349.0, loss:0.16812772\n",
      "step: 16350.0, loss:0.21182615\n",
      "step: 16351.0, loss:0.17508826\n",
      "step: 16352.0, loss:0.19786543\n",
      "step: 16353.0, loss:0.12700992\n",
      "step: 16354.0, loss:0.15326934\n",
      "step: 16355.0, loss:0.25590151\n",
      "step: 16356.0, loss:0.07731733\n",
      "step: 16357.0, loss:0.11697752\n",
      "step: 16358.0, loss:0.16764474\n",
      "step: 16359.0, loss:0.22058418\n",
      "step: 16360.0, loss:0.17217730\n",
      "step: 16361.0, loss:0.18626211\n",
      "step: 16362.0, loss:0.28833178\n",
      "step: 16363.0, loss:0.13307047\n",
      "step: 16364.0, loss:0.20458248\n",
      "step: 16365.0, loss:0.13395334\n",
      "step: 16366.0, loss:0.12026962\n",
      "step: 16367.0, loss:0.39360227\n",
      "step: 16368.0, loss:0.18481441\n",
      "step: 16369.0, loss:0.20270041\n",
      "step: 16370.0, loss:0.16123839\n",
      "step: 16371.0, loss:0.22725597\n",
      "step: 16372.0, loss:0.15423207\n",
      "step: 16373.0, loss:0.19889475\n",
      "step: 16374.0, loss:0.18087933\n",
      "step: 16375.0, loss:0.18920634\n",
      "step: 16376.0, loss:0.25375526\n",
      "step: 16377.0, loss:0.15123511\n",
      "step: 16378.0, loss:0.17620249\n",
      "step: 16379.0, loss:0.21068419\n",
      "step: 16380.0, loss:0.14329072\n",
      "step: 16381.0, loss:0.17780312\n",
      "step: 16382.0, loss:0.12900849\n",
      "step: 16383.0, loss:0.20771203\n",
      "step: 16384.0, loss:0.17296322\n",
      "step: 16385.0, loss:0.19266001\n",
      "step: 16386.0, loss:0.28654887\n",
      "step: 16387.0, loss:0.21282550\n",
      "step: 16388.0, loss:0.22026238\n",
      "step: 16389.0, loss:0.13561676\n",
      "step: 16390.0, loss:0.18559271\n",
      "step: 16391.0, loss:0.21098537\n",
      "step: 16392.0, loss:0.08893835\n",
      "step: 16393.0, loss:0.15585680\n",
      "step: 16394.0, loss:0.22400565\n",
      "step: 16395.0, loss:0.15399182\n",
      "step: 16396.0, loss:0.16769919\n",
      "step: 16397.0, loss:0.15585238\n",
      "step: 16398.0, loss:0.17391554\n",
      "step: 16399.0, loss:0.11212088\n",
      "step: 16400.0, loss:0.17977603\n",
      "step: 16401.0, loss:0.19571414\n",
      "step: 16402.0, loss:0.18561013\n",
      "step: 16403.0, loss:0.29194475\n",
      "step: 16404.0, loss:0.27655952\n",
      "step: 16405.0, loss:0.15282479\n",
      "step: 16406.0, loss:0.30857174\n",
      "step: 16407.0, loss:0.13220166\n",
      "step: 16408.0, loss:0.28389190\n",
      "step: 16409.0, loss:0.18003864\n",
      "step: 16410.0, loss:0.14690744\n",
      "step: 16411.0, loss:0.11411471\n",
      "step: 16412.0, loss:0.20376591\n",
      "step: 16413.0, loss:0.20912521\n",
      "step: 16414.0, loss:0.12085414\n",
      "step: 16415.0, loss:0.15172130\n",
      "step: 16416.0, loss:0.20510312\n",
      "step: 16417.0, loss:0.22912975\n",
      "step: 16418.0, loss:0.17220252\n",
      "step: 16419.0, loss:0.15331743\n",
      "step: 16420.0, loss:0.18436980\n",
      "step: 16421.0, loss:0.31893667\n",
      "step: 16422.0, loss:0.18085882\n",
      "step: 16423.0, loss:0.07758397\n",
      "step: 16424.0, loss:0.18840452\n",
      "step: 16425.0, loss:0.13649502\n",
      "step: 16426.0, loss:0.07501187\n",
      "step: 16427.0, loss:0.13521425\n",
      "step: 16428.0, loss:0.26947103\n",
      "step: 16429.0, loss:0.21650015\n",
      "step: 16430.0, loss:0.11527519\n",
      "step: 16431.0, loss:0.18222891\n",
      "step: 16432.0, loss:0.10096166\n",
      "step: 16433.0, loss:0.23300549\n",
      "step: 16434.0, loss:0.20437499\n",
      "step: 16435.0, loss:0.25640646\n",
      "step: 16436.0, loss:0.13734620\n",
      "step: 16437.0, loss:0.29336198\n",
      "step: 16438.0, loss:0.12530245\n",
      "step: 16439.0, loss:0.15309437\n",
      "step: 16440.0, loss:0.20586326\n",
      "step: 16441.0, loss:0.24164664\n",
      "step: 16442.0, loss:0.23890306\n",
      "step: 16443.0, loss:0.23785584\n",
      "step: 16444.0, loss:0.27943014\n",
      "step: 16445.0, loss:0.22760909\n",
      "step: 16446.0, loss:0.24909276\n",
      "step: 16447.0, loss:0.27668638\n",
      "step: 16448.0, loss:0.22247374\n",
      "step: 16449.0, loss:0.19716632\n",
      "step: 16450.0, loss:0.18321455\n",
      "step: 16451.0, loss:0.12525644\n",
      "step: 16452.0, loss:0.11907405\n",
      "step: 16453.0, loss:0.13537302\n",
      "step: 16454.0, loss:0.14682639\n",
      "step: 16455.0, loss:0.17482576\n",
      "step: 16456.0, loss:0.15383696\n",
      "step: 16457.0, loss:0.13411316\n",
      "step: 16458.0, loss:0.12496177\n",
      "step: 16459.0, loss:0.29919546\n",
      "step: 16460.0, loss:0.19110694\n",
      "step: 16461.0, loss:0.18883269\n",
      "step: 16462.0, loss:0.11463758\n",
      "step: 16463.0, loss:0.22564270\n",
      "step: 16464.0, loss:0.15587110\n",
      "step: 16465.0, loss:0.11390246\n",
      "step: 16466.0, loss:0.16849256\n",
      "step: 16467.0, loss:0.07987425\n",
      "step: 16468.0, loss:0.19040528\n",
      "step: 16469.0, loss:0.12126671\n",
      "step: 16470.0, loss:0.18395616\n",
      "step: 16471.0, loss:0.17931353\n",
      "step: 16472.0, loss:0.09911509\n",
      "step: 16473.0, loss:0.22245271\n",
      "step: 16474.0, loss:0.25998943\n",
      "step: 16475.0, loss:0.36724941\n",
      "step: 16476.0, loss:0.23506275\n",
      "step: 16477.0, loss:0.17162745\n",
      "step: 16478.0, loss:0.21096946\n",
      "step: 16479.0, loss:0.18569889\n",
      "step: 16480.0, loss:0.17737818\n",
      "step: 16481.0, loss:0.22138681\n",
      "step: 16482.0, loss:0.20907513\n",
      "step: 16483.0, loss:0.15459592\n",
      "step: 16484.0, loss:0.22184930\n",
      "step: 16485.0, loss:0.14828292\n",
      "step: 16486.0, loss:0.10360263\n",
      "step: 16487.0, loss:0.27276633\n",
      "step: 16488.0, loss:0.24125751\n",
      "step: 16489.0, loss:0.13160926\n",
      "step: 16490.0, loss:0.11715145\n",
      "step: 16491.0, loss:0.08624110\n",
      "step: 16492.0, loss:0.12537024\n",
      "step: 16493.0, loss:0.17575480\n",
      "step: 16494.0, loss:0.18098346\n",
      "step: 16495.0, loss:0.13499768\n",
      "step: 16496.0, loss:0.24832329\n",
      "step: 16497.0, loss:0.14974928\n",
      "step: 16498.0, loss:0.10895618\n",
      "step: 16499.0, loss:0.20414932\n",
      "step: 16500.0, loss:0.11320772\n",
      "step: 16501.0, loss:0.15197612\n",
      "step: 16502.0, loss:0.17345981\n",
      "step: 16503.0, loss:0.17247770\n",
      "step: 16504.0, loss:0.28141197\n",
      "step: 16505.0, loss:0.15393552\n",
      "step: 16506.0, loss:0.12945221\n",
      "step: 16507.0, loss:0.28046885\n",
      "step: 16508.0, loss:0.24342311\n",
      "step: 16509.0, loss:0.13919193\n",
      "step: 16510.0, loss:0.24566744\n",
      "step: 16511.0, loss:0.08204520\n",
      "step: 16512.0, loss:0.09704479\n",
      "step: 16513.0, loss:0.18651300\n",
      "step: 16514.0, loss:0.09951066\n",
      "step: 16515.0, loss:0.20798717\n",
      "step: 16516.0, loss:0.18301656\n",
      "step: 16517.0, loss:0.28147514\n",
      "step: 16518.0, loss:0.20726913\n",
      "step: 16519.0, loss:0.18791234\n",
      "step: 16520.0, loss:0.25093728\n",
      "step: 16521.0, loss:0.17663644\n",
      "step: 16522.0, loss:0.16941656\n",
      "step: 16523.0, loss:0.16144950\n",
      "step: 16524.0, loss:0.21900645\n",
      "step: 16525.0, loss:0.24772314\n",
      "step: 16526.0, loss:0.12585190\n",
      "step: 16527.0, loss:0.13642845\n",
      "step: 16528.0, loss:0.20064214\n",
      "step: 16529.0, loss:0.21869328\n",
      "step: 16530.0, loss:0.18845793\n",
      "step: 16531.0, loss:0.14060530\n",
      "step: 16532.0, loss:0.15527151\n",
      "step: 16533.0, loss:0.16761877\n",
      "step: 16534.0, loss:0.12528685\n",
      "step: 16535.0, loss:0.08830942\n",
      "step: 16536.0, loss:0.17578457\n",
      "step: 16537.0, loss:0.29018160\n",
      "step: 16538.0, loss:0.15979879\n",
      "step: 16539.0, loss:0.28761111\n",
      "step: 16540.0, loss:0.21640729\n",
      "step: 16541.0, loss:0.13815056\n",
      "step: 16542.0, loss:0.20389462\n",
      "step: 16543.0, loss:0.25963608\n",
      "step: 16544.0, loss:0.08738067\n",
      "step: 16545.0, loss:0.17756878\n",
      "step: 16546.0, loss:0.19328772\n",
      "step: 16547.0, loss:0.09105271\n",
      "step: 16548.0, loss:0.25715629\n",
      "step: 16549.0, loss:0.17499546\n",
      "step: 16550.0, loss:0.21153001\n",
      "step: 16551.0, loss:0.09647380\n",
      "step: 16552.0, loss:0.16232712\n",
      "step: 16553.0, loss:0.25907152\n",
      "step: 16554.0, loss:0.22102837\n",
      "step: 16555.0, loss:0.19516597\n",
      "step: 16556.0, loss:0.25224596\n",
      "step: 16557.0, loss:0.12145669\n",
      "step: 16558.0, loss:0.24239317\n",
      "step: 16559.0, loss:0.12215311\n",
      "step: 16560.0, loss:0.18876225\n",
      "step: 16561.0, loss:0.17557229\n",
      "step: 16562.0, loss:0.32539153\n",
      "step: 16563.0, loss:0.16601669\n",
      "step: 16564.0, loss:0.18966062\n",
      "step: 16565.0, loss:0.15125021\n",
      "step: 16566.0, loss:0.15799763\n",
      "step: 16567.0, loss:0.15999139\n",
      "step: 16568.0, loss:0.20852800\n",
      "step: 16569.0, loss:0.18006930\n",
      "step: 16570.0, loss:0.25468352\n",
      "step: 16571.0, loss:0.12156058\n",
      "step: 16572.0, loss:0.24435464\n",
      "step: 16573.0, loss:0.24155129\n",
      "step: 16574.0, loss:0.18389834\n",
      "step: 16575.0, loss:0.21775765\n",
      "step: 16576.0, loss:0.16720781\n",
      "step: 16577.0, loss:0.14515133\n",
      "step: 16578.0, loss:0.11140990\n",
      "step: 16579.0, loss:0.14038713\n",
      "step: 16580.0, loss:0.23784482\n",
      "step: 16581.0, loss:0.10198644\n",
      "step: 16582.0, loss:0.10610403\n",
      "step: 16583.0, loss:0.14966383\n",
      "step: 16584.0, loss:0.16130043\n",
      "step: 16585.0, loss:0.24315338\n",
      "step: 16586.0, loss:0.22138338\n",
      "step: 16587.0, loss:0.17717879\n",
      "step: 16588.0, loss:0.11807905\n",
      "step: 16589.0, loss:0.28171350\n",
      "step: 16590.0, loss:0.13121306\n",
      "step: 16591.0, loss:0.14745279\n",
      "step: 16592.0, loss:0.13207187\n",
      "step: 16593.0, loss:0.16030492\n",
      "step: 16594.0, loss:0.14304460\n",
      "step: 16595.0, loss:0.19989220\n",
      "step: 16596.0, loss:0.21032665\n",
      "step: 16597.0, loss:0.19544289\n",
      "step: 16598.0, loss:0.08659662\n",
      "step: 16599.0, loss:0.13469853\n",
      "step: 16600.0, loss:0.25707128\n",
      "step: 16601.0, loss:0.21543209\n",
      "step: 16602.0, loss:0.22549290\n",
      "step: 16603.0, loss:0.13409137\n",
      "step: 16604.0, loss:0.16667478\n",
      "step: 16605.0, loss:0.14381889\n",
      "step: 16606.0, loss:0.17330704\n",
      "step: 16607.0, loss:0.13818911\n",
      "step: 16608.0, loss:0.17909769\n",
      "step: 16609.0, loss:0.12151776\n",
      "step: 16610.0, loss:0.11600398\n",
      "step: 16611.0, loss:0.17360268\n",
      "step: 16612.0, loss:0.14886754\n",
      "step: 16613.0, loss:0.19183872\n",
      "step: 16614.0, loss:0.12617295\n",
      "step: 16615.0, loss:0.26992872\n",
      "step: 16616.0, loss:0.18692696\n",
      "step: 16617.0, loss:0.16631262\n",
      "step: 16618.0, loss:0.17686489\n",
      "step: 16619.0, loss:0.20194108\n",
      "step: 16620.0, loss:0.35170741\n",
      "step: 16621.0, loss:0.12962419\n",
      "step: 16622.0, loss:0.27171354\n",
      "step: 16623.0, loss:0.21755634\n",
      "step: 16624.0, loss:0.27072178\n",
      "step: 16625.0, loss:0.14579936\n",
      "step: 16626.0, loss:0.09140214\n",
      "step: 16627.0, loss:0.20642818\n",
      "step: 16628.0, loss:0.24862643\n",
      "step: 16629.0, loss:0.13693512\n",
      "step: 16630.0, loss:0.14937842\n",
      "step: 16631.0, loss:0.22493772\n",
      "step: 16632.0, loss:0.10183194\n",
      "step: 16633.0, loss:0.13983778\n",
      "step: 16634.0, loss:0.20451829\n",
      "step: 16635.0, loss:0.31686393\n",
      "step: 16636.0, loss:0.08790870\n",
      "step: 16637.0, loss:0.19563041\n",
      "step: 16638.0, loss:0.17443054\n",
      "step: 16639.0, loss:0.11426280\n",
      "step: 16640.0, loss:0.31768875\n",
      "step: 16641.0, loss:0.28382236\n",
      "step: 16642.0, loss:0.17347361\n",
      "step: 16643.0, loss:0.12903193\n",
      "step: 16644.0, loss:0.14999632\n",
      "step: 16645.0, loss:0.22335039\n",
      "step: 16646.0, loss:0.15353567\n",
      "step: 16647.0, loss:0.12449090\n",
      "step: 16648.0, loss:0.29099447\n",
      "step: 16649.0, loss:0.12019287\n",
      "step: 16650.0, loss:0.17447446\n",
      "step: 16651.0, loss:0.23087482\n",
      "step: 16652.0, loss:0.15504763\n",
      "step: 16653.0, loss:0.20996220\n",
      "step: 16654.0, loss:0.19975795\n",
      "step: 16655.0, loss:0.17929659\n",
      "step: 16656.0, loss:0.18046274\n",
      "step: 16657.0, loss:0.24231994\n",
      "step: 16658.0, loss:0.29667819\n",
      "step: 16659.0, loss:0.11078399\n",
      "step: 16660.0, loss:0.16501798\n",
      "step: 16661.0, loss:0.11352255\n",
      "step: 16662.0, loss:0.19741925\n",
      "step: 16663.0, loss:0.15832233\n",
      "step: 16664.0, loss:0.16785858\n",
      "step: 16665.0, loss:0.21190901\n",
      "step: 16666.0, loss:0.21162340\n",
      "step: 16667.0, loss:0.18262416\n",
      "step: 16668.0, loss:0.14931870\n",
      "step: 16669.0, loss:0.06264856\n",
      "step: 16670.0, loss:0.20780106\n",
      "step: 16671.0, loss:0.10637494\n",
      "step: 16672.0, loss:0.16894073\n",
      "step: 16673.0, loss:0.24704737\n",
      "step: 16674.0, loss:0.14375168\n",
      "step: 16675.0, loss:0.14799632\n",
      "step: 16676.0, loss:0.16135122\n",
      "step: 16677.0, loss:0.15515418\n",
      "step: 16678.0, loss:0.13582457\n",
      "step: 16679.0, loss:0.26446313\n",
      "step: 16680.0, loss:0.18659978\n",
      "step: 16681.0, loss:0.17181325\n",
      "step: 16682.0, loss:0.14268725\n",
      "step: 16683.0, loss:0.26885128\n",
      "step: 16684.0, loss:0.23885414\n",
      "step: 16685.0, loss:0.15928425\n",
      "step: 16686.0, loss:0.12124065\n",
      "step: 16687.0, loss:0.12607090\n",
      "step: 16688.0, loss:0.13699703\n",
      "step: 16689.0, loss:0.37357408\n",
      "step: 16690.0, loss:0.24086671\n",
      "step: 16691.0, loss:0.17852600\n",
      "step: 16692.0, loss:0.22075303\n",
      "step: 16693.0, loss:0.27518394\n",
      "step: 16694.0, loss:0.15514009\n",
      "step: 16695.0, loss:0.13795105\n",
      "step: 16696.0, loss:0.10325364\n",
      "step: 16697.0, loss:0.16005609\n",
      "step: 16698.0, loss:0.17213192\n",
      "step: 16699.0, loss:0.12788177\n",
      "step: 16700.0, loss:0.19043767\n",
      "step: 16701.0, loss:0.17414977\n",
      "step: 16702.0, loss:0.09615493\n",
      "step: 16703.0, loss:0.16019831\n",
      "step: 16704.0, loss:0.21335564\n",
      "step: 16705.0, loss:0.26724873\n",
      "step: 16706.0, loss:0.15470228\n",
      "step: 16707.0, loss:0.16786703\n",
      "step: 16708.0, loss:0.21968395\n",
      "step: 16709.0, loss:0.13826380\n",
      "step: 16710.0, loss:0.21732446\n",
      "step: 16711.0, loss:0.12774670\n",
      "step: 16712.0, loss:0.14810430\n",
      "step: 16713.0, loss:0.21684590\n",
      "step: 16714.0, loss:0.18266571\n",
      "step: 16715.0, loss:0.17435586\n",
      "step: 16716.0, loss:0.12879307\n",
      "step: 16717.0, loss:0.16974709\n",
      "step: 16718.0, loss:0.08863484\n",
      "step: 16719.0, loss:0.12677478\n",
      "step: 16720.0, loss:0.16029388\n",
      "step: 16721.0, loss:0.16287388\n",
      "step: 16722.0, loss:0.12382826\n",
      "step: 16723.0, loss:0.13815170\n",
      "step: 16724.0, loss:0.20275834\n",
      "step: 16725.0, loss:0.33330649\n",
      "step: 16726.0, loss:0.15646194\n",
      "step: 16727.0, loss:0.12332788\n",
      "step: 16728.0, loss:0.14952771\n",
      "step: 16729.0, loss:0.21591656\n",
      "step: 16730.0, loss:0.20496385\n",
      "step: 16731.0, loss:0.16818446\n",
      "step: 16732.0, loss:0.18979626\n",
      "step: 16733.0, loss:0.10906762\n",
      "step: 16734.0, loss:0.18344826\n",
      "step: 16735.0, loss:0.11803807\n",
      "step: 16736.0, loss:0.11505713\n",
      "step: 16737.0, loss:0.07813157\n",
      "step: 16738.0, loss:0.17116215\n",
      "step: 16739.0, loss:0.22103856\n",
      "step: 16740.0, loss:0.09343485\n",
      "step: 16741.0, loss:0.27131110\n",
      "step: 16742.0, loss:0.12589336\n",
      "step: 16743.0, loss:0.09714976\n",
      "step: 16744.0, loss:0.15274490\n",
      "step: 16745.0, loss:0.14945064\n",
      "step: 16746.0, loss:0.23501112\n",
      "step: 16747.0, loss:0.11809790\n",
      "step: 16748.0, loss:0.21212116\n",
      "step: 16749.0, loss:0.14389084\n",
      "step: 16750.0, loss:0.28185685\n",
      "step: 16751.0, loss:0.29348449\n",
      "step: 16752.0, loss:0.16579951\n",
      "step: 16753.0, loss:0.07287527\n",
      "step: 16754.0, loss:0.18777756\n",
      "step: 16755.0, loss:0.23741973\n",
      "step: 16756.0, loss:0.07593527\n",
      "step: 16757.0, loss:0.09465251\n",
      "step: 16758.0, loss:0.15699488\n",
      "step: 16759.0, loss:0.11414404\n",
      "step: 16760.0, loss:0.11710559\n",
      "step: 16761.0, loss:0.20842404\n",
      "step: 16762.0, loss:0.19067936\n",
      "step: 16763.0, loss:0.26685511\n",
      "step: 16764.0, loss:0.32332787\n",
      "step: 16765.0, loss:0.19370985\n",
      "step: 16766.0, loss:0.16506723\n",
      "step: 16767.0, loss:0.25257264\n",
      "step: 16768.0, loss:0.10547271\n",
      "step: 16769.0, loss:0.15867900\n",
      "step: 16770.0, loss:0.13730150\n",
      "step: 16771.0, loss:0.20367001\n",
      "step: 16772.0, loss:0.14512240\n",
      "step: 16773.0, loss:0.08264666\n",
      "step: 16774.0, loss:0.18035491\n",
      "step: 16775.0, loss:0.25835851\n",
      "step: 16776.0, loss:0.20970720\n",
      "step: 16777.0, loss:0.12941473\n",
      "step: 16778.0, loss:0.30946816\n",
      "step: 16779.0, loss:0.28767844\n",
      "step: 16780.0, loss:0.26780980\n",
      "step: 16781.0, loss:0.21572038\n",
      "step: 16782.0, loss:0.19485875\n",
      "step: 16783.0, loss:0.13819366\n",
      "step: 16784.0, loss:0.12562285\n",
      "step: 16785.0, loss:0.17973983\n",
      "step: 16786.0, loss:0.25423079\n",
      "step: 16787.0, loss:0.12789904\n",
      "step: 16788.0, loss:0.11656023\n",
      "step: 16789.0, loss:0.13645058\n",
      "step: 16790.0, loss:0.15545454\n",
      "step: 16791.0, loss:0.19473711\n",
      "step: 16792.0, loss:0.12842542\n",
      "step: 16793.0, loss:0.19595302\n",
      "step: 16794.0, loss:0.19241703\n",
      "step: 16795.0, loss:0.12814904\n",
      "step: 16796.0, loss:0.27041342\n",
      "step: 16797.0, loss:0.20984335\n",
      "step: 16798.0, loss:0.21448762\n",
      "step: 16799.0, loss:0.20490238\n",
      "step: 16800.0, loss:0.18039346\n",
      "step: 16801.0, loss:0.21334427\n",
      "step: 16802.0, loss:0.13059338\n",
      "step: 16803.0, loss:0.18634646\n",
      "step: 16804.0, loss:0.16027098\n",
      "step: 16805.0, loss:0.14614192\n",
      "step: 16806.0, loss:0.17040836\n",
      "step: 16807.0, loss:0.09783534\n",
      "step: 16808.0, loss:0.13856410\n",
      "step: 16809.0, loss:0.20509511\n",
      "step: 16810.0, loss:0.18452723\n",
      "step: 16811.0, loss:0.29355458\n",
      "step: 16812.0, loss:0.21759746\n",
      "step: 16813.0, loss:0.11566828\n",
      "step: 16814.0, loss:0.15847526\n",
      "step: 16815.0, loss:0.12314968\n",
      "step: 16816.0, loss:0.15759839\n",
      "step: 16817.0, loss:0.14144524\n",
      "step: 16818.0, loss:0.19781416\n",
      "step: 16819.0, loss:0.16859962\n",
      "step: 16820.0, loss:0.13932011\n",
      "step: 16821.0, loss:0.10612779\n",
      "step: 16822.0, loss:0.17486653\n",
      "step: 16823.0, loss:0.09807831\n",
      "step: 16824.0, loss:0.29460046\n",
      "step: 16825.0, loss:0.23365129\n",
      "step: 16826.0, loss:0.13990489\n",
      "step: 16827.0, loss:0.16200980\n",
      "step: 16828.0, loss:0.17161359\n",
      "step: 16829.0, loss:0.31685647\n",
      "step: 16830.0, loss:0.10516240\n",
      "step: 16831.0, loss:0.13077291\n",
      "step: 16832.0, loss:0.10768841\n",
      "step: 16833.0, loss:0.14916036\n",
      "step: 16834.0, loss:0.07388812\n",
      "step: 16835.0, loss:0.23619198\n",
      "step: 16836.0, loss:0.07875117\n",
      "step: 16837.0, loss:0.16863545\n",
      "step: 16838.0, loss:0.10448301\n",
      "step: 16839.0, loss:0.16923289\n",
      "step: 16840.0, loss:0.10185936\n",
      "step: 16841.0, loss:0.22828151\n",
      "step: 16842.0, loss:0.29869870\n",
      "step: 16843.0, loss:0.19291655\n",
      "step: 16844.0, loss:0.17661714\n",
      "step: 16845.0, loss:0.15060219\n",
      "step: 16846.0, loss:0.17053854\n",
      "step: 16847.0, loss:0.17029783\n",
      "step: 16848.0, loss:0.11906243\n",
      "step: 16849.0, loss:0.29820426\n",
      "step: 16850.0, loss:0.14651423\n",
      "step: 16851.0, loss:0.19718951\n",
      "step: 16852.0, loss:0.20650194\n",
      "step: 16853.0, loss:0.14188374\n",
      "step: 16854.0, loss:0.14627522\n",
      "step: 16855.0, loss:0.32616083\n",
      "step: 16856.0, loss:0.24527910\n",
      "step: 16857.0, loss:0.13022334\n",
      "step: 16858.0, loss:0.11592614\n",
      "step: 16859.0, loss:0.15308934\n",
      "step: 16860.0, loss:0.18037398\n",
      "step: 16861.0, loss:0.14371661\n",
      "step: 16862.0, loss:0.08627368\n",
      "step: 16863.0, loss:0.11183798\n",
      "step: 16864.0, loss:0.17154108\n",
      "step: 16865.0, loss:0.14863275\n",
      "step: 16866.0, loss:0.27277980\n",
      "step: 16867.0, loss:0.22039203\n",
      "step: 16868.0, loss:0.22186599\n",
      "step: 16869.0, loss:0.21438924\n",
      "step: 16870.0, loss:0.22364837\n",
      "step: 16871.0, loss:0.12009087\n",
      "step: 16872.0, loss:0.14819233\n",
      "step: 16873.0, loss:0.10612440\n",
      "step: 16874.0, loss:0.23090403\n",
      "step: 16875.0, loss:0.14252142\n",
      "step: 16876.0, loss:0.17278355\n",
      "step: 16877.0, loss:0.20789817\n",
      "step: 16878.0, loss:0.09596077\n",
      "step: 16879.0, loss:0.21807798\n",
      "step: 16880.0, loss:0.13666980\n",
      "step: 16881.0, loss:0.27605678\n",
      "step: 16882.0, loss:0.19682401\n",
      "step: 16883.0, loss:0.09024342\n",
      "step: 16884.0, loss:0.14464287\n",
      "step: 16885.0, loss:0.09455588\n",
      "step: 16886.0, loss:0.24659649\n",
      "step: 16887.0, loss:0.08465288\n",
      "step: 16888.0, loss:0.17517010\n",
      "step: 16889.0, loss:0.06483316\n",
      "step: 16890.0, loss:0.24681052\n",
      "step: 16891.0, loss:0.17808525\n",
      "step: 16892.0, loss:0.17721565\n",
      "step: 16893.0, loss:0.29775399\n",
      "step: 16894.0, loss:0.20539582\n",
      "step: 16895.0, loss:0.12892762\n",
      "step: 16896.0, loss:0.13873268\n",
      "step: 16897.0, loss:0.14507647\n",
      "step: 16898.0, loss:0.25036504\n",
      "step: 16899.0, loss:0.06175807\n",
      "step: 16900.0, loss:0.20700741\n",
      "step: 16901.0, loss:0.17346624\n",
      "step: 16902.0, loss:0.21428855\n",
      "step: 16903.0, loss:0.14769882\n",
      "step: 16904.0, loss:0.20647558\n",
      "step: 16905.0, loss:0.09922418\n",
      "step: 16906.0, loss:0.19774083\n",
      "step: 16907.0, loss:0.16532435\n",
      "step: 16908.0, loss:0.13354839\n",
      "step: 16909.0, loss:0.15499170\n",
      "step: 16910.0, loss:0.12074218\n",
      "step: 16911.0, loss:0.12400672\n",
      "step: 16912.0, loss:0.22342351\n",
      "step: 16913.0, loss:0.14776791\n",
      "step: 16914.0, loss:0.13579206\n",
      "step: 16915.0, loss:0.14368054\n",
      "step: 16916.0, loss:0.27137247\n",
      "step: 16917.0, loss:0.15836832\n",
      "step: 16918.0, loss:0.11170010\n",
      "step: 16919.0, loss:0.10581358\n",
      "step: 16920.0, loss:0.13407346\n",
      "step: 16921.0, loss:0.22546699\n",
      "step: 16922.0, loss:0.16334031\n",
      "step: 16923.0, loss:0.27198338\n",
      "step: 16924.0, loss:0.15911816\n",
      "step: 16925.0, loss:0.12881799\n",
      "step: 16926.0, loss:0.18560962\n",
      "step: 16927.0, loss:0.15919987\n",
      "step: 16928.0, loss:0.13825680\n",
      "step: 16929.0, loss:0.16403597\n",
      "step: 16930.0, loss:0.12558257\n",
      "step: 16931.0, loss:0.16175337\n",
      "step: 16932.0, loss:0.22746222\n",
      "step: 16933.0, loss:0.12981076\n",
      "step: 16934.0, loss:0.08543966\n",
      "step: 16935.0, loss:0.08309991\n",
      "step: 16936.0, loss:0.15211491\n",
      "step: 16937.0, loss:0.11080327\n",
      "step: 16938.0, loss:0.17513590\n",
      "step: 16939.0, loss:0.23875961\n",
      "step: 16940.0, loss:0.14427011\n",
      "step: 16941.0, loss:0.20506286\n",
      "step: 16942.0, loss:0.23077512\n",
      "step: 16943.0, loss:0.08855517\n",
      "step: 16944.0, loss:0.17256370\n",
      "step: 16945.0, loss:0.20321956\n",
      "step: 16946.0, loss:0.06729428\n",
      "step: 16947.0, loss:0.16625854\n",
      "step: 16948.0, loss:0.16468279\n",
      "step: 16949.0, loss:0.14006995\n",
      "step: 16950.0, loss:0.21964728\n",
      "step: 16951.0, loss:0.11554487\n",
      "step: 16952.0, loss:0.13898264\n",
      "step: 16953.0, loss:0.13572842\n",
      "step: 16954.0, loss:0.23534412\n",
      "step: 16955.0, loss:0.11839889\n",
      "step: 16956.0, loss:0.22764512\n",
      "step: 16957.0, loss:0.19712515\n",
      "step: 16958.0, loss:0.14325923\n",
      "step: 16959.0, loss:0.08994091\n",
      "step: 16960.0, loss:0.17425663\n",
      "step: 16961.0, loss:0.19977373\n",
      "step: 16962.0, loss:0.11522199\n",
      "step: 16963.0, loss:0.12387445\n",
      "step: 16964.0, loss:0.23646964\n",
      "step: 16965.0, loss:0.19915098\n",
      "step: 16966.0, loss:0.23372913\n",
      "step: 16967.0, loss:0.17766150\n",
      "step: 16968.0, loss:0.19218950\n",
      "step: 16969.0, loss:0.15159120\n",
      "step: 16970.0, loss:0.13627706\n",
      "step: 16971.0, loss:0.13180105\n",
      "step: 16972.0, loss:0.10267086\n",
      "step: 16973.0, loss:0.22062753\n",
      "step: 16974.0, loss:0.15725998\n",
      "step: 16975.0, loss:0.27062447\n",
      "step: 16976.0, loss:0.11765100\n",
      "step: 16977.0, loss:0.26413834\n",
      "step: 16978.0, loss:0.19959462\n",
      "step: 16979.0, loss:0.12024247\n",
      "step: 16980.0, loss:0.19809877\n",
      "step: 16981.0, loss:0.11940263\n",
      "step: 16982.0, loss:0.23415306\n",
      "step: 16983.0, loss:0.14938623\n",
      "step: 16984.0, loss:0.20856683\n",
      "step: 16985.0, loss:0.15764991\n",
      "step: 16986.0, loss:0.22664193\n",
      "step: 16987.0, loss:0.18611565\n",
      "step: 16988.0, loss:0.08811371\n",
      "step: 16989.0, loss:0.11919747\n",
      "step: 16990.0, loss:0.21199236\n",
      "step: 16991.0, loss:0.11265643\n",
      "step: 16992.0, loss:0.29428777\n",
      "step: 16993.0, loss:0.21272810\n",
      "step: 16994.0, loss:0.12075982\n",
      "step: 16995.0, loss:0.25811709\n",
      "step: 16996.0, loss:0.12183575\n",
      "step: 16997.0, loss:0.15723675\n",
      "step: 16998.0, loss:0.18262602\n",
      "step: 16999.0, loss:0.16187652\n",
      "step: 17000.0, loss:0.23152512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1264/1264 [09:15<00:00,  2.28it/s]\n",
      "2023-04-03 05:46:48,718 - INFO - step:17000.0, matthews_corr:0.781366, Acc:89.799654%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 17001.0, loss:0.14793932\n",
      "step: 17002.0, loss:0.12225099\n",
      "step: 17003.0, loss:0.18269999\n",
      "step: 17004.0, loss:0.24684590\n",
      "step: 17005.0, loss:0.14069422\n",
      "step: 17006.0, loss:0.28990704\n",
      "step: 17007.0, loss:0.27308259\n",
      "step: 17008.0, loss:0.11392724\n",
      "step: 17009.0, loss:0.20291383\n",
      "step: 17010.0, loss:0.22199003\n",
      "step: 17011.0, loss:0.15440793\n",
      "step: 17012.0, loss:0.31586906\n",
      "step: 17013.0, loss:0.13814423\n",
      "step: 17014.0, loss:0.10513492\n",
      "step: 17015.0, loss:0.11183846\n",
      "step: 17016.0, loss:0.39797610\n",
      "step: 17017.0, loss:0.13759109\n",
      "step: 17018.0, loss:0.13748104\n",
      "step: 17019.0, loss:0.25848205\n",
      "step: 17020.0, loss:0.14861492\n",
      "step: 17021.0, loss:0.25758596\n",
      "step: 17022.0, loss:0.18651737\n",
      "step: 17023.0, loss:0.26068532\n",
      "step: 17024.0, loss:0.29032930\n",
      "step: 17025.0, loss:0.25926329\n",
      "step: 17026.0, loss:0.16709531\n",
      "step: 17027.0, loss:0.16030300\n",
      "step: 17028.0, loss:0.16023549\n",
      "step: 17029.0, loss:0.14599758\n",
      "step: 17030.0, loss:0.26359579\n",
      "step: 17031.0, loss:0.36847389\n",
      "step: 17032.0, loss:0.16503618\n",
      "step: 17033.0, loss:0.21886958\n",
      "step: 17034.0, loss:0.14422273\n",
      "step: 17035.0, loss:0.11835066\n",
      "step: 17036.0, loss:0.11587149\n",
      "step: 17037.0, loss:0.14702793\n",
      "step: 17038.0, loss:0.16794132\n",
      "step: 17039.0, loss:0.24627194\n",
      "step: 17040.0, loss:0.21900200\n",
      "step: 17041.0, loss:0.14755430\n",
      "step: 17042.0, loss:0.12999107\n",
      "step: 17043.0, loss:0.24925385\n",
      "step: 17044.0, loss:0.18392112\n",
      "step: 17045.0, loss:0.30507686\n",
      "step: 17046.0, loss:0.19280883\n",
      "step: 17047.0, loss:0.13049272\n",
      "step: 17048.0, loss:0.08985216\n",
      "step: 17049.0, loss:0.18591797\n",
      "step: 17050.0, loss:0.13964045\n",
      "step: 17051.0, loss:0.29403325\n",
      "step: 17052.0, loss:0.23726102\n",
      "step: 17053.0, loss:0.23187505\n",
      "step: 17054.0, loss:0.09982313\n",
      "step: 17055.0, loss:0.27376349\n",
      "step: 17056.0, loss:0.07015273\n",
      "step: 17057.0, loss:0.23650314\n",
      "step: 17058.0, loss:0.28103338\n",
      "step: 17059.0, loss:0.14251986\n",
      "step: 17060.0, loss:0.25363498\n",
      "step: 17061.0, loss:0.22508463\n",
      "step: 17062.0, loss:0.17790479\n",
      "step: 17063.0, loss:0.22573879\n",
      "step: 17064.0, loss:0.23384007\n",
      "step: 17065.0, loss:0.15668493\n",
      "step: 17066.0, loss:0.19576603\n",
      "step: 17067.0, loss:0.22916433\n",
      "step: 17068.0, loss:0.23331441\n",
      "step: 17069.0, loss:0.09789390\n",
      "step: 17070.0, loss:0.19015193\n",
      "step: 17071.0, loss:0.26628395\n",
      "step: 17072.0, loss:0.13837959\n",
      "step: 17073.0, loss:0.17949524\n",
      "step: 17074.0, loss:0.19003804\n",
      "step: 17075.0, loss:0.19443290\n",
      "step: 17076.0, loss:0.16659490\n",
      "step: 17077.0, loss:0.18421742\n",
      "step: 17078.0, loss:0.14562901\n",
      "step: 17079.0, loss:0.19320936\n",
      "step: 17080.0, loss:0.15185729\n",
      "step: 17081.0, loss:0.23221470\n",
      "step: 17082.0, loss:0.20459398\n",
      "step: 17083.0, loss:0.06875432\n",
      "step: 17084.0, loss:0.10511636\n",
      "step: 17085.0, loss:0.10223744\n",
      "step: 17086.0, loss:0.18575935\n",
      "step: 17087.0, loss:0.24806364\n",
      "step: 17088.0, loss:0.25126381\n",
      "step: 17089.0, loss:0.25032509\n",
      "step: 17090.0, loss:0.10434241\n",
      "step: 17091.0, loss:0.21700707\n",
      "step: 17092.0, loss:0.16239916\n",
      "step: 17093.0, loss:0.15400080\n",
      "step: 17094.0, loss:0.15829809\n",
      "step: 17095.0, loss:0.20255003\n",
      "step: 17096.0, loss:0.24350785\n",
      "step: 17097.0, loss:0.30026143\n",
      "step: 17098.0, loss:0.11487773\n",
      "step: 17099.0, loss:0.27093774\n",
      "step: 17100.0, loss:0.16819977\n",
      "step: 17101.0, loss:0.17221283\n",
      "step: 17102.0, loss:0.12066459\n",
      "step: 17103.0, loss:0.13270319\n",
      "step: 17104.0, loss:0.35753746\n",
      "step: 17105.0, loss:0.17379697\n",
      "step: 17106.0, loss:0.19423078\n",
      "step: 17107.0, loss:0.19072996\n",
      "step: 17108.0, loss:0.24922536\n",
      "step: 17109.0, loss:0.17919830\n",
      "step: 17110.0, loss:0.09132883\n",
      "step: 17111.0, loss:0.18837143\n",
      "step: 17112.0, loss:0.15419972\n",
      "step: 17113.0, loss:0.19825782\n",
      "step: 17114.0, loss:0.20477457\n",
      "step: 17115.0, loss:0.37626833\n",
      "step: 17116.0, loss:0.17881341\n",
      "step: 17117.0, loss:0.07645255\n",
      "step: 17118.0, loss:0.30106409\n",
      "step: 17119.0, loss:0.17666632\n",
      "step: 17120.0, loss:0.16368521\n",
      "step: 17121.0, loss:0.34071303\n",
      "step: 17122.0, loss:0.07579297\n",
      "step: 17123.0, loss:0.14300865\n",
      "step: 17124.0, loss:0.21047476\n",
      "step: 17125.0, loss:0.12771587\n",
      "step: 17126.0, loss:0.18898308\n",
      "step: 17127.0, loss:0.20976800\n",
      "step: 17128.0, loss:0.30194477\n",
      "step: 17129.0, loss:0.08663719\n",
      "step: 17130.0, loss:0.13728463\n",
      "step: 17131.0, loss:0.27290542\n",
      "step: 17132.0, loss:0.19051128\n",
      "step: 17133.0, loss:0.26244194\n",
      "step: 17134.0, loss:0.10978020\n",
      "step: 17135.0, loss:0.30408447\n",
      "step: 17136.0, loss:0.15269872\n",
      "step: 17137.0, loss:0.17799834\n",
      "step: 17138.0, loss:0.24472974\n",
      "step: 17139.0, loss:0.20505170\n",
      "step: 17140.0, loss:0.23675054\n",
      "step: 17141.0, loss:0.10571180\n",
      "step: 17142.0, loss:0.17030680\n",
      "step: 17143.0, loss:0.18973329\n",
      "step: 17144.0, loss:0.24372125\n",
      "step: 17145.0, loss:0.21897927\n",
      "step: 17146.0, loss:0.23868393\n",
      "step: 17147.0, loss:0.16161259\n",
      "step: 17148.0, loss:0.10351859\n",
      "step: 17149.0, loss:0.19920012\n",
      "step: 17150.0, loss:0.22318064\n",
      "step: 17151.0, loss:0.21057590\n",
      "step: 17152.0, loss:0.10026878\n",
      "step: 17153.0, loss:0.18687463\n",
      "step: 17154.0, loss:0.12002435\n",
      "step: 17155.0, loss:0.25655256\n",
      "step: 17156.0, loss:0.12102848\n",
      "step: 17157.0, loss:0.17888449\n",
      "step: 17158.0, loss:0.23056453\n",
      "step: 17159.0, loss:0.12572353\n",
      "step: 17160.0, loss:0.15784053\n",
      "step: 17161.0, loss:0.11624299\n",
      "step: 17162.0, loss:0.09769169\n",
      "step: 17163.0, loss:0.18463614\n",
      "step: 17164.0, loss:0.25897474\n",
      "step: 17165.0, loss:0.14695217\n",
      "step: 17166.0, loss:0.10939496\n",
      "step: 17167.0, loss:0.19656274\n",
      "step: 17168.0, loss:0.16560425\n",
      "step: 17169.0, loss:0.20244882\n",
      "step: 17170.0, loss:0.23535134\n",
      "step: 17171.0, loss:0.17037248\n",
      "step: 17172.0, loss:0.10903255\n",
      "step: 17173.0, loss:0.22891254\n",
      "step: 17174.0, loss:0.05989294\n",
      "step: 17175.0, loss:0.20420166\n",
      "step: 17176.0, loss:0.16083966\n",
      "step: 17177.0, loss:0.18745642\n",
      "step: 17178.0, loss:0.20362281\n",
      "step: 17179.0, loss:0.18370782\n",
      "step: 17180.0, loss:0.24721470\n",
      "step: 17181.0, loss:0.17528155\n",
      "step: 17182.0, loss:0.18078168\n",
      "step: 17183.0, loss:0.25523334\n",
      "step: 17184.0, loss:0.21681553\n",
      "step: 17185.0, loss:0.08623477\n",
      "step: 17186.0, loss:0.20493327\n",
      "step: 17187.0, loss:0.27045576\n",
      "step: 17188.0, loss:0.18275938\n",
      "step: 17189.0, loss:0.10300472\n",
      "step: 17190.0, loss:0.27259861\n",
      "step: 17191.0, loss:0.24480668\n",
      "step: 17192.0, loss:0.14762610\n",
      "step: 17193.0, loss:0.28470923\n",
      "step: 17194.0, loss:0.17477124\n",
      "step: 17195.0, loss:0.25375014\n",
      "step: 17196.0, loss:0.13278427\n",
      "step: 17197.0, loss:0.26138878\n",
      "step: 17198.0, loss:0.21209440\n",
      "step: 17199.0, loss:0.20922752\n",
      "step: 17200.0, loss:0.29257050\n",
      "step: 17201.0, loss:0.20520446\n",
      "step: 17202.0, loss:0.22707038\n",
      "step: 17203.0, loss:0.21308695\n",
      "step: 17204.0, loss:0.14742417\n",
      "step: 17205.0, loss:0.13689222\n",
      "step: 17206.0, loss:0.13289470\n",
      "step: 17207.0, loss:0.19934990\n",
      "step: 17208.0, loss:0.10199548\n",
      "step: 17209.0, loss:0.14827603\n",
      "step: 17210.0, loss:0.26678149\n",
      "step: 17211.0, loss:0.15300434\n",
      "step: 17212.0, loss:0.19879276\n",
      "step: 17213.0, loss:0.21445375\n",
      "step: 17214.0, loss:0.10123316\n",
      "step: 17215.0, loss:0.06880146\n",
      "step: 17216.0, loss:0.26987139\n",
      "step: 17217.0, loss:0.17359269\n",
      "step: 17218.0, loss:0.14527372\n",
      "step: 17219.0, loss:0.17166747\n",
      "step: 17220.0, loss:0.29445169\n",
      "step: 17221.0, loss:0.22641277\n",
      "step: 17222.0, loss:0.26575922\n",
      "step: 17223.0, loss:0.14162541\n",
      "step: 17224.0, loss:0.22141182\n",
      "step: 17225.0, loss:0.12779796\n",
      "step: 17226.0, loss:0.08688906\n",
      "step: 17227.0, loss:0.11047102\n",
      "step: 17228.0, loss:0.09427471\n",
      "step: 17229.0, loss:0.22061200\n",
      "step: 17230.0, loss:0.23727844\n",
      "step: 17231.0, loss:0.22336403\n",
      "step: 17232.0, loss:0.13327312\n",
      "step: 17233.0, loss:0.13824321\n",
      "step: 17234.0, loss:0.23497294\n",
      "step: 17235.0, loss:0.14666790\n",
      "step: 17236.0, loss:0.20464675\n",
      "step: 17237.0, loss:0.14637780\n",
      "step: 17238.0, loss:0.19312127\n",
      "step: 17239.0, loss:0.20587239\n",
      "step: 17240.0, loss:0.18164014\n",
      "step: 17241.0, loss:0.13114286\n",
      "step: 17242.0, loss:0.17880415\n",
      "step: 17243.0, loss:0.18738553\n",
      "step: 17244.0, loss:0.14693207\n",
      "step: 17245.0, loss:0.14740000\n",
      "step: 17246.0, loss:0.16668200\n",
      "step: 17247.0, loss:0.12048708\n",
      "step: 17248.0, loss:0.14912177\n",
      "step: 17249.0, loss:0.16824861\n",
      "step: 17250.0, loss:0.28262369\n",
      "step: 17251.0, loss:0.16717563\n",
      "step: 17252.0, loss:0.13322335\n",
      "step: 17253.0, loss:0.16788666\n",
      "step: 17254.0, loss:0.10140711\n",
      "step: 17255.0, loss:0.18410538\n",
      "step: 17256.0, loss:0.25457482\n",
      "step: 17257.0, loss:0.16741612\n",
      "step: 17258.0, loss:0.25916949\n",
      "step: 17259.0, loss:0.13899603\n",
      "step: 17260.0, loss:0.27045590\n",
      "step: 17261.0, loss:0.17204059\n",
      "step: 17262.0, loss:0.12876463\n",
      "step: 17263.0, loss:0.14291308\n",
      "step: 17264.0, loss:0.28226733\n",
      "step: 17265.0, loss:0.23855027\n",
      "step: 17266.0, loss:0.15848340\n",
      "step: 17267.0, loss:0.13342975\n",
      "step: 17268.0, loss:0.12336885\n",
      "step: 17269.0, loss:0.25020343\n",
      "step: 17270.0, loss:0.16946912\n",
      "step: 17271.0, loss:0.16045595\n",
      "step: 17272.0, loss:0.19458784\n",
      "step: 17273.0, loss:0.16360339\n",
      "step: 17274.0, loss:0.15542858\n",
      "step: 17275.0, loss:0.23866292\n",
      "step: 17276.0, loss:0.14388182\n",
      "step: 17277.0, loss:0.32741322\n",
      "step: 17278.0, loss:0.27731743\n",
      "step: 17279.0, loss:0.18679832\n",
      "step: 17280.0, loss:0.19298280\n",
      "step: 17281.0, loss:0.30016385\n",
      "step: 17282.0, loss:0.11293044\n",
      "step: 17283.0, loss:0.24189484\n",
      "step: 17284.0, loss:0.15503806\n",
      "step: 17285.0, loss:0.14705424\n",
      "step: 17286.0, loss:0.15843833\n",
      "step: 17287.0, loss:0.22352265\n",
      "step: 17288.0, loss:0.26968047\n",
      "step: 17289.0, loss:0.20114338\n",
      "step: 17290.0, loss:0.10136042\n",
      "step: 17291.0, loss:0.26131871\n",
      "step: 17292.0, loss:0.17333865\n",
      "step: 17293.0, loss:0.13342082\n",
      "step: 17294.0, loss:0.21614132\n",
      "step: 17295.0, loss:0.16659426\n",
      "step: 17296.0, loss:0.16971464\n",
      "step: 17297.0, loss:0.22217750\n",
      "step: 17298.0, loss:0.19095758\n",
      "step: 17299.0, loss:0.16666924\n",
      "step: 17300.0, loss:0.19959152\n",
      "step: 17301.0, loss:0.12867833\n",
      "step: 17302.0, loss:0.16023236\n",
      "step: 17303.0, loss:0.14143933\n",
      "step: 17304.0, loss:0.15802009\n",
      "step: 17305.0, loss:0.14033636\n",
      "step: 17306.0, loss:0.15124741\n",
      "step: 17307.0, loss:0.16852729\n",
      "step: 17308.0, loss:0.12477143\n",
      "step: 17309.0, loss:0.12169382\n",
      "step: 17310.0, loss:0.09792799\n",
      "step: 17311.0, loss:0.22400370\n",
      "step: 17312.0, loss:0.28353938\n",
      "step: 17313.0, loss:0.12036842\n",
      "step: 17314.0, loss:0.10021825\n",
      "step: 17315.0, loss:0.14443952\n",
      "step: 17316.0, loss:0.18994273\n",
      "step: 17317.0, loss:0.16117400\n",
      "step: 17318.0, loss:0.13181884\n",
      "step: 17319.0, loss:0.23999443\n",
      "step: 17320.0, loss:0.18911178\n",
      "step: 17321.0, loss:0.18264746\n",
      "step: 17322.0, loss:0.22629226\n",
      "step: 17323.0, loss:0.15309209\n",
      "step: 17324.0, loss:0.08445349\n",
      "step: 17325.0, loss:0.21111000\n",
      "step: 17326.0, loss:0.21715420\n",
      "step: 17327.0, loss:0.11596287\n",
      "step: 17328.0, loss:0.09192841\n",
      "step: 17329.0, loss:0.07073016\n",
      "step: 17330.0, loss:0.19944653\n",
      "step: 17331.0, loss:0.14342324\n",
      "step: 17332.0, loss:0.23685687\n",
      "step: 17333.0, loss:0.20519216\n",
      "step: 17334.0, loss:0.12132370\n",
      "step: 17335.0, loss:0.20443557\n",
      "step: 17336.0, loss:0.10325357\n",
      "step: 17337.0, loss:0.29726626\n",
      "step: 17338.0, loss:0.24433297\n",
      "step: 17339.0, loss:0.13992209\n",
      "step: 17340.0, loss:0.20140515\n",
      "step: 17341.0, loss:0.18745091\n",
      "step: 17342.0, loss:0.16873950\n",
      "step: 17343.0, loss:0.25348124\n",
      "step: 17344.0, loss:0.26707670\n",
      "step: 17345.0, loss:0.12961677\n",
      "step: 17346.0, loss:0.22005815\n",
      "step: 17347.0, loss:0.23183274\n",
      "step: 17348.0, loss:0.18097975\n",
      "step: 17349.0, loss:0.14558878\n",
      "step: 17350.0, loss:0.17611693\n",
      "step: 17351.0, loss:0.17530932\n",
      "step: 17352.0, loss:0.13463398\n",
      "step: 17353.0, loss:0.21086126\n",
      "step: 17354.0, loss:0.12459483\n",
      "step: 17355.0, loss:0.27241408\n",
      "step: 17356.0, loss:0.08519969\n",
      "step: 17357.0, loss:0.21693367\n",
      "step: 17358.0, loss:0.11493358\n",
      "step: 17359.0, loss:0.22920864\n",
      "step: 17360.0, loss:0.17266745\n",
      "step: 17361.0, loss:0.14270698\n",
      "step: 17362.0, loss:0.23020436\n",
      "step: 17363.0, loss:0.15315078\n",
      "step: 17364.0, loss:0.09959616\n",
      "step: 17365.0, loss:0.11994920\n",
      "step: 17366.0, loss:0.15812961\n",
      "step: 17367.0, loss:0.21147958\n",
      "step: 17368.0, loss:0.14793423\n",
      "step: 17369.0, loss:0.15421118\n",
      "step: 17370.0, loss:0.10756830\n",
      "step: 17371.0, loss:0.22643554\n",
      "step: 17372.0, loss:0.15046766\n",
      "step: 17373.0, loss:0.11325517\n",
      "step: 17374.0, loss:0.16108606\n",
      "step: 17375.0, loss:0.15312815\n",
      "step: 17376.0, loss:0.16176517\n",
      "step: 17377.0, loss:0.14931187\n",
      "step: 17378.0, loss:0.27306689\n",
      "step: 17379.0, loss:0.24168312\n",
      "step: 17380.0, loss:0.25766130\n",
      "step: 17381.0, loss:0.15958924\n",
      "step: 17382.0, loss:0.08440619\n",
      "step: 17383.0, loss:0.18211856\n",
      "step: 17384.0, loss:0.18761187\n",
      "step: 17385.0, loss:0.09624323\n",
      "step: 17386.0, loss:0.09052570\n",
      "step: 17387.0, loss:0.10522505\n",
      "step: 17388.0, loss:0.20111248\n",
      "step: 17389.0, loss:0.19013678\n",
      "step: 17390.0, loss:0.16320165\n",
      "step: 17391.0, loss:0.12704661\n",
      "step: 17392.0, loss:0.10235054\n",
      "step: 17393.0, loss:0.09964287\n",
      "step: 17394.0, loss:0.14541579\n",
      "step: 17395.0, loss:0.21615780\n",
      "step: 17396.0, loss:0.22770299\n",
      "step: 17397.0, loss:0.16906629\n",
      "step: 17398.0, loss:0.07102091\n",
      "step: 17399.0, loss:0.13162883\n",
      "step: 17400.0, loss:0.18186767\n",
      "step: 17401.0, loss:0.12433828\n",
      "step: 17402.0, loss:0.22741849\n",
      "step: 17403.0, loss:0.10697206\n",
      "step: 17404.0, loss:0.18107324\n",
      "step: 17405.0, loss:0.09413600\n",
      "step: 17406.0, loss:0.35144600\n",
      "step: 17407.0, loss:0.24735256\n",
      "step: 17408.0, loss:0.14005867\n",
      "step: 17409.0, loss:0.09168470\n",
      "step: 17410.0, loss:0.22384188\n",
      "step: 17411.0, loss:0.20377980\n",
      "step: 17412.0, loss:0.28220645\n",
      "step: 17413.0, loss:0.19725451\n",
      "step: 17414.0, loss:0.10454957\n",
      "step: 17415.0, loss:0.11031873\n",
      "step: 17416.0, loss:0.17015674\n",
      "step: 17417.0, loss:0.20277257\n",
      "step: 17418.0, loss:0.15012545\n",
      "step: 17419.0, loss:0.27247119\n",
      "step: 17420.0, loss:0.14842721\n",
      "step: 17421.0, loss:0.20791712\n",
      "step: 17422.0, loss:0.17942682\n",
      "step: 17423.0, loss:0.20159375\n",
      "step: 17424.0, loss:0.15273687\n",
      "step: 17425.0, loss:0.17258820\n",
      "step: 17426.0, loss:0.17270609\n",
      "step: 17427.0, loss:0.23500220\n",
      "step: 17428.0, loss:0.16513272\n",
      "step: 17429.0, loss:0.18597858\n",
      "step: 17430.0, loss:0.18460132\n",
      "step: 17431.0, loss:0.24074303\n",
      "step: 17432.0, loss:0.15248447\n",
      "step: 17433.0, loss:0.19045743\n",
      "step: 17434.0, loss:0.24275746\n",
      "step: 17435.0, loss:0.27268693\n",
      "step: 17436.0, loss:0.23726231\n",
      "step: 17437.0, loss:0.23509661\n",
      "step: 17438.0, loss:0.08824040\n",
      "step: 17439.0, loss:0.23818027\n",
      "step: 17440.0, loss:0.12165318\n",
      "step: 17441.0, loss:0.16961899\n",
      "step: 17442.0, loss:0.20358544\n",
      "step: 17443.0, loss:0.16242628\n",
      "step: 17444.0, loss:0.26581906\n",
      "step: 17445.0, loss:0.08253451\n",
      "step: 17446.0, loss:0.09415908\n",
      "step: 17447.0, loss:0.14094412\n",
      "step: 17448.0, loss:0.20216520\n",
      "step: 17449.0, loss:0.14030213\n",
      "step: 17450.0, loss:0.23197292\n",
      "step: 17451.0, loss:0.10294578\n",
      "step: 17452.0, loss:0.08135933\n",
      "step: 17453.0, loss:0.13610780\n",
      "step: 17454.0, loss:0.28264274\n",
      "step: 17455.0, loss:0.17967375\n",
      "step: 17456.0, loss:0.12912644\n",
      "step: 17457.0, loss:0.23723867\n",
      "step: 17458.0, loss:0.08175826\n",
      "step: 17459.0, loss:0.14476502\n",
      "step: 17460.0, loss:0.23920450\n",
      "step: 17461.0, loss:0.14966643\n",
      "step: 17462.0, loss:0.14989293\n",
      "step: 17463.0, loss:0.21111424\n",
      "step: 17464.0, loss:0.13232267\n",
      "step: 17465.0, loss:0.21511955\n",
      "step: 17466.0, loss:0.33136512\n",
      "step: 17467.0, loss:0.17369267\n",
      "step: 17468.0, loss:0.09828823\n",
      "step: 17469.0, loss:0.13213786\n",
      "step: 17470.0, loss:0.12949991\n",
      "step: 17471.0, loss:0.23920936\n",
      "step: 17472.0, loss:0.13046513\n",
      "step: 17473.0, loss:0.07814311\n",
      "step: 17474.0, loss:0.17842740\n",
      "step: 17475.0, loss:0.31683806\n",
      "step: 17476.0, loss:0.15007539\n",
      "step: 17477.0, loss:0.20055133\n",
      "step: 17478.0, loss:0.13335415\n",
      "step: 17479.0, loss:0.14700074\n",
      "step: 17480.0, loss:0.12745477\n",
      "step: 17481.0, loss:0.09093804\n",
      "step: 17482.0, loss:0.13387198\n",
      "step: 17483.0, loss:0.17259850\n",
      "step: 17484.0, loss:0.20702454\n",
      "step: 17485.0, loss:0.17443108\n",
      "step: 17486.0, loss:0.18193181\n",
      "step: 17487.0, loss:0.16165728\n",
      "step: 17488.0, loss:0.14266605\n",
      "step: 17489.0, loss:0.21260375\n",
      "step: 17490.0, loss:0.21196825\n",
      "step: 17491.0, loss:0.19878157\n",
      "step: 17492.0, loss:0.18032025\n",
      "step: 17493.0, loss:0.24297323\n",
      "step: 17494.0, loss:0.21371231\n",
      "step: 17495.0, loss:0.15608664\n",
      "step: 17496.0, loss:0.19264466\n",
      "step: 17497.0, loss:0.14516478\n",
      "step: 17498.0, loss:0.17395522\n",
      "step: 17499.0, loss:0.15418667\n",
      "step: 17500.0, loss:0.19309792\n",
      "step: 17501.0, loss:0.14539950\n",
      "step: 17502.0, loss:0.17997709\n",
      "step: 17503.0, loss:0.12198537\n",
      "step: 17504.0, loss:0.13253423\n",
      "step: 17505.0, loss:0.16341568\n",
      "step: 17506.0, loss:0.28250381\n",
      "step: 17507.0, loss:0.08971483\n",
      "step: 17508.0, loss:0.12917762\n",
      "step: 17509.0, loss:0.22105420\n",
      "step: 17510.0, loss:0.22546264\n",
      "step: 17511.0, loss:0.15928903\n",
      "step: 17512.0, loss:0.16506514\n",
      "step: 17513.0, loss:0.13412897\n",
      "step: 17514.0, loss:0.16088783\n",
      "step: 17515.0, loss:0.23784835\n",
      "step: 17516.0, loss:0.11388926\n",
      "step: 17517.0, loss:0.12010032\n",
      "step: 17518.0, loss:0.21098855\n",
      "step: 17519.0, loss:0.17808913\n",
      "step: 17520.0, loss:0.06957805\n",
      "step: 17521.0, loss:0.20047043\n",
      "step: 17522.0, loss:0.28096472\n",
      "step: 17523.0, loss:0.16651143\n",
      "step: 17524.0, loss:0.33164633\n",
      "step: 17525.0, loss:0.10353803\n",
      "step: 17526.0, loss:0.28339420\n",
      "step: 17527.0, loss:0.21100086\n",
      "step: 17528.0, loss:0.17393376\n",
      "step: 17529.0, loss:0.20781548\n",
      "step: 17530.0, loss:0.20375531\n",
      "step: 17531.0, loss:0.25683910\n",
      "step: 17532.0, loss:0.13409488\n",
      "step: 17533.0, loss:0.10618363\n",
      "step: 17534.0, loss:0.13379446\n",
      "step: 17535.0, loss:0.24454189\n",
      "step: 17536.0, loss:0.08468370\n",
      "step: 17537.0, loss:0.23774868\n",
      "step: 17538.0, loss:0.17755910\n",
      "step: 17539.0, loss:0.14764999\n",
      "step: 17540.0, loss:0.14886739\n",
      "step: 17541.0, loss:0.21148316\n",
      "step: 17542.0, loss:0.12195991\n",
      "step: 17543.0, loss:0.21359565\n",
      "step: 17544.0, loss:0.14666805\n",
      "step: 17545.0, loss:0.07773443\n",
      "step: 17546.0, loss:0.20512878\n",
      "step: 17547.0, loss:0.23524809\n",
      "step: 17548.0, loss:0.29863798\n",
      "step: 17549.0, loss:0.15635165\n",
      "step: 17550.0, loss:0.28668685\n",
      "step: 17551.0, loss:0.12145397\n",
      "step: 17552.0, loss:0.20354985\n",
      "step: 17553.0, loss:0.14631789\n",
      "step: 17554.0, loss:0.22983439\n",
      "step: 17555.0, loss:0.11511519\n",
      "step: 17556.0, loss:0.19904641\n",
      "step: 17557.0, loss:0.11019380\n",
      "step: 17558.0, loss:0.13237679\n",
      "step: 17559.0, loss:0.18386456\n",
      "step: 17560.0, loss:0.18867690\n",
      "step: 17561.0, loss:0.09877935\n",
      "step: 17562.0, loss:0.09170473\n",
      "step: 17563.0, loss:0.11151896\n",
      "step: 17564.0, loss:0.18775984\n",
      "step: 17565.0, loss:0.23073240\n",
      "step: 17566.0, loss:0.15754295\n",
      "step: 17567.0, loss:0.21577612\n",
      "step: 17568.0, loss:0.21254508\n",
      "step: 17569.0, loss:0.26802894\n",
      "step: 17570.0, loss:0.12114366\n",
      "step: 17571.0, loss:0.26843914\n",
      "step: 17572.0, loss:0.24644627\n",
      "step: 17573.0, loss:0.30702870\n",
      "step: 17574.0, loss:0.17952116\n",
      "step: 17575.0, loss:0.12253869\n",
      "step: 17576.0, loss:0.25714880\n",
      "step: 17577.0, loss:0.15069928\n",
      "step: 17578.0, loss:0.10962596\n",
      "step: 17579.0, loss:0.06637215\n",
      "step: 17580.0, loss:0.18821458\n",
      "step: 17581.0, loss:0.13823996\n",
      "step: 17582.0, loss:0.42595471\n",
      "step: 17583.0, loss:0.22223466\n",
      "step: 17584.0, loss:0.14077463\n",
      "step: 17585.0, loss:0.11938784\n",
      "step: 17586.0, loss:0.15801180\n",
      "step: 17587.0, loss:0.04630685\n",
      "step: 17588.0, loss:0.14515249\n",
      "step: 17589.0, loss:0.20442046\n",
      "step: 17590.0, loss:0.16112364\n",
      "step: 17591.0, loss:0.22481734\n",
      "step: 17592.0, loss:0.08274020\n",
      "step: 17593.0, loss:0.17157467\n",
      "step: 17594.0, loss:0.12604884\n",
      "step: 17595.0, loss:0.13458407\n",
      "step: 17596.0, loss:0.13078161\n",
      "step: 17597.0, loss:0.28867365\n",
      "step: 17598.0, loss:0.22511894\n",
      "step: 17599.0, loss:0.08221913\n",
      "step: 17600.0, loss:0.23504405\n",
      "step: 17601.0, loss:0.15447014\n",
      "step: 17602.0, loss:0.35360303\n",
      "step: 17603.0, loss:0.21404488\n",
      "step: 17604.0, loss:0.17817511\n",
      "step: 17605.0, loss:0.21866880\n",
      "step: 17606.0, loss:0.28240301\n",
      "step: 17607.0, loss:0.19913597\n",
      "step: 17608.0, loss:0.09179228\n",
      "step: 17609.0, loss:0.23960389\n",
      "step: 17610.0, loss:0.19198181\n",
      "step: 17611.0, loss:0.22118401\n",
      "step: 17612.0, loss:0.11427997\n",
      "step: 17613.0, loss:0.16794756\n",
      "step: 17614.0, loss:0.19140731\n",
      "step: 17615.0, loss:0.26709949\n",
      "step: 17616.0, loss:0.19126502\n",
      "step: 17617.0, loss:0.12458820\n",
      "step: 17618.0, loss:0.15936772\n",
      "step: 17619.0, loss:0.24116813\n",
      "step: 17620.0, loss:0.17991956\n",
      "step: 17621.0, loss:0.09510048\n",
      "step: 17622.0, loss:0.14922220\n",
      "step: 17623.0, loss:0.25146786\n",
      "step: 17624.0, loss:0.19273730\n",
      "step: 17625.0, loss:0.13652227\n",
      "step: 17626.0, loss:0.28523906\n",
      "step: 17627.0, loss:0.16519753\n",
      "step: 17628.0, loss:0.09081126\n",
      "step: 17629.0, loss:0.17110644\n",
      "step: 17630.0, loss:0.18740566\n",
      "step: 17631.0, loss:0.16130708\n",
      "step: 17632.0, loss:0.10198849\n",
      "step: 17633.0, loss:0.06381684\n",
      "step: 17634.0, loss:0.19704637\n",
      "step: 17635.0, loss:0.19850900\n",
      "step: 17636.0, loss:0.21228678\n",
      "step: 17637.0, loss:0.21349743\n",
      "step: 17638.0, loss:0.22971234\n",
      "step: 17639.0, loss:0.14309009\n",
      "step: 17640.0, loss:0.15860411\n",
      "step: 17641.0, loss:0.19230488\n",
      "step: 17642.0, loss:0.18951251\n",
      "step: 17643.0, loss:0.14489205\n",
      "step: 17644.0, loss:0.20175055\n",
      "step: 17645.0, loss:0.11035806\n",
      "step: 17646.0, loss:0.27299026\n",
      "step: 17647.0, loss:0.20682709\n",
      "step: 17648.0, loss:0.17894260\n",
      "step: 17649.0, loss:0.13724814\n",
      "step: 17650.0, loss:0.23469964\n",
      "step: 17651.0, loss:0.18421216\n",
      "step: 17652.0, loss:0.21371024\n",
      "step: 17653.0, loss:0.16071784\n",
      "step: 17654.0, loss:0.15573881\n",
      "step: 17655.0, loss:0.17442808\n",
      "step: 17656.0, loss:0.20394620\n",
      "step: 17657.0, loss:0.20425798\n",
      "step: 17658.0, loss:0.08931946\n",
      "step: 17659.0, loss:0.18269070\n",
      "step: 17660.0, loss:0.20358298\n",
      "step: 17661.0, loss:0.12510291\n",
      "step: 17662.0, loss:0.17959640\n",
      "step: 17663.0, loss:0.29752673\n",
      "step: 17664.0, loss:0.13061383\n",
      "step: 17665.0, loss:0.27568106\n",
      "step: 17666.0, loss:0.18344472\n",
      "step: 17667.0, loss:0.09510741\n",
      "step: 17668.0, loss:0.21436586\n",
      "step: 17669.0, loss:0.15421448\n",
      "step: 17670.0, loss:0.14867263\n",
      "step: 17671.0, loss:0.29285734\n",
      "step: 17672.0, loss:0.19368840\n",
      "step: 17673.0, loss:0.11517058\n",
      "step: 17674.0, loss:0.22917053\n",
      "step: 17675.0, loss:0.16147144\n",
      "step: 17676.0, loss:0.24479416\n",
      "step: 17677.0, loss:0.29999905\n",
      "step: 17678.0, loss:0.15038912\n",
      "step: 17679.0, loss:0.23934952\n",
      "step: 17680.0, loss:0.26692290\n",
      "step: 17681.0, loss:0.23786706\n",
      "step: 17682.0, loss:0.22922654\n",
      "step: 17683.0, loss:0.23422644\n",
      "step: 17684.0, loss:0.19866880\n",
      "step: 17685.0, loss:0.15918656\n",
      "step: 17686.0, loss:0.22181994\n",
      "step: 17687.0, loss:0.14234806\n",
      "step: 17688.0, loss:0.25103785\n",
      "step: 17689.0, loss:0.30382628\n",
      "step: 17690.0, loss:0.27047800\n",
      "step: 17691.0, loss:0.22120947\n",
      "step: 17692.0, loss:0.36440438\n",
      "step: 17693.0, loss:0.09422890\n",
      "step: 17694.0, loss:0.16834609\n",
      "step: 17695.0, loss:0.17761997\n",
      "step: 17696.0, loss:0.23020357\n",
      "step: 17697.0, loss:0.14033239\n",
      "step: 17698.0, loss:0.09136011\n",
      "step: 17699.0, loss:0.14108471\n",
      "step: 17700.0, loss:0.18630695\n",
      "step: 17701.0, loss:0.13484468\n",
      "step: 17702.0, loss:0.17426127\n",
      "step: 17703.0, loss:0.26135855\n",
      "step: 17704.0, loss:0.22455803\n",
      "step: 17705.0, loss:0.14459953\n",
      "step: 17706.0, loss:0.12629215\n",
      "step: 17707.0, loss:0.10397575\n",
      "step: 17708.0, loss:0.22003553\n",
      "step: 17709.0, loss:0.30902153\n",
      "step: 17710.0, loss:0.16564079\n",
      "step: 17711.0, loss:0.11062472\n",
      "step: 17712.0, loss:0.22650477\n",
      "step: 17713.0, loss:0.24265385\n",
      "step: 17714.0, loss:0.31829335\n",
      "step: 17715.0, loss:0.29499086\n",
      "step: 17716.0, loss:0.19381785\n",
      "step: 17717.0, loss:0.21370114\n",
      "step: 17718.0, loss:0.24766325\n",
      "step: 17719.0, loss:0.23638122\n",
      "step: 17720.0, loss:0.26850702\n",
      "step: 17721.0, loss:0.22797690\n",
      "step: 17722.0, loss:0.12664356\n",
      "step: 17723.0, loss:0.18024568\n",
      "step: 17724.0, loss:0.19042272\n",
      "step: 17725.0, loss:0.15773250\n",
      "step: 17726.0, loss:0.19875169\n",
      "step: 17727.0, loss:0.23767327\n",
      "step: 17728.0, loss:0.24496227\n",
      "step: 17729.0, loss:0.19992445\n",
      "step: 17730.0, loss:0.12821121\n",
      "step: 17731.0, loss:0.23117791\n",
      "step: 17732.0, loss:0.15763105\n",
      "step: 17733.0, loss:0.25157970\n",
      "step: 17734.0, loss:0.25402550\n",
      "step: 17735.0, loss:0.20838075\n",
      "step: 17736.0, loss:0.17212925\n",
      "step: 17737.0, loss:0.23171810\n",
      "step: 17738.0, loss:0.21945509\n",
      "step: 17739.0, loss:0.15040348\n",
      "step: 17740.0, loss:0.10183384\n",
      "step: 17741.0, loss:0.23453879\n",
      "step: 17742.0, loss:0.14270310\n",
      "step: 17743.0, loss:0.23455755\n",
      "step: 17744.0, loss:0.24520420\n",
      "step: 17745.0, loss:0.23891633\n",
      "step: 17746.0, loss:0.12903090\n",
      "step: 17747.0, loss:0.27193544\n",
      "step: 17748.0, loss:0.16558238\n",
      "step: 17749.0, loss:0.11901248\n",
      "step: 17750.0, loss:0.18461373\n",
      "step: 17751.0, loss:0.12948225\n",
      "step: 17752.0, loss:0.16645481\n",
      "step: 17753.0, loss:0.15280855\n",
      "step: 17754.0, loss:0.39826659\n",
      "step: 17755.0, loss:0.28271784\n",
      "step: 17756.0, loss:0.18224850\n",
      "step: 17757.0, loss:0.14191009\n",
      "step: 17758.0, loss:0.23726604\n",
      "step: 17759.0, loss:0.14343044\n",
      "step: 17760.0, loss:0.16123728\n",
      "step: 17761.0, loss:0.22290896\n",
      "step: 17762.0, loss:0.14744666\n",
      "step: 17763.0, loss:0.18141480\n",
      "step: 17764.0, loss:0.08260044\n",
      "step: 17765.0, loss:0.17286445\n",
      "step: 17766.0, loss:0.11785126\n",
      "step: 17767.0, loss:0.10516440\n",
      "step: 17768.0, loss:0.20796247\n",
      "step: 17769.0, loss:0.09433404\n",
      "step: 17770.0, loss:0.24994449\n",
      "step: 17771.0, loss:0.14188196\n",
      "step: 17772.0, loss:0.18433223\n",
      "step: 17773.0, loss:0.22745137\n",
      "step: 17774.0, loss:0.31070843\n",
      "step: 17775.0, loss:0.17506717\n",
      "step: 17776.0, loss:0.15410370\n",
      "step: 17777.0, loss:0.11316123\n",
      "step: 17778.0, loss:0.13712876\n",
      "step: 17779.0, loss:0.14996247\n",
      "step: 17780.0, loss:0.19474660\n",
      "step: 17781.0, loss:0.22571460\n",
      "step: 17782.0, loss:0.14028656\n",
      "step: 17783.0, loss:0.16981828\n",
      "step: 17784.0, loss:0.20299117\n",
      "step: 17785.0, loss:0.26376023\n",
      "step: 17786.0, loss:0.18324966\n",
      "step: 17787.0, loss:0.18034506\n",
      "step: 17788.0, loss:0.16680787\n",
      "step: 17789.0, loss:0.14948010\n",
      "step: 17790.0, loss:0.14009419\n",
      "step: 17791.0, loss:0.21673581\n",
      "step: 17792.0, loss:0.28604635\n",
      "step: 17793.0, loss:0.23098531\n",
      "step: 17794.0, loss:0.09047571\n",
      "step: 17795.0, loss:0.19586839\n",
      "step: 17796.0, loss:0.21962119\n",
      "step: 17797.0, loss:0.27785952\n",
      "step: 17798.0, loss:0.19719815\n",
      "step: 17799.0, loss:0.10921082\n",
      "step: 17800.0, loss:0.13172632\n",
      "step: 17801.0, loss:0.12019042\n",
      "step: 17802.0, loss:0.07576174\n",
      "step: 17803.0, loss:0.25866394\n",
      "step: 17804.0, loss:0.23702743\n",
      "step: 17805.0, loss:0.16261437\n",
      "step: 17806.0, loss:0.26817109\n",
      "step: 17807.0, loss:0.11368973\n",
      "step: 17808.0, loss:0.20058445\n",
      "step: 17809.0, loss:0.13024914\n",
      "step: 17810.0, loss:0.13546544\n",
      "step: 17811.0, loss:0.16533035\n",
      "step: 17812.0, loss:0.19217124\n",
      "step: 17813.0, loss:0.21176808\n",
      "step: 17814.0, loss:0.27465079\n",
      "step: 17815.0, loss:0.13945458\n",
      "step: 17816.0, loss:0.21204021\n",
      "step: 17817.0, loss:0.22475877\n",
      "step: 17818.0, loss:0.16368913\n",
      "step: 17819.0, loss:0.16883498\n",
      "step: 17820.0, loss:0.04263876\n",
      "step: 17821.0, loss:0.17089569\n",
      "step: 17822.0, loss:0.10691804\n",
      "step: 17823.0, loss:0.25448429\n",
      "step: 17824.0, loss:0.25861680\n",
      "step: 17825.0, loss:0.11521706\n",
      "step: 17826.0, loss:0.06315689\n",
      "step: 17827.0, loss:0.21656717\n",
      "step: 17828.0, loss:0.19001768\n",
      "step: 17829.0, loss:0.19245997\n",
      "step: 17830.0, loss:0.21934254\n",
      "step: 17831.0, loss:0.20592434\n",
      "step: 17832.0, loss:0.24971190\n",
      "step: 17833.0, loss:0.15394890\n",
      "step: 17834.0, loss:0.09425253\n",
      "step: 17835.0, loss:0.12090273\n",
      "step: 17836.0, loss:0.08870487\n",
      "step: 17837.0, loss:0.21110231\n",
      "step: 17838.0, loss:0.24515393\n",
      "step: 17839.0, loss:0.17146956\n",
      "step: 17840.0, loss:0.26355266\n",
      "step: 17841.0, loss:0.17203934\n",
      "step: 17842.0, loss:0.20095248\n",
      "step: 17843.0, loss:0.29295838\n",
      "step: 17844.0, loss:0.21018297\n",
      "step: 17845.0, loss:0.18343686\n",
      "step: 17846.0, loss:0.20034749\n",
      "step: 17847.0, loss:0.10503353\n",
      "step: 17848.0, loss:0.19773538\n",
      "step: 17849.0, loss:0.10928810\n",
      "step: 17850.0, loss:0.15990571\n",
      "step: 17851.0, loss:0.15293961\n",
      "step: 17852.0, loss:0.23572652\n",
      "step: 17853.0, loss:0.09291793\n",
      "step: 17854.0, loss:0.35745032\n",
      "step: 17855.0, loss:0.17087390\n",
      "step: 17856.0, loss:0.25501854\n",
      "step: 17857.0, loss:0.09069865\n",
      "step: 17858.0, loss:0.25077353\n",
      "step: 17859.0, loss:0.34072731\n",
      "step: 17860.0, loss:0.17388582\n",
      "step: 17861.0, loss:0.27105813\n",
      "step: 17862.0, loss:0.15660615\n",
      "step: 17863.0, loss:0.24167082\n",
      "step: 17864.0, loss:0.22312554\n",
      "step: 17865.0, loss:0.10193912\n",
      "step: 17866.0, loss:0.22583005\n",
      "step: 17867.0, loss:0.09865469\n",
      "step: 17868.0, loss:0.26699988\n",
      "step: 17869.0, loss:0.20135880\n",
      "step: 17870.0, loss:0.18025666\n",
      "step: 17871.0, loss:0.13983229\n",
      "step: 17872.0, loss:0.18941878\n",
      "step: 17873.0, loss:0.17764684\n",
      "step: 17874.0, loss:0.32929168\n",
      "step: 17875.0, loss:0.16790257\n",
      "step: 17876.0, loss:0.20379883\n",
      "step: 17877.0, loss:0.15078386\n",
      "step: 17878.0, loss:0.13662077\n",
      "step: 17879.0, loss:0.12496596\n",
      "step: 17880.0, loss:0.16000217\n",
      "step: 17881.0, loss:0.16634331\n",
      "step: 17882.0, loss:0.15752366\n",
      "step: 17883.0, loss:0.17818862\n",
      "step: 17884.0, loss:0.12947053\n",
      "step: 17885.0, loss:0.14654203\n",
      "step: 17886.0, loss:0.19224481\n",
      "step: 17887.0, loss:0.15984486\n",
      "step: 17888.0, loss:0.13943181\n",
      "step: 17889.0, loss:0.18413151\n",
      "step: 17890.0, loss:0.14323115\n",
      "step: 17891.0, loss:0.10580522\n",
      "step: 17892.0, loss:0.21685765\n",
      "step: 17893.0, loss:0.20844318\n",
      "step: 17894.0, loss:0.10790149\n",
      "step: 17895.0, loss:0.22028515\n",
      "step: 17896.0, loss:0.19549564\n",
      "step: 17897.0, loss:0.25840391\n",
      "step: 17898.0, loss:0.23444738\n",
      "step: 17899.0, loss:0.21656612\n",
      "step: 17900.0, loss:0.09359652\n",
      "step: 17901.0, loss:0.21709608\n",
      "step: 17902.0, loss:0.15086635\n",
      "step: 17903.0, loss:0.10567601\n",
      "step: 17904.0, loss:0.27722128\n",
      "step: 17905.0, loss:0.10301120\n",
      "step: 17906.0, loss:0.06744170\n",
      "step: 17907.0, loss:0.11763160\n",
      "step: 17908.0, loss:0.25000145\n",
      "step: 17909.0, loss:0.14524282\n",
      "step: 17910.0, loss:0.18099419\n",
      "step: 17911.0, loss:0.27946600\n",
      "step: 17912.0, loss:0.11273330\n",
      "step: 17913.0, loss:0.22741130\n",
      "step: 17914.0, loss:0.09241295\n",
      "step: 17915.0, loss:0.18977381\n",
      "step: 17916.0, loss:0.20963146\n",
      "step: 17917.0, loss:0.15223203\n",
      "step: 17918.0, loss:0.11333297\n",
      "step: 17919.0, loss:0.05397343\n",
      "step: 17920.0, loss:0.17658969\n",
      "step: 17921.0, loss:0.13163387\n",
      "step: 17922.0, loss:0.12537767\n",
      "step: 17923.0, loss:0.29619622\n",
      "step: 17924.0, loss:0.23442847\n",
      "step: 17925.0, loss:0.16646160\n",
      "step: 17926.0, loss:0.19824915\n",
      "step: 17927.0, loss:0.18927949\n",
      "step: 17928.0, loss:0.04071888\n",
      "step: 17929.0, loss:0.20825055\n",
      "step: 17930.0, loss:0.14910477\n",
      "step: 17931.0, loss:0.14885167\n",
      "step: 17932.0, loss:0.21441855\n",
      "step: 17933.0, loss:0.19750385\n",
      "step: 17934.0, loss:0.19308964\n",
      "step: 17935.0, loss:0.15704000\n",
      "step: 17936.0, loss:0.19265391\n",
      "step: 17937.0, loss:0.30360128\n",
      "step: 17938.0, loss:0.13295166\n",
      "step: 17939.0, loss:0.19823353\n",
      "step: 17940.0, loss:0.13667662\n",
      "step: 17941.0, loss:0.16572682\n",
      "step: 17942.0, loss:0.17701482\n",
      "step: 17943.0, loss:0.10032634\n",
      "step: 17944.0, loss:0.21831784\n",
      "step: 17945.0, loss:0.19086051\n",
      "step: 17946.0, loss:0.23224071\n",
      "step: 17947.0, loss:0.24196522\n",
      "step: 17948.0, loss:0.16286943\n",
      "step: 17949.0, loss:0.24724374\n",
      "step: 17950.0, loss:0.16374779\n",
      "step: 17951.0, loss:0.10815309\n",
      "step: 17952.0, loss:0.20773334\n",
      "step: 17953.0, loss:0.20449813\n",
      "step: 17954.0, loss:0.12457004\n",
      "step: 17955.0, loss:0.13249976\n",
      "step: 17956.0, loss:0.08203388\n",
      "step: 17957.0, loss:0.14524161\n",
      "step: 17958.0, loss:0.13002852\n",
      "step: 17959.0, loss:0.12879462\n",
      "step: 17960.0, loss:0.32743342\n",
      "step: 17961.0, loss:0.17351008\n",
      "step: 17962.0, loss:0.15309215\n",
      "step: 17963.0, loss:0.13681710\n",
      "step: 17964.0, loss:0.20108423\n",
      "step: 17965.0, loss:0.10181034\n",
      "step: 17966.0, loss:0.13007597\n",
      "step: 17967.0, loss:0.19273009\n",
      "step: 17968.0, loss:0.21255806\n",
      "step: 17969.0, loss:0.21005357\n",
      "step: 17970.0, loss:0.15172853\n",
      "step: 17971.0, loss:0.11847113\n",
      "step: 17972.0, loss:0.07039039\n",
      "step: 17973.0, loss:0.12860313\n",
      "step: 17974.0, loss:0.22599043\n",
      "step: 17975.0, loss:0.23470170\n",
      "step: 17976.0, loss:0.16354434\n",
      "step: 17977.0, loss:0.17108218\n",
      "step: 17978.0, loss:0.25340824\n",
      "step: 17979.0, loss:0.09712639\n",
      "step: 17980.0, loss:0.09895275\n",
      "step: 17981.0, loss:0.21295009\n",
      "step: 17982.0, loss:0.20519142\n",
      "step: 17983.0, loss:0.10134068\n",
      "step: 17984.0, loss:0.15965519\n",
      "step: 17985.0, loss:0.18038125\n",
      "step: 17986.0, loss:0.09549632\n",
      "step: 17987.0, loss:0.22085311\n",
      "step: 17988.0, loss:0.15336026\n",
      "step: 17989.0, loss:0.10041374\n",
      "step: 17990.0, loss:0.11973171\n",
      "step: 17991.0, loss:0.24385747\n",
      "step: 17992.0, loss:0.21540423\n",
      "step: 17993.0, loss:0.12412000\n",
      "step: 17994.0, loss:0.09601339\n",
      "step: 17995.0, loss:0.15045053\n",
      "step: 17996.0, loss:0.16043998\n",
      "step: 17997.0, loss:0.21319400\n",
      "step: 17998.0, loss:0.16237337\n",
      "step: 17999.0, loss:0.19015107\n",
      "step: 18000.0, loss:0.18477909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1264/1264 [07:47<00:00,  2.71it/s] \n",
      "2023-04-03 06:26:38,881 - INFO - step:18000.0, matthews_corr:0.787201, Acc:90.004947%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 18001.0, loss:0.15868376\n",
      "step: 18002.0, loss:0.17256936\n",
      "step: 18003.0, loss:0.20056924\n",
      "step: 18004.0, loss:0.30804089\n",
      "step: 18005.0, loss:0.13284130\n",
      "step: 18006.0, loss:0.14885878\n",
      "step: 18007.0, loss:0.14361217\n",
      "step: 18008.0, loss:0.13350950\n",
      "step: 18009.0, loss:0.07949792\n",
      "step: 18010.0, loss:0.08000065\n",
      "step: 18011.0, loss:0.16420801\n",
      "step: 18012.0, loss:0.20162017\n",
      "step: 18013.0, loss:0.27640873\n",
      "step: 18014.0, loss:0.15659772\n",
      "step: 18015.0, loss:0.20094265\n",
      "step: 18016.0, loss:0.23863940\n",
      "step: 18017.0, loss:0.12554178\n",
      "step: 18018.0, loss:0.20051765\n",
      "step: 18019.0, loss:0.19776305\n",
      "step: 18020.0, loss:0.25087332\n",
      "step: 18021.0, loss:0.17153000\n",
      "step: 18022.0, loss:0.20151444\n",
      "step: 18023.0, loss:0.22766722\n",
      "step: 18024.0, loss:0.18460952\n",
      "step: 18025.0, loss:0.12835074\n",
      "step: 18026.0, loss:0.15818677\n",
      "step: 18027.0, loss:0.18280732\n",
      "step: 18028.0, loss:0.18382606\n",
      "step: 18029.0, loss:0.24013971\n",
      "step: 18030.0, loss:0.28101958\n",
      "step: 18031.0, loss:0.10808058\n",
      "step: 18032.0, loss:0.11328752\n",
      "step: 18033.0, loss:0.22277375\n",
      "step: 18034.0, loss:0.14289192\n",
      "step: 18035.0, loss:0.11925220\n",
      "step: 18036.0, loss:0.08506152\n",
      "step: 18037.0, loss:0.18680351\n",
      "step: 18038.0, loss:0.16250496\n",
      "step: 18039.0, loss:0.10737987\n",
      "step: 18040.0, loss:0.16095347\n",
      "step: 18041.0, loss:0.13416964\n",
      "step: 18042.0, loss:0.14923285\n",
      "step: 18043.0, loss:0.16752331\n",
      "step: 18044.0, loss:0.21592912\n",
      "step: 18045.0, loss:0.15634918\n",
      "step: 18046.0, loss:0.17314754\n",
      "step: 18047.0, loss:0.19558438\n",
      "step: 18048.0, loss:0.27642370\n",
      "step: 18049.0, loss:0.05561736\n",
      "step: 18050.0, loss:0.11126509\n",
      "step: 18051.0, loss:0.18512160\n",
      "step: 18052.0, loss:0.30450624\n",
      "step: 18053.0, loss:0.12677582\n",
      "step: 18054.0, loss:0.24861827\n",
      "step: 18055.0, loss:0.14748400\n",
      "step: 18056.0, loss:0.19933538\n",
      "step: 18057.0, loss:0.19814685\n",
      "step: 18058.0, loss:0.10298418\n",
      "step: 18059.0, loss:0.10015094\n",
      "step: 18060.0, loss:0.26653698\n",
      "step: 18061.0, loss:0.12056951\n",
      "step: 18062.0, loss:0.08527935\n",
      "step: 18063.0, loss:0.08152453\n",
      "step: 18064.0, loss:0.06568317\n",
      "step: 18065.0, loss:0.25184541\n",
      "step: 18066.0, loss:0.25384375\n",
      "step: 18067.0, loss:0.35719907\n",
      "step: 18068.0, loss:0.29362747\n",
      "step: 18069.0, loss:0.11060470\n",
      "step: 18070.0, loss:0.23549524\n",
      "step: 18071.0, loss:0.14423369\n",
      "step: 18072.0, loss:0.31842738\n",
      "step: 18073.0, loss:0.30316149\n",
      "step: 18074.0, loss:0.21409905\n",
      "step: 18075.0, loss:0.12927060\n",
      "step: 18076.0, loss:0.19529160\n",
      "step: 18077.0, loss:0.12034143\n",
      "step: 18078.0, loss:0.13504502\n",
      "step: 18079.0, loss:0.20650849\n",
      "step: 18080.0, loss:0.13610102\n",
      "step: 18081.0, loss:0.13242722\n",
      "step: 18082.0, loss:0.27478220\n",
      "step: 18083.0, loss:0.15894666\n",
      "step: 18084.0, loss:0.10192651\n",
      "step: 18085.0, loss:0.06700902\n",
      "step: 18086.0, loss:0.17545576\n",
      "step: 18087.0, loss:0.06053481\n",
      "step: 18088.0, loss:0.15899854\n",
      "step: 18089.0, loss:0.13142389\n",
      "step: 18090.0, loss:0.14820560\n",
      "step: 18091.0, loss:0.08754068\n",
      "step: 18092.0, loss:0.24532079\n",
      "step: 18093.0, loss:0.14469745\n",
      "step: 18094.0, loss:0.17092703\n",
      "step: 18095.0, loss:0.17567742\n",
      "step: 18096.0, loss:0.17300044\n",
      "step: 18097.0, loss:0.15231318\n",
      "step: 18098.0, loss:0.16160588\n",
      "step: 18099.0, loss:0.24108575\n",
      "step: 18100.0, loss:0.13091394\n",
      "step: 18101.0, loss:0.12460356\n",
      "step: 18102.0, loss:0.15003441\n",
      "step: 18103.0, loss:0.18698997\n",
      "step: 18104.0, loss:0.28319965\n",
      "step: 18105.0, loss:0.10235899\n",
      "step: 18106.0, loss:0.09309314\n",
      "step: 18107.0, loss:0.15502986\n",
      "step: 18108.0, loss:0.14972207\n",
      "step: 18109.0, loss:0.32156387\n",
      "step: 18110.0, loss:0.12111705\n",
      "step: 18111.0, loss:0.17245592\n",
      "step: 18112.0, loss:0.21351791\n",
      "step: 18113.0, loss:0.20143224\n",
      "step: 18114.0, loss:0.11971681\n",
      "step: 18115.0, loss:0.16779341\n",
      "step: 18116.0, loss:0.16411210\n",
      "step: 18117.0, loss:0.09889507\n",
      "step: 18118.0, loss:0.21979248\n",
      "step: 18119.0, loss:0.11891574\n",
      "step: 18120.0, loss:0.13773343\n",
      "step: 18121.0, loss:0.11688762\n",
      "step: 18122.0, loss:0.17213000\n",
      "step: 18123.0, loss:0.15206532\n",
      "step: 18124.0, loss:0.07585582\n",
      "step: 18125.0, loss:0.12260270\n",
      "step: 18126.0, loss:0.14149370\n",
      "step: 18127.0, loss:0.24122429\n",
      "step: 18128.0, loss:0.22249346\n",
      "step: 18129.0, loss:0.18481999\n",
      "step: 18130.0, loss:0.12711459\n",
      "step: 18131.0, loss:0.21134150\n",
      "step: 18132.0, loss:0.17062300\n",
      "step: 18133.0, loss:0.21915710\n",
      "step: 18134.0, loss:0.20044727\n",
      "step: 18135.0, loss:0.14198576\n",
      "step: 18136.0, loss:0.13087279\n",
      "step: 18137.0, loss:0.13100476\n",
      "step: 18138.0, loss:0.21231681\n",
      "step: 18139.0, loss:0.18985892\n",
      "step: 18140.0, loss:0.14492794\n",
      "step: 18141.0, loss:0.25408144\n",
      "step: 18142.0, loss:0.13049790\n",
      "step: 18143.0, loss:0.11001691\n",
      "step: 18144.0, loss:0.19199935\n",
      "step: 18145.0, loss:0.12122745\n",
      "step: 18146.0, loss:0.20108832\n",
      "step: 18147.0, loss:0.17483883\n",
      "step: 18148.0, loss:0.11739749\n",
      "step: 18149.0, loss:0.12500373\n",
      "step: 18150.0, loss:0.17822347\n",
      "step: 18151.0, loss:0.33575809\n",
      "step: 18152.0, loss:0.19835832\n",
      "step: 18153.0, loss:0.16571850\n",
      "step: 18154.0, loss:0.13387786\n",
      "step: 18155.0, loss:0.14120371\n",
      "step: 18156.0, loss:0.14190536\n",
      "step: 18157.0, loss:0.07302218\n",
      "step: 18158.0, loss:0.19102551\n",
      "step: 18159.0, loss:0.16947597\n",
      "step: 18160.0, loss:0.08069839\n",
      "step: 18161.0, loss:0.27040424\n",
      "step: 18162.0, loss:0.27515868\n",
      "step: 18163.0, loss:0.13401951\n",
      "step: 18164.0, loss:0.21856942\n",
      "step: 18165.0, loss:0.23260673\n",
      "step: 18166.0, loss:0.18238642\n",
      "step: 18167.0, loss:0.10903725\n",
      "step: 18168.0, loss:0.11005802\n",
      "step: 18169.0, loss:0.24389683\n",
      "step: 18170.0, loss:0.17052665\n",
      "step: 18171.0, loss:0.28992005\n",
      "step: 18172.0, loss:0.17420604\n",
      "step: 18173.0, loss:0.15319521\n",
      "step: 18174.0, loss:0.18138206\n",
      "step: 18175.0, loss:0.11097991\n",
      "step: 18176.0, loss:0.25348321\n",
      "step: 18177.0, loss:0.19048450\n",
      "step: 18178.0, loss:0.29478542\n",
      "step: 18179.0, loss:0.17274972\n",
      "step: 18180.0, loss:0.15489177\n",
      "step: 18181.0, loss:0.23363454\n",
      "step: 18182.0, loss:0.08816226\n",
      "step: 18183.0, loss:0.17969033\n",
      "step: 18184.0, loss:0.12582225\n",
      "step: 18185.0, loss:0.36232967\n",
      "step: 18186.0, loss:0.26692428\n",
      "step: 18187.0, loss:0.15240242\n",
      "step: 18188.0, loss:0.12104881\n",
      "step: 18189.0, loss:0.09162056\n",
      "step: 18190.0, loss:0.07827840\n",
      "step: 18191.0, loss:0.18254745\n",
      "step: 18192.0, loss:0.23025351\n",
      "step: 18193.0, loss:0.14839998\n",
      "step: 18194.0, loss:0.28220120\n",
      "step: 18195.0, loss:0.18143959\n",
      "step: 18196.0, loss:0.10075790\n",
      "step: 18197.0, loss:0.12665295\n",
      "step: 18198.0, loss:0.05363801\n",
      "step: 18199.0, loss:0.17366006\n",
      "step: 18200.0, loss:0.25419541\n",
      "step: 18201.0, loss:0.19588166\n",
      "step: 18202.0, loss:0.16111782\n",
      "step: 18203.0, loss:0.20492463\n",
      "step: 18204.0, loss:0.14540692\n",
      "step: 18205.0, loss:0.12981117\n",
      "step: 18206.0, loss:0.11369303\n",
      "step: 18207.0, loss:0.20715445\n",
      "step: 18208.0, loss:0.08519588\n",
      "step: 18209.0, loss:0.15649809\n",
      "step: 18210.0, loss:0.32196717\n",
      "step: 18211.0, loss:0.23249527\n",
      "step: 18212.0, loss:0.12584681\n",
      "step: 18213.0, loss:0.15487560\n",
      "step: 18214.0, loss:0.26489381\n",
      "step: 18215.0, loss:0.09561536\n",
      "step: 18216.0, loss:0.22865295\n",
      "step: 18217.0, loss:0.21701008\n",
      "step: 18218.0, loss:0.28805063\n",
      "step: 18219.0, loss:0.14438137\n",
      "step: 18220.0, loss:0.14684186\n",
      "step: 18221.0, loss:0.28744086\n",
      "step: 18222.0, loss:0.06542183\n",
      "step: 18223.0, loss:0.11651074\n",
      "step: 18224.0, loss:0.11184653\n",
      "step: 18225.0, loss:0.13506126\n",
      "step: 18226.0, loss:0.37803972\n",
      "step: 18227.0, loss:0.13516020\n",
      "step: 18228.0, loss:0.21234815\n",
      "step: 18229.0, loss:0.11339949\n",
      "step: 18230.0, loss:0.10062252\n",
      "step: 18231.0, loss:0.23773677\n",
      "step: 18232.0, loss:0.20714426\n",
      "step: 18233.0, loss:0.24950887\n",
      "step: 18234.0, loss:0.23320444\n",
      "step: 18235.0, loss:0.13842829\n",
      "step: 18236.0, loss:0.16381184\n",
      "step: 18237.0, loss:0.15039754\n",
      "step: 18238.0, loss:0.21080650\n",
      "step: 18239.0, loss:0.15429757\n",
      "step: 18240.0, loss:0.18103620\n",
      "step: 18241.0, loss:0.15983390\n",
      "step: 18242.0, loss:0.25181190\n",
      "step: 18243.0, loss:0.20804177\n",
      "step: 18244.0, loss:0.12251441\n",
      "step: 18245.0, loss:0.08585643\n",
      "step: 18246.0, loss:0.13270494\n",
      "step: 18247.0, loss:0.07505362\n",
      "step: 18248.0, loss:0.19518244\n",
      "step: 18249.0, loss:0.13586331\n",
      "step: 18250.0, loss:0.15307363\n",
      "step: 18251.0, loss:0.11432561\n",
      "step: 18252.0, loss:0.07951489\n",
      "step: 18253.0, loss:0.16209561\n",
      "step: 18254.0, loss:0.25361653\n",
      "step: 18255.0, loss:0.15822571\n",
      "step: 18256.0, loss:0.11421653\n",
      "step: 18257.0, loss:0.13666156\n",
      "step: 18258.0, loss:0.12194616\n",
      "step: 18259.0, loss:0.14742807\n",
      "step: 18260.0, loss:0.11569530\n",
      "step: 18261.0, loss:0.12544109\n",
      "step: 18262.0, loss:0.11811178\n",
      "step: 18263.0, loss:0.22496316\n",
      "step: 18264.0, loss:0.20184535\n",
      "step: 18265.0, loss:0.16528940\n",
      "step: 18266.0, loss:0.22081375\n",
      "step: 18267.0, loss:0.16883988\n",
      "step: 18268.0, loss:0.18921062\n",
      "step: 18269.0, loss:0.10321369\n",
      "step: 18270.0, loss:0.15684180\n",
      "step: 18271.0, loss:0.18314093\n",
      "step: 18272.0, loss:0.17098049\n",
      "step: 18273.0, loss:0.33215825\n",
      "step: 18274.0, loss:0.22551003\n",
      "step: 18275.0, loss:0.18631186\n",
      "step: 18276.0, loss:0.08128293\n",
      "step: 18277.0, loss:0.15652960\n",
      "step: 18278.0, loss:0.18280578\n",
      "step: 18279.0, loss:0.21478348\n",
      "step: 18280.0, loss:0.12742868\n",
      "step: 18281.0, loss:0.15296619\n",
      "step: 18282.0, loss:0.09423904\n",
      "step: 18283.0, loss:0.09564587\n",
      "step: 18284.0, loss:0.13037814\n",
      "step: 18285.0, loss:0.12282519\n",
      "step: 18286.0, loss:0.18037238\n",
      "step: 18287.0, loss:0.12572563\n",
      "step: 18288.0, loss:0.17156917\n",
      "step: 18289.0, loss:0.15074512\n",
      "step: 18290.0, loss:0.16846134\n",
      "step: 18291.0, loss:0.09450054\n",
      "step: 18292.0, loss:0.14291093\n",
      "step: 18293.0, loss:0.18323977\n",
      "step: 18294.0, loss:0.06427953\n",
      "step: 18295.0, loss:0.12496169\n",
      "step: 18296.0, loss:0.17879981\n",
      "step: 18297.0, loss:0.12647484\n",
      "step: 18298.0, loss:0.12420116\n",
      "step: 18299.0, loss:0.11062108\n",
      "step: 18300.0, loss:0.14096954\n",
      "step: 18301.0, loss:0.18061365\n",
      "step: 18302.0, loss:0.23869886\n",
      "step: 18303.0, loss:0.18997239\n",
      "step: 18304.0, loss:0.19249707\n",
      "step: 18305.0, loss:0.12021610\n",
      "step: 18306.0, loss:0.07917513\n",
      "step: 18307.0, loss:0.14341347\n",
      "step: 18308.0, loss:0.14825705\n",
      "step: 18309.0, loss:0.15650433\n",
      "step: 18310.0, loss:0.23771963\n",
      "step: 18311.0, loss:0.15546480\n",
      "step: 18312.0, loss:0.11687386\n",
      "step: 18313.0, loss:0.19921903\n",
      "step: 18314.0, loss:0.12578703\n",
      "step: 18315.0, loss:0.05098810\n",
      "step: 18316.0, loss:0.08118603\n",
      "step: 18317.0, loss:0.17062246\n",
      "step: 18318.0, loss:0.16159384\n",
      "step: 18319.0, loss:0.15498186\n",
      "step: 18320.0, loss:0.19435310\n",
      "step: 18321.0, loss:0.16392754\n",
      "step: 18322.0, loss:0.21396920\n",
      "step: 18323.0, loss:0.17089386\n",
      "step: 18324.0, loss:0.24719107\n",
      "step: 18325.0, loss:0.17445904\n",
      "step: 18326.0, loss:0.20666803\n",
      "step: 18327.0, loss:0.14943163\n",
      "step: 18328.0, loss:0.19833895\n",
      "step: 18329.0, loss:0.21539473\n",
      "step: 18330.0, loss:0.07811577\n",
      "step: 18331.0, loss:0.21873718\n",
      "step: 18332.0, loss:0.15061480\n",
      "step: 18333.0, loss:0.25951900\n",
      "step: 18334.0, loss:0.20370267\n",
      "step: 18335.0, loss:0.38153941\n",
      "step: 18336.0, loss:0.27523653\n",
      "step: 18337.0, loss:0.09015707\n",
      "step: 18338.0, loss:0.10148062\n",
      "step: 18339.0, loss:0.09648517\n",
      "step: 18340.0, loss:0.16280075\n",
      "step: 18341.0, loss:0.17243809\n",
      "step: 18342.0, loss:0.35435484\n",
      "step: 18343.0, loss:0.09890090\n",
      "step: 18344.0, loss:0.17107276\n",
      "step: 18345.0, loss:0.12486254\n",
      "step: 18346.0, loss:0.22382496\n",
      "step: 18347.0, loss:0.19545028\n",
      "step: 18348.0, loss:0.24250910\n",
      "step: 18349.0, loss:0.26707745\n",
      "step: 18350.0, loss:0.19817302\n",
      "step: 18351.0, loss:0.20710525\n",
      "step: 18352.0, loss:0.14885992\n",
      "step: 18353.0, loss:0.14677596\n",
      "step: 18354.0, loss:0.15135503\n",
      "step: 18355.0, loss:0.17092740\n",
      "step: 18356.0, loss:0.13840926\n",
      "step: 18357.0, loss:0.12856620\n",
      "step: 18358.0, loss:0.13681916\n",
      "step: 18359.0, loss:0.22685082\n",
      "step: 18360.0, loss:0.20382090\n",
      "step: 18361.0, loss:0.19738514\n",
      "step: 18362.0, loss:0.13592765\n",
      "step: 18363.0, loss:0.21195604\n",
      "step: 18364.0, loss:0.10794565\n",
      "step: 18365.0, loss:0.13960233\n",
      "step: 18366.0, loss:0.17407427\n",
      "step: 18367.0, loss:0.15226308\n",
      "step: 18368.0, loss:0.16841697\n",
      "step: 18369.0, loss:0.06743786\n",
      "step: 18370.0, loss:0.17823951\n",
      "step: 18371.0, loss:0.24652902\n",
      "step: 18372.0, loss:0.13597079\n",
      "step: 18373.0, loss:0.25367883\n",
      "step: 18374.0, loss:0.18322189\n",
      "step: 18375.0, loss:0.21047871\n",
      "step: 18376.0, loss:0.26253401\n",
      "step: 18377.0, loss:0.19309123\n",
      "step: 18378.0, loss:0.23525139\n",
      "step: 18379.0, loss:0.23210032\n",
      "step: 18380.0, loss:0.19678165\n",
      "step: 18381.0, loss:0.26560800\n",
      "step: 18382.0, loss:0.19258790\n",
      "step: 18383.0, loss:0.20546272\n",
      "step: 18384.0, loss:0.24261202\n",
      "step: 18385.0, loss:0.23530177\n",
      "step: 18386.0, loss:0.20427870\n",
      "step: 18387.0, loss:0.21984625\n",
      "step: 18388.0, loss:0.18816984\n",
      "step: 18389.0, loss:0.19605414\n",
      "step: 18390.0, loss:0.12871566\n",
      "step: 18391.0, loss:0.22902995\n",
      "step: 18392.0, loss:0.22275381\n",
      "step: 18393.0, loss:0.11605345\n",
      "step: 18394.0, loss:0.23715086\n",
      "step: 18395.0, loss:0.26936966\n",
      "step: 18396.0, loss:0.15802979\n",
      "step: 18397.0, loss:0.11181056\n",
      "step: 18398.0, loss:0.20930495\n",
      "step: 18399.0, loss:0.25357358\n",
      "step: 18400.0, loss:0.23211459\n",
      "step: 18401.0, loss:0.17317696\n",
      "step: 18402.0, loss:0.25116806\n",
      "step: 18403.0, loss:0.19724399\n",
      "step: 18404.0, loss:0.15462913\n",
      "step: 18405.0, loss:0.16974956\n",
      "step: 18406.0, loss:0.16666402\n",
      "step: 18407.0, loss:0.06873212\n",
      "step: 18408.0, loss:0.16000206\n",
      "step: 18409.0, loss:0.22665932\n",
      "step: 18410.0, loss:0.15660529\n",
      "step: 18411.0, loss:0.11811458\n",
      "step: 18412.0, loss:0.17695397\n",
      "step: 18413.0, loss:0.15907210\n",
      "step: 18414.0, loss:0.19439678\n",
      "step: 18415.0, loss:0.08835263\n",
      "step: 18416.0, loss:0.08212957\n",
      "step: 18417.0, loss:0.18701799\n",
      "step: 18418.0, loss:0.18306985\n",
      "step: 18419.0, loss:0.11323352\n",
      "step: 18420.0, loss:0.21950891\n",
      "step: 18421.0, loss:0.13847253\n",
      "step: 18422.0, loss:0.10501046\n",
      "step: 18423.0, loss:0.17132892\n",
      "step: 18424.0, loss:0.16676284\n",
      "step: 18425.0, loss:0.21084780\n",
      "step: 18426.0, loss:0.23756551\n",
      "step: 18427.0, loss:0.13828684\n",
      "step: 18428.0, loss:0.16134447\n",
      "step: 18429.0, loss:0.11506145\n",
      "step: 18430.0, loss:0.43843186\n",
      "step: 18431.0, loss:0.28731600\n",
      "step: 18432.0, loss:0.18277860\n",
      "step: 18433.0, loss:0.13595000\n",
      "step: 18434.0, loss:0.15556076\n",
      "step: 18435.0, loss:0.16335118\n",
      "step: 18436.0, loss:0.17262597\n",
      "step: 18437.0, loss:0.26973482\n",
      "step: 18438.0, loss:0.12805449\n",
      "step: 18439.0, loss:0.15863282\n",
      "step: 18440.0, loss:0.15125746\n",
      "step: 18441.0, loss:0.18468290\n",
      "step: 18442.0, loss:0.22618929\n",
      "step: 18443.0, loss:0.20451174\n",
      "step: 18444.0, loss:0.23362070\n",
      "step: 18445.0, loss:0.14458891\n",
      "step: 18446.0, loss:0.14140251\n",
      "step: 18447.0, loss:0.20904054\n",
      "step: 18448.0, loss:0.39919193\n",
      "step: 18449.0, loss:0.17041680\n",
      "step: 18450.0, loss:0.20285888\n",
      "step: 18451.0, loss:0.22065018\n",
      "step: 18452.0, loss:0.22353048\n",
      "step: 18453.0, loss:0.10822151\n",
      "step: 18454.0, loss:0.20367380\n",
      "step: 18455.0, loss:0.13370665\n",
      "step: 18456.0, loss:0.38087891\n",
      "step: 18457.0, loss:0.19662484\n",
      "step: 18458.0, loss:0.21366568\n",
      "step: 18459.0, loss:0.21752554\n",
      "step: 18460.0, loss:0.20340462\n",
      "step: 18461.0, loss:0.12187478\n",
      "step: 18462.0, loss:0.16793841\n",
      "step: 18463.0, loss:0.16479190\n",
      "step: 18464.0, loss:0.18484976\n",
      "step: 18465.0, loss:0.39827503\n",
      "step: 18466.0, loss:0.27466385\n",
      "step: 18467.0, loss:0.14937244\n",
      "step: 18468.0, loss:0.21095960\n",
      "step: 18469.0, loss:0.18994758\n",
      "step: 18470.0, loss:0.16076487\n",
      "step: 18471.0, loss:0.23072348\n",
      "step: 18472.0, loss:0.31415442\n",
      "step: 18473.0, loss:0.24870319\n",
      "step: 18474.0, loss:0.23833346\n",
      "step: 18475.0, loss:0.13037957\n",
      "step: 18476.0, loss:0.15449572\n",
      "step: 18477.0, loss:0.20712829\n",
      "step: 18478.0, loss:0.22149714\n",
      "step: 18479.0, loss:0.24123549\n",
      "step: 18480.0, loss:0.21652750\n",
      "step: 18481.0, loss:0.18062842\n",
      "step: 18482.0, loss:0.16179194\n",
      "step: 18483.0, loss:0.30685318\n",
      "step: 18484.0, loss:0.14262408\n",
      "step: 18485.0, loss:0.18840933\n",
      "step: 18486.0, loss:0.19255684\n",
      "step: 18487.0, loss:0.16926788\n",
      "step: 18488.0, loss:0.09172611\n",
      "step: 18489.0, loss:0.21144698\n",
      "step: 18490.0, loss:0.13970531\n",
      "step: 18491.0, loss:0.09419364\n",
      "step: 18492.0, loss:0.12056515\n",
      "step: 18493.0, loss:0.09487752\n",
      "step: 18494.0, loss:0.16134119\n",
      "step: 18495.0, loss:0.20971769\n",
      "step: 18496.0, loss:0.20835279\n",
      "step: 18497.0, loss:0.14383741\n",
      "step: 18498.0, loss:0.08562181\n",
      "step: 18499.0, loss:0.23124265\n",
      "step: 18500.0, loss:0.14032260\n",
      "step: 18501.0, loss:0.15678584\n",
      "step: 18502.0, loss:0.15234176\n",
      "step: 18503.0, loss:0.16575125\n",
      "step: 18504.0, loss:0.20599562\n",
      "step: 18505.0, loss:0.19587846\n",
      "step: 18506.0, loss:0.16410491\n",
      "step: 18507.0, loss:0.25549460\n",
      "step: 18508.0, loss:0.23893145\n",
      "step: 18509.0, loss:0.17612628\n",
      "step: 18510.0, loss:0.15735190\n",
      "step: 18511.0, loss:0.18296664\n",
      "step: 18512.0, loss:0.22846467\n",
      "step: 18513.0, loss:0.17088403\n",
      "step: 18514.0, loss:0.14044019\n",
      "step: 18515.0, loss:0.24715107\n",
      "step: 18516.0, loss:0.29257732\n",
      "step: 18517.0, loss:0.15203509\n",
      "step: 18518.0, loss:0.11866714\n",
      "step: 18519.0, loss:0.16924227\n",
      "step: 18520.0, loss:0.25225778\n",
      "step: 18521.0, loss:0.24718165\n",
      "step: 18522.0, loss:0.16479725\n",
      "step: 18523.0, loss:0.11090251\n",
      "step: 18524.0, loss:0.13377160\n",
      "step: 18525.0, loss:0.14741600\n",
      "step: 18526.0, loss:0.21973126\n",
      "step: 18527.0, loss:0.26241157\n",
      "step: 18528.0, loss:0.15396086\n",
      "step: 18529.0, loss:0.13674355\n",
      "step: 18530.0, loss:0.20613965\n",
      "step: 18531.0, loss:0.15719798\n",
      "step: 18532.0, loss:0.12514137\n",
      "step: 18533.0, loss:0.22945905\n",
      "step: 18534.0, loss:0.08588423\n",
      "step: 18535.0, loss:0.18293472\n",
      "step: 18536.0, loss:0.12108396\n",
      "step: 18537.0, loss:0.14964562\n",
      "step: 18538.0, loss:0.19320322\n",
      "step: 18539.0, loss:0.12814022\n",
      "step: 18540.0, loss:0.06637083\n",
      "step: 18541.0, loss:0.18997715\n",
      "step: 18542.0, loss:0.09585481\n",
      "step: 18543.0, loss:0.10582755\n",
      "step: 18544.0, loss:0.11426142\n",
      "step: 18545.0, loss:0.17200963\n",
      "step: 18546.0, loss:0.19822891\n",
      "step: 18547.0, loss:0.23679214\n",
      "step: 18548.0, loss:0.20702082\n",
      "step: 18549.0, loss:0.10443259\n",
      "step: 18550.0, loss:0.21503176\n",
      "step: 18551.0, loss:0.11832801\n",
      "step: 18552.0, loss:0.12745560\n",
      "step: 18553.0, loss:0.22774969\n",
      "step: 18554.0, loss:0.21051477\n",
      "step: 18555.0, loss:0.24636139\n",
      "step: 18556.0, loss:0.28343766\n",
      "step: 18557.0, loss:0.09799602\n",
      "step: 18558.0, loss:0.18572342\n",
      "step: 18559.0, loss:0.12374630\n",
      "step: 18560.0, loss:0.16642718\n",
      "step: 18561.0, loss:0.31643368\n",
      "step: 18562.0, loss:0.14451461\n",
      "step: 18563.0, loss:0.19203317\n",
      "step: 18564.0, loss:0.31173727\n",
      "step: 18565.0, loss:0.22968158\n",
      "step: 18566.0, loss:0.25036495\n",
      "step: 18567.0, loss:0.21967122\n",
      "step: 18568.0, loss:0.14358472\n",
      "step: 18569.0, loss:0.14844349\n",
      "step: 18570.0, loss:0.20653698\n",
      "step: 18571.0, loss:0.21194068\n",
      "step: 18572.0, loss:0.17129378\n",
      "step: 18573.0, loss:0.24943474\n",
      "step: 18574.0, loss:0.09362596\n",
      "step: 18575.0, loss:0.24706918\n",
      "step: 18576.0, loss:0.14250534\n",
      "step: 18577.0, loss:0.15862538\n",
      "step: 18578.0, loss:0.15802804\n",
      "step: 18579.0, loss:0.23246769\n",
      "step: 18580.0, loss:0.33643378\n",
      "step: 18581.0, loss:0.09981214\n",
      "step: 18582.0, loss:0.18773030\n",
      "step: 18583.0, loss:0.23638020\n",
      "step: 18584.0, loss:0.29959451\n",
      "step: 18585.0, loss:0.28773604\n",
      "step: 18586.0, loss:0.21292715\n",
      "step: 18587.0, loss:0.24495092\n",
      "step: 18588.0, loss:0.23785193\n",
      "step: 18589.0, loss:0.21744695\n",
      "step: 18590.0, loss:0.11756082\n",
      "step: 18591.0, loss:0.25053318\n",
      "step: 18592.0, loss:0.12650692\n",
      "step: 18593.0, loss:0.10636445\n",
      "step: 18594.0, loss:0.19757241\n",
      "step: 18595.0, loss:0.18393557\n",
      "step: 18596.0, loss:0.23122127\n",
      "step: 18597.0, loss:0.12919008\n",
      "step: 18598.0, loss:0.23378289\n",
      "step: 18599.0, loss:0.23561898\n",
      "step: 18600.0, loss:0.07600588\n",
      "step: 18601.0, loss:0.12297086\n",
      "step: 18602.0, loss:0.10925096\n",
      "step: 18603.0, loss:0.23461159\n",
      "step: 18604.0, loss:0.27692172\n",
      "step: 18605.0, loss:0.20466983\n",
      "step: 18606.0, loss:0.27980603\n",
      "step: 18607.0, loss:0.22767063\n",
      "step: 18608.0, loss:0.14151920\n",
      "step: 18609.0, loss:0.10073118\n",
      "step: 18610.0, loss:0.27613980\n",
      "step: 18611.0, loss:0.27467172\n",
      "step: 18612.0, loss:0.18339298\n",
      "step: 18613.0, loss:0.17862158\n",
      "step: 18614.0, loss:0.14277614\n",
      "step: 18615.0, loss:0.19655132\n",
      "step: 18616.0, loss:0.22608193\n",
      "step: 18617.0, loss:0.16234006\n",
      "step: 18618.0, loss:0.16085891\n",
      "step: 18619.0, loss:0.27053241\n",
      "step: 18620.0, loss:0.15045841\n",
      "step: 18621.0, loss:0.12561322\n",
      "step: 18622.0, loss:0.32963528\n",
      "step: 18623.0, loss:0.24354768\n",
      "step: 18624.0, loss:0.28336255\n",
      "step: 18625.0, loss:0.12878125\n",
      "step: 18626.0, loss:0.20049747\n",
      "step: 18627.0, loss:0.18998157\n",
      "step: 18628.0, loss:0.18874518\n",
      "step: 18629.0, loss:0.22802574\n",
      "step: 18630.0, loss:0.19571003\n",
      "step: 18631.0, loss:0.18041109\n",
      "step: 18632.0, loss:0.16833867\n",
      "step: 18633.0, loss:0.15242521\n",
      "step: 18634.0, loss:0.24656110\n",
      "step: 18635.0, loss:0.10403970\n",
      "step: 18636.0, loss:0.26038358\n",
      "step: 18637.0, loss:0.15643942\n",
      "step: 18638.0, loss:0.12071520\n",
      "step: 18639.0, loss:0.20947636\n",
      "step: 18640.0, loss:0.10816460\n",
      "step: 18641.0, loss:0.25168012\n",
      "step: 18642.0, loss:0.13763884\n",
      "step: 18643.0, loss:0.16906369\n",
      "step: 18644.0, loss:0.17151650\n",
      "step: 18645.0, loss:0.23845617\n",
      "step: 18646.0, loss:0.14972540\n",
      "step: 18647.0, loss:0.43591494\n",
      "step: 18648.0, loss:0.20462616\n",
      "step: 18649.0, loss:0.13466338\n",
      "step: 18650.0, loss:0.20232887\n",
      "step: 18651.0, loss:0.17147609\n",
      "step: 18652.0, loss:0.15864087\n",
      "step: 18653.0, loss:0.19019344\n",
      "step: 18654.0, loss:0.34920761\n",
      "step: 18655.0, loss:0.13512171\n",
      "step: 18656.0, loss:0.18699702\n",
      "step: 18657.0, loss:0.14890188\n",
      "step: 18658.0, loss:0.15419025\n",
      "step: 18659.0, loss:0.15418242\n",
      "step: 18660.0, loss:0.08603024\n",
      "step: 18661.0, loss:0.17126329\n",
      "step: 18662.0, loss:0.18374773\n",
      "step: 18663.0, loss:0.20870002\n",
      "step: 18664.0, loss:0.26546849\n",
      "step: 18665.0, loss:0.28690743\n",
      "step: 18666.0, loss:0.16011220\n",
      "step: 18667.0, loss:0.21781274\n",
      "step: 18668.0, loss:0.16934769\n",
      "step: 18669.0, loss:0.16885557\n",
      "step: 18670.0, loss:0.13922249\n",
      "step: 18671.0, loss:0.17486577\n",
      "step: 18672.0, loss:0.22339676\n",
      "step: 18673.0, loss:0.18401371\n",
      "step: 18674.0, loss:0.15192484\n",
      "step: 18675.0, loss:0.22948829\n",
      "step: 18676.0, loss:0.19978966\n",
      "step: 18677.0, loss:0.19763584\n",
      "step: 18678.0, loss:0.15279622\n",
      "step: 18679.0, loss:0.11600734\n",
      "step: 18680.0, loss:0.14155868\n",
      "step: 18681.0, loss:0.22135634\n",
      "step: 18682.0, loss:0.14181939\n",
      "step: 18683.0, loss:0.24412387\n",
      "step: 18684.0, loss:0.27862308\n",
      "step: 18685.0, loss:0.20853749\n",
      "step: 18686.0, loss:0.09722929\n",
      "step: 18687.0, loss:0.14292816\n",
      "step: 18688.0, loss:0.15133204\n",
      "step: 18689.0, loss:0.10577990\n",
      "step: 18690.0, loss:0.21122484\n",
      "step: 18691.0, loss:0.16676313\n",
      "step: 18692.0, loss:0.11571142\n",
      "step: 18693.0, loss:0.24840912\n",
      "step: 18694.0, loss:0.11618170\n",
      "step: 18695.0, loss:0.17446763\n",
      "step: 18696.0, loss:0.12787064\n",
      "step: 18697.0, loss:0.17981921\n",
      "step: 18698.0, loss:0.22652218\n",
      "step: 18699.0, loss:0.23814496\n",
      "step: 18700.0, loss:0.27232986\n",
      "step: 18701.0, loss:0.07980674\n",
      "step: 18702.0, loss:0.16347135\n",
      "step: 18703.0, loss:0.17846568\n",
      "step: 18704.0, loss:0.24213158\n",
      "step: 18705.0, loss:0.17706590\n",
      "step: 18706.0, loss:0.13081618\n",
      "step: 18707.0, loss:0.27208586\n",
      "step: 18708.0, loss:0.23018960\n",
      "step: 18709.0, loss:0.14143310\n",
      "step: 18710.0, loss:0.21209812\n",
      "step: 18711.0, loss:0.11329679\n",
      "step: 18712.0, loss:0.15488912\n",
      "step: 18713.0, loss:0.18816363\n",
      "step: 18714.0, loss:0.10773320\n",
      "step: 18715.0, loss:0.17109489\n",
      "step: 18716.0, loss:0.21956172\n",
      "step: 18717.0, loss:0.38923574\n",
      "step: 18718.0, loss:0.16719336\n",
      "step: 18719.0, loss:0.15096152\n",
      "step: 18720.0, loss:0.13004522\n",
      "step: 18721.0, loss:0.18590109\n",
      "step: 18722.0, loss:0.11639608\n",
      "step: 18723.0, loss:0.17955368\n",
      "step: 18724.0, loss:0.15896557\n",
      "step: 18725.0, loss:0.19542414\n",
      "step: 18726.0, loss:0.22245897\n",
      "step: 18727.0, loss:0.20059905\n",
      "step: 18728.0, loss:0.16132422\n",
      "step: 18729.0, loss:0.08193369\n",
      "step: 18730.0, loss:0.10726257\n",
      "step: 18731.0, loss:0.14118038\n",
      "step: 18732.0, loss:0.05050646\n",
      "step: 18733.0, loss:0.12943446\n",
      "step: 18734.0, loss:0.12176266\n",
      "step: 18735.0, loss:0.11919916\n",
      "step: 18736.0, loss:0.18548057\n",
      "step: 18737.0, loss:0.24935780\n",
      "step: 18738.0, loss:0.16794429\n",
      "step: 18739.0, loss:0.26612492\n",
      "step: 18740.0, loss:0.09648233\n",
      "step: 18741.0, loss:0.18849427\n",
      "step: 18742.0, loss:0.14820607\n",
      "step: 18743.0, loss:0.12744162\n",
      "step: 18744.0, loss:0.19702379\n",
      "step: 18745.0, loss:0.13716863\n",
      "step: 18746.0, loss:0.16102707\n",
      "step: 18747.0, loss:0.18603395\n",
      "step: 18748.0, loss:0.12530061\n",
      "step: 18749.0, loss:0.16981077\n",
      "step: 18750.0, loss:0.19116040\n",
      "step: 18751.0, loss:0.17762764\n",
      "step: 18752.0, loss:0.34226053\n",
      "step: 18753.0, loss:0.08603757\n",
      "step: 18754.0, loss:0.11347049\n",
      "step: 18755.0, loss:0.22705937\n",
      "step: 18756.0, loss:0.10637462\n",
      "step: 18757.0, loss:0.18181252\n",
      "step: 18758.0, loss:0.16025319\n",
      "step: 18759.0, loss:0.15815212\n",
      "step: 18760.0, loss:0.15946863\n",
      "step: 18761.0, loss:0.19216448\n",
      "step: 18762.0, loss:0.14801200\n",
      "step: 18763.0, loss:0.15506521\n",
      "step: 18764.0, loss:0.18161262\n",
      "step: 18765.0, loss:0.15468701\n",
      "step: 18766.0, loss:0.16368203\n",
      "step: 18767.0, loss:0.18120320\n",
      "step: 18768.0, loss:0.16489342\n",
      "step: 18769.0, loss:0.09667637\n",
      "step: 18770.0, loss:0.13300868\n",
      "step: 18771.0, loss:0.12127148\n",
      "step: 18772.0, loss:0.16893963\n",
      "step: 18773.0, loss:0.08895613\n",
      "step: 18774.0, loss:0.12529084\n",
      "step: 18775.0, loss:0.13847577\n",
      "step: 18776.0, loss:0.13287887\n",
      "step: 18777.0, loss:0.13000894\n",
      "step: 18778.0, loss:0.19368556\n",
      "step: 18779.0, loss:0.15388631\n",
      "step: 18780.0, loss:0.16495312\n",
      "step: 18781.0, loss:0.25805196\n",
      "step: 18782.0, loss:0.14984916\n",
      "step: 18783.0, loss:0.19193876\n",
      "step: 18784.0, loss:0.09766240\n",
      "step: 18785.0, loss:0.11605492\n",
      "step: 18786.0, loss:0.09097484\n",
      "step: 18787.0, loss:0.16218788\n",
      "step: 18788.0, loss:0.08512888\n",
      "step: 18789.0, loss:0.22515681\n",
      "step: 18790.0, loss:0.12369644\n",
      "step: 18791.0, loss:0.18137745\n",
      "step: 18792.0, loss:0.13323016\n",
      "step: 18793.0, loss:0.15302440\n",
      "step: 18794.0, loss:0.11462027\n",
      "step: 18795.0, loss:0.12357476\n",
      "step: 18796.0, loss:0.16103364\n",
      "step: 18797.0, loss:0.22732643\n",
      "step: 18798.0, loss:0.16073889\n",
      "step: 18799.0, loss:0.26834029\n",
      "step: 18800.0, loss:0.08655772\n",
      "step: 18801.0, loss:0.10428927\n",
      "step: 18802.0, loss:0.15678253\n",
      "step: 18803.0, loss:0.14323119\n",
      "step: 18804.0, loss:0.24217923\n",
      "step: 18805.0, loss:0.16443974\n",
      "step: 18806.0, loss:0.23945361\n",
      "step: 18807.0, loss:0.14851616\n",
      "step: 18808.0, loss:0.13717948\n",
      "step: 18809.0, loss:0.28908185\n",
      "step: 18810.0, loss:0.18256897\n",
      "step: 18811.0, loss:0.05682626\n",
      "step: 18812.0, loss:0.11349448\n",
      "step: 18813.0, loss:0.22312398\n",
      "step: 18814.0, loss:0.23236388\n",
      "step: 18815.0, loss:0.24614986\n",
      "step: 18816.0, loss:0.15514186\n",
      "step: 18817.0, loss:0.20396950\n",
      "step: 18818.0, loss:0.15668059\n",
      "step: 18819.0, loss:0.11882018\n",
      "step: 18820.0, loss:0.26674454\n",
      "step: 18821.0, loss:0.11691750\n",
      "step: 18822.0, loss:0.15023746\n",
      "step: 18823.0, loss:0.23396888\n",
      "step: 18824.0, loss:0.11623487\n",
      "step: 18825.0, loss:0.14517894\n",
      "step: 18826.0, loss:0.21389110\n",
      "step: 18827.0, loss:0.17382635\n",
      "step: 18828.0, loss:0.22362748\n",
      "step: 18829.0, loss:0.11066074\n",
      "step: 18830.0, loss:0.25055684\n",
      "step: 18831.0, loss:0.08819071\n",
      "step: 18832.0, loss:0.10980069\n",
      "step: 18833.0, loss:0.16717436\n",
      "step: 18834.0, loss:0.19547588\n",
      "step: 18835.0, loss:0.15435964\n",
      "step: 18836.0, loss:0.19705878\n",
      "step: 18837.0, loss:0.08727116\n",
      "step: 18838.0, loss:0.12966980\n",
      "step: 18839.0, loss:0.21781659\n",
      "step: 18840.0, loss:0.25868938\n",
      "step: 18841.0, loss:0.15465377\n",
      "step: 18842.0, loss:0.15320132\n",
      "step: 18843.0, loss:0.25544318\n",
      "step: 18844.0, loss:0.37236816\n",
      "step: 18845.0, loss:0.17502503\n",
      "step: 18846.0, loss:0.25594971\n",
      "step: 18847.0, loss:0.20867544\n",
      "step: 18848.0, loss:0.08557687\n",
      "step: 18849.0, loss:0.16454024\n",
      "step: 18850.0, loss:0.13275854\n",
      "step: 18851.0, loss:0.14502252\n",
      "step: 18852.0, loss:0.16572014\n",
      "step: 18853.0, loss:0.10794418\n",
      "step: 18854.0, loss:0.13037989\n",
      "step: 18855.0, loss:0.26056961\n",
      "step: 18856.0, loss:0.25953170\n",
      "step: 18857.0, loss:0.20234535\n",
      "step: 18858.0, loss:0.14819382\n",
      "step: 18859.0, loss:0.22024234\n",
      "step: 18860.0, loss:0.18593377\n",
      "step: 18861.0, loss:0.15806339\n",
      "step: 18862.0, loss:0.13678387\n",
      "step: 18863.0, loss:0.19998482\n",
      "step: 18864.0, loss:0.10230052\n",
      "step: 18865.0, loss:0.13151686\n",
      "step: 18866.0, loss:0.13821708\n",
      "step: 18867.0, loss:0.24628685\n",
      "step: 18868.0, loss:0.14648542\n",
      "step: 18869.0, loss:0.31919192\n",
      "step: 18870.0, loss:0.17344096\n",
      "step: 18871.0, loss:0.19744491\n",
      "step: 18872.0, loss:0.19203492\n",
      "step: 18873.0, loss:0.13234882\n",
      "step: 18874.0, loss:0.07951810\n",
      "step: 18875.0, loss:0.18516741\n",
      "step: 18876.0, loss:0.16843496\n",
      "step: 18877.0, loss:0.17181992\n",
      "step: 18878.0, loss:0.14048569\n",
      "step: 18879.0, loss:0.19440301\n",
      "step: 18880.0, loss:0.15547898\n",
      "step: 18881.0, loss:0.19148652\n",
      "step: 18882.0, loss:0.14935389\n",
      "step: 18883.0, loss:0.16176074\n",
      "step: 18884.0, loss:0.13978381\n",
      "step: 18885.0, loss:0.13100854\n",
      "step: 18886.0, loss:0.19890520\n",
      "step: 18887.0, loss:0.12660633\n",
      "step: 18888.0, loss:0.17026822\n",
      "step: 18889.0, loss:0.31061911\n",
      "step: 18890.0, loss:0.14839068\n",
      "step: 18891.0, loss:0.20535734\n",
      "step: 18892.0, loss:0.28232076\n",
      "step: 18893.0, loss:0.11022333\n",
      "step: 18894.0, loss:0.10678380\n",
      "step: 18895.0, loss:0.23412965\n",
      "step: 18896.0, loss:0.16439215\n",
      "step: 18897.0, loss:0.14059278\n",
      "step: 18898.0, loss:0.08423846\n",
      "step: 18899.0, loss:0.25124122\n",
      "step: 18900.0, loss:0.23973245\n",
      "step: 18901.0, loss:0.06275859\n",
      "step: 18902.0, loss:0.25668056\n",
      "step: 18903.0, loss:0.17291351\n",
      "step: 18904.0, loss:0.22631741\n",
      "step: 18905.0, loss:0.17004950\n",
      "step: 18906.0, loss:0.12471695\n",
      "step: 18907.0, loss:0.18016624\n",
      "step: 18908.0, loss:0.14032265\n",
      "step: 18909.0, loss:0.15123763\n",
      "step: 18910.0, loss:0.21380660\n",
      "step: 18911.0, loss:0.17297579\n",
      "step: 18912.0, loss:0.16360750\n",
      "step: 18913.0, loss:0.31700178\n",
      "step: 18914.0, loss:0.08172787\n",
      "step: 18915.0, loss:0.12789910\n",
      "step: 18916.0, loss:0.23501112\n",
      "step: 18917.0, loss:0.24987411\n",
      "step: 18918.0, loss:0.24427138\n",
      "step: 18919.0, loss:0.07776203\n",
      "step: 18920.0, loss:0.20404512\n",
      "step: 18921.0, loss:0.22043184\n",
      "step: 18922.0, loss:0.19590725\n",
      "step: 18923.0, loss:0.24596027\n",
      "step: 18924.0, loss:0.17911264\n",
      "step: 18925.0, loss:0.13940222\n",
      "step: 18926.0, loss:0.15990022\n",
      "step: 18927.0, loss:0.23549450\n",
      "step: 18928.0, loss:0.11680915\n",
      "step: 18929.0, loss:0.14323577\n",
      "step: 18930.0, loss:0.17433820\n",
      "step: 18931.0, loss:0.19933214\n",
      "step: 18932.0, loss:0.24313221\n",
      "step: 18933.0, loss:0.14215435\n",
      "step: 18934.0, loss:0.23268570\n",
      "step: 18935.0, loss:0.07954468\n",
      "step: 18936.0, loss:0.13436843\n",
      "step: 18937.0, loss:0.17148355\n",
      "step: 18938.0, loss:0.13788144\n",
      "step: 18939.0, loss:0.21476115\n",
      "step: 18940.0, loss:0.11641477\n",
      "step: 18941.0, loss:0.08449371\n",
      "step: 18942.0, loss:0.12187867\n",
      "step: 18943.0, loss:0.13677902\n",
      "step: 18944.0, loss:0.18202255\n",
      "step: 18945.0, loss:0.16159730\n",
      "step: 18946.0, loss:0.14925610\n",
      "step: 18947.0, loss:0.16347449\n",
      "step: 18948.0, loss:0.19679879\n",
      "step: 18949.0, loss:0.14720784\n",
      "step: 18950.0, loss:0.18728661\n",
      "step: 18951.0, loss:0.15718492\n",
      "step: 18952.0, loss:0.20535515\n",
      "step: 18953.0, loss:0.08825966\n",
      "step: 18954.0, loss:0.14265764\n",
      "step: 18955.0, loss:0.20082218\n",
      "step: 18956.0, loss:0.13983431\n",
      "step: 18957.0, loss:0.09385626\n",
      "step: 18958.0, loss:0.17761085\n",
      "step: 18959.0, loss:0.12080702\n",
      "step: 18960.0, loss:0.08417668\n",
      "step: 18961.0, loss:0.19779602\n",
      "step: 18962.0, loss:0.15615532\n",
      "step: 18963.0, loss:0.14738547\n",
      "step: 18964.0, loss:0.15973263\n",
      "step: 18965.0, loss:0.07752613\n",
      "step: 18966.0, loss:0.16967806\n",
      "step: 18967.0, loss:0.15922588\n",
      "step: 18968.0, loss:0.15824127\n",
      "step: 18969.0, loss:0.08691663\n",
      "step: 18970.0, loss:0.25030233\n",
      "step: 18971.0, loss:0.11707433\n",
      "step: 18972.0, loss:0.23748125\n",
      "step: 18973.0, loss:0.27297516\n",
      "step: 18974.0, loss:0.16841147\n",
      "step: 18975.0, loss:0.19727102\n",
      "step: 18976.0, loss:0.24080564\n",
      "step: 18977.0, loss:0.11759650\n",
      "step: 18978.0, loss:0.17802950\n",
      "step: 18979.0, loss:0.18056747\n",
      "step: 18980.0, loss:0.12414998\n",
      "step: 18981.0, loss:0.18011332\n",
      "step: 18982.0, loss:0.16304198\n",
      "step: 18983.0, loss:0.26388361\n",
      "step: 18984.0, loss:0.05865491\n",
      "step: 18985.0, loss:0.22892912\n",
      "step: 18986.0, loss:0.13522447\n",
      "step: 18987.0, loss:0.19995029\n",
      "step: 18988.0, loss:0.19400227\n",
      "step: 18989.0, loss:0.13398026\n",
      "step: 18990.0, loss:0.17358176\n",
      "step: 18991.0, loss:0.07776203\n",
      "step: 18992.0, loss:0.24246998\n",
      "step: 18993.0, loss:0.07920604\n",
      "step: 18994.0, loss:0.19099914\n",
      "step: 18995.0, loss:0.15326070\n",
      "step: 18996.0, loss:0.17247743\n",
      "step: 18997.0, loss:0.08470174\n",
      "step: 18998.0, loss:0.11183472\n",
      "step: 18999.0, loss:0.19771592\n",
      "step: 19000.0, loss:0.16024407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1264/1264 [07:02<00:00,  2.99it/s]\n",
      "2023-04-03 07:05:46,790 - INFO - step:19000.0, matthews_corr:0.785818, Acc:89.962899%,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 19001.0, loss:0.10336617\n",
      "step: 19002.0, loss:0.14679741\n",
      "step: 19003.0, loss:0.23970042\n",
      "step: 19004.0, loss:0.25660980\n",
      "step: 19005.0, loss:0.14857306\n",
      "step: 19006.0, loss:0.21562614\n",
      "step: 19007.0, loss:0.17342545\n",
      "step: 19008.0, loss:0.15946268\n",
      "step: 19009.0, loss:0.25000261\n",
      "step: 19010.0, loss:0.10784198\n",
      "step: 19011.0, loss:0.19546281\n",
      "step: 19012.0, loss:0.15219539\n",
      "step: 19013.0, loss:0.11110044\n",
      "step: 19014.0, loss:0.20320374\n",
      "step: 19015.0, loss:0.20210715\n",
      "step: 19016.0, loss:0.14321972\n",
      "step: 19017.0, loss:0.13002963\n",
      "step: 19018.0, loss:0.17457901\n",
      "step: 19019.0, loss:0.22200810\n",
      "step: 19020.0, loss:0.14793122\n",
      "step: 19021.0, loss:0.13272374\n",
      "step: 19022.0, loss:0.28501651\n",
      "step: 19023.0, loss:0.15185093\n",
      "step: 19024.0, loss:0.13546640\n",
      "step: 19025.0, loss:0.18059765\n",
      "step: 19026.0, loss:0.12000169\n",
      "step: 19027.0, loss:0.16514407\n",
      "step: 19028.0, loss:0.18856536\n",
      "step: 19029.0, loss:0.13998816\n",
      "step: 19030.0, loss:0.14265320\n",
      "step: 19031.0, loss:0.20459912\n",
      "step: 19032.0, loss:0.11060892\n",
      "step: 19033.0, loss:0.10119717\n",
      "step: 19034.0, loss:0.13924879\n",
      "step: 19035.0, loss:0.16957683\n",
      "step: 19036.0, loss:0.17821450\n",
      "step: 19037.0, loss:0.23476830\n",
      "step: 19038.0, loss:0.18283260\n",
      "step: 19039.0, loss:0.25096763\n",
      "step: 19040.0, loss:0.15487948\n",
      "step: 19041.0, loss:0.14741806\n",
      "step: 19042.0, loss:0.11750806\n",
      "step: 19043.0, loss:0.22589579\n",
      "step: 19044.0, loss:0.10530169\n",
      "step: 19045.0, loss:0.09500110\n",
      "step: 19046.0, loss:0.18241837\n",
      "step: 19047.0, loss:0.16309238\n",
      "step: 19048.0, loss:0.23295320\n",
      "step: 19049.0, loss:0.09301360\n",
      "step: 19050.0, loss:0.21348488\n",
      "step: 19051.0, loss:0.26995944\n",
      "step: 19052.0, loss:0.03867621\n",
      "step: 19053.0, loss:0.13634135\n",
      "step: 19054.0, loss:0.13360454\n",
      "step: 19055.0, loss:0.13616032\n",
      "step: 19056.0, loss:0.26652703\n",
      "step: 19057.0, loss:0.16659242\n",
      "step: 19058.0, loss:0.18988570\n",
      "step: 19059.0, loss:0.19648041\n",
      "step: 19060.0, loss:0.21363164\n",
      "step: 19061.0, loss:0.07935212\n",
      "step: 19062.0, loss:0.18276182\n",
      "step: 19063.0, loss:0.09664008\n",
      "step: 19064.0, loss:0.14869005\n",
      "step: 19065.0, loss:0.15355070\n",
      "step: 19066.0, loss:0.11261789\n",
      "step: 19067.0, loss:0.14721909\n",
      "step: 19068.0, loss:0.14158917\n",
      "step: 19069.0, loss:0.18130610\n",
      "step: 19070.0, loss:0.24842412\n",
      "step: 19071.0, loss:0.12041573\n",
      "step: 19072.0, loss:0.26274929\n",
      "step: 19073.0, loss:0.20583191\n",
      "step: 19074.0, loss:0.09807705\n",
      "step: 19075.0, loss:0.20149228\n",
      "step: 19076.0, loss:0.19084170\n",
      "step: 19077.0, loss:0.20549347\n",
      "step: 19078.0, loss:0.12244054\n",
      "step: 19079.0, loss:0.21617363\n",
      "step: 19080.0, loss:0.16577798\n",
      "step: 19081.0, loss:0.11071218\n",
      "step: 19082.0, loss:0.12730057\n",
      "step: 19083.0, loss:0.08380826\n",
      "step: 19084.0, loss:0.10643529\n",
      "step: 19085.0, loss:0.15402693\n",
      "step: 19086.0, loss:0.14017972\n",
      "step: 19087.0, loss:0.16447895\n",
      "step: 19088.0, loss:0.28872722\n",
      "step: 19089.0, loss:0.15984017\n",
      "step: 19090.0, loss:0.09391293\n",
      "step: 19091.0, loss:0.13444822\n",
      "step: 19092.0, loss:0.24954103\n",
      "step: 19093.0, loss:0.14617302\n",
      "step: 19094.0, loss:0.20471815\n",
      "step: 19095.0, loss:0.12237620\n",
      "step: 19096.0, loss:0.19947683\n",
      "step: 19097.0, loss:0.06975095\n",
      "step: 19098.0, loss:0.15063993\n",
      "step: 19099.0, loss:0.17022060\n",
      "step: 19100.0, loss:0.21016837\n",
      "step: 19101.0, loss:0.18666437\n",
      "step: 19102.0, loss:0.14349636\n",
      "step: 19103.0, loss:0.14716237\n",
      "step: 19104.0, loss:0.14402744\n",
      "step: 19105.0, loss:0.17058909\n",
      "step: 19106.0, loss:0.17844162\n",
      "step: 19107.0, loss:0.05275961\n",
      "step: 19108.0, loss:0.14791514\n",
      "step: 19109.0, loss:0.09191124\n",
      "step: 19110.0, loss:0.13761238\n",
      "step: 19111.0, loss:0.13508374\n",
      "step: 19112.0, loss:0.14134539\n",
      "step: 19113.0, loss:0.17968367\n",
      "step: 19114.0, loss:0.15680012\n",
      "step: 19115.0, loss:0.21265784\n",
      "step: 19116.0, loss:0.22962511\n",
      "step: 19117.0, loss:0.07086477\n",
      "step: 19118.0, loss:0.15935988\n",
      "step: 19119.0, loss:0.16047175\n",
      "step: 19120.0, loss:0.22540038\n",
      "step: 19121.0, loss:0.24282390\n",
      "step: 19122.0, loss:0.21951978\n",
      "step: 19123.0, loss:0.08357688\n",
      "step: 19124.0, loss:0.16089577\n",
      "step: 19125.0, loss:0.12401620\n",
      "step: 19126.0, loss:0.13218351\n",
      "step: 19127.0, loss:0.20522099\n",
      "step: 19128.0, loss:0.12558449\n",
      "step: 19129.0, loss:0.18550115\n",
      "step: 19130.0, loss:0.18307191\n",
      "step: 19131.0, loss:0.11160642\n",
      "step: 19132.0, loss:0.32106024\n",
      "step: 19133.0, loss:0.27256391\n",
      "step: 19134.0, loss:0.14204438\n",
      "step: 19135.0, loss:0.14770419\n",
      "step: 19136.0, loss:0.15983342\n",
      "step: 19137.0, loss:0.11694131\n",
      "step: 19138.0, loss:0.12982096\n",
      "step: 19139.0, loss:0.19610992\n",
      "step: 19140.0, loss:0.10936754\n",
      "step: 19141.0, loss:0.25971245\n",
      "step: 19142.0, loss:0.15841755\n",
      "step: 19143.0, loss:0.24864399\n",
      "step: 19144.0, loss:0.13637530\n",
      "step: 19145.0, loss:0.11431485\n",
      "step: 19146.0, loss:0.17273889\n",
      "step: 19147.0, loss:0.31380912\n",
      "step: 19148.0, loss:0.18710238\n",
      "step: 19149.0, loss:0.23840388\n",
      "step: 19150.0, loss:0.16751135\n",
      "step: 19151.0, loss:0.12352604\n",
      "step: 19152.0, loss:0.10594373\n",
      "step: 19153.0, loss:0.23481202\n",
      "step: 19154.0, loss:0.16798988\n",
      "step: 19155.0, loss:0.17639711\n",
      "step: 19156.0, loss:0.17657864\n",
      "step: 19157.0, loss:0.11486274\n",
      "step: 19158.0, loss:0.13995934\n",
      "step: 19159.0, loss:0.06918112\n",
      "step: 19160.0, loss:0.17500529\n",
      "step: 19161.0, loss:0.12886668\n",
      "step: 19162.0, loss:0.16354609\n",
      "step: 19163.0, loss:0.23870638\n",
      "step: 19164.0, loss:0.14933122\n",
      "step: 19165.0, loss:0.14731616\n",
      "step: 19166.0, loss:0.18695119\n",
      "step: 19167.0, loss:0.12739700\n",
      "step: 19168.0, loss:0.22559805\n",
      "step: 19169.0, loss:0.21450112\n",
      "step: 19170.0, loss:0.22545673\n",
      "step: 19171.0, loss:0.17262579\n",
      "step: 19172.0, loss:0.12887336\n",
      "step: 19173.0, loss:0.19956729\n",
      "step: 19174.0, loss:0.20482142\n",
      "step: 19175.0, loss:0.17213769\n",
      "step: 19176.0, loss:0.19461489\n",
      "step: 19177.0, loss:0.21216198\n",
      "step: 19178.0, loss:0.12937130\n",
      "step: 19179.0, loss:0.11697300\n",
      "step: 19180.0, loss:0.19918402\n",
      "step: 19181.0, loss:0.16246359\n",
      "step: 19182.0, loss:0.18517576\n",
      "step: 19183.0, loss:0.18514983\n",
      "step: 19184.0, loss:0.16488807\n",
      "step: 19185.0, loss:0.21416006\n",
      "step: 19186.0, loss:0.21891985\n",
      "step: 19187.0, loss:0.17408335\n",
      "step: 19188.0, loss:0.25556790\n",
      "step: 19189.0, loss:0.20409956\n",
      "step: 19190.0, loss:0.15841618\n",
      "step: 19191.0, loss:0.20341013\n",
      "step: 19192.0, loss:0.09812762\n",
      "step: 19193.0, loss:0.10542063\n",
      "step: 19194.0, loss:0.15124220\n",
      "step: 19195.0, loss:0.13056909\n",
      "step: 19196.0, loss:0.19865187\n",
      "step: 19197.0, loss:0.16412500\n",
      "step: 19198.0, loss:0.08776807\n",
      "step: 19199.0, loss:0.29361793\n",
      "step: 19200.0, loss:0.31958231\n",
      "step: 19201.0, loss:0.13212474\n",
      "step: 19202.0, loss:0.18378080\n",
      "step: 19203.0, loss:0.17391490\n",
      "step: 19204.0, loss:0.19751704\n",
      "step: 19205.0, loss:0.14103396\n",
      "step: 19206.0, loss:0.14023758\n",
      "step: 19207.0, loss:0.16701923\n",
      "step: 19208.0, loss:0.11814420\n",
      "step: 19209.0, loss:0.11698195\n",
      "step: 19210.0, loss:0.30138187\n",
      "step: 19211.0, loss:0.21884401\n",
      "step: 19212.0, loss:0.12411066\n",
      "step: 19213.0, loss:0.16848458\n",
      "step: 19214.0, loss:0.14513732\n",
      "step: 19215.0, loss:0.09462083\n",
      "step: 19216.0, loss:0.19715789\n",
      "step: 19217.0, loss:0.12328213\n",
      "step: 19218.0, loss:0.20002249\n",
      "step: 19219.0, loss:0.13677911\n",
      "step: 19220.0, loss:0.17023475\n",
      "step: 19221.0, loss:0.10864569\n",
      "step: 19222.0, loss:0.11470835\n",
      "step: 19223.0, loss:0.13364900\n",
      "step: 19224.0, loss:0.22987989\n",
      "step: 19225.0, loss:0.33877923\n",
      "step: 19226.0, loss:0.06529495\n",
      "step: 19227.0, loss:0.18138506\n",
      "step: 19228.0, loss:0.18952892\n",
      "step: 19229.0, loss:0.12076670\n",
      "step: 19230.0, loss:0.14175597\n",
      "step: 19231.0, loss:0.14111578\n",
      "step: 19232.0, loss:0.09788282\n",
      "step: 19233.0, loss:0.13099795\n",
      "step: 19234.0, loss:0.21751511\n",
      "step: 19235.0, loss:0.13214308\n",
      "step: 19236.0, loss:0.19880413\n",
      "step: 19237.0, loss:0.16302896\n",
      "step: 19238.0, loss:0.07903039\n",
      "step: 19239.0, loss:0.13517678\n",
      "step: 19240.0, loss:0.24105930\n",
      "step: 19241.0, loss:0.12195721\n",
      "step: 19242.0, loss:0.26214837\n",
      "step: 19243.0, loss:0.15123993\n",
      "step: 19244.0, loss:0.11219624\n",
      "step: 19245.0, loss:0.12995928\n",
      "step: 19246.0, loss:0.13153842\n",
      "step: 19247.0, loss:0.13262440\n",
      "step: 19248.0, loss:0.11942779\n",
      "step: 19249.0, loss:0.18180279\n",
      "step: 19250.0, loss:0.23522036\n",
      "step: 19251.0, loss:0.23817778\n",
      "step: 19252.0, loss:0.27957123\n",
      "step: 19253.0, loss:0.10216751\n",
      "step: 19254.0, loss:0.13086451\n",
      "step: 19255.0, loss:0.16314433\n",
      "step: 19256.0, loss:0.10998237\n",
      "step: 19257.0, loss:0.11288236\n",
      "step: 19258.0, loss:0.12146340\n",
      "step: 19259.0, loss:0.17612302\n",
      "step: 19260.0, loss:0.15454204\n",
      "step: 19261.0, loss:0.24744374\n",
      "step: 19262.0, loss:0.16268137\n",
      "step: 19263.0, loss:0.11167252\n",
      "step: 19264.0, loss:0.08989211\n",
      "step: 19265.0, loss:0.23589573\n",
      "step: 19266.0, loss:0.13296552\n",
      "step: 19267.0, loss:0.13943574\n",
      "step: 19268.0, loss:0.25890484\n",
      "step: 19269.0, loss:0.17567497\n",
      "step: 19270.0, loss:0.16294400\n",
      "step: 19271.0, loss:0.08916880\n",
      "step: 19272.0, loss:0.25111724\n",
      "step: 19273.0, loss:0.13907393\n",
      "step: 19274.0, loss:0.09778174\n",
      "step: 19275.0, loss:0.06851437\n",
      "step: 19276.0, loss:0.10912652\n",
      "step: 19277.0, loss:0.16587809\n",
      "step: 19278.0, loss:0.14858059\n",
      "step: 19279.0, loss:0.17371305\n",
      "step: 19280.0, loss:0.07226644\n",
      "step: 19281.0, loss:0.14739371\n",
      "step: 19282.0, loss:0.12188067\n",
      "step: 19283.0, loss:0.11795263\n",
      "step: 19284.0, loss:0.10858573\n",
      "step: 19285.0, loss:0.19545004\n",
      "step: 19286.0, loss:0.14057893\n",
      "step: 19287.0, loss:0.11754918\n",
      "step: 19288.0, loss:0.20197030\n",
      "step: 19289.0, loss:0.20127093\n",
      "step: 19290.0, loss:0.14806838\n",
      "step: 19291.0, loss:0.12701231\n",
      "step: 19292.0, loss:0.09872181\n",
      "step: 19293.0, loss:0.07321585\n",
      "step: 19294.0, loss:0.15048405\n",
      "step: 19295.0, loss:0.10794062\n",
      "step: 19296.0, loss:0.24302529\n",
      "step: 19297.0, loss:0.25005759\n",
      "step: 19298.0, loss:0.13890564\n",
      "step: 19299.0, loss:0.16739831\n",
      "step: 19300.0, loss:0.18636893\n",
      "step: 19301.0, loss:0.15789561\n",
      "step: 19302.0, loss:0.21903282\n",
      "step: 19303.0, loss:0.26741370\n",
      "step: 19304.0, loss:0.10220932\n",
      "step: 19305.0, loss:0.30784929\n",
      "step: 19306.0, loss:0.12842887\n",
      "step: 19307.0, loss:0.14538617\n",
      "step: 19308.0, loss:0.10976745\n",
      "step: 19309.0, loss:0.07973235\n",
      "step: 19310.0, loss:0.11442247\n",
      "step: 19311.0, loss:0.22396624\n",
      "step: 19312.0, loss:0.12041674\n",
      "step: 19313.0, loss:0.23319035\n",
      "step: 19314.0, loss:0.09755550\n",
      "step: 19315.0, loss:0.09917351\n",
      "step: 19316.0, loss:0.13397361\n",
      "step: 19317.0, loss:0.17616321\n",
      "step: 19318.0, loss:0.13866469\n",
      "step: 19319.0, loss:0.20896060\n",
      "step: 19320.0, loss:0.12413162\n",
      "step: 19321.0, loss:0.09618003\n",
      "step: 19322.0, loss:0.15673492\n",
      "step: 19323.0, loss:0.18698747\n",
      "step: 19324.0, loss:0.11394314\n",
      "step: 19325.0, loss:0.18283455\n",
      "step: 19326.0, loss:0.20623108\n",
      "step: 19327.0, loss:0.34471683\n",
      "step: 19328.0, loss:0.19502951\n",
      "step: 19329.0, loss:0.18042006\n",
      "step: 19330.0, loss:0.20587164\n",
      "step: 19331.0, loss:0.20137045\n",
      "step: 19332.0, loss:0.13476620\n",
      "step: 19333.0, loss:0.16107514\n",
      "step: 19334.0, loss:0.15132035\n",
      "step: 19335.0, loss:0.20412152\n",
      "step: 19336.0, loss:0.13521172\n",
      "step: 19337.0, loss:0.11617451\n",
      "step: 19338.0, loss:0.10413669\n",
      "step: 19339.0, loss:0.20059685\n",
      "step: 19340.0, loss:0.12108457\n",
      "step: 19341.0, loss:0.16232438\n",
      "step: 19342.0, loss:0.14520185\n",
      "step: 19343.0, loss:0.12037965\n",
      "step: 19344.0, loss:0.08683513\n",
      "step: 19345.0, loss:0.21927213\n",
      "step: 19346.0, loss:0.27972249\n",
      "step: 19347.0, loss:0.24787267\n",
      "step: 19348.0, loss:0.11506639\n",
      "step: 19349.0, loss:0.14001821\n",
      "step: 19350.0, loss:0.29623382\n",
      "step: 19351.0, loss:0.24275366\n",
      "step: 19352.0, loss:0.15293062\n",
      "step: 19353.0, loss:0.22578647\n",
      "step: 19354.0, loss:0.18464874\n",
      "step: 19355.0, loss:0.16444248\n",
      "step: 19356.0, loss:0.17105177\n",
      "step: 19357.0, loss:0.28071930\n",
      "step: 19358.0, loss:0.16491578\n",
      "step: 19359.0, loss:0.18602388\n",
      "step: 19360.0, loss:0.15913898\n",
      "step: 19361.0, loss:0.24432279\n",
      "step: 19362.0, loss:0.21337684\n",
      "step: 19363.0, loss:0.13020877\n",
      "step: 19364.0, loss:0.10368389\n",
      "step: 19365.0, loss:0.05026006\n",
      "step: 19366.0, loss:0.20900879\n",
      "step: 19367.0, loss:0.20984214\n",
      "step: 19368.0, loss:0.13445558\n",
      "step: 19369.0, loss:0.11110223\n",
      "step: 19370.0, loss:0.07738766\n",
      "step: 19371.0, loss:0.11515917\n",
      "step: 19372.0, loss:0.29324196\n",
      "step: 19373.0, loss:0.10638006\n",
      "step: 19374.0, loss:0.20021777\n",
      "step: 19375.0, loss:0.12062241\n",
      "step: 19376.0, loss:0.25651621\n",
      "step: 19377.0, loss:0.15979520\n",
      "step: 19378.0, loss:0.15332670\n",
      "step: 19379.0, loss:0.20247190\n",
      "step: 19380.0, loss:0.08723705\n",
      "step: 19381.0, loss:0.09635461\n",
      "step: 19382.0, loss:0.11804172\n",
      "step: 19383.0, loss:0.25711309\n",
      "step: 19384.0, loss:0.19012428\n",
      "step: 19385.0, loss:0.13705673\n",
      "step: 19386.0, loss:0.11815573\n",
      "step: 19387.0, loss:0.19703881\n",
      "step: 19388.0, loss:0.08593730\n",
      "step: 19389.0, loss:0.18257830\n",
      "step: 19390.0, loss:0.19799975\n",
      "step: 19391.0, loss:0.19537313\n",
      "step: 19392.0, loss:0.24794650\n",
      "step: 19393.0, loss:0.12505339\n",
      "step: 19394.0, loss:0.11157092\n",
      "step: 19395.0, loss:0.14724774\n",
      "step: 19396.0, loss:0.17609954\n",
      "step: 19397.0, loss:0.26199648\n",
      "step: 19398.0, loss:0.16295831\n",
      "step: 19399.0, loss:0.14960423\n",
      "step: 19400.0, loss:0.18419285\n",
      "step: 19401.0, loss:0.18633850\n",
      "step: 19402.0, loss:0.22049083\n",
      "step: 19403.0, loss:0.10844089\n",
      "step: 19404.0, loss:0.20974904\n",
      "step: 19405.0, loss:0.16822287\n",
      "step: 19406.0, loss:0.15172445\n",
      "step: 19407.0, loss:0.16203011\n",
      "step: 19408.0, loss:0.14654802\n",
      "step: 19409.0, loss:0.15006123\n",
      "step: 19410.0, loss:0.11856317\n",
      "step: 19411.0, loss:0.13986907\n",
      "step: 19412.0, loss:0.21300403\n",
      "step: 19413.0, loss:0.20885220\n",
      "step: 19414.0, loss:0.10070371\n",
      "step: 19415.0, loss:0.20009317\n",
      "step: 19416.0, loss:0.15304189\n",
      "step: 19417.0, loss:0.07518536\n",
      "step: 19418.0, loss:0.08466898\n",
      "step: 19419.0, loss:0.16231945\n",
      "step: 19420.0, loss:0.12070734\n",
      "step: 19421.0, loss:0.27742992\n",
      "step: 19422.0, loss:0.17281968\n",
      "step: 19423.0, loss:0.06622833\n",
      "step: 19424.0, loss:0.08341223\n",
      "step: 19425.0, loss:0.09105243\n",
      "step: 19426.0, loss:0.11638260\n",
      "step: 19427.0, loss:0.08306565\n",
      "step: 19428.0, loss:0.27940842\n",
      "step: 19429.0, loss:0.13464625\n",
      "step: 19430.0, loss:0.18514916\n",
      "step: 19431.0, loss:0.12357462\n",
      "step: 19432.0, loss:0.14018675\n",
      "step: 19433.0, loss:0.13772479\n",
      "step: 19434.0, loss:0.12997803\n",
      "step: 19435.0, loss:0.14209962\n",
      "step: 19436.0, loss:0.11276904\n",
      "step: 19437.0, loss:0.24955004\n",
      "step: 19438.0, loss:0.13163848\n",
      "step: 19439.0, loss:0.28324678\n",
      "step: 19440.0, loss:0.14760021\n",
      "step: 19441.0, loss:0.18315183\n",
      "step: 19442.0, loss:0.16058197\n",
      "step: 19443.0, loss:0.22277817\n",
      "step: 19444.0, loss:0.19341829\n",
      "step: 19445.0, loss:0.19459014\n",
      "step: 19446.0, loss:0.23047393\n",
      "step: 19447.0, loss:0.18677037\n",
      "step: 19448.0, loss:0.20856141\n",
      "step: 19449.0, loss:0.11286829\n",
      "step: 19450.0, loss:0.20147514\n",
      "step: 19451.0, loss:0.27944334\n",
      "step: 19452.0, loss:0.16382561\n",
      "step: 19453.0, loss:0.12409518\n",
      "step: 19454.0, loss:0.18998341\n",
      "step: 19455.0, loss:0.13515908\n",
      "step: 19456.0, loss:0.15321952\n",
      "step: 19457.0, loss:0.19514327\n",
      "step: 19458.0, loss:0.16709173\n",
      "step: 19459.0, loss:0.08502309\n",
      "step: 19460.0, loss:0.13604565\n",
      "step: 19461.0, loss:0.10908004\n",
      "step: 19462.0, loss:0.09402508\n",
      "step: 19463.0, loss:0.08924493\n",
      "step: 19464.0, loss:0.19667174\n",
      "step: 19465.0, loss:0.11627773\n",
      "step: 19466.0, loss:0.19246510\n",
      "step: 19467.0, loss:0.13624570\n",
      "step: 19468.0, loss:0.18265603\n",
      "step: 19469.0, loss:0.25886630\n",
      "step: 19470.0, loss:0.17790833\n",
      "step: 19471.0, loss:0.25589161\n",
      "step: 19472.0, loss:0.05559594\n",
      "step: 19473.0, loss:0.18190522\n",
      "step: 19474.0, loss:0.21633601\n",
      "step: 19475.0, loss:0.13652905\n",
      "step: 19476.0, loss:0.22642250\n",
      "step: 19477.0, loss:0.21563439\n",
      "step: 19478.0, loss:0.19017350\n",
      "step: 19479.0, loss:0.19158004\n",
      "step: 19480.0, loss:0.09560849\n",
      "step: 19481.0, loss:0.08658991\n",
      "step: 19482.0, loss:0.16121992\n",
      "step: 19483.0, loss:0.26382768\n",
      "step: 19484.0, loss:0.15864323\n",
      "step: 19485.0, loss:0.06820452\n",
      "step: 19486.0, loss:0.20572359\n",
      "step: 19487.0, loss:0.14557873\n",
      "step: 19488.0, loss:0.18540887\n",
      "step: 19489.0, loss:0.22544600\n",
      "step: 19490.0, loss:0.12413075\n",
      "step: 19491.0, loss:0.14307438\n",
      "step: 19492.0, loss:0.21360208\n",
      "step: 19493.0, loss:0.37465853\n",
      "step: 19494.0, loss:0.08934583\n",
      "step: 19495.0, loss:0.09736923\n",
      "step: 19496.0, loss:0.14248202\n",
      "step: 19497.0, loss:0.03421090\n",
      "step: 19498.0, loss:0.10162119\n",
      "step: 19499.0, loss:0.09490112\n",
      "step: 19500.0, loss:0.27274178\n",
      "step: 19501.0, loss:0.20833027\n",
      "step: 19502.0, loss:0.15802815\n",
      "step: 19503.0, loss:0.09605401\n",
      "step: 19504.0, loss:0.23622924\n",
      "step: 19505.0, loss:0.19584464\n",
      "step: 19506.0, loss:0.24129095\n",
      "step: 19507.0, loss:0.14030832\n",
      "step: 19508.0, loss:0.09780795\n",
      "step: 19509.0, loss:0.14541885\n",
      "step: 19510.0, loss:0.12243779\n",
      "step: 19511.0, loss:0.14943322\n",
      "step: 19512.0, loss:0.19635505\n",
      "step: 19513.0, loss:0.15623065\n",
      "step: 19514.0, loss:0.13479789\n",
      "step: 19515.0, loss:0.16585711\n",
      "step: 19516.0, loss:0.22079447\n",
      "step: 19517.0, loss:0.21605477\n",
      "step: 19518.0, loss:0.16023301\n",
      "step: 19519.0, loss:0.18967182\n",
      "step: 19520.0, loss:0.32392802\n",
      "step: 19521.0, loss:0.21445431\n",
      "step: 19522.0, loss:0.11923467\n",
      "step: 19523.0, loss:0.12281603\n",
      "step: 19524.0, loss:0.13487180\n",
      "step: 19525.0, loss:0.25791379\n",
      "step: 19526.0, loss:0.15547401\n",
      "step: 19527.0, loss:0.30625622\n",
      "step: 19528.0, loss:0.23470640\n",
      "step: 19529.0, loss:0.20461728\n",
      "step: 19530.0, loss:0.12290680\n",
      "step: 19531.0, loss:0.05815997\n",
      "step: 19532.0, loss:0.16913213\n",
      "step: 19533.0, loss:0.11925160\n",
      "step: 19534.0, loss:0.25992572\n",
      "step: 19535.0, loss:0.10840669\n",
      "step: 19536.0, loss:0.13225872\n",
      "step: 19537.0, loss:0.13359554\n",
      "step: 19538.0, loss:0.19626049\n",
      "step: 19539.0, loss:0.12807609\n",
      "step: 19540.0, loss:0.28864431\n",
      "step: 19541.0, loss:0.11011034\n",
      "step: 19542.0, loss:0.15004986\n",
      "step: 19543.0, loss:0.08976187\n",
      "step: 19544.0, loss:0.18812019\n",
      "step: 19545.0, loss:0.11496104\n",
      "step: 19546.0, loss:0.06864180\n",
      "step: 19547.0, loss:0.14584040\n",
      "step: 19548.0, loss:0.18066691\n",
      "step: 19549.0, loss:0.13314820\n",
      "step: 19550.0, loss:0.10480518\n",
      "step: 19551.0, loss:0.14668892\n",
      "step: 19552.0, loss:0.25954977\n",
      "step: 19553.0, loss:0.15140890\n",
      "step: 19554.0, loss:0.19679126\n",
      "step: 19555.0, loss:0.30689441\n",
      "step: 19556.0, loss:0.14283164\n",
      "step: 19557.0, loss:0.14888346\n",
      "step: 19558.0, loss:0.17156758\n",
      "step: 19559.0, loss:0.11513761\n",
      "step: 19560.0, loss:0.20183201\n",
      "step: 19561.0, loss:0.10812820\n",
      "step: 19562.0, loss:0.26742396\n",
      "step: 19563.0, loss:0.14248610\n",
      "step: 19564.0, loss:0.26087233\n",
      "step: 19565.0, loss:0.24376984\n",
      "step: 19566.0, loss:0.22506838\n",
      "step: 19567.0, loss:0.17845665\n",
      "step: 19568.0, loss:0.08478804\n",
      "step: 19569.0, loss:0.08284296\n",
      "step: 19570.0, loss:0.26435984\n",
      "step: 19571.0, loss:0.16817650\n",
      "step: 19572.0, loss:0.27163490\n",
      "step: 19573.0, loss:0.16513961\n",
      "step: 19574.0, loss:0.17752436\n",
      "step: 19575.0, loss:0.18166525\n",
      "step: 19576.0, loss:0.17216754\n",
      "step: 19577.0, loss:0.13631987\n",
      "step: 19578.0, loss:0.15055601\n",
      "step: 19579.0, loss:0.24035583\n",
      "step: 19580.0, loss:0.13418874\n",
      "step: 19581.0, loss:0.15001824\n",
      "step: 19582.0, loss:0.15373284\n",
      "step: 19583.0, loss:0.14742233\n",
      "step: 19584.0, loss:0.14716620\n",
      "step: 19585.0, loss:0.12194008\n",
      "step: 19586.0, loss:0.13635045\n",
      "step: 19587.0, loss:0.12595392\n",
      "step: 19588.0, loss:0.20714320\n",
      "step: 19589.0, loss:0.12468878\n",
      "step: 19590.0, loss:0.17259324\n",
      "step: 19591.0, loss:0.19802503\n",
      "step: 19592.0, loss:0.11019556\n",
      "step: 19593.0, loss:0.11169319\n",
      "step: 19594.0, loss:0.09372985\n",
      "step: 19595.0, loss:0.16156463\n",
      "step: 19596.0, loss:0.11618487\n",
      "step: 19597.0, loss:0.23660779\n",
      "step: 19598.0, loss:0.06524816\n",
      "step: 19599.0, loss:0.21010860\n",
      "step: 19600.0, loss:0.12082491\n",
      "step: 19601.0, loss:0.09572815\n",
      "step: 19602.0, loss:0.13163909\n",
      "step: 19603.0, loss:0.20083322\n",
      "step: 19604.0, loss:0.09171271\n",
      "step: 19605.0, loss:0.09468523\n",
      "step: 19606.0, loss:0.18402205\n",
      "step: 19607.0, loss:0.14946407\n",
      "step: 19608.0, loss:0.19019247\n",
      "step: 19609.0, loss:0.15057841\n",
      "step: 19610.0, loss:0.15520998\n",
      "step: 19611.0, loss:0.11067606\n",
      "step: 19612.0, loss:0.12183753\n",
      "step: 19613.0, loss:0.17179862\n",
      "step: 19614.0, loss:0.08194380\n",
      "step: 19615.0, loss:0.14198103\n",
      "step: 19616.0, loss:0.19336637\n",
      "step: 19617.0, loss:0.18412853\n",
      "step: 19618.0, loss:0.10139295\n",
      "step: 19619.0, loss:0.21979880\n",
      "step: 19620.0, loss:0.21366930\n",
      "step: 19621.0, loss:0.13369494\n",
      "step: 19622.0, loss:0.24161509\n",
      "step: 19623.0, loss:0.10116337\n",
      "step: 19624.0, loss:0.24831818\n",
      "step: 19625.0, loss:0.24264867\n",
      "step: 19626.0, loss:0.16658059\n",
      "step: 19627.0, loss:0.11392157\n",
      "step: 19628.0, loss:0.09610271\n",
      "step: 19629.0, loss:0.27962035\n",
      "step: 19630.0, loss:0.12471047\n",
      "step: 19631.0, loss:0.15874222\n",
      "step: 19632.0, loss:0.14391675\n",
      "step: 19633.0, loss:0.17080951\n",
      "step: 19634.0, loss:0.16998229\n",
      "step: 19635.0, loss:0.08269107\n",
      "step: 19636.0, loss:0.18931310\n",
      "step: 19637.0, loss:0.15365885\n",
      "step: 19638.0, loss:0.18259846\n",
      "step: 19639.0, loss:0.14637664\n",
      "step: 19640.0, loss:0.06742297\n",
      "step: 19641.0, loss:0.10240885\n",
      "step: 19642.0, loss:0.10808640\n",
      "step: 19643.0, loss:0.10878702\n",
      "step: 19644.0, loss:0.15328938\n",
      "step: 19645.0, loss:0.09231518\n",
      "step: 19646.0, loss:0.16675279\n",
      "step: 19647.0, loss:0.15675887\n",
      "step: 19648.0, loss:0.15229281\n",
      "step: 19649.0, loss:0.15377982\n",
      "step: 19650.0, loss:0.21299491\n",
      "step: 19651.0, loss:0.11849885\n",
      "step: 19652.0, loss:0.24473480\n",
      "step: 19653.0, loss:0.21721608\n",
      "step: 19654.0, loss:0.18095119\n",
      "step: 19655.0, loss:0.21188489\n",
      "step: 19656.0, loss:0.10226144\n",
      "step: 19657.0, loss:0.15238726\n",
      "step: 19658.0, loss:0.23169832\n",
      "step: 19659.0, loss:0.18618705\n",
      "step: 19660.0, loss:0.24003618\n",
      "step: 19661.0, loss:0.16375870\n",
      "step: 19662.0, loss:0.26078438\n",
      "step: 19663.0, loss:0.15940576\n",
      "step: 19664.0, loss:0.10654295\n",
      "step: 19665.0, loss:0.22216560\n",
      "step: 19666.0, loss:0.22519932\n",
      "step: 19667.0, loss:0.13622036\n",
      "step: 19668.0, loss:0.18723387\n",
      "step: 19669.0, loss:0.32525818\n",
      "step: 19670.0, loss:0.31267646\n",
      "step: 19671.0, loss:0.08317465\n",
      "step: 19672.0, loss:0.10119121\n",
      "step: 19673.0, loss:0.16763598\n",
      "step: 19674.0, loss:0.19672689\n",
      "step: 19675.0, loss:0.24831466\n",
      "step: 19676.0, loss:0.11673102\n",
      "step: 19677.0, loss:0.27846699\n",
      "step: 19678.0, loss:0.13477590\n",
      "step: 19679.0, loss:0.18124497\n",
      "step: 19680.0, loss:0.10000306\n",
      "step: 19681.0, loss:0.21834926\n",
      "step: 19682.0, loss:0.24874003\n",
      "step: 19683.0, loss:0.16142585\n",
      "step: 19684.0, loss:0.15013501\n",
      "step: 19685.0, loss:0.14156083\n",
      "step: 19686.0, loss:0.10632039\n",
      "step: 19687.0, loss:0.21184211\n",
      "step: 19688.0, loss:0.21729174\n",
      "step: 19689.0, loss:0.12463451\n",
      "step: 19690.0, loss:0.16172306\n",
      "step: 19691.0, loss:0.18008463\n",
      "step: 19692.0, loss:0.38511635\n",
      "step: 19693.0, loss:0.19655087\n",
      "step: 19694.0, loss:0.16604653\n",
      "step: 19695.0, loss:0.16845946\n",
      "step: 19696.0, loss:0.23670416\n",
      "step: 19697.0, loss:0.19639821\n",
      "step: 19698.0, loss:0.24779813\n",
      "step: 19699.0, loss:0.30887915\n",
      "step: 19700.0, loss:0.20937307\n",
      "step: 19701.0, loss:0.17563847\n",
      "step: 19702.0, loss:0.16920278\n",
      "step: 19703.0, loss:0.16373270\n",
      "step: 19704.0, loss:0.05417867\n",
      "step: 19705.0, loss:0.13445048\n",
      "step: 19706.0, loss:0.19414744\n",
      "step: 19707.0, loss:0.20885691\n",
      "step: 19708.0, loss:0.17528345\n",
      "step: 19709.0, loss:0.13258096\n",
      "step: 19710.0, loss:0.08646379\n",
      "step: 19711.0, loss:0.18719774\n",
      "step: 19712.0, loss:0.19046838\n",
      "step: 19713.0, loss:0.09347972\n",
      "step: 19714.0, loss:0.14003156\n",
      "step: 19715.0, loss:0.14751931\n",
      "step: 19716.0, loss:0.19220107\n",
      "step: 19717.0, loss:0.15558151\n",
      "step: 19718.0, loss:0.19551732\n",
      "step: 19719.0, loss:0.23362023\n",
      "step: 19720.0, loss:0.09748513\n",
      "step: 19721.0, loss:0.11524509\n",
      "step: 19722.0, loss:0.06799313\n",
      "step: 19723.0, loss:0.18120377\n",
      "step: 19724.0, loss:0.18741861\n",
      "step: 19725.0, loss:0.23573254\n",
      "step: 19726.0, loss:0.28079294\n",
      "step: 19727.0, loss:0.26773899\n",
      "step: 19728.0, loss:0.17959352\n",
      "step: 19729.0, loss:0.19463174\n",
      "step: 19730.0, loss:0.10862195\n",
      "step: 19731.0, loss:0.23223689\n",
      "step: 19732.0, loss:0.09286596\n",
      "step: 19733.0, loss:0.18196170\n",
      "step: 19734.0, loss:0.16248562\n",
      "step: 19735.0, loss:0.23150973\n",
      "step: 19736.0, loss:0.30386278\n",
      "step: 19737.0, loss:0.16521097\n",
      "step: 19738.0, loss:0.10236501\n",
      "step: 19739.0, loss:0.22646390\n",
      "step: 19740.0, loss:0.20717969\n",
      "step: 19741.0, loss:0.21796364\n",
      "step: 19742.0, loss:0.10453817\n",
      "step: 19743.0, loss:0.13522334\n",
      "step: 19744.0, loss:0.30335054\n",
      "step: 19745.0, loss:0.08382215\n",
      "step: 19746.0, loss:0.21551284\n",
      "step: 19747.0, loss:0.21649962\n",
      "step: 19748.0, loss:0.16116818\n",
      "step: 19749.0, loss:0.14789158\n",
      "step: 19750.0, loss:0.19116731\n",
      "step: 19751.0, loss:0.11820776\n",
      "step: 19752.0, loss:0.24120462\n",
      "step: 19753.0, loss:0.24432312\n",
      "step: 19754.0, loss:0.22835702\n",
      "step: 19755.0, loss:0.14503348\n",
      "step: 19756.0, loss:0.08746766\n",
      "step: 19757.0, loss:0.17740949\n",
      "step: 19758.0, loss:0.13354782\n",
      "step: 19759.0, loss:0.25695585\n",
      "step: 19760.0, loss:0.18810645\n",
      "step: 19761.0, loss:0.27847933\n",
      "step: 19762.0, loss:0.09052520\n",
      "step: 19763.0, loss:0.14125031\n",
      "step: 19764.0, loss:0.21197007\n",
      "step: 19765.0, loss:0.14523987\n",
      "step: 19766.0, loss:0.11468040\n",
      "step: 19767.0, loss:0.18480200\n",
      "step: 19768.0, loss:0.13524870\n",
      "step: 19769.0, loss:0.14873463\n",
      "step: 19770.0, loss:0.14904180\n",
      "step: 19771.0, loss:0.24052164\n",
      "step: 19772.0, loss:0.18730171\n",
      "step: 19773.0, loss:0.20214793\n",
      "step: 19774.0, loss:0.14157136\n",
      "step: 19775.0, loss:0.20389898\n",
      "step: 19776.0, loss:0.17877674\n",
      "step: 19777.0, loss:0.13629440\n",
      "step: 19778.0, loss:0.11880749\n",
      "step: 19779.0, loss:0.10691301\n",
      "step: 19780.0, loss:0.17196058\n",
      "step: 19781.0, loss:0.20742516\n",
      "step: 19782.0, loss:0.19500536\n",
      "step: 19783.0, loss:0.11123479\n",
      "step: 19784.0, loss:0.22061142\n",
      "step: 19785.0, loss:0.14631894\n",
      "step: 19786.0, loss:0.26528840\n",
      "step: 19787.0, loss:0.22788639\n",
      "step: 19788.0, loss:0.15071430\n",
      "step: 19789.0, loss:0.16618243\n",
      "step: 19790.0, loss:0.26824090\n",
      "step: 19791.0, loss:0.22463946\n",
      "step: 19792.0, loss:0.20066167\n",
      "step: 19793.0, loss:0.25050552\n",
      "step: 19794.0, loss:0.20833146\n",
      "step: 19795.0, loss:0.13815646\n",
      "step: 19796.0, loss:0.19114840\n",
      "step: 19797.0, loss:0.08552805\n",
      "step: 19798.0, loss:0.05631179\n",
      "step: 19799.0, loss:0.15264427\n",
      "step: 19800.0, loss:0.21255322\n",
      "step: 19801.0, loss:0.33617011\n",
      "step: 19802.0, loss:0.13733216\n",
      "step: 19803.0, loss:0.25344772\n",
      "step: 19804.0, loss:0.11545263\n",
      "step: 19805.0, loss:0.11875892\n",
      "step: 19806.0, loss:0.17384113\n",
      "step: 19807.0, loss:0.18735510\n",
      "step: 19808.0, loss:0.19606738\n",
      "step: 19809.0, loss:0.15731823\n",
      "step: 19810.0, loss:0.18722822\n",
      "step: 19811.0, loss:0.09846487\n",
      "step: 19812.0, loss:0.20734766\n",
      "step: 19813.0, loss:0.06778385\n",
      "step: 19814.0, loss:0.13787974\n",
      "step: 19815.0, loss:0.12815033\n",
      "step: 19816.0, loss:0.13953975\n",
      "step: 19817.0, loss:0.14042202\n",
      "step: 19818.0, loss:0.26686411\n",
      "step: 19819.0, loss:0.06263639\n",
      "step: 19820.0, loss:0.20471802\n",
      "step: 19821.0, loss:0.16499395\n",
      "step: 19822.0, loss:0.27847081\n",
      "step: 19823.0, loss:0.22290573\n",
      "step: 19824.0, loss:0.23688771\n",
      "step: 19825.0, loss:0.16865901\n",
      "step: 19826.0, loss:0.15019844\n",
      "step: 19827.0, loss:0.21224090\n",
      "step: 19828.0, loss:0.14404586\n",
      "step: 19829.0, loss:0.12718351\n",
      "step: 19830.0, loss:0.08876548\n",
      "step: 19831.0, loss:0.24050352\n",
      "step: 19832.0, loss:0.07650133\n",
      "step: 19833.0, loss:0.14340535\n",
      "step: 19834.0, loss:0.14731550\n",
      "step: 19835.0, loss:0.13716918\n",
      "step: 19836.0, loss:0.14659069\n",
      "step: 19837.0, loss:0.21190050\n",
      "step: 19838.0, loss:0.17767763\n",
      "step: 19839.0, loss:0.13548409\n",
      "step: 19840.0, loss:0.05858036\n",
      "step: 19841.0, loss:0.12311822\n",
      "step: 19842.0, loss:0.13089467\n",
      "step: 19843.0, loss:0.12774155\n",
      "step: 19844.0, loss:0.13163519\n",
      "step: 19845.0, loss:0.15492037\n",
      "step: 19846.0, loss:0.16822622\n",
      "step: 19847.0, loss:0.21656928\n",
      "step: 19848.0, loss:0.18562471\n",
      "step: 19849.0, loss:0.10023668\n",
      "step: 19850.0, loss:0.20839974\n",
      "step: 19851.0, loss:0.10754091\n",
      "step: 19852.0, loss:0.16897103\n",
      "step: 19853.0, loss:0.10484776\n",
      "step: 19854.0, loss:0.08734050\n",
      "step: 19855.0, loss:0.11227363\n",
      "step: 19856.0, loss:0.22234394\n",
      "step: 19857.0, loss:0.13892588\n",
      "step: 19858.0, loss:0.17765905\n",
      "step: 19859.0, loss:0.14841099\n",
      "step: 19860.0, loss:0.20691715\n",
      "step: 19861.0, loss:0.19874319\n",
      "step: 19862.0, loss:0.16005939\n",
      "step: 19863.0, loss:0.07698836\n",
      "step: 19864.0, loss:0.14793580\n",
      "step: 19865.0, loss:0.11214602\n",
      "step: 19866.0, loss:0.18188931\n",
      "step: 19867.0, loss:0.22355415\n",
      "step: 19868.0, loss:0.14647571\n",
      "step: 19869.0, loss:0.08598950\n",
      "step: 19870.0, loss:0.20595768\n",
      "step: 19871.0, loss:0.12648658\n",
      "step: 19872.0, loss:0.10586035\n",
      "step: 19873.0, loss:0.13312513\n",
      "step: 19874.0, loss:0.10432126\n",
      "step: 19875.0, loss:0.21277320\n",
      "step: 19876.0, loss:0.27268821\n",
      "step: 19877.0, loss:0.12615203\n",
      "step: 19878.0, loss:0.17253699\n",
      "step: 19879.0, loss:0.07765433\n",
      "step: 19880.0, loss:0.07444226\n",
      "step: 19881.0, loss:0.14041903\n",
      "step: 19882.0, loss:0.15964074\n",
      "step: 19883.0, loss:0.21744303\n",
      "step: 19884.0, loss:0.22009069\n",
      "step: 19885.0, loss:0.16708578\n",
      "step: 19886.0, loss:0.12851780\n",
      "step: 19887.0, loss:0.15848295\n",
      "step: 19888.0, loss:0.11487608\n",
      "step: 19889.0, loss:0.14336270\n",
      "step: 19890.0, loss:0.11511018\n",
      "step: 19891.0, loss:0.12042685\n",
      "step: 19892.0, loss:0.10077474\n",
      "step: 19893.0, loss:0.24840702\n",
      "step: 19894.0, loss:0.17603668\n",
      "step: 19895.0, loss:0.19765710\n",
      "step: 19896.0, loss:0.14878952\n",
      "step: 19897.0, loss:0.10024939\n",
      "step: 19898.0, loss:0.27704119\n",
      "step: 19899.0, loss:0.35209504\n",
      "step: 19900.0, loss:0.26130380\n",
      "step: 19901.0, loss:0.17106829\n",
      "step: 19902.0, loss:0.18875278\n",
      "step: 19903.0, loss:0.17728100\n",
      "step: 19904.0, loss:0.17088351\n",
      "step: 19905.0, loss:0.16521969\n",
      "step: 19906.0, loss:0.09592990\n",
      "step: 19907.0, loss:0.21671255\n",
      "step: 19908.0, loss:0.15622167\n",
      "step: 19909.0, loss:0.08268107\n",
      "step: 19910.0, loss:0.28895250\n",
      "step: 19911.0, loss:0.11440091\n",
      "step: 19912.0, loss:0.14184672\n",
      "step: 19913.0, loss:0.11983764\n",
      "step: 19914.0, loss:0.20773000\n",
      "step: 19915.0, loss:0.23536358\n",
      "step: 19916.0, loss:0.16593803\n",
      "step: 19917.0, loss:0.11868638\n",
      "step: 19918.0, loss:0.09189631\n",
      "step: 19919.0, loss:0.11771659\n",
      "step: 19920.0, loss:0.18553631\n",
      "step: 19921.0, loss:0.06783297\n",
      "step: 19922.0, loss:0.26653280\n",
      "step: 19923.0, loss:0.18845677\n",
      "step: 19924.0, loss:0.07445351\n",
      "step: 19925.0, loss:0.10026135\n",
      "step: 19926.0, loss:0.17865528\n",
      "step: 19927.0, loss:0.17155722\n",
      "step: 19928.0, loss:0.11634871\n",
      "step: 19929.0, loss:0.09283282\n",
      "step: 19930.0, loss:0.18096608\n",
      "step: 19931.0, loss:0.19946745\n",
      "step: 19932.0, loss:0.20405081\n",
      "step: 19933.0, loss:0.14792780\n",
      "step: 19934.0, loss:0.19343724\n",
      "step: 19935.0, loss:0.10712367\n",
      "step: 19936.0, loss:0.11349541\n",
      "step: 19937.0, loss:0.15160555\n",
      "step: 19938.0, loss:0.10383717\n",
      "step: 19939.0, loss:0.14824892\n",
      "step: 19940.0, loss:0.11183173\n",
      "step: 19941.0, loss:0.17437990\n",
      "step: 19942.0, loss:0.14552860\n",
      "step: 19943.0, loss:0.05653664\n",
      "step: 19944.0, loss:0.16650337\n",
      "step: 19945.0, loss:0.08905469\n",
      "step: 19946.0, loss:0.23005962\n",
      "step: 19947.0, loss:0.18351203\n",
      "step: 19948.0, loss:0.08297285\n",
      "step: 19949.0, loss:0.20051858\n",
      "step: 19950.0, loss:0.30193451\n",
      "step: 19951.0, loss:0.25608871\n",
      "step: 19952.0, loss:0.17151944\n",
      "step: 19953.0, loss:0.12567856\n",
      "step: 19954.0, loss:0.13944673\n",
      "step: 19955.0, loss:0.16665038\n",
      "step: 19956.0, loss:0.13531262\n",
      "step: 19957.0, loss:0.16373294\n",
      "step: 19958.0, loss:0.05748795\n",
      "step: 19959.0, loss:0.15249046\n",
      "step: 19960.0, loss:0.09517413\n",
      "step: 19961.0, loss:0.11796626\n",
      "step: 19962.0, loss:0.19447491\n",
      "step: 19963.0, loss:0.11992604\n",
      "step: 19964.0, loss:0.18846042\n",
      "step: 19965.0, loss:0.13528009\n",
      "step: 19966.0, loss:0.16176416\n",
      "step: 19967.0, loss:0.17263640\n",
      "step: 19968.0, loss:0.16051868\n",
      "step: 19969.0, loss:0.11039709\n",
      "step: 19970.0, loss:0.05158636\n",
      "step: 19971.0, loss:0.17020371\n",
      "step: 19972.0, loss:0.09666288\n",
      "step: 19973.0, loss:0.18649904\n",
      "step: 19974.0, loss:0.19451592\n",
      "step: 19975.0, loss:0.16263929\n",
      "step: 19976.0, loss:0.14838233\n",
      "step: 19977.0, loss:0.31609299\n",
      "step: 19978.0, loss:0.13498218\n",
      "step: 19979.0, loss:0.09781622\n",
      "step: 19980.0, loss:0.20649276\n",
      "step: 19981.0, loss:0.14284995\n",
      "step: 19982.0, loss:0.18710682\n",
      "step: 19983.0, loss:0.32145907\n",
      "step: 19984.0, loss:0.09419016\n",
      "step: 19985.0, loss:0.15922458\n",
      "step: 19986.0, loss:0.11575196\n",
      "step: 19987.0, loss:0.11228685\n",
      "step: 19988.0, loss:0.13681076\n",
      "step: 19989.0, loss:0.18199483\n",
      "step: 19990.0, loss:0.18688827\n",
      "step: 19991.0, loss:0.09707028\n",
      "step: 19992.0, loss:0.23467058\n",
      "step: 19993.0, loss:0.20951420\n",
      "step: 19994.0, loss:0.16766077\n",
      "step: 19995.0, loss:0.18759844\n",
      "step: 19996.0, loss:0.17634586\n",
      "step: 19997.0, loss:0.17441602\n",
      "step: 19998.0, loss:0.13376291\n",
      "step: 19999.0, loss:0.19519939\n",
      "step: 20000.0, loss:0.21206375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1264/1264 [07:02<00:00,  2.99it/s]\n",
      "2023-04-03 07:44:52,283 - INFO - step:20000.0, matthews_corr:0.784825, Acc:89.883750%,\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "# loss_mat = np.zeros((len(batch_size_list),len(scheduler_list), len(optimizer_list), len(lr_list),steps))\n",
    "\n",
    " # evaluate test metric each step\n",
    "# metric_mat = np.zeros((len(batch_size_list),len(scheduler_list), len(optimizer_list), len(lr_list),steps//report_step,2))\n",
    "for i,this_batch_size in enumerate(batch_size_list):\n",
    "    for j,this_scheduler in enumerate(scheduler_list):\n",
    "        for k,this_optimizer in enumerate(optimizer_list):\n",
    "            for m, this_lr in enumerate(lr_list):\n",
    "                report_loss = 0.\n",
    "                loss_list = []\n",
    "                metric_list = []\n",
    "                acc_list = []\n",
    "                train_metric_list = []\n",
    "                train_acc_list = []\n",
    "                model = BertForSequenceClassification.from_pretrained(\"C:/Users/Xiang/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b\").to(device)\n",
    "\n",
    "                train_loader = DataLoader(train_dataset, batch_size=int(this_batch_size/accum_iter))\n",
    "                sche, opt = prepare(this_scheduler, this_optimizer)\n",
    "                optimizer = opt(model.parameters(), lr = this_lr if this_scheduler == 'no' else this_lr*2)\n",
    "                scheduler = sche(optimizer, num_warmup_steps=int(steps/(10*accum_iter)),num_training_steps=int(steps/accum_iter))\n",
    "                step = 0\n",
    "\n",
    "                metric,acc = evaluate(model,valid_dataset)\n",
    "                metric_list.append(metric)\n",
    "                acc_list.append(acc)\n",
    "\n",
    "                # tmetric, tacc = evaluate(model, train_dataset)\n",
    "                # train_metric_list.append(tmetric)\n",
    "                # train_acc_list.append(tacc)\n",
    "                # metric_mat[i,j,k,m,step//report_step - 1,0] = metric\n",
    "                # metric_mat[i,j,k,m,step//report_step - 1,1] = acc\n",
    "\n",
    "                print(f\"step:{step}, matthews_corr:{metric:.6f}, Acc:{acc*100:4f}%\")\n",
    "\n",
    "                # print(f'Start training for: sche:{this_scheduler},opt:{this_optimizer},batchsize:{this_batch_size}, lr:{this_lr}')\n",
    "                logger.info(f'Start training for: sche:{this_scheduler},opt:{this_optimizer},batchsize:{this_batch_size}, lr:{this_lr}')\n",
    "                while True:\n",
    "\n",
    "                    for X in train_loader:\n",
    "                        model.train()\n",
    "\n",
    "                        batch = {k: v.to(device) for k, v in X.items()}\n",
    "                        loss = model(**batch).loss/accum_iter\n",
    "                        report_loss+=loss.item()\n",
    "                        loss.backward()\n",
    "                        if (step+1)%accum_iter == 0:\n",
    "                            print(f\"step: {(step+1)/accum_iter}, loss:{report_loss:.8f}\")\n",
    "\n",
    "                        # loss_mat[i,j,k,m,step] = loss.item()\n",
    "                            loss_list.append(report_loss)\n",
    "\n",
    "                            optimizer.step()\n",
    "                            optimizer.zero_grad()\n",
    "                            scheduler.step()\n",
    "                            report_loss = 0\n",
    "\n",
    "                        step += 1\n",
    "\n",
    "                    # valid\n",
    "                        if step % (report_step*accum_iter) == 0:\n",
    "\n",
    "                            metric,acc = evaluate(model,valid_dataset)\n",
    "                            # print(i,j,k,m,step//report_step)\n",
    "                            metric_list.append(metric)\n",
    "                            acc_list.append(acc)\n",
    "                            # tmetric, tacc = evaluate(model, train_dataset)\n",
    "                            # train_metric_list.append(tmetric)\n",
    "                            # train_acc_list.append(tacc)\n",
    "                            # metric_mat[i,j,k,m,step//report_step - 1,0] = metric\n",
    "                            # metric_mat[i,j,k,m,step//report_step - 1,1] = acc\n",
    "                            # print(f\"step:{step}, matthews_corr:{metric:.6f}, Acc:{acc*100:4f}%\")\n",
    "                            logger.info(f\"step:{step/accum_iter}, matthews_corr:{metric:.6f}, Acc:{acc*100:4f}%,\")\n",
    "\n",
    "                        if step == steps:\n",
    "                            break\n",
    "                    if step == steps:\n",
    "                        break\n",
    "                file_name = dataset_name+\",batchsize\"+str(this_batch_size)+\",scheduler\"+this_scheduler+\",optimizer\"+str(this_optimizer)+\",LR\"+str(this_lr)\n",
    "                np.save(current_path/(file_name+'loss.npy'),np.array(loss_list))\n",
    "                np.save(current_path/(file_name+'metric.npy'),np.array(metric_list))\n",
    "                np.save(current_path/(file_name+'acc.npy'),np.array(acc_list))\n",
    "                # np.save(current_path/(file_name+'trainmetric.npy'),np.array(train_metric_list))\n",
    "                # np.save(current_path/(file_name+'trainacc.npy'),np.array(train_acc_list))\n",
    "\n",
    "                del model\n",
    "                del optimizer\n",
    "                del scheduler\n",
    "                del train_loader\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
