{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_linear_schedule_with_warmup, get_polynomial_decay_schedule_with_warmup\n",
    "from lion_pytorch import Lion\n",
    "from torch.utils.data import DataLoader\n",
    "import GLUEGPT2\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "import matplotlib.pyplot as plt\n",
    "import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import GPT2Tokenizer\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "\n",
    "\n",
    "# Set up device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (/Users/xiongbowen/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ada1ecdff7c94f0789a977b5c256f193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/xiongbowen/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-3bec0afcd36b72dc.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d79c9b149749472f901850a4acbdf626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1043 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/xiongbowen/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-d55a8b5eb6b0e41a.arrow\n",
      "Loading cached processed dataset at /Users/xiongbowen/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-2257558fcd85bd6c.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a36b0cbd1b2c46b793a59e9532b24247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1043 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([237., 395., 198., 110.,  52.,  24.,  12.,   7.,   4.,   4.]),\n",
       " array([ 3. ,  6.1,  9.2, 12.3, 15.4, 18.5, 21.6, 24.7, 27.8, 30.9, 34. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.nn.utils.rnn as rnn_utils\n",
    "\n",
    "train_dataset, test_dataset, _  = GLUEGPT2.get_torch_dataset('gpt2', \"cola\")\n",
    "\n",
    "def pad_examples(batch):\n",
    "    input_ids = rnn_utils.pad_sequence(batch['input_ids'], batch_first=True, padding_value=0)\n",
    "    attention_mask = rnn_utils.pad_sequence(batch['attention_mask'], batch_first=True, padding_value=0)\n",
    "    labels = batch['labels']\n",
    "    return {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': labels}\n",
    "\n",
    "train_dataset = train_dataset.map(pad_examples, batched=True)\n",
    "test_dataset = test_dataset.map(pad_examples, batched=True)\n",
    "\n",
    "\n",
    "# length = torch.sum(train_dataset[:][\"attention_mask\"], dim=1).numpy()\n",
    "attention_masks_sum = []\n",
    "for i in range(len(train_dataset)):\n",
    "    attention_mask = train_dataset[i]['attention_mask']\n",
    "    attention_mask_sum = torch.sum(attention_mask).item()\n",
    "    attention_masks_sum.append(attention_mask_sum)\n",
    "plt.hist(attention_masks_sum)\n",
    "\n",
    "attention_masks_sum_test = []\n",
    "for i in range(len(test_dataset)):\n",
    "    attention_mask = test_dataset[i]['attention_mask']\n",
    "    attention_mask_sum = torch.sum(attention_mask).item()\n",
    "    attention_masks_sum_test.append(attention_mask_sum)\n",
    "# length = torch.sum(test_dataset[:][\"attention_mask\"], dim=1).numpy()\n",
    "plt.hist(attention_masks_sum_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def constant_scheduler(\n",
    "    optimizer, num_warmup_steps, num_training_steps, lr_end=1e-7, power=1.0, last_epoch=-1\n",
    "):\n",
    "    def lambda_func(step:int):\n",
    "        return 1.\n",
    "\n",
    "    return LambdaLR(optimizer, lambda_func, last_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(sche, opt):\n",
    "    if sche == 'no':\n",
    "        sches = partial(constant_scheduler)\n",
    "    if sche == 'linear':\n",
    "        sches = partial(get_linear_schedule_with_warmup)\n",
    "    if sche == 'ord10':\n",
    "        sches = partial(get_polynomial_decay_schedule_with_warmup,power = 10.0)\n",
    "\n",
    "    if opt == 'Lion':\n",
    "        opts = partial(Lion)\n",
    "    if opt == 'Adam':\n",
    "        opts = partial(torch.optim.Adam)\n",
    "    if opt == 'AdamW':\n",
    "        opts = partial(torch.optim.AdamW)\n",
    "\n",
    "\n",
    "    return sches, opts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8551 1043\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset),len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list = [1e-5,1e-4]\n",
    "scheduler_list = ['no',  'ord10']\n",
    "optimizer_list = ['Lion', 'AdamW']\n",
    "batch_size_list = [32,64]\n",
    "steps = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, shuffle = False, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': tensor([1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "         1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "         1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1]),\n",
       " 'input_ids': tensor([[  464, 29996, 22075,  ...,     0,     0,     0],\n",
       "         [  464, 19590,   925,  ...,     0,     0,     0],\n",
       "         [  464, 12370,  3654,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [   40,  1101,  1654,  ...,     0,     0,     0],\n",
       "         [49444,    88,  6619,  ...,     0,     0,     0],\n",
       "         [30847,  6619,   546,  ...,     0,     0,     0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, shuffle = False, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Define the padding token\n",
    "\n",
    "input_ids = tokenizer(['HA HA HA.','you are pig right?','You are bad.'], return_tensors='pt', padding=True)\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(**input_ids).logits\n",
    "\n",
    "predicted_class_id = logits.argmax().item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training for: sche:no,opt:Lion,batchsize:32, lr:1e-05\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (928) to match target batch_size (31).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 26\u001B[0m\n\u001B[1;32m     24\u001B[0m optimizer\u001B[39m.\u001B[39mzero_grad()\n\u001B[1;32m     25\u001B[0m batch \u001B[39m=\u001B[39m {k: v\u001B[39m.\u001B[39mto(device) \u001B[39mfor\u001B[39;00m k, v \u001B[39min\u001B[39;00m X\u001B[39m.\u001B[39mitems()}\n\u001B[0;32m---> 26\u001B[0m loss \u001B[39m=\u001B[39m model(\u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mbatch)\u001B[39m.\u001B[39mloss\n\u001B[1;32m     27\u001B[0m \u001B[39mprint\u001B[39m(\u001B[39mf\u001B[39m\u001B[39m\"\u001B[39m\u001B[39mstep: \u001B[39m\u001B[39m{\u001B[39;00mstep\u001B[39m+\u001B[39m\u001B[39m1\u001B[39m\u001B[39m}\u001B[39;00m\u001B[39m, loss:\u001B[39m\u001B[39m{\u001B[39;00mloss\u001B[39m.\u001B[39mitem()\u001B[39m:\u001B[39;00m\u001B[39m.8f\u001B[39m\u001B[39m}\u001B[39;00m\u001B[39m\"\u001B[39m)\n\u001B[1;32m     29\u001B[0m loss_mat[i,j,k,m,step] \u001B[39m=\u001B[39m loss\u001B[39m.\u001B[39mitem()\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/pyt310/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1186\u001B[0m \u001B[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1187\u001B[0m \u001B[39m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1188\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mnot\u001B[39;00m (\u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_backward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_pre_hooks \u001B[39mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1189\u001B[0m         \u001B[39mor\u001B[39;00m _global_forward_hooks \u001B[39mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1190\u001B[0m     \u001B[39mreturn\u001B[39;00m forward_call(\u001B[39m*\u001B[39;49m\u001B[39minput\u001B[39;49m, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwargs)\n\u001B[1;32m   1191\u001B[0m \u001B[39m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[39m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/pyt310/lib/python3.10/site-packages/transformers/models/gpt2/modeling_gpt2.py:1077\u001B[0m, in \u001B[0;36mGPT2LMHeadModel.forward\u001B[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1075\u001B[0m     \u001B[39m# Flatten the tokens\u001B[39;00m\n\u001B[1;32m   1076\u001B[0m     loss_fct \u001B[39m=\u001B[39m CrossEntropyLoss()\n\u001B[0;32m-> 1077\u001B[0m     loss \u001B[39m=\u001B[39m loss_fct(shift_logits\u001B[39m.\u001B[39;49mview(\u001B[39m-\u001B[39;49m\u001B[39m1\u001B[39;49m, shift_logits\u001B[39m.\u001B[39;49msize(\u001B[39m-\u001B[39;49m\u001B[39m1\u001B[39;49m)), shift_labels\u001B[39m.\u001B[39;49mview(\u001B[39m-\u001B[39;49m\u001B[39m1\u001B[39;49m))\n\u001B[1;32m   1079\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mnot\u001B[39;00m return_dict:\n\u001B[1;32m   1080\u001B[0m     output \u001B[39m=\u001B[39m (lm_logits,) \u001B[39m+\u001B[39m transformer_outputs[\u001B[39m1\u001B[39m:]\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/pyt310/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1186\u001B[0m \u001B[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1187\u001B[0m \u001B[39m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1188\u001B[0m \u001B[39mif\u001B[39;00m \u001B[39mnot\u001B[39;00m (\u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_backward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_hooks \u001B[39mor\u001B[39;00m \u001B[39mself\u001B[39m\u001B[39m.\u001B[39m_forward_pre_hooks \u001B[39mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1189\u001B[0m         \u001B[39mor\u001B[39;00m _global_forward_hooks \u001B[39mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1190\u001B[0m     \u001B[39mreturn\u001B[39;00m forward_call(\u001B[39m*\u001B[39;49m\u001B[39minput\u001B[39;49m, \u001B[39m*\u001B[39;49m\u001B[39m*\u001B[39;49mkwargs)\n\u001B[1;32m   1191\u001B[0m \u001B[39m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[39m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/pyt310/lib/python3.10/site-packages/torch/nn/modules/loss.py:1174\u001B[0m, in \u001B[0;36mCrossEntropyLoss.forward\u001B[0;34m(self, input, target)\u001B[0m\n\u001B[1;32m   1173\u001B[0m \u001B[39mdef\u001B[39;00m \u001B[39mforward\u001B[39m(\u001B[39mself\u001B[39m, \u001B[39minput\u001B[39m: Tensor, target: Tensor) \u001B[39m-\u001B[39m\u001B[39m>\u001B[39m Tensor:\n\u001B[0;32m-> 1174\u001B[0m     \u001B[39mreturn\u001B[39;00m F\u001B[39m.\u001B[39;49mcross_entropy(\u001B[39minput\u001B[39;49m, target, weight\u001B[39m=\u001B[39;49m\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mweight,\n\u001B[1;32m   1175\u001B[0m                            ignore_index\u001B[39m=\u001B[39;49m\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mignore_index, reduction\u001B[39m=\u001B[39;49m\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mreduction,\n\u001B[1;32m   1176\u001B[0m                            label_smoothing\u001B[39m=\u001B[39;49m\u001B[39mself\u001B[39;49m\u001B[39m.\u001B[39;49mlabel_smoothing)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/pyt310/lib/python3.10/site-packages/torch/nn/functional.py:3026\u001B[0m, in \u001B[0;36mcross_entropy\u001B[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001B[0m\n\u001B[1;32m   3024\u001B[0m \u001B[39mif\u001B[39;00m size_average \u001B[39mis\u001B[39;00m \u001B[39mnot\u001B[39;00m \u001B[39mNone\u001B[39;00m \u001B[39mor\u001B[39;00m reduce \u001B[39mis\u001B[39;00m \u001B[39mnot\u001B[39;00m \u001B[39mNone\u001B[39;00m:\n\u001B[1;32m   3025\u001B[0m     reduction \u001B[39m=\u001B[39m _Reduction\u001B[39m.\u001B[39mlegacy_get_string(size_average, reduce)\n\u001B[0;32m-> 3026\u001B[0m \u001B[39mreturn\u001B[39;00m torch\u001B[39m.\u001B[39;49m_C\u001B[39m.\u001B[39;49m_nn\u001B[39m.\u001B[39;49mcross_entropy_loss(\u001B[39minput\u001B[39;49m, target, weight, _Reduction\u001B[39m.\u001B[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001B[0;31mValueError\u001B[0m: Expected input batch_size (928) to match target batch_size (31)."
     ]
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "loss_mat = np.zeros((len(batch_size_list),len(scheduler_list), len(optimizer_list), len(lr_list),steps))\n",
    "\n",
    "report_step = 20 # evaluate test metric each step\n",
    "metric_mat = np.zeros((len(batch_size_list),len(scheduler_list), len(optimizer_list), len(lr_list),steps//report_step))\n",
    "for i,this_batch_size in enumerate(batch_size_list):\n",
    "    for j,this_scheduler in enumerate(scheduler_list):\n",
    "        for k,this_optimizer in enumerate(optimizer_list):\n",
    "            for m, this_lr in enumerate(lr_list):\n",
    "\n",
    "                model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\n",
    "                train_loader = DataLoader(train_dataset, batch_size=this_batch_size)\n",
    "                sche, opt = prepare(this_scheduler, this_optimizer)\n",
    "                optimizer = opt(model.parameters(), lr = this_lr)\n",
    "                scheduler = sche(optimizer, num_warmup_steps=int(steps/10),num_training_steps=steps)\n",
    "                step = 0\n",
    "                print(f'Start training for: sche:{this_scheduler},opt:{this_optimizer},batchsize:{this_batch_size}, lr:{this_lr}')\n",
    "\n",
    "                while True:\n",
    "                    \n",
    "                    for X in train_loader:\n",
    "                        model.train()\n",
    "                        optimizer.zero_grad()\n",
    "                        batch = {k: v.to(device) for k, v in X.items()}\n",
    "                        loss = model(**batch).loss\n",
    "                        print(f\"step: {step+1}, loss:{loss.item():.8f}\")\n",
    "\n",
    "                        loss_mat[i,j,k,m,step] = loss.item()\n",
    "\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        scheduler.step()\n",
    "                        step += 1\n",
    "\n",
    "                    # valid\n",
    "                        if (step)%report_step == 0:\n",
    "                            model.eval()\n",
    "                            with torch.no_grad():\n",
    "                                logits = []\n",
    "                                labelss = []\n",
    "                                for X in test_loader:\n",
    "                                    batch = {k: v.to(device) for k, v in X.items()}\n",
    "                                    logits.append(model(**batch).logits)\n",
    "                                    labelss.append(batch['labels'])\n",
    "                                total_test = torch.concatenate(logits, dim = 0)\n",
    "                                _,predicted = torch.max(total_test,dim = 1)\n",
    "                                real_label =torch.concatenate(labelss,dim=0).cpu().numpy()\n",
    "                                predicted = predicted.cpu().numpy()\n",
    "                                metric = matthews_corrcoef(real_label, predicted)\n",
    "                                acc = np.mean(predicted==real_label)\n",
    "                                print(f\"step:{step}, matthews_corr:{metric:.6f}, Acc:{acc*100:4f}%\")\n",
    "\n",
    "                        if step == steps:\n",
    "                            break\n",
    "                    if step == steps:\n",
    "                      break\n",
    "\n",
    "                del model\n",
    "                del optimizer\n",
    "                del scheduler\n",
    "                del train_loader\n",
    "                torch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bb29411df98891e4b4ff9dedff8578a7fd29d2046d35b9f963b4aefac49b351d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
