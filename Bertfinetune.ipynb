{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, BertForSequenceClassification, get_linear_schedule_with_warmup,get_polynomial_decay_schedule_with_warmup\n",
    "import torch.nn as nn\n",
    "import logging\n",
    "from lion_pytorch import Lion\n",
    "from torch.utils.data import DataLoader\n",
    "import GLUE\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "from sklearn.metrics import matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (C:/Users/Xiang/.cache/huggingface/datasets/mariosasko___glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ec6d98a311fd447096ddbc7034520784"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Xiang\\.cache\\huggingface\\datasets\\mariosasko___glue\\cola\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-2bc0360bf4726f4f.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "66ee0c4bebfd48918ac7dcf43c2c0762"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Xiang\\.cache\\huggingface\\datasets\\mariosasko___glue\\cola\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-31cb33c6889f365c.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset,_,test_dataset = GLUE.get_torch_dataset(tokenizer, \"cola\", padding=\"max_length\", truncation=True, max_length=64)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://huggingface.co/docs/transformers/v4.26.1/en/main_classes/optimizer_schedules#schedules\n",
    "Reference of Scheduler"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "\n",
    "def constant_scheduler(\n",
    "    optimizer, num_warmup_steps, num_training_steps, lr_end=1e-7, power=1.0, last_epoch=-1\n",
    "):\n",
    "    def lambda_func(step:int):\n",
    "        return 1.\n",
    "\n",
    "    return LambdaLR(optimizer, lambda_func, last_epoch)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def prepare(sche, opt):\n",
    "    if sche == 'no':\n",
    "        sches = partial(constant_scheduler)\n",
    "    if sche == 'linear':\n",
    "        sches = partial(get_linear_schedule_with_warmup)\n",
    "    if sche == 'ord10':\n",
    "        sches = partial(get_polynomial_decay_schedule_with_warmup,power = 10.0)\n",
    "\n",
    "    if opt == 'Lion':\n",
    "        opts = partial(Lion)\n",
    "    if opt == 'Adam':\n",
    "        opts = partial(torch.optim.Adam)\n",
    "    if opt == 'AdamW':\n",
    "        opts = partial(torch.optim.AdamW)\n",
    "\n",
    "\n",
    "    return sches, opts"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8551 1043\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset),len(test_dataset))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "sche, opt = prepare('no','Adam')\n",
    "optimizer = opt(model.parameters(),lr = 1e-4)\n",
    "scheduler = sche(optimizer, num_warmup_steps=100,num_training_steps=100*10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "lr_list = [1e-5,1e-4,1e-3]\n",
    "scheduler_list = ['no',  'ord10']\n",
    "optimizer_list = ['Lion', 'AdamW']\n",
    "batch_size_list = [32,64]\n",
    "steps = 500\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1, 1, 1,  ..., 0, 1, 1])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset['labels']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, shuffle = True, batch_size = 16)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "{'label': tensor([1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1]),\n 'input_ids': tensor([[ 101, 1045, 2064,  ...,    0,    0,    0],\n         [ 101, 3021, 2134,  ...,    0,    0,    0],\n         [ 101, 2040, 2467,  ...,    0,    0,    0],\n         ...,\n         [ 101, 2673, 2017,  ...,    0,    0,    0],\n         [ 101, 2008, 3520,  ...,    0,    0,    0],\n         [ 101, 1045, 2741,  ...,    0,    0,    0]]),\n 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         ...,\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0]]),\n 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n         [1, 1, 1,  ..., 0, 0, 0],\n         [1, 1, 1,  ..., 0, 0, 0],\n         ...,\n         [1, 1, 1,  ..., 0, 0, 0],\n         [1, 1, 1,  ..., 0, 0, 0],\n         [1, 1, 1,  ..., 0, 0, 0]])}"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(test_loader))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "test_input = ['HA HA HA.','you are pig right?','You are bad.']\n",
    "test_input = tokenizer(test_input,return_tensors ='pt', padding = True)\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "with torch.no_grad():\n",
    "    logits = model(**test_input).logits\n",
    "\n",
    "predicted_class_id = logits.argmax().item()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 2])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "loss_mat = np.zeros((len(batch_size_list),len(scheduler_list), len(optimizer_list), len(lr_list),steps))\n",
    "\n",
    "report_step = 10 # evaluate test metric each step\n",
    "metric_mat = np.zeros((len(batch_size_list),len(scheduler_list), len(optimizer_list), len(lr_list),steps//report_step))\n",
    "for i,this_batch_size in enumerate(batch_size_list):\n",
    "    for j,this_scheduler in enumerate(scheduler_list):\n",
    "        for k,this_optimizer in enumerate(optimizer_list):\n",
    "            for m, this_lr in enumerate(lr_list):\n",
    "\n",
    "                model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\").to(device)\n",
    "                train_loader = DataLoader(train_dataset, batch_size=this_batch_size)\n",
    "                optimizer = this_optimizer(model.parameters(), lr = this_lr)\n",
    "                scheduler = this_scheduler(optimizer, num_warmup_steps=int(steps/100),num_training_steps=steps)\n",
    "                step = 0\n",
    "\n",
    "                while True:\n",
    "                    model.train()\n",
    "                    for X in train_loader:\n",
    "                        optimizer.zero_grad()\n",
    "                        batch = {k: v.to(device) for k, v in X.items()}\n",
    "                        loss = model(**batch).loss\n",
    "                        print(f\"step: {step+1}, loss:{loss.item():.8f}\")\n",
    "\n",
    "                        loss_mat[i,j,k,m,step] = loss.item()\n",
    "\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        scheduler.step()\n",
    "                        step += 1\n",
    "\n",
    "                    # valid\n",
    "                    if (step+1)%report_step == 0:\n",
    "                        model.eval()\n",
    "                        with torch.no_grad():\n",
    "                            logits = []\n",
    "                            for X in test_loader:\n",
    "                                batch = {k: v.to(device) for k, v in X.items()}\n",
    "                                logits.append(model(**batch).logits)\n",
    "                            total_test = torch.concatenate(logits, dim = 0)\n",
    "                            _,predicted = torch.max(total_test,dim = 1)\n",
    "                            real_label =test_dataset['labels'].numpy()\n",
    "                            predicted = predicted.cpu().numpy()\n",
    "                            metric = matthews_corrcoef(real_label, predicted)\n",
    "                            print(f\"step:{step}, matthews_corr:{metric:.6f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.return_types.max(\nvalues=tensor([ 1.9424,  1.7879,  0.9814,  0.1394,  0.7443,  1.0075,  1.7859,  2.2063,\n        -0.2133]),\nindices=tensor([0, 1, 0, 0, 0, 0, 0, 0, 1]))"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(torch.concatenate([torch.randn((3,2)) for i in range(3)],dim=0),dim = 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
